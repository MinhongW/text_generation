{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmzIJYNzFMOKmGTcFv4rh2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5a291065407649f9a22c53da27d1f542": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b34420aee0bf4a6f980118f1d46adbf8",
              "IPY_MODEL_4030b39321584feca8bee0a6169f057c",
              "IPY_MODEL_984c51557cb1430faab7e4b138c75959"
            ],
            "layout": "IPY_MODEL_497db597d4074655a4cc03f321f163eb"
          }
        },
        "b34420aee0bf4a6f980118f1d46adbf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8ad8d38443b485686a25ac3d6ccf46a",
            "placeholder": "​",
            "style": "IPY_MODEL_bb9cee9102644eef8b7c22fb9be05c07",
            "value": "Downloading builder script: 100%"
          }
        },
        "4030b39321584feca8bee0a6169f057c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f445e2796e5411498847db8b46c006c",
            "max": 6270,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e787ae9c4eef4bd282c3c14931492dd2",
            "value": 6270
          }
        },
        "984c51557cb1430faab7e4b138c75959": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7eb4f12e0ede44ac9ab9e6cc6ea9b6fe",
            "placeholder": "​",
            "style": "IPY_MODEL_eced9ec7eab64e0693330d200be4b853",
            "value": " 6.27k/6.27k [00:00&lt;00:00, 353kB/s]"
          }
        },
        "497db597d4074655a4cc03f321f163eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8ad8d38443b485686a25ac3d6ccf46a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb9cee9102644eef8b7c22fb9be05c07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f445e2796e5411498847db8b46c006c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e787ae9c4eef4bd282c3c14931492dd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7eb4f12e0ede44ac9ab9e6cc6ea9b6fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eced9ec7eab64e0693330d200be4b853": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MinhongW/text_generation/blob/main/build_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7wxAtBDq-eu0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets SentencePiece rouge-score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5lExSVMqNih",
        "outputId": "e449f965-cf20-41dc-fe63-8d387f0dd23b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.28.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.9/dist-packages (2.11.0)\n",
            "Requirement already satisfied: SentencePiece in /usr/local/lib/python3.9/dist-packages (0.1.98)\n",
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.9/dist-packages (0.1.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.14.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.4.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from rouge-score) (1.16.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from rouge-score) (3.8.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->rouge-score) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk->rouge-score) (8.1.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/MinhongW/text_generation.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyfT6_J9-mSk",
        "outputId": "33e66f59-b56e-43ed-f80d-397636abd7d5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'text_generation' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = open('text_generation/data/table_train.json')\n",
        "t2 = open('text_generation/data/table_desc_train.json')\n",
        "t3 = open('text_generation/data/paper_train.json')\n",
        "\n",
        "v1 = open('text_generation/data/table_val.json')\n",
        "v2 = open('text_generation/data/table_desc_val.json')\n",
        "v3 = open('text_generation/data/paper_val.json')\n",
        "\n",
        "te1 = open('text_generation/data/table_test.json')\n",
        "te2 = open('text_generation/data/table_desc_test.json')\n",
        "te3 = open('text_generation/data/paper_test.json')"
      ],
      "metadata": {
        "id": "JEDPEbFA-pEq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tables_train = json.load(t1)\n",
        "descs_train = json.load(t2)\n",
        "papers_train = json.load(t3)\n",
        "\n",
        "tables_val = json.load(v1)\n",
        "descs_val = json.load(v2)\n",
        "papers_val = json.load(v3)\n",
        "\n",
        "tables_test = json.load(te1)\n",
        "descs_test = json.load(te2)\n",
        "papers_test = json.load(te3)"
      ],
      "metadata": {
        "id": "CxWJ54kB-r3Q"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def naive_representation(tables, descs):\n",
        "    \"\"\"\n",
        "    Input_text is generated by naive representation of the tables.\n",
        "    Each table is simply flattened into a sequence ignoring its table structure\n",
        "    by concatenating captions, headers, metrics and targeted cell values.\n",
        "    Target_text is the description of the corresponding table.\n",
        "    Returns a df contains input_text and target_text\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    data = {'input_text':[],\n",
        "           'target_text':[]}\n",
        "    \n",
        "    for i in range(len(tables)):\n",
        "        table = tables[i]\n",
        "        caption = table['table_id'] + ' ' + table['caption']\n",
        "        row_names = ' '.join(' '.join(x) for x in table['row_headers'])\n",
        "        col_names = ' '.join(' '.join(x) for x in table['column_headers'])\n",
        "        metrics = ' '.join(table['metrics_type'])\n",
        "        values = ' '.join(' '.join(x) for x in table['contents'])        \n",
        "        tmp = [caption, row_names, col_names, metrics, values]\n",
        "        text = ' '.join(tmp)\n",
        "        \n",
        "        desc = descs[i]['description']        \n",
        "        \n",
        "        data['input_text'].append(text)\n",
        "        data['target_text'].append(desc)\n",
        "    \n",
        "    df = pd.DataFrame(data)      \n",
        "    \n",
        "    return df"
      ],
      "metadata": {
        "id": "2sT-3_Z5-w3b"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = naive_representation(tables_train, descs_train)\n",
        "df_val = naive_representation(tables_val, descs_val)\n",
        "df_test = naive_representation(tables_test, descs_test)"
      ],
      "metadata": {
        "id": "sxa8qCS1-z-3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "n9vbz3ie-1xe",
        "outputId": "376fc402-3692-410e-e746-682a886ac2d3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          input_text  \\\n",
              "0  table_2 Comparison of different position featu...   \n",
              "1  table_3 Pearson correlation values between hum...   \n",
              "2  table_4 Comparison between rationale models (m...   \n",
              "3  table_2 Spearman’s rank correlation results on...   \n",
              "4  table_4 Examples of attention weights in diffe...   \n",
              "\n",
              "                                         target_text  \n",
              "0  Table 2 summarizes the performances of propose...  \n",
              "1  Table 3 presents the correlation results for t...  \n",
              "2  Results. Table 4 presents the results of our r...  \n",
              "3  Table 2 shows the results of our contextdepend...  \n",
              "4  From Table 4, we can find that in the first ho...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3e58df09-cc5f-4843-83df-6c346bd44319\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input_text</th>\n",
              "      <th>target_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>table_2 Comparison of different position featu...</td>\n",
              "      <td>Table 2 summarizes the performances of propose...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>table_3 Pearson correlation values between hum...</td>\n",
              "      <td>Table 3 presents the correlation results for t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>table_4 Comparison between rationale models (m...</td>\n",
              "      <td>Results. Table 4 presents the results of our r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>table_2 Spearman’s rank correlation results on...</td>\n",
              "      <td>Table 2 shows the results of our contextdepend...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>table_4 Examples of attention weights in diffe...</td>\n",
              "      <td>From Table 4, we can find that in the first ho...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e58df09-cc5f-4843-83df-6c346bd44319')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3e58df09-cc5f-4843-83df-6c346bd44319 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3e58df09-cc5f-4843-83df-6c346bd44319');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build RNN model by pulling out the last layer of T5 model as embeddings"
      ],
      "metadata": {
        "id": "nq3ODJwM-43p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from transformers import AutoTokenizer, T5Model\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxzu__uqhYdU",
        "outputId": "b44b9e07-b7d6-4446-8192-88e14f8da47e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameters\n",
        "batch_size = 32\n",
        "#embedding_dim = 128\n",
        "hidden_dim = 256\n",
        "num_layers = 2\n",
        "lr = 1e-3\n",
        "num_epochs = 10\n",
        "\n",
        "# Define custom dataset and dataloader\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer):\n",
        "        self.df = df\n",
        "        self.tokenizer = tokenizer\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        input_text = self.df.iloc[index][\"input_text\"]\n",
        "        target_text = self.df.iloc[index][\"target_text\"]\n",
        "        input_tokens = self.tokenizer.encode(input_text, add_special_tokens=False, padding='max_length', truncation=True)\n",
        "        target_tokens = self.tokenizer.encode(target_text, add_special_tokens=False, padding='max_length', truncation=True)\n",
        "        return torch.tensor(input_tokens), torch.tensor(target_tokens)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    input_batch = [item[0] for item in batch]\n",
        "    target_batch = [item[1] for item in batch]\n",
        "    input_padded = pad_sequence(input_batch, batch_first=True, padding_value=0)\n",
        "    target_padded = pad_sequence(target_batch, batch_first=True, padding_value=0)\n",
        "    return input_padded, target_padded\n",
        "\n",
        "# Prepare data\n",
        "tokenizer = AutoTokenizer.from_pretrained('t5-small')\n",
        "model_t5 = T5Model.from_pretrained('t5-small')\n",
        "train_dataset = TextDataset(df_train, tokenizer)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "val_dataset = TextDataset(df_val, tokenizer)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "test_dataset = TextDataset(df_test, tokenizer)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "\n",
        "# Freeze T5 parameters\n",
        "for param in model_t5.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "t5_embedding = model_t5.get_input_embeddings()\n",
        "\n",
        "\n",
        "# Define model architecture\n",
        "class LSTMGenerator(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, num_layers):\n",
        "        super(LSTMGenerator, self).__init__()\n",
        "        #self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.embedding = t5_embedding\n",
        "        #self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
        "        self.lstm = nn.LSTM(t5_embedding.embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        output, _ = self.lstm(x)\n",
        "        output = self.fc(output)\n",
        "        return output\n",
        "\n",
        "#vocab_size = tokenizer.vocab_size\n",
        "vocab_size = tokenizer.vocab_size\n",
        "model = LSTMGenerator(t5_embedding.embedding_dim, hidden_dim, vocab_size, num_layers)\n",
        "model.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)     "
      ],
      "metadata": {
        "id": "IlkOv4qRfsZj"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def calculate_rouge(all_preds, all_targets):\n",
        "#     rouge_scores = []\n",
        "#     for i in range(len(all_preds)):\n",
        "#         pred = all_preds[i]\n",
        "#         target = all_targets[i]\n",
        "#         pred_str = tokenizer.decode(pred, skip_special_tokens=True)\n",
        "#         target_str = tokenizer.decode(target, skip_special_tokens=True)\n",
        "#         rouge_scores.append(rouge.compute(predictions=[pred_str], references=[target_str])[\"rouge2\"].fmeasure)\n",
        "\n",
        "#     return sum(rouge_scores) / len(rouge_scores)"
      ],
      "metadata": {
        "id": "2dL1NbLmsSiT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate nltk"
      ],
      "metadata": {
        "id": "2rMDoghlwx-V",
        "outputId": "a07d5f1a-51a9-41c1-a3d4-86408b220214",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.9/dist-packages (0.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (3.8.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from evaluate) (1.5.3)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (2023.4.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.3.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from evaluate) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from evaluate) (23.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.70.14)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from evaluate) (3.2.0)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (2.11.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.14.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from evaluate) (4.65.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (2.27.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.11.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->evaluate) (2022.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import evaluate\n",
        "\n",
        "# rouge_metric = evaluate.load('rouge')\n",
        "\n",
        "# def calculate_rouge(all_preds, all_targets):\n",
        "#     rouge_scores = []\n",
        "#     for i in range(len(all_preds)):\n",
        "#         pred = all_preds[i]\n",
        "#         target = all_targets[i]\n",
        "#         pred_str = tokenizer.decode(pred, skip_special_tokens=True)\n",
        "#         target_str = tokenizer.decode(target, skip_special_tokens=True)\n",
        "#         results = rouge_metric.compute(predictions=pred_str, references=target_str, use_stemmer=True)\n",
        "#         # Extract ROUGE f1 scores\n",
        "#         result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
        "#         rouge_scores.append(scores)\n",
        "\n",
        "#     return sum(rouge_scores) / len(rouge_scores)\n"
      ],
      "metadata": {
        "id": "t229gDSCuFH4",
        "outputId": "7d3195b2-b0a6-4bf7-ce1c-55ba2bfe9926",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "5a291065407649f9a22c53da27d1f542",
            "b34420aee0bf4a6f980118f1d46adbf8",
            "4030b39321584feca8bee0a6169f057c",
            "984c51557cb1430faab7e4b138c75959",
            "497db597d4074655a4cc03f321f163eb",
            "b8ad8d38443b485686a25ac3d6ccf46a",
            "bb9cee9102644eef8b7c22fb9be05c07",
            "9f445e2796e5411498847db8b46c006c",
            "e787ae9c4eef4bd282c3c14931492dd2",
            "7eb4f12e0ede44ac9ab9e6cc6ea9b6fe",
            "eced9ec7eab64e0693330d200be4b853"
          ]
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a291065407649f9a22c53da27d1f542"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import string\n",
        "     \n",
        "\n",
        "rouge_metric = evaluate.load('rouge')\n",
        "\n",
        "def calculate_rouge(all_preds, all_targets):\n",
        "    rouge_scores = []\n",
        "    decoded_preds = tokenizer.batch_decode(all_preds, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(all_targets, skip_special_tokens=True)\n",
        "\n",
        "    # Rouge expects a newline after each sentence\n",
        "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip()))\n",
        "                      for pred in decoded_preds]\n",
        "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) \n",
        "                      for label in decoded_labels]\n",
        "\n",
        "    result = rouge_metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "    # Extract ROUGE f1 scores\n",
        "    print(result)\n",
        "    #result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
        "    result = {key: value * 100 for key, value in result.items()} # changed load_metric to evaluate, hence there is a change here as well\n",
        "\n",
        "    # Add mean generated length to metrics\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id)\n",
        "                      for pred in all_preds]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    \n",
        "    return {k: round(v, 4) for k, v in result.items()}\n",
        "\n"
      ],
      "metadata": {
        "id": "l_MMxlGsxgo2",
        "outputId": "e13e6913-494f-4b9c-c26b-92d89db7810d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, batch in enumerate(train_loader):\n",
        "        inputs, targets = batch\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        #outputs = outputs[:, :-1, :].contiguous().view(-1, vocab_size)\n",
        "        #targets = targets[:, 1:].contiguous().view(-1)\n",
        "        #loss = criterion(outputs, targets)\n",
        "        loss = criterion(outputs.view(-1, vocab_size), targets.view(-1).to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if i % 10 == 9:    # print every 10 batches\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{len(train_loader)}], Loss: {running_loss/100:.4f}\")\n",
        "            running_loss = 0.0\n",
        "\n",
        "    # run validation after each epoch\n",
        "    model.eval() # set model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        val_loss = 0.0\n",
        "        all_preds = []\n",
        "        all_targets = []\n",
        "        for batch in val_loader:\n",
        "            inputs, targets = batch\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs.view(-1, vocab_size), targets.view(-1).to(device))\n",
        "            val_loss += loss.item()\n",
        "            preds = torch.argmax(outputs, dim=2)\n",
        "            all_preds.extend(preds.tolist())\n",
        "            all_targets.extend(targets.tolist())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        rouge_scores = calculate_rouge(all_preds, all_targets)\n",
        "        print(rouge_scores)\n",
        "        #print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss:.4f}, Validation Rouge: {rouge_score:.4f}\")"
      ],
      "metadata": {
        "id": "VKHisqM8ggZ7",
        "outputId": "e78a7aff-f1ec-44e4-8015-269c6d255f5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Batch [10/34], Loss: 0.8145\n",
            "Epoch [1/10], Batch [20/34], Loss: 0.3643\n",
            "Epoch [1/10], Batch [30/34], Loss: 0.3261\n",
            "{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
            "{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0, 'gen_len': 1.0}\n",
            "Epoch [2/10], Batch [10/34], Loss: 0.2958\n",
            "Epoch [2/10], Batch [20/34], Loss: 0.3091\n",
            "Epoch [2/10], Batch [30/34], Loss: 0.2990\n",
            "{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
            "{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0, 'gen_len': 1.0}\n",
            "Epoch [3/10], Batch [10/34], Loss: 0.2938\n",
            "Epoch [3/10], Batch [20/34], Loss: 0.2910\n",
            "Epoch [3/10], Batch [30/34], Loss: 0.2839\n",
            "{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
            "{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0, 'gen_len': 1.0}\n",
            "Epoch [4/10], Batch [10/34], Loss: 0.2867\n",
            "Epoch [4/10], Batch [20/34], Loss: 0.2869\n",
            "Epoch [4/10], Batch [30/34], Loss: 0.2832\n",
            "{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
            "{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0, 'gen_len': 1.0}\n",
            "Epoch [5/10], Batch [10/34], Loss: 0.2645\n",
            "Epoch [5/10], Batch [20/34], Loss: 0.2872\n",
            "Epoch [5/10], Batch [30/34], Loss: 0.2900\n",
            "{'rouge1': 0.019783167915554453, 'rouge2': 0.0, 'rougeL': 0.019938000371216687, 'rougeLsum': 0.019880433003484646}\n",
            "{'rouge1': 1.9783, 'rouge2': 0.0, 'rougeL': 1.9938, 'rougeLsum': 1.988, 'gen_len': 1.0}\n",
            "Epoch [6/10], Batch [10/34], Loss: 0.2906\n",
            "Epoch [6/10], Batch [20/34], Loss: 0.2830\n",
            "Epoch [6/10], Batch [30/34], Loss: 0.2732\n",
            "{'rouge1': 0.118076762060467, 'rouge2': 8.261731658955717e-05, 'rougeL': 0.11229557828615486, 'rougeLsum': 0.11491949725333733}\n",
            "{'rouge1': 11.8077, 'rouge2': 0.0083, 'rougeL': 11.2296, 'rougeLsum': 11.4919, 'gen_len': 1.0}\n",
            "Epoch [7/10], Batch [10/34], Loss: 0.2747\n",
            "Epoch [7/10], Batch [20/34], Loss: 0.2864\n",
            "Epoch [7/10], Batch [30/34], Loss: 0.2717\n",
            "{'rouge1': 0.13087770096514026, 'rouge2': 7.619628162145688e-05, 'rougeL': 0.123136266519758, 'rougeLsum': 0.1275861612380307}\n",
            "{'rouge1': 13.0878, 'rouge2': 0.0076, 'rougeL': 12.3136, 'rougeLsum': 12.7586, 'gen_len': 1.0}\n",
            "Epoch [8/10], Batch [10/34], Loss: 0.2795\n",
            "Epoch [8/10], Batch [20/34], Loss: 0.2850\n",
            "Epoch [8/10], Batch [30/34], Loss: 0.2668\n",
            "{'rouge1': 0.12290374167298823, 'rouge2': 6.808278867102396e-05, 'rougeL': 0.11624618355380328, 'rougeLsum': 0.12024097791543435}\n",
            "{'rouge1': 12.2904, 'rouge2': 0.0068, 'rougeL': 11.6246, 'rougeLsum': 12.0241, 'gen_len': 1.0}\n",
            "Epoch [9/10], Batch [10/34], Loss: 0.2627\n",
            "Epoch [9/10], Batch [20/34], Loss: 0.2853\n",
            "Epoch [9/10], Batch [30/34], Loss: 0.2742\n",
            "{'rouge1': 0.11383789552925483, 'rouge2': 5.4872695346795435e-05, 'rougeL': 0.10670350932015428, 'rougeLsum': 0.11070166865694886}\n",
            "{'rouge1': 11.3838, 'rouge2': 0.0055, 'rougeL': 10.6704, 'rougeLsum': 11.0702, 'gen_len': 1.0}\n",
            "Epoch [10/10], Batch [10/34], Loss: 0.2577\n",
            "Epoch [10/10], Batch [20/34], Loss: 0.2578\n",
            "Epoch [10/10], Batch [30/34], Loss: 0.2706\n",
            "{'rouge1': 0.09854381085918695, 'rouge2': 5.159958720330237e-05, 'rougeL': 0.09266421822761946, 'rougeLsum': 0.09586852708228046}\n",
            "{'rouge1': 9.8544, 'rouge2': 0.0052, 'rougeL': 9.2664, 'rougeLsum': 9.5869, 'gen_len': 1.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9ldAhNTazjtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate model on test set"
      ],
      "metadata": {
        "id": "MmU3eiYn2qqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval() # set model to evaluation mode\n",
        "with torch.no_grad():\n",
        "    test_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "    for batch in test_loader:\n",
        "        inputs, targets = batch\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs.view(-1, vocab_size), targets.view(-1).to(device))\n",
        "        test_loss += loss.item()\n",
        "        preds = torch.argmax(outputs, dim=2)\n",
        "        all_preds.extend(preds.tolist())\n",
        "        all_targets.extend(targets.tolist())\n",
        "\n",
        "    test_loss /= len(test_loader)\n",
        "    rouge_scores = calculate_rouge(all_preds, all_targets)\n",
        "    print(rouge_scores)"
      ],
      "metadata": {
        "id": "uCM03G0H2uTP",
        "outputId": "8ff8683c-c748-482f-fdb3-3626ba187932",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'rouge1': 0.10152991205489142, 'rouge2': 0.00013811668379121495, 'rougeL': 0.09617968215066196, 'rougeLsum': 0.09939267483683162}\n",
            "{'rouge1': 10.153, 'rouge2': 0.0138, 'rougeL': 9.618, 'rougeLsum': 9.9393, 'gen_len': 1.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "id": "TEgEMd9VLmQH",
        "outputId": "e70336c8-b06d-44bd-af12-add4b5f1de29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4398, 4398, 4398,  ...,    0,    0,    0],\n",
              "        [4398, 4398, 4398,  ...,    0,    0,    0],\n",
              "        [4398, 4398, 4398,  ...,    0,    0,    0],\n",
              "        ...,\n",
              "        [4398, 4398, 4398,  ...,    0,    0,    0],\n",
              "        [4398, 4398, 4398,  ...,    0,    0,    0],\n",
              "        [4398, 4398, 4398,  ...,    0,    0,    0]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print out some examples\n",
        "input_text = df_test['input_text'][0]\n",
        "input_text"
      ],
      "metadata": {
        "id": "Nl3bvUFT2729",
        "outputId": "f81b538b-e421-4137-9f34-c4d6b174c750",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'table_5 Link prediction results on the test-I, test-II, and test-all sets of FB122 and WN18 (filtered setting). FB122 TransE FB122 TransH FB122 TransR FB122 KALE-Trip FB122 KALE-Pre FB122 KALE-Joint WN18 TransE WN18 TransH WN18 TransR WN18 KALE-Trip WN18 KALE-Pre WN18 KALE-Joint Test-I MRR Test-I MED Test-I HITS@3 (%) Test-I HITS@5 (%) Test-I HITS@10 (%) Test-II MRR Test-II MED Test-II HITS@3 (%) Test-II HITS@5 (%) Test-II HITS@10 (%) Test-ALL MRR Test-ALL MED Test-ALL HITS@3 (%) Test-ALL HITS@5 (%) Test-ALL HITS@10 (%) MRR MED HITS@3 (%) HITS@5 (%) HITS@10 (%) MRR MED HITS@3 (%) HITS@5 (%) HITS@10 (%) MRR MED HITS@3 (%) HITS@5 (%) HITS@10 (%) 0.296 13.0 36.0 41.5 48.1 0.630 2.0 77.5 82.8 88.4 0.480 2.0 58.9 64.2 70.2 0.280 15.0 33.6 39.1 46.4 0.606 2.0 70.1 75.4 82.0 0.460 3.0 53.7 59.1 66.0 0.283 16.0 33.4 39.2 46.0 0.499 2.0 57.0 63.2 70.1 0.401 5.0 46.4 52.4 59.3 0.299 10.0 36.6 42.9 50.2 0.650 2.0 79.0 83.4 88.7 0.492 2.0 59.9 65.2 71.4 0.291 11.0 35.8 41.9 49.8 0.713 1.0 82.9 86.1 89.9 0.523 2.0 61.7 66.2 71.8 0.325 9.0 38.4 44.7 52.2 0.684 1.0 79.7 84.1 89.6 0.523 2.0 61.2 66.4 72.8 0.306 3.0 57.4 72.3 80.1 0.511 2.0 87.5 95.6 98.7 0.453 2.0 79.1 89.1 93.6 0.318 3.0 61.7 72.4 78.2 0.653 2.0 87.1 91.4 94.6 0.560 2.0 80.0 86.1 90.0 0.299 3.0 56.1 66.7 74.5 0.597 2.0 75.0 81.7 88.0 0.514 2.0 69.7 77.5 84.3 0.322 3.0 61.0 73.9 80.8 0.555 2.0 90.6 96.3 98.8 0.490 2.0 82.3 90.1 93.8 0.322 3.0 60.6 74.5 81.1 0.612 2.0 96.4 98.6 99.6 0.532 2.0 86.4 91.9 94.4 0.338 3.0 65.5 76.3 82.1 0.787 1.0 93.3 95.4 97.2 0.662 2.0 85.5 90.1 93.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_tokens = tokenizer.encode(input_text, add_special_tokens=False, padding='max_length', truncation=True)\n",
        "input = torch.tensor(input_tokens)"
      ],
      "metadata": {
        "id": "S-dZneyo8337"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = input.to(device)"
      ],
      "metadata": {
        "id": "AE0qtcK69W4k"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "id": "VTe8C96A9ou-",
        "outputId": "2ffaca1e-6896-4dd0-fac9-aff9b26e6779",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMGenerator(\n",
              "  (embedding): Embedding(32128, 512)\n",
              "  (lstm): LSTM(512, 256, num_layers=2, batch_first=True)\n",
              "  (fc): Linear(in_features=256, out_features=32100, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = model(input)"
      ],
      "metadata": {
        "id": "moSh3OES9Xus"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "id": "PPC8qRxq9kDV",
        "outputId": "720ed8fa-fe8e-4998-d752-1df8fef72c56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 3.3844, -3.1741,  1.6518,  ..., -3.7198, -3.4341, -3.4878],\n",
              "        [ 4.3015, -4.3983,  2.4005,  ..., -5.0663, -5.0490, -4.8750],\n",
              "        [ 4.9788, -4.9176,  2.7413,  ..., -5.5665, -5.7839, -5.5590],\n",
              "        ...,\n",
              "        [11.2103, -6.7511,  2.8730,  ..., -7.6216, -7.7668, -8.1272],\n",
              "        [11.3172, -6.7299,  2.8132,  ..., -7.6593, -7.8201, -8.1341],\n",
              "        [11.4348, -6.8158,  2.8811,  ..., -7.7128, -7.8758, -8.2143]],\n",
              "       device='cuda:0', grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = torch.argmax(output, dim=1)\n",
        "pred"
      ],
      "metadata": {
        "id": "pO_93vwL9-mH",
        "outputId": "f80f1359-39c2-4fb7-f14e-14f4cd627bb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4398, 4398, 4398,    8,    8,    8,    8,    8,    8,    8,    8,    8,\n",
              "           8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,\n",
              "           8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,\n",
              "           8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,\n",
              "           8,    8,    8,    8,    0,    8,    8,    8,    8,    8,    8,    8,\n",
              "           8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,\n",
              "           8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,\n",
              "           8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,\n",
              "           8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,\n",
              "           8,    8,    8,    8,    8,    8,    8,    8,    8,    0,    8,    8,\n",
              "           8,    8,    8,    8,    8,    8,    8,    0,    0,    0,    0,    0,\n",
              "           8,    8,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(pred, skip_special_tokens=True)\n"
      ],
      "metadata": {
        "id": "gVqst4VH-Fpg",
        "outputId": "63d463ac-900e-4dbc-d431-a737f4ef75a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Table Table Table the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn(4, 4)\n",
        "a\n",
        "torch.argmax(a)"
      ],
      "metadata": {
        "id": "HM-NYSzA-dZb",
        "outputId": "0880d9ee-1c53-41a1-ac05-72d22c56f89a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(9)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "id": "PSCr5dEj_d-3",
        "outputId": "959e74e4-e6e0-4e39-cb7f-63764e0b7a20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.5970,  0.8134,  0.3729, -0.1163],\n",
              "        [ 0.3832,  0.3426,  0.4931, -0.8252],\n",
              "        [ 0.9373,  1.0971,  0.3978,  0.3802],\n",
              "        [-0.3165,  0.0450, -0.4167, -1.5057]])"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZNUTmhSt_gCS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}