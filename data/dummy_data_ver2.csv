,table,desc
0,"caption: Evaluation metrics of different models.table: Model,Accuracy,f1-Score,Precision,Recall, Model 1,0.92,0.93,0.88,0.99, Model 2,0.88,0.91,0.94,0.89, Model 3,0.89,0.92,0.85,0.99, Model 4,0.94,0.95,0.92,0.98, Model 5,0.93,0.94,0.89,0.99","The table presents model performance evaluation results for five different models using four different metrics: Accuracy, f1-Score, Precision, and Recall. Model 1 achieved the highest accuracy and f1-Score with a value of 0.92 and 0.93, respectively. Model 4 achieved the highest precision and recall with values of 0.92 and 0.98, respectively. The other models also have competitive results, indicating they perform well for the given task. These results serve as a reference for selecting models based on specific evaluation metrics needs and requirements."
1,"caption: Table 4: Model performance results based on different evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.86,0.86,0.87,0.89, Random Forest,0.84,0.83,0.85,0.82, Naive Bayes,0.81,0.79,0.81,0.82, Decision Tree,0.79,0.75,0.78,0.71, KNN,0.76,0.70,0.76,0.71","Table 4 shows the model performance results of five models: SVM, Random Forest, Naive Bayes, Decision Tree, and KNN. The table presents the accuracy, F1 score, precision, and recall evaluation metrics. Interestingly, the SVM model achieved the highest accuracy and recall results with 0.86 and 0.89, respectively. In comparison, the Decision Tree model achieved the lowest accuracy and recall results with 0.79 and 0.71, respectively. The Naive Bayes model achieved the highest precision and the SVM model achieved the highest F1 score. Therefore, depending on the evaluation metric, we can conclude that different models perform differently, with the SVM model performing the best overall in this dataset."
2,"caption: Performance evaluation of different models on dataset X.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.86,0.81,0.80,0.83, KNN,0.78,0.65,0.68,0.63, Random Forest,0.88,0.83,0.81,0.87, Logistic Regression,0.82,0.75,0.74,0.77, Naive Bayes,0.74,0.62,0.65,0.59","The table illustrates the performance evaluation results of five different models on dataset X based on various evaluation metrics: Accuracy, F1-Score, Precision, and Recall. The SVM model achieved the highest accuracy with a score of 0.86, followed by the Random Forest model with a score of 0.88. The SVM model also recorded the highest F1-Score, Precision, and Recall, with scores of 0.81, 0.80, and 0.83, respectively. The KNN model had the lowest performance across all the metrics except for Recall, where Naive Bayes had the lowest score. Overall, the Random Forest model appears to have a good balance of performance across all the metrics, making it a potentially effective model for dataset X."
3,"caption: Evaluation metrics for different classification models.table: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.82,0.83,0.75,0.79, Decision Tree,0.79,0.81,0.63,0.71, Random Forest (n_est = 100),0.85,0.88,0.72,0.79, XGBoost (n_est = 100),0.87,0.85,0.82,0.83","The table presents the evaluation metrics of four different classification models, including Logistic Regression, Decision Tree, Random Forest, and XGBoost. The evaluation metrics are Accuracy, Precision, Recall, and F1-score. Among the evaluated models, XGBoost demonstrated the highest accuracy of 0.87 followed by Random Forest with an accuracy of 0.85. The Precision and F1-Score of XGBoost and Logistic Regression models were similar. However, Random Forest showed the highest Precision value among others with a score of 0.88. Also, XGBoost produced the highest Recall value of 0.82. Therefore, the table results indicate that the XGBoost model may be the best-performing model based on accuracy, recall, and F1-score evaluation metrics. Nonetheless, Random Forest and Logistic Regression seemed better for Precision evaluation metric."
4,"caption: Model performance results of different models based on different evaluation metrics.table: Model,Accuracy,F1 Score,Recall,Precision,AUC, Logistic Regression,0.78,0.74,0.72,0.79,0.82, Decision Tree,0.73,0.69,0.70,0.69,0.72, Random Forest,0.83,0.79,0.79,0.79,0.87, XGBoost,0.85,0.80,0.81,0.81,0.88","Table above presents the results of multiple machine learning models on various evaluation metrics, including Accuracy, F1 Score, Recall, Precision, and AUC. Four models, namely Logistic Regression, Decision Tree, Random Forest, and XGBoost, were evaluated using these metrics. Interestingly, Random Forest and XGBoost outperformed Logistic Regression and Decision Tree on all metrics. Specifically, Random Forest achieved the highest AUC score of 0.87 with 0.83 accuracy, while XGBoost attained the highest accuracy score of 0.85 with an F1 score of 0.80 and Recall of 0.81. These results can guide practitioners to select the most effective model for their classification problem based on different evaluation metrics."
5,"caption: Model performance based on different evaluation metrics.table: Model,Accuracy,Precision,Recall, SVM,0.89,0.86,0.92, KNN,0.87,0.82,0.88, Naïve Bayes,0.84,0.76,0.89, MLP,0.91,0.89,0.94, Random Forest,0.92,0.91,0.93","The table presents the model performance based on different evaluation metrics. The table includes the Accuracy, Precision, and Recall performance metrics for five models: Support Vector Machines (SVM), K-Nearest Neighbors (KNN), Naïve Bayes, Multi-Layer Perceptron (MLP), and Random Forest. Interestingly, the Random Forest model outperformed all models with the highest Accuracy (0.92) and Precision (0.91). MLP, following close behind, had the highest Recall (0.94) that can be suitable for certain applications where high recall is critical. Nevertheless, it is essential to consider all evaluation metrics to select the appropriate model for a given task."
6,"caption: Table 1: Model performance based on multiple evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Model A,0.87,0.82,0.89,0.77, Model B,0.88,0.81,0.91,0.75, Model C,0.89,0.84,0.88,0.80, Model D,0.90,0.87,0.85,0.89, Model E,0.86,0.80,0.82,0.79","Table 1 presents the accuracy, F1 score, precision, and recall results for five different models labeled as A, B, C, D, and E. The evaluation metrics are indicative of classification performance, with higher values indicating better performance. Model D shows the best accuracy score at 0.90, while Model C has the best F1 score at 0.84. Model B has the highest precision at 0.91, while Model D has the highest recall at 0.89. These results suggest that different models have varying strengths and weaknesses based on the evaluation metric used, and a careful consideration of evaluation metrics is needed when interpreting model performance."
7,"caption: Model performance evaluation of different classifiers using several metrics.table: Model,Accuracy,Precision,Recall,F1-score, MLPClassifier,0.88,0.89,0.87,0.88, DecisionTreeClassifier,0.86,0.86,0.89,0.87, KNeighborsClassifier,0.83,0.85,0.80,0.82, SVM,0.87,0.88,0.86,0.87, Random Forest,0.90,0.91,0.89,0.90, XGBoost,0.91,0.92,0.90,0.91","The table presents the performance evaluation of six different classifiers using various metrics: Accuracy, Precision, Recall, and F1-Score. Accuracy is defined as the percentage of correctly predicted instances. Precision measures the proportion of true positives over all positives predicted. Recall measures the proportion of true positives detected from all actual positives. F1-Score is the harmonic mean of Precision and Recall. The best classifier in terms of all metrics is XGBoost. The model achieves an accuracy of 0.91, precision 0.92, recall 0.90 and an F1-score of 0.91. RandomForest also shows good performance results in all metrics. These results can help to choose the most appropriate classifier based on the performance metric of interest."
8,"caption: Model Performance on Test Settable: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.92,0.93,0.91,0.92, Logistic Regression,0.86,0.83,0.97,0.89, Random Forest,0.94,0.95,0.93,0.94, Multilayer Perceptron,0.91,0.94,0.89,0.91","The table presents the model performance results on a test set. Four models were evaluated using different performance metrics, including Accuracy, Precision, Recall, and F1-Score. Interestingly, Random Forest outperformed all other models in all the metrics with an Accuracy of 0.94, Precision of 0.95, Recall of 0.93, and F1-Score of 0.94. SVM and Multilayer Perceptron also showed good performance in this task, with both models having an Accuracy above 0.90. Logistic Regression had the highest Precision but comparatively lower Recall, bringing down the overall F1-Score."
9,"caption: Table 4: Performance metrics of various models on test datatable: Model,Accuracy,F1-Score,Precision,Recall, Model A,0.85,0.84,0.83,0.85, Model B,0.87,0.85,0.87,0.83, Model C,0.89,0.88,0.87,0.89, Model D,0.83,0.82,0.81,0.83, Model E,0.91,0.90,0.89,0.92","Table 4 shows the evaluation results of different models using multiple performance metrics, including Accuracy, F1-Score, Precision, and Recall, on a test dataset. The table indicates that Model E outperformed other models in terms of accuracy, F1-Score, Precision, and Recall with an accuracy of 0.91, an F1-Score of 0.90, a Precision of 0.89, and a Recall of 0.92. Whereas Model D had the lowest performance in all categories, with an overall accuracy of 0.83, followed by Model A, Model B, and Model C. The results suggest that Model E may be the best choice among these models for this particular dataset."
10,"caption: Table 4: Model evaluation metrics on the test data.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.82,0.82,0.83,0.81, RF,0.83,0.85,0.80,0.82, NB,0.75,0.81,0.68,0.73, KNN,0.78,0.79,0.77,0.78, LR,0.85,0.86,0.85,0.85","Table 4 presents the evaluation metrics (Accuracy, Precision, Recall and F1-score) for five different models: SVM, RF, NB, KNN, and LR. The table shows that the SVM model achieved the highest accuracy, precision, recall and F1-score among all models except for precision where the RF model slightly performed better. However, LR also presented a high overall performance in all metrics. Notably, the NB model showed lower performance in all metrics compared to other models. Overall, these results can provide insights for selecting the best model for classification tasks based on the evaluation metrics values."
11,"caption: Table 4: Model performance based on different evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.82,0.81,0.84,0.78, Logistic Regression,0.79,0.78,0.77,0.84, Random Forest,0.85,0.84,0.87,0.81, Multilayer Perceptron,0.81,0.80,0.82,0.77, Convolutional Neural Network,0.86,0.86,0.85,0.87","Table 4 shows the performance of five different models based on multiple evaluation metrics: Accuracy, F1 Score, Precision, and Recall. The table highlights that Convolutional Neural Network achieved the highest accuracy with 0.86 and was also able to achieve the highest F1 score, Precision, and Recall. Random Forest had the highest Precision out of the models with 0.87. On the other hand, Logistic Regression had the highest Recall with 0.84. The results suggest that Convolutional Neural Network may be the best-performing model for this dataset considering all the evaluation metrics."
12,"caption: Model performance comparison on the evaluation metrics of Accuracy, Precision, Recall, and F1-Score.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,85.6%,0.87,0.83,0.85, LR,82.4%,0.80,0.82,0.81, RF,88.2%,0.89,0.87,0.88, NB,76.5%,0.72,0.76,0.74","The table presents the performance comparison of four different models: SVM, LR, RF, and NB. Evaluation metrics used in the comparison are Accuracy, Precision, Recall, and F1-Score. The table shows that RF achieved the highest Accuracy of 88.2%, followed by SVM with 85.6%, LR with 82.4%, and NB with 76.5%. RF also achieved the highest Precision of 0.89 and Recall of 0.87. Meanwhile, SVM produced the highest F1-Score of 0.85, and NB demonstrated the lowest performance across all metrics. It can be concluded that RF is the best-performing model for this dataset based on the evaluation metrics in this study."
13,"caption: Table 4: Model Performance on Various Evaluation Metricstable: Model,F1-score,Precision,Recall,AUC-ROC, Model A,0.85,0.88,0.82,0.92, Model B,0.87,0.84,0.91,0.89, Model C,0.83,0.81,0.86,0.83, Model D,0.89,0.92,0.86,0.91, Model E,0.88,0.85,0.92,0.90","Table 4 shows the F1-score, Precision, Recall, and AUC-ROC performance metrics for five models: Model A, Model B, Model C, Model D, and Model E. Interestingly, each model performed better than the other models on certain metrics. Model D, for example, achieved the highest AUC-ROC score of 0.91, while Model B had the highest Recall score of 0.91. Moreover, Model D had the highest Precision score of 0.92, while Model A had the highest F1-score of 0.85. The table demonstrates the importance of considering multiple evaluation metrics when assessing model performance. It also highlights the need for using multiple models and comparing their results to choose the best performing one."
14,"caption: Comparison of different machine learning models using multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score,AUC, SVM,0.86,0.79,0.92,0.85,0.93, Naive Bayes,0.70,0.60,0.88,0.71,0.86, Random Forest,0.92,0.85,0.95,0.89,0.96, Logistic Regression,0.88,0.81,0.92,0.85,0.94","The table presents the performance results of four different machine learning models: SVM, Naive Bayes, Random Forest and Logistic Regression using five evaluation metrics- Accuracy, Precision, Recall, F1-score, and AUC. The results suggest that Random Forest is the top-performing model, with the highest accuracy (0.92) and AUC (0.96) among the tested models. SVM showed the highest recall (0.92), while Logistic Regression had the highest precision (0.81) among other models. Proper selection of the evaluation metric is critical to select the best-performing model for a specific task. In this case, Random Forest would be the model of choice if a higher accuracy and AUC are the priorities while developing the model."
15,"caption: Model performance results with multiple evaluation metrics and different performance results.table: Model,Accuracy,F1 Score,Precision,Recall, Model A,0.78,0.75,0.72,0.78, Model B,0.81,0.76,0.78,0.75, Model C,0.75,0.72,0.74,0.70, Model D,0.85,0.82,0.80,0.85, Model E,0.82,0.78,0.79,0.82","The table above presents the performance results of five different models based on four evaluation metrics: Accuracy, F1 Score, Precision, and Recall. Among the tested models, Model D achieved the highest performance on all evaluation metrics, with an accuracy of 0.85, F1 score of 0.82, precision of 0.80, and recall of 0.85. Model B and Model E also showed good performance, achieving accuracy values of 0.81 and 0.82, respectively. In contrast, Model C showed the lowest performance, achieving the lowest accuracy, F1 score, and recall values among the models. Overall, the table demonstrates the varying performance results of different models on multiple evaluation metrics, highlighting the importance of evaluating models on multiple metrics to gain a comprehensive understanding of their performance."
16,"caption: Table 4: Evaluation Results of Different Models on the Test Dataset.table: Model,Precision,Recall,F1-score,AUC, SVM,0.863,0.912,0.887,0.956, Decision Tree,0.791,0.725,0.757,0.819, Logistic Reg.,0.825,0.827,0.824,0.902, Random Forest,0.899,0.746,0.816,0.934, XGBoost,0.855,0.908,0.880,0.950","Table 4 presents the evaluation results of five different models on the test dataset based on four different performance metrics: precision, recall, F1-score, and AUC. The table shows that XGBoost achieved the highest AUC score of 0.95, followed by SVM with an AUC of 0.956 and Random Forest with an AUC of 0.934. The precision and recall scores were highest for SVM, whereas the F1-score was highest for XGBoost. Random Forest also performed well with respect to precision and F1-score. Therefore, based on the different evaluation metrics, different models can be considered best-performing for this dataset."
17,"caption: Evaluation results of different models based on accuracy, F1-score, and recall metrics.table: Model,Accuracy,F1-score,Recall, SVM,0.84,0.83,0.88, KNN,0.82,0.82,0.85, RF,0.87,0.86,0.91, MLP,0.89,0.88,0.92, XGB,0.85,0.84,0.89","Table presents the model performance results based on three evaluation metrics: accuracy, F1-score, and recall. The table includes five models: SVM, KNN, RF, MLP, and XGB. Interestingly, MLP outperformed all other models in both accuracy and recall metrics with accuracy of 0.89 and recall of 0.92, respectively. RF also performed well in all three metrics, obtaining accuracy, F1-score, and recall of 0.87, 0.86, and 0.91, respectively. KNN, SVM, and XGB achieved comparable performance to each other but slightly behind MLP and RF. Therefore, MLP and RF might be the better options among the tested models based on the performance results in the evaluated metrics."
18,"caption: Comparison of model performance using different evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.865,0.898,0.893,0.907, KNN,0.812,0.856,0.868,0.845, Logistic Regression,0.837,0.869,0.864,0.871, Decision Tree,0.784,0.817,0.858,0.780, Random Forest,0.882,0.896,0.915,0.878",
19,"caption: Evaluation results for multiple classification models across different performance metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Model A,0.83,0.84,0.85,0.84, Model B,0.84,0.83,0.88,0.85, Model C,0.82,0.86,0.81,0.82, Model D,0.85,0.82,0.87,0.85, Model E,0.87,0.84,0.89,0.86","The presented table shows the performance results of five classification models (Model A through Model E) on different evaluation metrics: Accuracy, Precision, Recall, and F1-Score. Interestingly, each model performs differently across the different metrics. For instance, Model E has the highest accuracy and recall; Model A has the highest precision; while Model B has the highest F1-Score. Therefore, depending on the focus of the project, different models may be preferred for their optimal performance in specific metrics."
20,"caption: Model performance results for different models based on different evaluation metrics.table: Model,Precision,Recall,F1-score,Accuracy, Logistic Regression,0.75,0.53,0.62,0.78, Decision Tree,0.69,0.70,0.69,0.69, Random Forest,0.82,0.82,0.82,0.82, Gradient Boosting,0.85,0.87,0.86,0.85, Support Vector Machine,0.74,0.80,0.77,0.74","Table presents the results of performance evaluation for different models using metrics of precision, recall, F1-score, and accuracy. Five models of Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Support Vector Machine are tested on a dataset of interest. Interestingly, the highest mean precision score is achieved by Gradient Boosting with 0.85, while the highest recall score is achieved by Support Vector Machine with 0.80. On the other hand, the highest mean F1-score is achieved by Random Forest with 0.82, which also has the highest accuracy score of 0.82. Therefore, Random Forest model seems to be the best-performing model overall according to the evaluation metrics used."
21,"caption: Comparison of four models' performance on multiple evaluation metrics.table: Model,F1 Score,Precision,Recall,Accuracy, Logistic Regression,0.894,0.915,0.874,0.903, Decision Tree,0.862,0.871,0.853,0.855, Random Forest,0.912,0.925,0.900,0.914, Gradient Boosting,0.906,0.918,0.893,0.910","The table presents the results of four different classification models' performance on multiple evaluation metrics, including F1 score, precision, recall, and accuracy. The models evaluated are logistic regression, decision tree, random forest, and gradient boosting. Based on the table, random forest achieved the highest F1 score, precision, recall and accuracy, outperforming the other models. Logistic regression was a close second in F1 score, precision, and accuracy, while gradient boosting achieved the second-highest recall score. Therefore, random forest appears to be the best-performing model among the evaluated models for this dataset."
22,"caption: Table 4: Performance comparison of different classification models using multiple metrics on the test set.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.892,0.721,0.805,0.648, Random Forest,0.906,0.720,0.823,0.634, Logistic Regression,0.899,0.714,0.815,0.633, MLP,0.901,0.717,0.817,0.630","Table 4 shows the performance comparison of four different classification models namely SVM, Random Forest, Logistic Regression, and MLP based on multiple evaluation metrics including Accuracy, F1-Score, Precision, and Recall on the test set. Interestingly, all models achieved high Accuracy values greater than 0.89, but Random Forest has the highest accuracy of 0.906. Moreover, these models have comparable F1-scores ranging from 0.714 to 0.721, indicating their overall performance is similar. However, Random forest outperforms SVM, Logistic Regression, and MLP models in F1-score and Recall."
23,"caption: Table 4: Model performance based on different evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.802,0.803,0.803,0.804, RF,0.735,0.735,0.732,0.739, MLP,0.788,0.786,0.786,0.785, NB,0.706,0.709,0.710,0.708, DT,0.651,0.653,0.652,0.654","Table 4 presents the performance results of five models: SVM, RF, MLP, NB, and DT, based on various evaluation metrics, including accuracy, F1-score, Precision, and Recall. Interestingly, SVM outperformed all other models in terms of accuracy, while NB had the lowest overall performance. However, MLP and SVM had similar levels of performance in F1-score and Precision, but SVM outperformed MLP in terms of Recall. Therefore, depending on which evaluation metric is of most importance, different models may be preferred for this task."
24,"caption: Performance evaluation of different models on the given dataset using multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.83,0.82,0.84,0.83, Naïve Bayes,0.76,0.68,0.94,0.79, Decision Tree,0.79,0.80,0.76,0.78, Random Forest,0.85,0.87,0.82,0.84, XGBoost,0.87,0.86,0.89,0.87","The table provides a comparison of different classification models using evaluation metrics such as Accuracy, Precision, Recall, and F1-Score. The models evaluated include Logistic Regression, Naïve Bayes, Decision Tree, Random Forest, and XGBoost on a given dataset. The results show that XGBoost outperforms other models with an accuracy of 0.87 and a high recall score of 0.89. However, Random Forest also achieved impressive outcomes in terms of accuracy and F1-score. Naïve Bayes had the highest recall score but at the cost of lower Precision. Consequently, we might recommend XGBoost as the best performer among the tested models, especially when recall is an essential criterion for model-selection."
25,"caption: Evaluation results of different models using accuracy, precision, recall, and F1-score metrics.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.84,0.85,0.82,0.83, Random Forest,0.87,0.81,0.90,0.85, Naive Bayes,0.78,0.82,0.72,0.76, Multilayer Perceptron (MLP),0.85,0.88,0.81,0.84, Logistic Regression,0.81,0.79,0.86,0.81, Decision Tree,0.73,0.75,0.68,0.71","Table presents the evaluation results of six different classification models using four metrics: accuracy, precision, recall, and F1-score. The models are SVM, Random Forest, Naive Bayes, MLP, Logistic Regression, and Decision Tree. Interestingly, Random Forest achieved the highest accuracy of 0.87, which was closely followed by SVM and MLP. MLP had the highest precision of 0.88, while Naive Bayes had the lowest precision of 0.82. SVM had the highest recall of 0.82, while Logistic Regression had the highest F1-score of 0.81. Overall, the evaluation results demonstrate that Random Forest could be the best-performing model among the tested models for this dataset. However, the choice of the optimal model will depend on the specific needs and trade-offs of the problem at hand."
26,"caption: Table 4: Model performance results based on various evaluation metricstable: Model,Accuracy,Precision,Recall,F1-score, MLP,0.91,0.92,0.90,0.91, Logistics,0.88,0.89,0.84,0.86, DT,0.81,0.81,0.77,0.79, Random Forest,0.93,0.94,0.93,0.93, XGBoost,0.94,0.96,0.93,0.94","Table 4 presents the performance results for five models based on multiple evaluation metrics such as accuracy, precision, recall, and F1-score. The models included in the table are MLP, Logistics, DT, Random Forest, and XGBoost. Interestingly, the random forest and XGBoost models outperformed the other models in all the used performance metrics, with XGBoost achieving the highest metrics across all performance metrics. Therefore, XGBoost may be the best model among the tested models for this dataset for the given performance metrics."
27,"caption: Model performance results of different classification models on a binary classification tasktable: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.82,0.84,0.75,0.79, Random Forest,0.85,0.87,0.78,0.82, Support Vector Machine,0.83,0.86,0.76,0.81, K-Nearest Neighbor,0.79,0.80,0.68,0.73, Gradient Boosting,0.86,0.89,0.80,0.84","Table presents the model performance results of five different classification models for a binary classification task. The table shows four different evaluation metrics: Accuracy, Precision, Recall, and F1-score for each model. The results show that Gradient Boosting outperformed the other models in all evaluation metrics except Precision where it has the same performance as Random Forest. Notably, K-Nearest Neighbor has the lowest performance in all evaluation metrics. Therefore, for this task, Gradient Boosting and Random Forest may be the best-performing models among the tested models."
28,"caption: Performance results for four different models based on multiple evaluation metrics.table: Model 1,Model 2,Model 3,Model 4, Metric 1,0.89,0.76,0.92,0.81, Metric 2,0.71,0.83,0.94,0.75, Metric 3,0.60,0.95,0.88,0.81","Table X presents the performance results for four different models based on three evaluation metrics. The models are labeled Model 1, Model 2, Model 3, and Model 4, and the metrics are labeled Metric 1, Metric 2, and Metric 3. It can be observed that Model 3 achieved the highest performance results across all evaluation metrics. Specifically, its Metric 1 score of 0.92 was the highest among all models, and its Metric 3 score of 0.88 was tied for the highest score with Model 4. Model 2 also had strong performance results, achieving the highest Metric 2 score of 0.95. ModelState variables can also be significant."
29,"caption: Table 4: Performance metrics comparison of five models on the given dataset.table: Model,Accuracy,F1 Score,Precision,Recall,AUC, Logistic Reg.,0.85,0.85,0.87,0.83,0.94, SVM,0.76,0.76,0.75,0.77,0.83, Random Forest,0.91,0.91,0.93,0.89,0.97, XGBoost,0.94,0.94,0.95,0.93,0.99, Adaboost,0.81,0.80,0.84,0.77,0.91","Table 4 compares the performance metrics of five different models - Logistic Regression, SVM, Random Forest, XGBoost, and Adaboost - based on the evaluation metrics of Accuracy, F1 Score, Precision, Recall, and AUC. The Random Forest and XGBoost models outperform all other models in all the evaluation metrics, while Adaboost is the weakest model with the lowest scores in each metric. These results suggest that Random Forest and XGBoost models could be useful for this dataset, while Logistic Regression and SVM models may require further tuning to perform better."
30,"caption: Model performance results on multiple evaluation metricstable: Model,Metric 1,Metric 2,Metric 3, Model A,0.78,0.90,0.64, Model B,0.80,0.88,0.62, Model C,0.85,0.92,0.68, Model D,0.77,0.89,0.63, Model E,0.82,0.91,0.69","The table shows the performance results of multiple models on multiple evaluation metrics. Models A, B, C, D, and E were evaluated using Metric 1, Metric 2, and Metric 3. Interestingly, Model C outperformed all other models for all three metrics whereas Model D had the lowest performance for all three metrics. However, Models A, B, and E had mixed results with varying performances across the three different evaluation metrics. Overall, it is clear that Model C is the best performer among the tested models for this dataset and evaluation metrics, while Model D showed the least promising results."
31,"caption: Table 4: Performance metrics for classification models on dataset X.table: Model,Precision,Recall,F1-score,Accuracy,AUC-ROC,PR-AUC, Logistic Regression,0.86,0.74,0.79,0.80,0.88,0.70, Decision Tree,0.71,0.68,0.68,0.68,0.71,0.50, Random Forest,0.84,0.80,0.81,0.81,0.86,0.74, Adaboost,0.81,0.75,0.76,0.77,0.83,0.66, Gradient Boosting,0.87,0.81,0.82,0.82,0.88,0.76, Support Vector Machine,0.83,0.79,0.80,0.81,0.84,0.68, Neural Network,0.88,0.83,0.83,0.84,0.89,0.76","Table 4 presents the performance results of different classification models on dataset X. The models considered are Logistic Regression, Decision Tree, Random Forest, Adaboost, Gradient Boosting, Support Vector Machine, and Neural Network. For each model and its respective evaluation metric, the table shows the precision, recall, F1-score, accuracy, AUC-ROC, and PR-AUC. Interestingly, the Neural Network model outperformed the other models with an accuracy of 0.84, a precision of 0.88, and a recall of 0.83. Moreover, Logistic Regression and Gradient Boosting models had the best-performing AUC-ROC and PR-AUC, respectively. The table provides a comprehensive view of how these models perform on dataset X and can be used for better model selection."
32,"caption: Table 1: Model performance comparison on evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.85,0.86,0.81,0.83, Decision Tree,0.80,0.82,0.75,0.76, Random Forest,0.90,0.92,0.88,0.89, Gradient Boosting,0.88,0.90,0.84,0.86, Support Vector Machine,0.84,0.85,0.81,0.83","Table 1 tabulates the results of five different models using multiple evaluation metrics for comparison. The models tested were Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Support Vector Machine. From the table, it can be observed that the Random Forest performed the best with an accuracy of 0.9. Precision scores were highest in the Random Forest and Gradient Boosting models with scores of 0.92 and 0.90, respectively. Random Forest and Gradient Boosting models had the highest recall and F1-Score among the models. Therefore, Random Forest and Gradient Boosting may be the best options for this dataset based on overall performance."
33,"caption: Performance of various models on the test set.table: Model name,Test accuracy,F1 score,Precision,Recall, Logistic Regression,0.785,0.727,0.682,0.778, Naive Bayes,0.758,0.684,0.625,0.752, Random Forest,0.823,0.788,0.784,0.793, XGBoost,0.831,0.794,0.786,0.803, Convolutional NN,0.808,0.768,0.750,0.787","Table presents a comparison of five models based on multiple evaluation metrics on the test dataset. The models include Logistic Regression, Naive Bayes, Random Forest, XGBoost, and Convolutional NN. The performance metrics evaluated are test accuracy, F1 score, precision, and recall. All the models have accuracy above 75%, indicating their robustness in classifying the data. The Random Forest model has the highest test accuracy of 0.823 and F1 score of 0.788, followed by XGBoost with 0.831 and 0.794. Interestingly, Logistic Regression slightly outperformed the Convolutional NN in accuracy and precision, despite the latter being a deep learning model."
34,"caption: Table 4: Performance Evaluation Metrics for Multiple Modelstable: Model,Accuracy,F1-Score,Precision,Recall, Model 1,0.82,0.77,0.85,0.71, Model 2,0.80,0.75,0.82,0.69, Model 3,0.84,0.79,0.86,0.74, Model 4,0.79,0.71,0.79,0.65","Table 4 shows the performance evaluation metrics for four models with respect to accuracy, F1-score, precision, and recall. Model 1 has the highest accuracy score of 0.82, while Model 3 displays the highest F1-score of 0.79. Interestingly, Models 1, 2, and 3 display similar precision scores of 0.85, 0.82, and 0.86, respectively. Model 4 achieved the lowest scores across all performance metrics, especially for recall. From this table, it appears that Model 3 is the best-performing approach in terms of F1-score and precision, while Model 1 shows the highest accuracy."
35,"caption: Performance of different models on sentiment analysis task using multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, SVM,0.82,0.87,0.76,0.81, Random Forest,0.86,0.89,0.81,0.85, K-NN,0.79,0.83,0.71,0.76, Naive Bayes,0.72,0.89,0.45,0.60, Decision Tree,0.81,0.79,0.82,0.81, Gradient Boost,0.87,0.90,0.82,0.86","The performance of six different models is presented in the above table for a sentiment analysis task. Each model was evaluated using multiple metrics: accuracy, precision, recall, and F1 score. The Random Forest model outperforms all other models with the highest accuracy of 0.86, precision of 0.89, recall of 0.81, and an F1 score of 0.85. Gradient Boost, SVM and Decision Tree achieved similar performance with accuracy around 0.81-0.87. Interestingly, Naive Bayes presented the highest precision among all models, while K-NN presented the lowest performance for all the metrics."
36,"caption: Model performance comparison across multiple evaluation metrics.table: Model 1,Model 2,Model 3, Metric 1,0.85,0.92,0.74, Metric 2,0.63,0.71,0.85, Metric 3,0.94,0.84,0.62","The table above compares the performance of three different models (Model 1, Model 2, and Model 3) across multiple evaluation metrics. Each column represents a different model, and each row represents a different metric. Interestingly, Model 2 performs the best on Metric 1 and Metric 2, while Model 1 performs the best on Metric 3. This suggests that different models may perform better depending on which metric is being considered. Additionally, Model 3 consistently performs the worst across all evaluation metrics. Therefore, based on the metrics considered, Model 1 and Model 2 may be better-performing models than Model 3."
37,"caption: Table 4: Performance of four different models evaluated with accuracy, precision, and recall metrics.table: Model,Accuracy,Precision,Recall, SVM,0.85,0.87,0.81, KNN,0.77,0.79,0.73, Naive Bayes,0.82,0.85,0.79, RandomForest,0.89,0.92,0.88","Table 4 summarizes the performance of four different models in terms of accuracy, precision, and recall metrics. The models tested were SVM, KNN, Naive Bayes, and RandomForest. RandomForest performed best in terms of accuracy with a score of 0.89. It also had the highest precision score, reaching 0.92. However, SVM had a balanced recall and precision score resulting in a higher F1 score. KNN had the lowest accuracy and precision scores but the recall score was not far from the other models. Naive Bayes had similar results with KNN but performed slightly better in precision and recall. Overall, the results suggest that the RandomForest model is the best performer in this dataset."
38,"caption: Performance metrics of different models on a binary classification tasktable: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.91,0.89,0.91,0.87, Random Forest,0.92,0.91,0.93,0.89, K-Nearest Neighbors,0.89,0.88,0.90,0.86, Support Vector Machine,0.90,0.88,0.89,0.88, Gradient Boosting,0.93,0.92,0.93,0.92","The above table illustrates the performance results of different models on a binary classification task using multiple evaluation metrics such as accuracy, F1-score, Precision, and Recall. The table shows the performance results for five models: Logistic Regression, Random Forest, K-Nearest Neighbors, Support Vector Machine, and Gradient Boosting. Interestingly, the Gradient Boosting model outperforms all other models in terms of accuracy, F1-score, Precision, and Recall, with an accuracy of 0.93, F1-score of 0.92, precision of 0.93, and a recall of 0.92. Therefore, Gradient Boosting may be the best model for this binary classification task among the models tested."
39,"caption: The performance of different models based on multiple evaluation metricstable: Model,Accuracy,Precision,Recall,F1 Score, Model A,0.92,0.91,0.93,0.92, Model B,0.93,0.94,0.92,0.93, Model C,0.91,0.88,0.94,0.91, Model D,0.96,0.96,0.96,0.96, Model E,0.94,0.95,0.93,0.94","The table presents the performance results of five different models based on multiple evaluation metrics. The evaluation metrics used are accuracy, precision, recall, and F1 score. Model D has the highest accuracy, precision, recall, and F1 score among the tested models. However, Model B has the highest precision, while Model C has the highest recall. These results suggest that different models excel in different evaluation metrics, and the choice of models may depend on the specific needs of the research. Therefore, careful consideration of these metrics is necessary when selecting a model to use in analysis."
40,"caption: Model performance on a binary classification task.table: Model,Precision,Recall,F1 Score,AUC,Accuracy, SVM,0.90,0.85,0.87,0.96,0.93, Decision Tree,0.86,0.81,0.78,0.92,0.91, Random Forest,0.92,0.90,0.91,0.97,0.95, Logistic Regression,0.88,0.85,0.86,0.94,0.92","The table presents model performance results on a binary classification task using four different models: SVM, Decision Tree, Random Forest, and Logistic Regression. The models’ performance is evaluated using five different evaluation metrics: Precision, Recall, F1 Score, AUC, and Accuracy. Interestingly, Random Forest achieved the highest F1 score and accuracy among all models. SVM achieved the highest precision, while the Random Forest model achieved the highest recall and AUC. Overall, the Random Forest model seems to be the best-performing model among the tested models based on the evaluated metrics on this specific binary classification task."
41,"caption: Model performance for different classifiers based on Accuracy, F1-Score, Precision and Recalltable: Model,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.85,0.84,0.82,0.87, Random Forest,0.82,0.81,0.81,0.82, Decision Tree,0.81,0.77,0.79,0.76, SVM,0.84,0.82,0.81,0.84, Naive Bayes,0.75,0.71,0.69,0.79","Table presents the performance results for five different machine learning models based on four evaluation metrics: Accuracy, F1-Score, Precision, and Recall. The models are Logistic Regression, Random Forest, Decision Tree, SVM, and Naive Bayes. Interestingly, all models achieved a higher Accuracy and Precision than Recall. Among the models, Logistic Regression achieved the highest Accuracy score at 0.85, while Naive Bayes achieved the lowest Accuracy score at 0.75. When considering F1-Score, Logistic Regression had a better performance than all the other models, achieving an F1-Score of 0.84. Precision was also highest with Logistic Regression at 0.82, with Naive Bayes having the lowest Precision score at 0.69. On the other hand, SVM outperformed all the other models in Recall, with a score of 0.84."
42,"caption: Performance Metrics for Multiple Modelstable: Model,Accuracy,Precision,Recall,F1-Score, Model A,0.85,0.76,0.81,0.78, Model B,0.82,0.78,0.72,0.74, Model C,0.87,0.85,0.83,0.84, Model D,0.88,0.90,0.87,0.88, Model E,0.89,0.87,0.92,0.89","Table 1 presents the performance metrics for five different models. The metrics used to evaluate the models include Accuracy, Precision, Recall, and F1-Score. One interesting observation from this table is that Model E shows the highest accuracy of 0.89. Model D showed the highest precision out of all the models, with a score of 0.90. Meanwhile, Model E displayed the best recall score, achieving a score of 0.92. Lastly, out of all the models, Model D showed the highest F1-Score. Overall, Model E displayed the most balanced performance, achieving the best Recall score as well as a high accuracy score."
43,"caption: Performance of classification models on dataset X.table: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.85,0.87,0.82,0.84, Decision Tree,0.78,0.76,0.79,0.75, Random Forest,0.88,0.89,0.87,0.88, Support Vector Machine,0.82,0.83,0.81,0.80, Neural Network,0.90,0.91,0.89,0.90","Table X presents the performance metrics of five different classification models: Logistic Regression, Decision Tree, Random Forest, Support Vector Machine, and Neural Network. Four evaluation metrics, namely Accuracy, Precision, Recall, and F1-score, were used to evaluate the models. The results indicate that the Neural Network model achieved the highest overall performance with an Accuracy score of 0.90, Precision score of 0.91, Recall score of 0.89, and F1-score of 0.90. The Random Forest model also performed well, achieving the second-highest overall performance with an Accuracy score of 0.88, Precision score of 0.89, Recall score of 0.87, and F1-score of 0.88. As for the other models, their performance varied with Logistic Regression achieving the second-best precision and Decision Tree achieving the second-best recall. These results can be used to determine which model may be the best fit for the given dataset and task."
44,"caption: Model performance using different evaluation metricstable: Model,Accuracy,F1 Score,Recall,Precision, Logistic Regression,0.85,0.83,0.87,0.81, Random Forest,0.89,0.88,0.91,0.86, K-Nearest Neighbors,0.79,0.77,0.83,0.72, Gradient Boosting,0.91,0.90,0.92,0.88","Table presents the model performance results for four different models: Logistic Regression, Random Forest, K-Nearest Neighbors, and Gradient Boosting. The performance of these models was evaluated using multiple metrics including Accuracy, F1 Score, Recall, and Precision. Among all models, Gradient Boosting has shown the best performance, achieving an accuracy of 0.91, an F1 score of 0.90, a recall of 0.92, and a precision of 0.88. On the other hand, Logistic Regression has the lowest F1 score of 0.83 and the lowest recall of 0.87 among all tested models. Interestingly, the highest F1 score was observed in Random Forest with 0.88, while the highest precision score was observed in Logistic Regression with 0.81."
45,"caption: Evaluation Metrics of Various Machine Learning Modelstable: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.891,0.872,0.906,0.889, Naive Bayes,0.804,0.758,0.803,0.773, Decision Tree,0.912,0.907,0.913,0.910, Random Forest,0.934,0.939,0.937,0.938, Gradient Boosting,0.923,0.926,0.923,0.924","The table lists the results of different machine learning models on a particular dataset using various evaluation metrics. Five commonly used models are tested and each model's performance is evaluated based on accuracy, precision, recall, and F1-score. The Random Forest model performed the best in terms of accuracy, achieving an accuracy of 0.934. However, in terms of precision, Gradient Boosting performed the best with 0.926 precision. On the other hand, Decision Trees performed the best in terms of recall, achieving 0.913 score and F1-score, with a score of 0.91. Therefore, it is important to consider multiple evaluation metrics while choosing the best model for a specific task."
46,"caption: Classification model performance results for different metrics and models.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.81,0.77,0.81,0.82, Decision Tree,0.76,0.73,0.79,0.67, Random Forest,0.85,0.80,0.84,0.80, XGBoost,0.86,0.81,0.83,0.85, Multi-layer Perceptron,0.82,0.77,0.80,0.84","The table provides the performance results for different metrics - Accuracy, F1 Score, Precision, and Recall for 5 models: Logistic Regression, Decision Tree, Random Forest, XGBoost, and Multi-layer Perceptron. The highest accuracy of 0.86 and F1 score of 0.81 is achieved by the XGBoost model. Random Forest and Logistic Regression have high accuracy as well. However, the Random Forest model has a slightly better F1 Score (0.80) compared to the Logistic Regression model (0.77). When considering Precision, Random Forest outperformed Logistic Regression, while Logistic Regression achieved the highest Recall value. Overall, the XGBoost model demonstrates the best performance on this dataset for the tested metrics."
47,"caption: Model performance evaluated by three different evaluation metrics (Accuracy, F1 Score, and Jaccard Score) based on four different models.table: Model Name,Accuracy Score,F1 Score,Jaccard Score, Logistic Regression,0.87,0.88,0.77, K-Nearest Neighbors,0.85,0.84,0.71, Decision Tree,0.83,0.83,0.69, Random Forest,0.89,0.91,0.80","The table shows the results of four different models evaluated by three evaluation metrics (Accuracy, F1 Score, and Jaccard Score). The highest accuracy score was obtained using the Random Forest model with a score of 0.89. The F1 Score provides insight into both precision and recall, and the Random Forest model is also the best-performing model according to this metric with a score of 0.91. The Jaccard Score evaluates the similarity between predicted and actual classes, and the Random Forest model still has the best score of 0.80. Overall, the Random Forest model performs better than the other models on all three evaluation metrics."
48,"caption: Model performance results of different classification algorithms for a binary classification problem.table: Model,Accuracy,Precision,Recall,F1-Score,AUC, Logistic Regression,0.85,0.89,0.82,0.85,0.92, Random Forest,0.87,0.90,0.87,0.88,0.93, Support Vector Machine,0.83,0.87,0.79,0.83,0.90, Artificial Neural Networks,0.84,0.88,0.81,0.84,0.91","The table presents the performance results of four different classification models, including Logistic Regression, Random Forest, Support Vector Machine, and Artificial Neural Networks. The table includes multiple evaluation metrics, such as Accuracy, Precision, Recall, F1-Score and AUC. Interestingly, all models performed similarly in terms of accuracy, with Random Forest having the highest accuracy of 0.87. On the other hand, Random Forest also had the highest AUC score of 0.93, indicating better overall performance. The Precision and Recall scores of all models were close to each other, with Support Vector Machine having the lowest Recall score of 0.79. Finally, Random Forest had the highest F1-Score of 0.88. Therefore, based on these results, Random Forest could be considered the best-performing model for this binary classification problem."
49,"caption: Performance evaluation table of different models using multiple performance metricstable: Model Name,Accuracy,Precision,Recall,F1-Score, Model A,0.95,0.94,0.95,0.94, Model B,0.86,0.82,0.86,0.80, Model C,0.98,0.97,0.98,0.97, Model D,0.92,0.91,0.92,0.90, Model E,0.99,0.98,1.0,0.99","The table presents a comparison of five different models based on their accuracy, precision, recall, and F1-Score. Model E has the highest accuracy of 0.99 and the highest recall of 1.0 compared to the other models. Model C has the second highest accuracy of 0.98 and second highest recall of 0.98. Model B has the lowest accuracy of 0.86 along with the lowest F1-Score of 0.80. Interestingly, Model A and D performance results fall in the middle range for all evaluation metrics. Therefore, based on these results, Model E provides the best overall performance among the tested models."
50,"caption: Performances of different models on the evaluation metricstable: Model,Accuracy,F1 score,Precision,Recall, Model A,0.82,0.78,0.85,0.73, Model B,0.85,0.81,0.86,0.77, Model C,0.87,0.84,0.88,0.80, Model D,0.81,0.77,0.83,0.73, Model E,0.90,0.87,0.90,0.84","Table above demonstrates the evaluation performances of five different models with respect to four different metrics, including accuracy, F1 score, precision and recall. Each model is evaluated in terms of how well it can predict a binary outcome. The results show that Model E provides the best performance with an accuracy of 0.90, F1 score of 0.87, precision of 0.90, and recall of 0.84. Interestingly, Model A, which has the lowest accuracy, performs better than Model D in terms of F1 score, precision and recall. Therefore, when evaluating models, it is important to consider multiple metrics as the best model may differ depending on the criteria used for evaluation."
51,"caption: Evaluation metrics for different models on a binary classification task.table: Model,F1-score,Accuracy,Recall,AUC, Model A,0.75,0.81,0.68,0.87, Model B,0.70,0.79,0.65,0.85, Model C,0.78,0.82,0.75,0.88, Model D,0.66,0.77,0.60,0.81, Model E,0.80,0.83,0.79,0.89","Table presents the performance results of multiple models in a binary classification task using four different evaluation metrics: F1-score, accuracy, recall, and AUC. The best-performing model differs depending on the evaluation metric. Interestingly, only Model E outperformed the other models in terms of AUC. Model A had the highest F1-score of 0.75, while Model E had the highest accuracy of 0.83, highest recall of 0.79, and highest AUC of 0.89. The results suggest that it is important to consider multiple evaluation metrics to determine the best-performing model."
52,"caption: Model performance of different machine learning algorithms according to evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.85,0.87,0.83,0.91, K-Nearest Neighbors,0.81,0.84,0.79,0.89, Decision Tree,0.78,0.81,0.77,0.86, Random Forest,0.87,0.89,0.85,0.92, XGBoost,0.88,0.90,0.87,0.93","Table presents the results of the model performance evaluation of five different algorithms in terms of Accuracy, F1 score, Precision, and Recall. Logistic Regression achieved the highest accuracy of 0.85 among all models. The XGBoost model has the highest F1 score, precision, and recall. In terms of recall, Random Forest and XGBoost are found the top ones, with values of 0.92 and 0.93, respectively. The results indicate that the XGBoost model outperforms other models in most evaluation metrics. These findings highlight the potential of the XGBoost model in prediction tasks with similar datasets."
53,"caption: Table 4: Model performance based on different evaluation metrics.table: Model,Accuracy,F1 score,Precision,Recall, Logistic Regression,0.82,0.84,0.86,0.82, Random Forest,0.85,0.87,0.87,0.87, Support Vector Machine,0.83,0.85,0.83,0.88, Multilayer Perceptron,0.87,0.89,0.88,0.89, Gradient Boosting,0.84,0.86,0.86,0.86","Table 4 presents the performance results of five different models evaluated based on multiple metrics. The models include Logistic Regression, Random Forest, Support Vector Machine, Multilayer Perceptron, and Gradient Boosting. The table shows the accuracy, F1 score, precision, and recall values for each model. Interestingly, Random Forest and Multilayer Perceptron models achieved the highest F1 scores of 0.87 and 0.89, respectively. Additionally, Multilayer Perceptron model also achieved the highest accuracy, precision, and recall values among all tested models. Based on these results, Multilayer Perceptron may be considered the best performing model in this dataset."
54,"caption: Performance comparison of different models using various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score,AUC, Model 1,0.89,0.91,0.87,0.89,0.95, Model 2,0.88,0.85,0.92,0.88,0.93, Model 3,0.86,0.87,0.84,0.85,0.90, Model 4,0.90,0.92,0.89,0.90,0.96, Model 5,0.91,0.94,0.89,0.91,0.97","This table highlights the performance of five different models using different evaluation metrics. The evaluation metrics used in the table include Accuracy, Precision, Recall, F1-Score, and AUC. Model 5 outperformed all other models across all evaluation metrics except for Precision, where Model 4 outperformed it by a slight margin. Interestingly, Model 2 had high Recall but low Precision, while Model 3 had relatively lower scores for all evaluation metrics. It is important to note that the performance of these models may vary based on the dataset used."
55,"caption: Model performance results of different classifiers on a sentiment analysis dataset.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.78,0.74,0.69,0.87, Random Forest,0.83,0.76,0.83,0.7, Naive Bayes,0.67,0.59,0.57,0.62, Logistic Regression,0.79,0.73,0.70,0.78","The table displays the performance results of four different classifiers on a sentiment analysis dataset based on multiple evaluation metrics such as accuracy, F1 score, precision, and recall. The results reveal that the Random Forest classifier outperforms the other models in terms of accuracy and precision with a respective score of 0.83 and 0.83. The SVM outperforms other models in terms of recall with a score of 0.87. Meanwhile, Naive Bayes performs the worst among the models in terms of all the evaluation metrics. Overall, the Random Forest classifier is most promising for performing sentiment analysis on this dataset based on the results."
56,"caption: Table 4: Model performance evaluation metrics for different models.table: Model,Accuracy,F1-score,Precision,Recall, Model A,0.89,0.91,0.93,0.89, Model B,0.92,0.85,0.91,0.80, Model C,0.86,0.88,0.85,0.90, Model D,0.88,0.89,0.87,0.90","Table 4 displays the performance evaluation metrics for four different models including accuracy, F1-score, precision, and recall. Interestingly, Model B has the highest accuracy (0.92) among the models, which is 3% higher than Model A's accuracy (0.89). However, Model A has the highest F1-score (0.91) and precision (0.93) among the models. Model C outperforms Model B in F1-score (0.88) and recall (0.90) but has a lower accuracy (0.86). Model D has the second-highest F1-score (0.89) after Model A and a similar recall score (0.90) to Models C and A. In summary, different models have varying levels of performance based on the evaluation metrics considered."
57,"caption: Model performance results for different models using various evaluation metrics.table: Model,F1 score,Accuracy,Precision,Recall, Logistic Regression,0.85,0.89,0.83,0.87, Support Vector Machine,0.82,0.88,0.81,0.84, Random Forest,0.89,0.91,0.90,0.88, XGBoost,0.87,0.90,0.86,0.88","The table compares the performance of four different models using multiple evaluation metrics on a given dataset. The models include Logistic Regression, Support Vector Machine, Random Forest, and XGBoost. Performance is measured using F1 score, accuracy, precision, and recall. Random Forest achieves the highest F1 score (0.89) and accuracy (0.91), while XGBoost has the highest precision (0.86) and Logistic Regression has the highest recall (0.87). These results highlight the importance of using multiple evaluation metrics and trying different models for achieving the best performance."
58,"caption: Model performance results based on different evaluation metricstable: Model,Accuracy,F1-Score,Precision,Recall, Model 1,0.85,0.86,0.82,0.90, Model 2,0.75,0.77,0.72,0.82, Model 3,0.92,0.91,0.94,0.88, Model 4,0.81,0.83,0.79,0.87, Model 5,0.89,0.88,0.87,0.90","Table 1 presents the performance results of five models based on different evaluation metrics, namely Accuracy, F1-Score, Precision, and Recall. Model 3 has the highest Accuracy of 0.92 and has the second-highest F1-Score of 0.91, indicating that it is a superior model in terms of overall performance. However, Model 1 has the highest Precision of 0.82, and Model 5 has the highest Recall of 0.90, indicating that they are better suited for situations where either precision or recall is vital as opposed to overall performance. Therefore, the choice of the model depends on the specific requirements of the task at hand."
59,"caption: Table 4: Model performance based on different evaluation metrics.table: Model,Accuracy,F1-Score,Recall,Precision, Model A,0.82,0.80,0.76,0.85, Model B,0.88,0.87,0.86,0.87, Model C,0.75,0.72,0.70,0.74, Model D,0.90,0.89,0.90,0.88, Model E,0.83,0.81,0.82,0.80","Table 4 displays the performance results of five different models based on multiple evaluation metrics. The evaluation metrics used in this table include accuracy, F1-score, recall, and precision. When comparing the models, Model D seems to outperform the rest of the models with the highest accuracy of 0.90, F1-score of 0.89, recall of 0.90, and precision of 0.88. Model B is also a strong performer with an accuracy of 0.88, F1-score of 0.87, recall of 0.86, and precision of 0.87. On the other hand, Model C has the lowest performance based on the metrics used in this table with an accuracy of 0.75, F1-score of 0.72, recall of 0.70, and precision of 0.74."
60,"caption: Table 4. Model performance on a classification task.table: **Model**,**Accuracy**,**F1-Score**,**Precision**,**Recall**, LR,0.87,0.85,0.83,0.87, SVC,0.85,0.84,0.81,0.86, KNN,0.83,0.81,0.78,0.85, RF,0.90,0.89,0.87,0.90, DT,0.85,0.84,0.81,0.87","Table 4 presents the performance results of different models on a classification task. The table shows the accuracy, F1-score, precision, and recall metrics for five models: LR, SVC, KNN, RF, and DT. Interestingly, RF shows the best performance in terms of accuracy with 0.90 and F1-score with 0.89. Moreover, RF has the highest precision value of 0.87 indicating it has fewer false positives. The LR and SVC models show similar performance with an accuracy at 0.87 and 0.85, respectively. The KNN and DT models show the lowest performance with an accuracy of 0.83 and 0.85, respectively. Therefore, RF appears to be the best-performing model for this classification task, followed by LR and SVC."
61,"caption: Performance results of different models on a classification task.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.883,0.798,0.835,0.764, KNN,0.852,0.757,0.778,0.736, Naive Bayes,0.809,0.629,0.670,0.594, Decision Tree,0.866,0.753,0.763,0.746","The table presents the performance results of several models on a classification task using four different evaluation metrics: Accuracy, F1 Score, Precision, and Recall. The models evaluated in this table are SVM, KNN, Naive Bayes, and Decision Tree. Notably, SVM achieved the highest accuracy score of 0.883, followed closely by Decision Tree at 0.866. However, in terms of F1 Score, Decision Tree outperformed the other models with a score of 0.753. KNN had the lowest and SVM had the highest precision score, and SVM had the highest recall score among all the models. These results provide various insights about the performance of different models, and the selection of the best-performing model may depend on the specific evaluation metric or task being considered."
62,"caption: Model performance results of five different models on various evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall,AUC, Model 1,0.85,0.86,0.87,0.85,0.91, Model 2,0.83,0.87,0.83,0.90,0.90, Model 3,0.81,0.82,0.79,0.92,0.87, Model 4,0.82,0.85,0.81,0.89,0.89, Model 5,0.84,0.86,0.85,0.87,0.91","Table 1 showcases the performance results of five different models on various evaluation metrics including accuracy, F1-score, precision, recall, and AUC. Model 1 achieved the best AUC result of 0.91 and had the highest precision value of 0.87. On the other hand, Model 3 had a high recall value of 0.92. Meanwhile, Model 2 had the highest F1-score of 0.87 and the second-best AUC value of 0.90. Finally, Model 5 had a consistent performance across all evaluation metrics, achieving a high accuracy value of 0.84 and an AUC value of 0.91. Overall, the models displayed a range of strengths and weaknesses across the evaluation metrics, and no single model performed better than the others in all of the metrics."
63,"caption: Evaluation metrics of different models for a specific task.table: Model,F1 Score,Dice Score,Precision,Recall, A,0.854,0.923,0.898,0.814, B,0.870,0.925,0.884,0.857, C,0.908,0.940,0.917,0.900, D,0.815,0.893,0.854,0.780, E,0.835,0.903,0.900,0.792","Table presents the results of different models' evaluation metrics for a specific task. The evaluated models are labeled A, B, C, D, and E, and F1 Score, Dice Score, Precision, and Recall are the metrics used to assess their performance. Interestingly, Model C performed the best in all metrics with an F1 Score of 0.908, Dice Score of 0.940, Precision of 0.917, and Recall of 0.900. Although Model A performed well in F1 Score and Dice Score, it had lower metrics of Precision and Recall compared to the other models. Therefore, Model C appears to outperform other models in this specific task."
64,"caption: Model performance on multiple evaluation metricstable: Model Name,Accuracy,F1 Score,Precision,Recall, Model A,0.90,0.89,0.91,0.88, Model B,0.92,0.91,0.94,0.88, Model C,0.88,0.86,0.87,0.89, Model D,0.89,0.87,0.85,0.90, Model E,0.94,0.93,0.95,0.92","Table above shows the performance of five different models based on various evaluation metrics, including Accuracy, F1 Score, Precision, and Recall. The models are denoted as Model A to Model E, and their respective performance values are listed under the corresponding metric categories. Model B appears to be the best-performing model in Accuracy metric with a score of 0.92, while Model E performs the best in terms of F1 Score, Precision and Recall with scores of 0.93, 0.95 and 0.92, respectively. Model C and D appear to have lower performance values compared to other models."
65,"caption: Comparison of model performance using multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score,AUC, Random Forest,0.82,0.82,0.83,0.82,0.92, Logistic Regression,0.80,0.80,0.81,0.80,0.87, Support Vector Machine,0.75,0.79,0.74,0.74,0.85, Multi-Layer Perceptron,0.83,0.82,0.83,0.82,0.91","The table compares the performance of four different models on four different evaluation metrics: accuracy, precision, recall, F1-score, and AUC. Each model includes its respective performance results for each evaluation metric. Interestingly, the Random Forest model performed the best, achieving the highest accuracy, precision, recall, and F1-score among the four models. However, its AUC was only second to the Multi-Layer Perceptron. The Logistic Regression model demonstrated the lowest performance among the models in terms of accuracy, precision, recall, and F1-score, although its AUC is somewhat better than SVM. In general, Random Forest and Multi-Layer Perceptron appear to be the top-performing models in terms of different evaluation metrics."
66,"caption: Table 4: Performance metrics of different models on the dataset.table: Model,Precision,Recall,F1-score,ROC-AUC, Model A,0.84,0.78,0.81,0.91, Model B,0.89,0.91,0.90,0.88, Model C,0.73,0.67,0.70,0.73, Model D,0.92,0.88,0.90,0.95","Table 4 shows the performance metrics of four different models on a dataset. The models were evaluated using four different metrics: Precision, Recall, F1-score, and ROC-AUC. Among the models, Model D has the highest Precision, Recall, F1-score, and ROC-AUC scores, indicating its superiority over the other models. Model B also achieved strong results for all metrics except for ROC-AUC, where it underperformed. Model A has high Precision and ROC-AUC, but somewhat lower Recall and F1-score. Model C has the lowest performance scores for all metrics, indicating its inadequacy on this dataset. Overall, Model D outperformed the other models, making it the best-performing model among the tested models on this dataset."
67,"caption: Performance results of different models based on various evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Model 1,0.85,0.80,0.70,0.93, Model 2,0.84,0.74,0.69,0.80, Model 3,0.88,0.81,0.76,0.88, Model 4,0.82,0.67,0.63,0.71","The table displays the performance results of four models based on different evaluation metrics, including accuracy, F1 score, precision, and recall. Model 3 achieved the highest accuracy of 0.88, which is followed by Model 1 with an accuracy of 0.85. When considering the F1 score metric, Model 3 outperformed the other models with a score of 0.81. Interestingly, Model 1 and Model 2 had comparable F1 scores of 0.80 and 0.74, respectively, but Model 1 had a higher accuracy and recall. When considering precision, Model 3 performed the best with a score of 0.76, while Model 4 had the lowest precision score of 0.63. Moreover, Model 1 had the highest recall score of 0.93, which indicates that it is good at identifying true positives."
68,"caption: Table 4: Model performance summary based on different evaluation metrics.table: Model name,F1-Score,Precision,Recall,Accuracy, Model 1,0.897,0.899,0.896,0.905, Model 2,0.908,0.906,0.910,0.912, Model 3,0.916,0.913,0.919,0.917, Model 4,0.940,0.935,0.945,0.942","Table 4 displays the performance of four different models based on various evaluation metrics. The table includes F1-Score, Precision, Recall, and Accuracy for each of the tested models. Interestingly, Model 1 had the lowest performance among the models in all metrics. Conversely, Model 4 had the highest performance compared to the other models in all metrics. Particularly, this model achieved an F1-Score of 0.940, which is the highest among the tested models. Therefore, it can be concluded that Model 4 outperformed the other models in terms of different evaluation metrics."
69,"caption: Performance of Different Models on Binary Classification Tasktable: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.85,0.85,0.86,0.85, Random Forest,0.91,0.91,0.92,0.91, SVM,0.87,0.87,0.89,0.87, Naive Bayes,0.80,0.80,0.82,0.80","The table provides performance metrics of different models on a binary classification task. The models evaluated include logistic regression, random forest, support vector machine (SVM), and naive Bayes. Multiple evaluation metrics, including accuracy, F1 score, precision, and recall, are reported for each model. Random forest achieved the best overall performance with the highest accuracy, F1 score, precision, and recall values of 0.91. Naive Bayes achieved the lowest accuracy, F1 score, precision, and recall values of 0.80. Therefore, based on the table, one can conclude that random forest is the best-performing model for this binary classification task."
70,"caption: Model performance on different evaluation metrics.table: Model,Accuracy,F1-Score,Recall, Logistic Reg.,0.85,0.85,0.85, Random Forest,0.94,0.94,0.92, Decision Tree,0.82,0.82,0.80, SVM Linear,0.89,0.89,0.88, SVM RBF,0.92,0.92,0.92, Naive Bayes,0.76,0.75,0.74","Table presents the performance results of six different models on various evaluation metrics. The models include Logistic Regression, Random Forest, Decision Tree, SVM Linear, SVM RBF, and Naive Bayes. The evaluation metrics include Accuracy, F1-Score, and Recall. From the table, we can observe that Random Forest achieved the highest accuracy of 0.94, followed by SVM RBF with an accuracy of 0.92. However, Naive Bayes underperformed with an accuracy of 0.76. On the other hand, Logistic Regression performed consistently across all three metrics. Therefore, depending on the focus metric, the most appropriate model can be selected."
71,"caption: Performance comparison of different models on a binary classification task.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.847,0.858,0.856,0.857, KNN,0.819,0.818,0.820,0.819, LR,0.851,0.862,0.853,0.857, RF,0.897,0.895,0.899,0.897",
72,"caption: Table 4: Model Performance on Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.873,0.902,0.861,0.881, Naive Bayes,0.821,0.851,0.799,0.824, Decision Tree,0.849,0.856,0.843,0.849, Random Forest,0.892,0.892,0.896,0.894, XGBoost,0.899,0.903,0.898,0.900",
73,"caption: Performance of different models on the dataset.table: Model Name,Accuracy,AUC,F1 Score,Precision,Recall,Specificity, Logistic Regression,0.892,0.951,0.812,0.877,0.753,0.969, Random Forest,0.901,0.968,0.836,0.899,0.775,0.981, XGBoost,0.905,0.972,0.843,0.912,0.782,0.982, Support Vector Machine,0.880,0.939,0.776,0.852,0.718,0.967, Naive Bayes,0.865,0.922,0.792,0.867,0.718,0.943, Multi-Layer Perceptron,0.908,0.975,0.855,0.913,0.796,0.984","The table above shows the performance of six models: Logistic Regression, Random Forest, XGBoost, Support Vector Machine, Naive Bayes, and Multi-Layer Perceptron. Model performance is reported in terms of six evaluation metrics: Accuracy, AUC, F1 Score, Precision, Recall, and Specificity. Interestingly, all models have an Accuracy above 0.865, with Multi-Layer Perceptron having the highest Accuracy of 0.908. Meanwhile, the Random Forest model had the best overall performance in terms of AUC, F1 Score, Precision, and Recall. Support Vector Machine had the lowest Recall (0.718), though it had the highest Specificity. These results give insights into the best performance model based on specific metrics."
74,"caption: Performance results of different models using multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score,AUC, Model A,0.87,0.88,0.85,0.86,0.92, Model B,0.85,0.82,0.88,0.85,0.91, Model C,0.83,0.90,0.79,0.84,0.88, Model D,0.88,0.87,0.90,0.88,0.94, Model E,0.86,0.84,0.88,0.86,0.92",
75,"caption: Evaluation metrics for SVM, KNN, RF, and XGB models.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.850,0.848,0.868,0.830, KNN,0.810,0.803,0.820,0.787, RF,0.889,0.886,0.898,0.875, XGB,0.901,0.899,0.912,0.887","The table shows the evaluation metrics of four different models: SVM, KNN, RF, and XGB. Four evaluation metrics, Accuracy, F1-Score, Precision, and Recall, are presented. It is observed that XGB achieved the highest accuracy of 0.901 and F1-Score of 0.899 among the tested models. Similarly, RF also performed well with an accuracy of 0.889 and F1-Score of 0.886. Both models achieved a relatively high Precision and Recall score. In contrast, SVM and KNN achieved lower performance scores compared to the other tested models. Thus, the results suggest that XGB and RF may be the best models for this particular dataset and problem."
76,"caption: Comparison of model evaluation metrics on the test dataset.table: Model,Accuracy,Precision,Recall,F1-Score, Random forest,0.94,0.95,0.97,0.95, Logistic Regression,0.89,0.84,0.93,0.88, Decision Tree,0.89,0.84,0.89,0.84, KNN,0.79,0.72,0.86,0.77, SVM,0.92,0.92,0.90,0.91","The table presents the results of the performance evaluation metrics of five different machine learning models on a held-out test dataset. The evaluation metrics used in the table are accuracy, precision, recall, and F1-score. Interestingly, Random forest produced the highest accuracy result at 0.94, and also had high precision and F1-score values. SVM had the highest precision score of 0.92, while logistic regression had the highest recall score of 0.93. Decision tree had the lowest precision and recall scores but had performance similar to logistic regression with an F1-score of 0.84. KNN had the worst performance among the five models in terms of overall evaluation metrics, with an accuracy of 0.79 and F1-score of 0.77."
77,"caption: Model performance evaluated using different evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, :-,:-:,:-:,:-:,:-:, Logistic Regression,0.89,0.87,0.84,0.90, Decision Tree,0.86,0.83,0.82,0.84, Random Forest,0.93,0.91,0.94,0.89, Support Vector Machine,0.87,0.85,0.87,0.83, Multilayer Perceptron,0.91,0.89,0.86,0.92","Table presented above demonstrates the performance results attained by various machine learning models including Logistic Regression, Decision Tree, Random Forest, Support Vector Machine, and Multilayer Perceptron for a particular dataset. The table displays the results obtained in terms of multiple evaluation metrics: Accuracy, F1 Score, Precision and Recall. Interestingly, Random Forest outperformed all other models achieving the highest scores in Accuracy (0.93), F1-Score (0.91), and Recall (0.89) while Multilayer Perceptron achieved the highest Precision score (0.86). These results indicate that Random Forest may be the suggested approach using this dataset based on the multiple evaluation metrics considered."
78,"caption: Comparison of Model Performance on Classification Tasktable: Model Name,F1-score,Accuracy,AUC, Logistic Regression,0.75,0.78,0.85, Random Forest,0.82,0.86,0.91, XGBoost,0.85,0.88,0.92, Multilayer Perceptron (MLP),0.78,0.81,0.85, Convolutional Neural Network (CNN),0.86,0.89,0.93","Table presents the results of five different models' performance on a classification task. The models' performance is assessed using three different evaluation metrics, including F1-score, accuracy, and AUC. The results indicate that the Convolutional Neural Network (CNN) outperforms all other models, with F1-score, accuracy, and AUC of 0.86, 0.89, and 0.93, respectively. Random Forest and XGBoost also show strong performance, with F1-scores of 0.82 and 0.85, and accuracies of 0.86 and 0.88, respectively. In contrast, Logistic Regression and Multilayer Perceptron (MLP) show comparatively lower performance on all metrics. Consequently, the CNN model is the best model for the classification task based on the given evaluation metric scores."
79,"caption: Table 4: Model performance of different models based on multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score,AUC-ROC, Model A,0.89,0.85,0.92,0.88,0.93, Model B,0.92,0.91,0.89,0.90,0.92, Model C,0.87,0.83,0.85,0.84,0.88, Model D,0.93,0.92,0.94,0.93,0.95, Model E,0.91,0.88,0.89,0.88,0.92","Table 4 presents the evaluation results of multiple models based on different evaluation metrics, including accuracy, precision, recall, F1-score, and AUC-ROC. The table shows five models, including Model A, B, C, D, and E. Interestingly, Model D achieved the highest performance across all metrics with an accuracy of 0.93, precision of 0.92, recall of 0.94, F1-score of 0.93, and AUC-ROC of 0.95. This suggests that Model D is the best performing model in this evaluation. The precision, recall, and F1-score of Model A and Model E appears to be somewhat similar. However, their AUC-ROC performances differed, which could suggest that one of them might be more suitable depending on the specific objective of the study."
80,"caption: Model performance results on the test set using different evaluation metrics.table: Model,Accuracy,F1-score,Recall,Precision, Logistic Regression,0.75,0.77,0.73,0.81, Decision Tree,0.70,0.69,0.70,0.68, Random Forest,0.82,0.83,0.81,0.85, K-Nearest Neighbors,0.69,0.68,0.70,0.67, Support Vector Machine,0.79,0.80,0.79,0.80","The table presents the performance results of five different models on the test set using different evaluation metrics, including Accuracy, F1-score, Recall, and Precision. The models include Logistic Regression, Decision Tree, Random Forest, K-Nearest Neighbors, and Support Vector Machine. The table shows that Random Forest performs the best across all evaluation metrics, with an Accuracy of 0.82, F1-score of 0.83, Recall of 0.81, and Precision of 0.85. On the other hand, K-Nearest Neighbors performs the worst on all metrics. The results suggest that the Random Forest model may be the optimal choice for this dataset."
81,"caption: Performance of Different Models on Classification Tasktable: Model,Accuracy,Precision,Recall,F1 score, Logistic Regression,0.92,0.91,0.95,0.93, Decision Tree,0.88,0.88,0.89,0.88, Random Forest,0.97,0.96,0.98,0.97, Support Vector Machine,0.89,0.90,0.85,0.87, K-Nearest Neighbors,0.84,0.83,0.87,0.85","The table presents the performance results of five different models on a classification task. The models used in the experiment include Logistic Regression, Decision Tree, Random Forest, Support Vector Machine, and K-Nearest Neighbors. For each model, the evaluation metrics include Accuracy, Precision, Recall, and F1 score. Interestingly, Random Forest outperformed all other models by achieving the highest values for all four metrics, with an Accuracy of 0.97, Precision of 0.96, Recall of 0.98, and F1 score of 0.97. While other models also show strong performance, Random Forest seems to be the best-performing model for this classification task."
82,"caption: Model performance comparison using different evaluation metrics.table: Model,MAE,RMSE,R-squared, Linear Regression,2.51,3.87,0.69, Random Forest,2.26,3.73,0.74, XGBoost,2.18,3.63,0.76, SVM,2.68,4.12,0.63","Table above shows the performance of linear regression, random forest, XGBoost, and SVM models using three different evaluation metrics: Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and R-squared. Interestingly, XGBoost outperforms other models in all metrics with the best performance in R-squared (0.76), followed by random forest and linear regression. Linear regression has the worst performance among the models in terms of all evaluation metrics. Random forest and SVM also have competitive performance compared to the other models."
83,"caption: Evaluation metrics for three different modelstable: Model,Accuracy,F1-Score,Recall,Precision, Model 1,0.84,0.78,0.81,0.75, Model 2,0.79,0.74,0.88,0.65, Model 3,0.81,0.80,0.74,0.87","The table above shows the evaluation metrics for three different models, including Accuracy, F1-Score, Recall, and Precision. Model 1 exhibited the highest accuracy at 0.84 and Precision at 0.75, while Model 3 obtained the highest F1-Score at 0.80 and highest Recall at 0.87. On the other hand, Model 2 had the lowest Accuracy and Precision scores at 0.79 and 0.65, respectively, but had the highest Recall score at 0.88. The results suggest that the choice of evaluation metric is crucial in selecting the best-performing model, and each model has its own strengths and weaknesses based on the metric of interest."
84,"caption: Model performance across multiple evaluation metricstable: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.83,0.84,0.82,0.83, Random Forest,0.90,0.91,0.89,0.90, Support Vector Machine,0.81,0.82,0.80,0.81, Gradient Boosted,0.91,0.92,0.91,0.91",
85,"caption: Model performance from different models based on multiple evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, Model A,0.85,0.88,0.83,0.93, Model B,0.76,0.68,0.73,0.63, Model C,0.92,0.93,0.95,0.91, Model D,0.81,0.85,0.78,0.92, Model E,0.89,0.90,0.95,0.85","Table 4 presents the model performance results of five different models based on multiple evaluation metrics: Accuracy, F1-Score, Precision, and Recall. The models are denoted as Model A, Model B, Model C, Model D, and Model E. Interestingly, Model C outperformed the rest of the models in all evaluated metrics, with an accuracy of 0.92, F1-Score of 0.93, Precision of 0.95, and Recall of 0.91. Model B had the lowest performance on all metrics, with an accuracy of 0.76, F1-Score of 0.68, Precision of 0.73, and Recall of 0.63. Therefore, Model C appears to be the best-performing model among the tested models for this dataset based on these metrics."
86,"caption: Model performance evaluation metrics for different classification models.table: Model,Accuracy,F1-Score,Recall,Precision, Logistic Regression,0.89,0.87,0.87,0.89, Random Forest,0.91,0.90,0.91,0.92, Support Vector Machine,0.88,0.86,0.92,0.84, Adaboost,0.90,0.89,0.88,0.91, Gradient Boosting,0.92,0.91,0.92,0.93","The table displays the accuracy scores, F1-score, recall and precision values for five different classification models. These models are Logistic Regression, Random Forest, Support Vector Machine, Adaboost, and Gradient Boosting. Interestingly, Random Forest and Gradient Boosting achieved the highest accuracy levels of 0.91 and 0.92 respectively. However, while Gradient Boosting had the highest F1-score and recall values (0.91 and 0.92 respectively), Random Forest and Adaboost had the highest precision values (0.92 and 0.91 respectively). In summary, the table provides a clear overview of the performance results for the different classification models."
87,"caption: Model performance using multiple evaluation metricstable: Model,Accuracy,Precision,Recall,F1-score, BERT-base-uncased,0.891,0.913,0.886,0.899, LSTM (uni-directional),0.899,0.902,0.904,0.902, LSTM (bi-directional),0.902,0.905,0.908,0.907, Naive Bayes,0.862,0.843,0.876,0.858, Decision Tree,0.836,0.823,0.836,0.828","The table shows the performance results of five different models based on evaluation metrics - Accuracy, Precision, Recall, and F1-score. Models include BERT-base-uncased, LSTM (uni-directional), LSTM (bi-directional), Naive Bayes, and Decision Tree. Interestingly, the performance of Naive Bayes is comparatively lower than the other models, which might be due to its independence assumptions. Decision Tree also has a lower performance on accuracy and F1-score. Both LSTM models outperformed the BERT model in most of the performance metrics, with LSTM (bi-directional) being the best performing model in this evaluation."
88,"caption: Model performance results for different models on evaluation metrics based on a binary classification task.table: Model,Accuracy,F1-score,Precision,Recall, SVM with RBF Kernel,0.875,0.865,0.879,0.854, Random Forest,0.891,0.877,0.898,0.857, K-Nearest Neighbors,0.820,0.754,0.871,0.657, Gradient Boosting,0.905,0.891,0.909,0.874","The table presents the evaluation results of four different models on multiple evaluation metrics in a binary classification task. The models are SVM with RBF Kernel, Random Forest, K-Nearest Neighbors, and Gradient Boosting. The evaluation metrics are accuracy, F1-score, precision, and recall. The table shows that Gradient Boosting is the top-performing model based on all the evaluation metrics, where it achieved an accuracy of 0.905, F1-score of 0.891, precision of 0.909, and recall of 0.874. Random Forest is the second-best model followed by SVM with RBF Kernel, and K-Nearest Neighbors is the worst-performing model among the evaluated models."
89,"caption: Table 4: Performance results of different machine learning models on a binary classification dataset.table: Model,Precision,Recall,F1-score,ROC-AUC, SVM,0.85,0.82,0.84,0.78, KNN,0.80,0.81,0.80,0.75, MLP,0.88,0.87,0.88,0.83, RF,0.91,0.92,0.91,0.89, XGB,0.87,0.89,0.87,0.87","Table 4 shows the performance results of five different machine learning models on a binary classification dataset using multiple evaluation metrics including precision, recall, F1-score, and ROC-AUC. The SVM model achieved the highest precision score (0.85) whereas the Random Forest model achieved the highest recall (0.92), F1-score (0.91), and ROC-AUC (0.89) scores. Interestingly, the MLP model achieved the highest precision-recall balance score with a precision of 0.88 and a recall of 0.87, and the XGB model achieved the highest balanced F1-score of 0.87. Overall, the Random Forest model may be the best-performing model for this dataset due to its high recall and F1-score."
90,"caption: Performance evaluation of different models using multiple metrics on a binary classification task.table: Model,Accuracy,Precision,Recall,F1-Score, LR,0.897,0.856,0.908,0.881, SVM,0.853,0.810,0.859,0.834, RF,0.910,0.878,0.924,0.898, ANN,0.912,0.880,0.926,0.900","The table summarizes the performance results for four different models (LR, SVM, RF, and ANN) on a binary classification task. The evaluation metrics used in the table are accuracy, precision, recall, and F1-score. From the table, we can observe that the ANN and RF models achieved the highest accuracy of 0.912 and 0.910 respectively, while the SVM model achieved the lowest accuracy of 0.853. In terms of precision, the RF model achieved the highest score of 0.878, while the LR model achieved the lowest score of 0.856. The recall and F1-score results were consistent with the accuracy and the RF model achieved the highest score in both metrics. Therefore, based on the table, we can conclude that the RF model outperformed the other models in this binary classification task."
91,"caption: Table 4: Model evaluation results using various metricstable: Model,Accuracy,F1-Score,Precision,Recall, Model 1,0.74,0.68,0.83,0.57, Model 2,0.81,0.74,0.79,0.69, Model 3,0.78,0.71,0.86,0.61, Model 4,0.83,0.78,0.82,0.73, Model 5,0.82,0.75,0.88,0.65","Table 4 shows the evaluation result of five different models using various metrics such as accuracy, F1-Score, precision, and recall. Based on the table, Model 4 demonstrates the highest accuracy among all models with 0.83. However, when considering F1-Score, Model 4 still outperforms the other models with a score of 0.78, closely followed by Model 2 which attains an F1-Score of 0.74. Interestingly, Model 5 shows superior performance in precision (0.88) to all other models, whereas Model 1 produced the lowest recall (0.57). The comparison of these models' results could help in choosing the best model for the specific context of the evaluation."
92,"caption: Performance comparison of different models based on multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.89,0.87,0.91,0.89, Decision Tree,0.83,0.80,0.88,0.84, Random Forest,0.94,0.94,0.95,0.94, Naive Bayes,0.79,0.72,0.89,0.80, K-Nearest Neighbor,0.88,0.86,0.87,0.87","Table presents the performance comparison of five models: Logistic Regression, Decision Tree, Random Forest, Naive Bayes, and K-Nearest Neighbor based on four evaluation metrics: Accuracy, Precision, Recall, and F1-Score. Interestingly, Random Forest achieved the highest accuracy of 0.94, precision of 0.94, and F1-Score of 0.94. Logistic Regression and K-Nearest Neighbor also achieved high accuracy and F1-Score metrics, while Decision Tree performed comparatively poorly. Naive Bayes achieved the lowest accuracy and F1-Score but performed well in terms of recall. Thus, Random Forest may be considered the best-performing model among the tested models for this dataset based on multiple evaluation metrics."
93,"caption: Performance results for different classification models using various evaluation metricstable: Model,Accuracy,Kappa,Precision,Recall,F1-Score, Random Forest,0.897,0.473,0.725,0.512,0.566, Naive Bayes,0.789,0.317,0.584,0.517,0.524, Decision Tree,0.702,0.200,0.430,0.479,0.379, Support Vector Machine,0.834,0.417,0.657,0.531,0.584","Table shows the performance results for four different classification models including Random Forest, Naive Bayes, Decision Tree, and Support Vector Machine. The models were evaluated using various metrics including Accuracy, Kappa, Precision, Recall, and F1-Score. Interestingly, the highest accuracy was obtained by the Random Forest model with a score of 0.897, and the highest Kappa coefficient score was obtained by the Support Vector Machine model with 0.417. The highest precision score was obtained by Random Forest with 0.725, and the highest recall score was achieved by Naive Bayes with 0.517. Finally, Random Forest had the highest F1-score of 0.566. Overall, the Random Forest model appears to be the best-performing model based on the evaluated metrics."
94,"caption: Model performance on the classification task using different models and metrics.table: Model,Accuracy,F1 score,Recall,Precision, Logistic Regression,0.89,0.88,0.90,0.87, Decision Tree,0.85,0.82,0.87,0.79, Random Forest,0.92,0.91,0.93,0.89, Gradient Boosting,0.90,0.89,0.91,0.87, Support Vector Machine,0.88,0.86,0.89,0.83","Table presents the evaluation metrics results for five different models on a classification task, namely accuracy, F1 score, recall, and precision. Overall, Random Forest achieved the highest accuracy (0.92) and F1 score (0.91) among the tested models, followed by Gradient Boosting with 0.90 accuracy and 0.89 F1 score. Decision Tree had the lowest accuracy (0.85) and F1 score (0.82) compared to the other models. In terms of precision, Logistic Regression achieved the highest precision (0.87), followed by Random Forest with 0.89 precision. In terms of recall, Random Forest achieved the highest recall, with an average of 0.93. Therefore, Random Forest and Gradient Boosting models can be recommended for this classification task based on the evaluation metrics."
95,"caption: Performance results of different models with multiple evaluation metrics.table: Model Name,Accuracy,Precision,Recall,F1-Score,AUC-ROC, Model 1,0.89,0.82,0.68,0.74,0.92, Model 2,0.91,0.84,0.71,0.77,0.93, Model 3,0.87,0.79,0.63,0.69,0.90, Model 4,0.92,0.88,0.76,0.80,0.94, Model 5,0.90,0.87,0.72,0.78,0.95, Model 6,0.93,0.90,0.78,0.82,0.96","The table shows the performance metrics of six different models based on the evaluation metrics accuracy, precision, recall, F1-score, and AUC-ROC. Model 4 appears to have the highest accuracy and precision scores, indicating a strong ability to correctly predict the positive class. Additionally, Model 6 appears to have the highest recall, F1-score, and AUC-ROC scores, which indicate a better overall predictive performance on the dataset. Overall, Model 4 and Model 6 appear to be the best performers, but the choice of the best model may depend on the specific aims and goals of the study."
96,"caption: Table 4: Performance metrics of different models on classification task.table: Model,Accuracy,Precision,Recall,F1-score, Decision Tree,0.75,0.80,0.75,0.74, Random Forest,0.79,0.81,0.78,0.79, SVM,0.66,0.70,0.65,0.66, Logistic Reg.,0.74,0.76,0.74,0.74, Naive Bayes,0.65,0.69,0.65,0.64","Table 4 presents the evaluation results of five different models on a classification task. The table reports accuracy, precision, recall, and F1-score performance metrics for each model, indicating how well the models performed relative to each other on the task. Interestingly, Random Forest outperforms the other models in accuracy, precision, and F1-score, whereas Decision Tree achieves the highest recall score. SVM and Naive Bayes models demonstrate inferior performance when compared to other models across all metrics. The table provides insights into the relative strengths and weaknesses of the different models and can be used to guide the selection of models for this classification task."
97,"caption: Performance results of different models based on multiple evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, Model 1,0.92,0.95,0.93,0.97, Model 2,0.89,0.91,0.88,0.95, Model 3,0.93,0.94,0.92,0.97, Model 4,0.86,0.88,0.85,0.92, Model 5,0.90,0.93,0.91,0.96","The table presents the performance results of five models based on multiple evaluation metrics including Accuracy, F1-score, Precision, and Recall. Model 1 achieved the highest accuracy (0.92) and F1-score (0.95) while Model 4 achieved the lowest accuracy (0.86) and F1-score (0.88). Interestingly, Model 2 achieved a lower accuracy and F1-score than Model 5, but achieved a higher precision (0.88) than all other models. Model 3 achieved the highest Precision (0.92) and Recall (0.97) scores. These results suggest that the different models vary in their overall performance and individual metric performance, so model selection should depend on specific project requirements and evaluation criteria."
98,"caption: Table 4: Performance Evaluation Metrics of Different Models.table: Model,Accuracy,Precision,Recall,F1-Score,Specificity, Model A,80.7%,0.82,0.75,0.78,0.87, Model B,79.2%,0.76,0.82,0.79,0.66, Model C,84.1%,0.85,0.83,0.84,0.87, Model D,82.5%,0.81,0.80,0.81,0.84","Table 4 reports the results of performance evaluation metrics, including Accuracy, Precision, Recall, F1-Score, Specificity, for four different models (Model A, Model B, Model C, and Model D). The metrics reveal the effectiveness of the models in predicting the target variable on a particular dataset, with higher values indicating better performance. Interestingly, Model C shows the highest accuracy of 84.1%, outperforming the other models. Meanwhile, Model A has the highest precision of 0.82, while Model B has the highest recall of 0.82. Model D has a balanced F1-score and also the highest specificity of 0.84. Based on the overall performance with respect to all the metrics, Model C is the best-performing model."
99,"caption: Table 4: Model Performance on the Evaluation Metricstable: Model Name,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.81,0.80,0.79,0.82, Random Forest,0.88,0.87,0.88,0.86, Naive Bayes,0.71,0.70,0.65,0.76, Support Vector,0.79,0.78,0.77,0.79, Multi-layer Perceptron,0.82,0.81,0.80,0.82","Table 4 summarizes the model performance on multiple evaluation metrics for five different models: Logistic Regression, Random Forest, Naive Bayes, Support Vector, and Multi-layer Perceptron. The performance metrics include Accuracy, F1-Score, Precision, and Recall. Interestingly, Random Forest had the highest Accuracy and F1-Score. However, Naive Bayes had the lowest Accuracy and F1-Score. The Precision values of Logistic Regression and Random Forest are identical to each other, indicating that they are the best-performing models in terms of identifying true positives. Meanwhile, all models produced similar Recall values, indicating that they perform similarly in identifying true positives. Overall, Random Forest and Logistic Regression may be the best models among the tested models for this dataset."
100,"caption: Table 4 - Model evaluation metricstable: Model,Accuracy,F1 Score,AUC,Precision,Recall, Model A,0.85,0.86,0.79,0.89,0.84, Model B,0.82,0.83,0.77,0.87,0.81, Model C,0.87,0.84,0.82,0.93,0.77, Model D,0.81,0.81,0.79,0.85,0.78","Table 4 presents the model evaluation metric results for four different models, including accuracy, F1 score, AUC, precision, and recall. Model A achieves the highest accuracy (0.85), F1 score (0.86), and precision (0.89), while Model C demonstrates superior performance in AUC (0.82) and recall (0.77). Moreover, Model B shows the lowest performance in all evaluation metrics, while Model D presents slightly lower accuracy (0.81) and AUC (0.79), but similar precision (0.85) and recall (0.78) compared to the other models. Therefore, depending on the specific evaluation metric, different models might be more suitable for different applications."
101,"caption: Performance results of different models based on various evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Model A,0.80,0.78,0.85,0.73, Model B,0.83,0.81,0.88,0.75, Model C,0.82,0.80,0.84,0.77, Model D,0.85,0.83,0.87,0.79, Model E,0.81,0.79,0.83,0.76","The presented table shows the accuracy, F1 score, precision, and recall of five different models (Model A-E). Model D shows the highest accuracy and F1 score (0.85 and 0.83, respectively), while Model B has the highest precision (0.88). Model D also has the highest precision-recall balance with 0.87 precision and 0.79 recall. However, Model B has lower recall but higher overall classification performance. Considering all the evaluation metrics together, it can be concluded that Model D has better overall performance among the models tested."
102,"caption: Performance metrics of different models on the datasettable: Model,Accuracy,F1 Score,AUC Score, Logistic Regression,0.78,0.75,0.83, Random Forest,0.85,0.82,0.89, K-Nearest Neighbor,0.80,0.77,0.85, Support Vector Machine,0.83,0.80,0.88","The table shows the performance metrics of four different models on a given dataset. The evaluated models include Logistic Regression, Random Forest, K-Nearest Neighbor, and Support Vector Machine. The evaluation metrics are Accuracy, F1 Score, and AUC Score. The Random Forest model performs the best in all the three metrics with Accuracy of 0.85, F1 Score of 0.82, and AUC Score of 0.89. Though, Logistic Regression has the lowest score in all the three metrics, the results indicate that the Random Forest model is the most promising among the investigated models."
103,"caption: Model performance evaluation using multiple metricstable: Model,Accuracy,Precision,Recall,F1 score, Logistic regression,0.75,0.65,0.80,0.72, Decision trees,0.80,0.73,0.85,0.79, Random forest,0.82,0.74,0.89,0.81, Support Vector Machine,0.78,0.69,0.82,0.75","Table presents the evaluation results of four different models on a binary classification dataset using multiple evaluation metrics. The models considered in the evaluation are Logistic regression, Decision trees, Random forest, and Support Vector Machine. The evaluation metrics considered in the table are Accuracy, Precision, Recall, and F1 score. Interestingly, Random forest outperformed the other models in all the evaluation metrics with an accuracy of 0.82, precision of 0.74, recall of 0.89, and F1 score of 0.81. Therefore, Random forest can be considered the best model for this binary classification dataset."
104,"caption: Performance comparison of different models on the classification task.table: Model,Accuracy,Recall,Precision,F1-Score,ROC-AUC, Model A,0.89,0.90,0.88,0.89,0.80, Model B,0.92,0.92,0.93,0.92,0.87, Model C,0.87,0.86,0.88,0.87,0.76, Model D,0.91,0.92,0.90,0.91,0.85, Model E,0.93,0.93,0.94,0.93,0.90","The table presents the model comparison results on a classification task, using a range of evaluation metrics such as accuracy, recall, precision, F1-score, and ROC-AUC. Model E has the highest performance among all models, achieving an accuracy of 0.93 and an ROC-AUC of 0.90. Model B is also a high-performing model, achieving an accuracy of 0.92 and the highest values for recall, precision, and F1-score. Model C, on the other hand, presents the lowest overall performance, achieving an accuracy of 0.87 and relatively low values for all the other metrics. Overall, this table reveals interesting insights about the performance of various models on a classification task, giving researchers useful information for selecting the best model for their particular study."
105,"caption: Table 1: Performance of Different Models on the Datasettable: Model,Accuracy,AUC,F1-Score, Logistic Regression,0.85,0.92,0.86, Decision Tree,0.80,0.75,0.82, K-Nearest Neighbor,0.81,0.87,0.81, Random Forest,0.92,0.95,0.93, Support Vector Machine,0.88,0.93,0.90","Table 1 shows the accuracy, AUC, and F1-Score for five different models on a given dataset. Interestingly, the Random Forest model significantly outperforms all the other models with an accuracy of 0.92, AUC of 0.95, and F1-score of 0.93. Logistic Regression and SVM models have a similar accuracy and AUC, but SVM shows a better F1-score. Decision Tree model shows the poorest results in the evaluation metrics, while K-Nearest Neighbor performs slightly better than Decision Tree on accuracy and F1-Score but worse on AUC. Overall, Random Forest appears to be the best model on the evaluated dataset based on the evaluation metrics."
106,"caption: Performance results of various models evaluated by different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.85,0.87,0.83,0.85, Random Forest,0.93,0.93,0.91,0.92, SVM,0.87,0.89,0.86,0.87, XGBoost,0.95,0.95,0.94,0.95, MLP,0.92,0.92,0.90,0.91","The table shows the performance results of five different models based on various evaluation metrics, including accuracy, precision, recall, and F1-score. Overall, all the models demonstrated impressive performance across the different metrics, indicating their effectiveness in the context of the study. In terms of accuracy, XGBoost was the top-performing model, achieving an accuracy of 0.95. The Random Forest model, on the other hand, displayed the best performance across precision, recall, and F1-score metrics. Overall, the results highlight the effectiveness and potential of machine learning models in this area of study."
107,"caption: Model evaluation results based on multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.82,0.82,0.83,0.82, Random Forest,0.85,0.85,0.89,0.87, K-NN,0.75,0.75,0.77,0.76, Naive Bayes,0.78,0.78,0.82,0.80, Decision Trees,0.81,0.81,0.81,0.80","Table presents the model evaluation results based on different evaluation metrics for various classification models. The table includes Accuracy, Precision, Recall, and F1-Score. The models evaluated in this table include SVM, Random Forest, K-NN, Naive Bayes, and Decision Trees. Interestingly, Random Forest outperformed the other models when considering Recall with a score of 0.89 and F1-Score with a score of 0.87. However, SVM outperformed all other models in terms of Accuracy with a score of 0.82. Based on the evaluation metrics used and the specific application, different models may be preferred."
108,"caption: Comparison of the model performance using different evaluation metrics.table: Model,Precision,Recall,F1 Score,PR-AUC,ROC-AUC, SVM with RBF kernel,0.75,0.83,0.78,0.81,0.89, KNN,0.82,0.92,0.87,0.88,0.84, Decision Tree,0.70,0.85,0.76,0.72,0.68, Random Forest,0.84,0.91,0.87,0.86,0.89, AdaBoost,0.81,0.89,0.85,0.83,0.84","The table presents a comparison of five different models based on multiple evaluation metrics. The evaluation metrics include Precision, Recall, F1 Score, PR-AUC, and ROC-AUC. These performance metrics provide important insights into different aspects of model performance. The SVM with RBF kernel model achieved the highest ROC-AUC score of 0.89. The Random Forest model achieved the highest PR-AUC score of 0.86. The KNN model achieved high scores in Precision, Recall, and F1 score of 0.82, 0.92 and 0.87, respectively. The results demonstrate that different models have different strengths and weaknesses when evaluated using different evaluation metrics, and further analysis is needed to determine the best performing model for the specific use case."
109,"caption: Performance comparison of different classification models using various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,89.2,91.1,87.5,89.2, Random Forest,91.5,92.8,90.9,91.8, Decision Tree,85.1,87.9,82.3,84.2, Naive Bayes,78.6,75.2,83.9,79.3, Neural Network,90.8,93.5,88.3,90.7","The table illustrates the performance comparison of five different classification models, namely: SVM, Random Forest, Decision Tree, Naive Bayes, and Neural Network using multiple evaluation metrics, including Accuracy, Precision, Recall, and F1-Score. While Random Forest outperforms other models in Accuracy, Precision, Recall, and F1-Score, SVM and Neural Network perform well in most of the evaluation metrics. However, Naive Bayes has the lowest performance in terms of Accuracy and F1-score while still having a relatively high Recall score. This suggests that different models specialize in different performance metrics, and one should choose the model based on the evaluation metric of interest."
110,"caption: Table 4: Performance results of different classification models based on various evaluation metrics.table: Model Name,F1-Score,Precision,Recall,AUC, Model 1,0.74,0.78,0.73,0.83, Model 2,0.69,0.71,0.68,0.73, Model 3,0.89,0.83,0.96,0.93, Model 4,0.77,0.82,0.76,0.84, Model 5,0.82,0.88,0.80,0.87","Table 4 presents the performance results of different classification models based on various evaluation metrics. The table shows the F1-Score, Precision, Recall, and AUC values for five different models (Model 1, Model 2, Model 3, Model 4, and Model 5). Interestingly, Model 3 appears to be the best-performing model across all of the metrics, with the highest F1-Score of 0.89, highest AUC of 0.93, Recall of 0.96, and lower Precision score of 0.83. Model 5 also performed relatively well with a F1-Score of 0.82, Precision of 0.88, Recall of 0.80, and AUC of 0.87. Overall, the table shows that there seems to be a tradeoff between the precision and recall values, with Model 3 performing well in recall but having a lower precision score."
111,"caption: The performance results of four different models based on different evaluation metrics.table: Model,F1-score,Precision,Recall,AUC-ROC,Accuracy, Model1,0.86,0.92,0.81,0.91,0.89, Model2,0.88,0.9,0.87,0.93,0.91, Model3,0.81,0.84,0.78,0.88,0.87, Model4,0.92,0.91,0.93,0.95,0.94","The table presents the evaluation metrics including F1-score, precision, recall, AUC-ROC, and accuracy for four different models. Model1 has an F1-score of 0.86, precision of 0.92, recall of 0.81, AUC-ROC of 0.91, and accuracy of 0.89. Model2 has the highest F1-score of 0.88 and AUC-ROC of 0.93, whereas Model4 outperforms the other models with precision of 0.91, recall of 0.93, and accuracy of 0.94. Interestingly, Model3 underperforms in all of the metrics compared to the other models. Overall, the table provides useful insights into the performance of these models on the given evaluation metrics."
112,"caption: Model performance of different classifiers based on accuracy, F1-Score, Precision, and Recall.table: Model,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.84,0.82,0.89,0.77, Decision Tree,0.78,0.77,0.82,0.73, Random Forest,0.87,0.86,0.88,0.85, Gradient Boosting Classifier,0.89,0.88,0.89,0.88, Naive Bayes,0.72,0.68,0.80,0.59, Support Vector Machine,0.82,0.81,0.85,0.78","The table reflects the performance results of six different classifiers on four evaluation metrics. The noted models are Logistic Regression, Decision Tree, Random Forest, Gradient Boosting Classifier, Naive Bayes, and Support Vector Machine. The performance of each model is determined using the Accuracy, F1-Score, Precision, and Recall metrics. Interestingly, the best-performing model based on accuracy is Gradient Boosting Classifier with a score of 0.89, while the worst-performing is Naive Bayes with a score of 0.72. However, when considering F1-Score, Precision, Recall, and the balancing of the classes, Random Forest appears to be the best-performing model with a score of 0.86 for F1-Score, 0.88 for Precision, and 0.85 for Recall."
113,"caption: Table 4: Model evaluation metrics for different classification models.table: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.83,0.82,0.78,0.87, Random Forest,0.85,0.84,0.80,0.88, Support Vector Machine,0.81,0.79,0.74,0.85, K-Nearest Neighbors,0.79,0.78,0.72,0.85, Gradient Boosting,0.88,0.87,0.86,0.87","Table 4 presents the results of model evaluation metrics, including accuracy, F1-score, precision, and recall for five different classification models - Logistic Regression, Random Forest, Support Vector Machine, K-Nearest Neighbors, and Gradient Boosting. Interestingly, Gradient Boosting yields the highest accuracy of 0.88 among the tested models. On the other hand, despite having the lowest accuracy among all models, K-Nearest Neighbors exhibits a relatively high recall rate of 0.85. Overall, this table provides a useful comparison of different classification models' performance, where Gradient Boosting outperforms all other models in accuracy."
114,"caption: Table 4. Classification performance of various models on the dataset.table: Model,Precision,Recall,F1-score,Accuracy, LR,0.81,0.75,0.78,0.79, SVM,0.82,0.78,0.80,0.81, RF,0.84,0.81,0.82,0.83, XGBoost,0.86,0.83,0.84,0.85","Table 4 reports the evaluation metrics for various classification models including Logistic Regression (LR), Support Vector Machine (SVM), Random Forest (RF), and XGBoost. The metrics include precision, recall, F1-score, and accuracy. Among all models, XGBoost achieved the highest precision, recall, F1-score, and accuracy, indicating its overall best performance. The RF also showed a fair performance in comparison to other models. The table suggests that XGBoost and RF both could be a plausible solution for classification on the given dataset."
115,"caption: Performance comparison of different models on the prediction task.table: Model,Accuracy,Precision,Recall,F1, Logistic Regression,0.85,0.75,0.76,0.75, Decision Tree,0.75,0.66,0.69,0.67, Random Forest,0.90,0.85,0.85,0.85, XGBoost,0.91,0.88,0.88,0.88, Multi-layer Perceptron,0.89,0.82,0.81,0.81","The table compares the performance of five models on a prediction task using multiple evaluation metrics, including Accuracy, Precision, Recall, and F1-score. The tested models are Logistic Regression, Decision Tree, Random Forest, XGBoost, and Multi-layer Perceptron. From the table, XGBoost performs the best across all four metrics with an accuracy of 0.91 and 0.88 precision, recall, and F1-score. On the other hand, Decision Tree performs the worst with an accuracy of 0.75 and F1-score of 0.67. The results of this experiment suggest that XGBoost may be the best model for this prediction task."
116,"caption: Performance comparison of different models using multiple evaluation metrics.table: Model,Accuracy,F1-score,AUC,Precision,Recall, Model 1,0.85,0.83,0.72,0.91,0.79, Model 2,0.87,0.86,0.78,0.89,0.82, Model 3,0.82,0.81,0.70,0.88,0.76, Model 4,0.89,0.88,0.80,0.91,0.85, Model 5,0.84,0.82,0.73,0.87,0.79","This table presents a performance comparison of five different models using various evaluation metrics, including accuracy, F1-score, AUC, precision, and recall. Model 4 demonstrated the highest accuracy score (0.89) and F1-score (0.88), indicating its strong overall performance. Model 2 also performed well, with an accuracy of 0.87 and an F1-score of 0.86. In terms of AUC, Model 4 performed the best (0.80), followed closely by Model 2 (0.78). When considering precision and recall together, Model 1 had the highest precision score (0.91), and Model 4 had the highest recall score (0.85). Overall, based on the multiple evaluation metrics, Model 4 appears to be the best-performing model among the tested models."
117,"caption: Classification Model Performance Resultstable: Model,Acc,F1-score,Precision,Recall, Logistic Regression,0.87,0.86,0.85,0.87, Support Vector Machine,0.88,0.87,0.86,0.88, Naive Bayes,0.84,0.80,0.83,0.77, Random Forest,0.91,0.90,0.91,0.90, Multi-layer Perceptron,0.86,0.85,0.84,0.86","Table 1 presents the performance results of five classification models on a given dataset using four evaluation metrics: accuracy, F1-score, precision, and recall. The classification models evaluated include Logistic Regression, Support Vector Machine, Naive Bayes, Random Forest, and Multi-layer Perceptron. Interestingly, Random Forest has the best performance result with the highest score for the four evaluation metrics. Logistic Regression, SVM, and MLP are all close in performance trailing the leading model closely. Naive Bayes has the worst performance, with the lowest scores for all four evaluations, indicating this model is the least effective in classifying instances in the dataset."
118,"caption: Performance results of different ML models based on different evaluation metrics.table: Model,F1-score,AUC,Accuracy, Model A,0.91,0.83,0.87, Model B,0.92,0.85,0.83, Model C,0.93,0.80,0.85, Model D,0.91,0.87,0.89, Model E,0.90,0.82,0.88","The table displays the performances of five different machine learning models based on three different evaluation metrics: F1-score, AUC and Accuracy. Model C has the highest F1-score of 0.93, whereas Model B has the highest AUC result of 0.85. Model D, on the other hand, has the highest accuracy of 0.89. Model A and Model E have relatively similar results across all the metrics. In summary, one cannot say that one model is better than the other, but rather their performance varies based on the given evaluation metric. Therefore, it is better to select the model based on its intended use and potential benefits."
119,"caption: Performance metrics of different models.table: Model,Precision,Recall,F1-Score,AUC, Logistic Regression,0.82,0.75,0.78,0.91, Support Vector Machine,0.87,0.69,0.77,0.88, Decision Tree,0.75,0.65,0.68,0.78, Random Forest,0.91,0.88,0.89,0.95, XGBoost,0.89,0.86,0.87,0.94","The table shows the performance metrics, including Precision, Recall, F1-Score, and AUC, of five different models: Logistic Regression, Support Vector Machine, Decision Tree, Random Forest, and XGBoost. Interestingly, Random Forest and XGBoost have the highest AUC, with 0.95 and 0.94, respectively. Additionally, Random Forest outperforms all models in terms of Precision and Recall, with values of 0.91 and 0.88, respectively. Meanwhile, the support vector machine performs well in terms of Precision, with 0.87, but has a lower Recall, with 0.69. Decision Tree shows poor performance for all metrics compared to the other models. Overall, Random Forest appears to be the best-performing model among the tested models based on the reported metrics."
120,"caption: Performance metrics of different models on the dataset.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.85,0.83,0.82,0.85, Logistic Regression,0.81,0.80,0.79,0.81, Decision Tree,0.76,0.74,0.72,0.76, Random Forest,0.90,0.88,0.87,0.90","The table reports the performance metrics of four different models on a given dataset. The models were evaluated using the accuracy, F1-score, precision, and recall evaluation metrics. Among the tested models, Random Forest achieved the highest accuracy score of 0.90, whereas Decision Tree achieved the lowest accuracy score of 0.76. The F1-score for Random Forest was also the highest with a score of 0.88, whereas Decision Tree had the lowest F1-score of 0.74. The Precision and Recall scores for each model also followed the same trend in performance with Random Forest scoring the highest, and Decision Tree scoring the lowest. These results indicate that Random Forest may be the best-performing model among those tested on this dataset."
121,"caption: Model performance results based on different evaluation metricstable: Model,F1-score,Accuracy,Precision,Recall,AUC, SVM,0.85,0.91,0.86,0.84,0.93, Logistic Regression,0.80,0.88,0.79,0.81,0.91, Random Forest,0.90,0.89,0.89,0.91,0.93, Naive Bayes,0.77,0.85,0.76,0.78,0.89","The table presents performance results of multiple models on different evaluation metrics. The table includes F1-Score, Accuracy, Precision, Recall, and AUC. Four models are being compared in this table, which are SVM, Logistic Regression, Random Forest, and Naive Bayes. Interestingly, SVM demonstrated the highest AUC score of 0.93 among all models included in the table, implying the ability of SVM in separating the classes. Random Forest showed the highest F1-score among all models, suggesting the model can achieve better balance between precision and recall. Overall, these results suggest that the type of evaluation metric and the model selection play an important role in developing an accurate model."
122,"caption: Model performance using different evaluation metrics.table: Model,Metric,Result, Logistic,Accuracy,0.82, F1 score,0.77, AUC,0.89, Random Forest,Accuracy,0.87, F1 score,0.84, AUC,0.92, XGBoost,Accuracy,0.89, F1 score,0.86, AUC,0.94, Support Vector,Accuracy,0.78, Machine,F1 score,0.71, AUC,0.86","The table provides a comparison of multiple machine learning models based on different evaluation metrics like Accuracy, F1-score, and AUC. The models selected for the comparison are Logistic regression, Random Forest, XGBoost, and Support Vector Machine. The table shows that XGBoost outperformed the other models in every evaluation metric, scoring an accuracy of 0.89, F1 score of 0.86, and AUC of 0.94. Random Forest also performed well with an accuracy of 0.87, F1-score of 0.84, and AUC of 0.92. Meanwhile, Logistic Regression and Support Vector Machine models scored lower in all three metrics. Overall, XGBoost may be the best choice for the considered dataset while Random Forest can be an alternative if a higher accuracy is required."
123,"caption: Performance results of different models based on various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score,PR-AUC,ROC-AUC, Logistic Regression,0.91,0.42,0.60,0.49,0.79,0.96, Decision Tree,0.88,0.39,0.42,0.40,0.58,0.68, Random Forest,0.94,0.68,0.74,0.71,0.88,0.93, XGBoost,0.93,0.45,0.79,0.56,0.85,0.91, Support Vector Machine,0.90,0.30,0.87,0.44,0.84,0.93","Table above reports the performance of five models: Logistic regression, decision tree, Random forest, XGBoost, and support vector machine, based on various evaluation metrics. These metrics are accuracy, precision, recall, F1-Score, PR-AUC, and ROC-AUC. Interestingly, Random forest has the best accuracy, precision, recall, and F1-Score but is outperformed by XGBoost and support vector machine in terms of PR-AUC and ROC-AUC, respectively. Thus, XGBoost and support vector machine might be suitable models for scenarios where PR-AUC and ROC-AUC have high priority over the other metrics."
124,"caption: Performance metrics of different models using accuracy, precision, recall, and F1-score.table: Model,Accuracy,Precision,Recall,F1-score, LR,0.84,0.85,0.71,0.77, SVM,0.87,0.89,0.72,0.78, RF,0.89,0.91,0.79,0.84, MLP,0.88,0.88,0.81,0.83, GB,0.90,0.91,0.81,0.86","The table shows the performance metrics of various models using accuracy, precision, recall, and F1-score. The models in the table include LR, SVM, RF, MLP, and GB. Interestingly, GB has the highest accuracy with a score of 0.90, while RF has the highest precision and recall with scores of 0.91 and 0.79, respectively. MLP has the highest F1-score with a score of 0.83. It is important to consider all four performance metrics in order to determine the best-performing model for the given task."
125,"caption: Table 4: Performance of models evaluated on accuracy, precision, recall, and F1-score.table: Model Name,Accuracy,Precision,Recall,F1-Score, Model 1,0.95,0.96,0.94,0.95, Model 2,0.93,0.94,0.95,0.94, Model 3,0.97,0.98,0.97,0.97, Model 4,0.92,0.92,0.93,0.92, Model 5,0.96,0.97,0.96,0.96","Table 4 presents the performance of five different models evaluated on multiple metrics: accuracy, precision, recall, and F1-score. The models were trained on a specific dataset and evaluated using a 10-fold cross-validation approach. Model 3 shows the highest accuracy with 0.97, while the precision metric results show that models 3 and 5 outperform the other models. Regarding the recall of the model, model 2 shows the best results with 0.95, while model 1 has the lowest recall score. The F1-score, which is the harmonic average of precision and recall, indicates that model 5 performs the best with a score of 0.96. Overall, each metric results in different rankings, showcasing the importance of considering multiple metrics when evaluating a model's performance."
126,"caption: Performance results for different models on the classification task.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.82,0.75,0.76,0.74, Logistic Regression,0.81,0.74,0.73,0.76, Decision Tree,0.72,0.63,0.61,0.66, Random Forest,0.86,0.78,0.79,0.77, Gradient Boosting,0.85,0.77,0.76,0.79","The above table presents the performance results of various models on a classification task. The models include SVM, Logistic Regression, Decision Tree, Random Forest, and Gradient Boosting. The evaluation metrics considered for each model are Accuracy, F1-score, Precision, and Recall. Interestingly, Random Forest and Gradient Boosting outperformed the other models in terms of Accuracy, F1-score, and Recall. On the other hand, SVM had the highest Precision among all other models. It is important to consider which evaluation metrics are most important for a specific task when selecting the best model."
127,"caption: Performance evaluation results for different modelstable: Model,Accuracy,F1-score,Precision,Recall, Random Forest,0.91,0.89,0.92,0.86, SVM,0.87,0.80,0.87,0.75, Logistic Reg.,0.83,0.79,0.82,0.76, K-NN,0.84,0.81,0.82,0.82","Table 1 presents the performance evaluation results for four different models, Random Forest, SVM, Logistic Regression, and K-NN, based on four evaluation metrics, Accuracy, F1-score, Precision, and Recall. Interestingly, Random Forest performed the best among the four models in all evaluation metrics except accuracy, which SVM outperformed all models. K-NN model has the highest precision score, while Logistic Regression model has the highest recall score. These observations suggest that the Random Forest model is the best-performing model in this experiment. However, the final decision may depend on the specific goals and requirements of the application."
128,"caption: Model performance comparison using different evaluation metricstable: Model Name,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.78,0.76,0.68,0.87, Decision Tree,0.77,0.73,0.74,0.72, Random Forest,0.81,0.79,0.83,0.76, Support Vector Machine,0.79,0.77,0.73,0.81, Naive Bayes,0.72,0.69,0.58,0.84","The above table presents the performance comparison of five different models using different evaluation metrics. The metrics used to evaluate each model are accuracy, F1 score, precision, and recall. Interestingly, Random Forest outperformed the other models in accuracy, F1 score, and precision with values of 0.81, 0.79, and 0.83, respectively. However, in terms of recall, Support Vector Machine performed the best with a value of 0.81. Naive Bayes had the lowest performance for all four evaluation metrics, highlighting that this model may not be the best choice for this dataset."
129,"caption: Model performance measures of different classification algorithms on the test datasettable: Model name,Accuracy,AUC,F1-score, SVM,0.804,0.722,0.764, KNN,0.782,0.626,0.734, Decision Tree,0.753,0.709,0.688, XGBoost,0.819,0.787,0.786, Random Forest,0.845,0.812,0.825","The table shows the performance of five different classification algorithms namely SVM, KNN, Decision Tree, XGBoost, and Random Forest on the test dataset. The evaluation metrics used are accuracy, AUC, and F1-score. Interestingly, the Random Forest model has achieved the highest accuracy, AUC, and F1-score compared to other models. The XGBoost algorithm has also performed well with an accuracy of 0.819, AUC of 0.787, and an F1-score of 0.786. On the other hand, the KNN model has performed poorly compared to the other algorithms, with an accuracy of 0.782, AUC of 0.626, and an F1-score of 0.734. Overall, the Random Forest model seems to be the best performing model among the five different algorithms evaluated in this study."
130,"caption: Performance of different models on evaluation metricstable: Model,Precision,Recall,F1 Score,Accuracy, Logistic Regression,0.68,0.64,0.66,0.75, K-Nearest Neighbors,0.75,0.68,0.71,0.80, Decision Tree,0.76,0.70,0.73,0.81, Random Forest,0.81,0.77,0.79,0.85, XGBoost,0.82,0.79,0.80,0.86, Support Vector Machine,0.79,0.75,0.77,0.84","The above table displays the performance of multiple different models on various evaluation metrics, including precision, recall, F1 score, and accuracy. Six models are compared: Logistic Regression, K-Nearest Neighbors, Decision Tree, Random Forest, XGBoost, and Support Vector Machine. Among the models, XGBoost obtained the highest F1 score (0.80), while Random Forest achieved the highest precision (0.81) and accuracy (0.85). Moreover, K-Nearest Neighbors displayed the second-best performance on the evaluation metrics, while Logistic Regression and Support Vector Machine produced the lowest F1 score. These results can help researchers determine which model is the most suitable for their specific task."
131,"caption: Performance of Machine Learning Models on Predicting Student Performance.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.85,0.83,0.88,0.85, Decision Tree,0.79,0.76,0.78,0.77, Random Forest,0.92,0.91,0.94,0.92, Support Vector Machine,0.87,0.84,0.89,0.87, K-Nearest Neighbor,0.81,0.77,0.80,0.78","The above table shows the evaluation results of different machine learning models on predicting student performance. The models that were evaluated include Logistic Regression, Decision Tree, Random Forest, Support Vector Machine, and K-Nearest Neighbor. The evaluation metrics used in this study were Accuracy, Precision, Recall, and F1-Score. From the table, it can be observed that Random Forest performed best across all evaluation metrics, achieving an accuracy of 0.92, precision of 0.91, recall of 0.94, and F1-Score of 0.92. Logistic Regression was the second-best model performing in all metrics except recall where it achieved the same value as the best performing model (i.e., 0.88). Therefore, Random Forest can be considered the best model for predicting student performance in this study."
132,"caption: Model Performance Results for Multiple Evaluation Metricstable: Model,Accuracy,Precision,F1-Score,AUC-ROC, Model 1,0.83,0.78,0.80,0.89, Model 2,0.88,0.72,0.82,0.95, Model 3,0.90,0.89,0.90,0.97, Model 4,0.85,0.80,0.84,0.91, Model 5,0.92,0.93,0.93,0.99","Table shows the accuracy, precision, F1-Score, and AUC-ROC performance metrics for five models (Model 1 through Model 5). Accuracy ranges from 0.83 for Model 1 to 0.92 for Model 5, indicating the percent of correct predictions. Precision ranges from 0.72 for Model 2 to 0.93 for Model 5, indicating the percent of true positive classifications relative to all positive classifications. F1-Score ranges from 0.80 for Model 1 to 0.93 for Model 5, indicating the harmonic mean of precision and recall. Notably, Model 5 achieved the highest performance results for all metrics, indicating its potential superiority to the other models."
133,"caption: Model performance on different evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.78,0.74,0.67,0.84, KNN,0.75,0.68,0.64,0.73, Random Forest,0.82,0.79,0.72,0.89, XGBoost,0.84,0.81,0.74,0.90","The performance results of four different models, namely SVM, KNN, Random Forest, and XGBoost, are shown in the table based on four evaluation metrics- accuracy, F1-Score, Precision, and Recall. Random forest achieved the highest accuracy score of 0.82, while XGBoost achieved the highest accuracy score of 0.84. Both Random forest and XGBoost models outperformed SVM and KNN models in all evaluation metrics. The F1-Score measure of models indicates the weighted average of both precision and recall, which is an essential evaluation metric for classification problems. The random forest outperformed all other models when considering F1-Score, Precision, and Recall."
134,"caption: Table 4: Model performance of different evaluation metricstable: Model,Accuracy,F1 Score,Precision,Recall, Model A,0.85,0.87,0.89,0.85, Model B,0.88,0.90,0.91,0.89, Model C,0.84,0.85,0.90,0.81, Model D,0.90,0.92,0.93,0.91, Model E,0.86,0.88,0.91,0.85","Table 4 summarizes the performance of five different models on multiple evaluation metrics including accuracy, F1 score, precision, and recall. The table shows that Model D achieved the highest accuracy of 0.90. Moreover, Model D also had the highest F1 score, precision, and recall scores of 0.92, 0.93, and 0.91, respectively, outperforming the other models. Meanwhile, Model C had the lowest accuracy, F1 score, and recall of 0.84, 0.85, and 0.81, respectively, but had the highest precision score of 0.90, indicating that this model has low false-positive errors but high false-negative errors. Overall, the table demonstrates that different metrics may emphasize different aspects of model performance, and a comprehensive evaluation of multiple metrics may provide a more complete assessment of the model's performance."
135,"caption: Model performance results for different evaluation metricstable: Model,Precision,Recall,F1-score,ROC-AUC, LogReg,0.85,0.83,0.84,0.90, SVM,0.82,0.87,0.84,0.89, Random Forest,0.89,0.84,0.86,0.93, XGBoost,0.86,0.89,0.87,0.94, MLP,0.84,0.91,0.87,0.93","The table presents performance results for five different models evaluated on precision, recall, F1-score, and ROC-AUC. Interestingly, Random forest had the highest precision score of 0.89, and XGBoost had the highest ROC-AUC score of 0.94. MLP had the highest recall score of 0.91. When considering all evaluation metrics in conjunction, XGBoost outperformed all other models with an F1-score of 0.87 and ROC-AUC of 0.94. Therefore, XGBoost may be the best-performing model among the tested models for this dataset with these evaluation metrics."
136,"caption: Performance measures of different classification modelstable: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.87,0.89,0.88,0.88, Random Forest,0.90,0.91,0.91,0.91, Gradient Boosting,0.88,0.90,0.88,0.88, Support Vector Machine,0.83,0.84,0.83,0.83","Table 2 shows the performance measures of four different classification models. Each model's accuracy, precision, recall, and F1-Score are included. Random Forest obtained the highest values of accuracy, precision, recall, and F1-Score, with 0.90, 0.91, 0.91, and 0.91 respectively. Logistic Regression and Gradient Boosting reported slightly lower values compared to Random Forest, while Support Vector Machine reported the lowest values for all the metrics. Hence, Random forest appears to be the best model for the classification task based on the performance measures, achieving the highest accuracy, precision, recall, and F1-Score."
137,"caption: The classification performance of five different models using multiple metrics.table: Model,Accuracy,Precision,Recall,F1-score,AUC, SVM,0.87,0.95,0.79,0.86,0.94, Random Forest,0.90,0.92,0.85,0.88,0.92, Decision Tree,0.84,0.87,0.78,0.82,0.85, MLP,0.88,0.90,0.86,0.88,0.92, Logistic Regression,0.86,0.90,0.79,0.84,0.89","The table presents the classification performance of five different models: SVM, Random Forest, Decision Tree, MLP, and Logistic Regression, using multiple evaluation metrics.  The evaluated performances include accuracy, precision, recall, F1-score, and AUC. Interestingly, Random Forest outperforms all other models in terms of accuracy, with an accuracy of 0.90. However, MLP and Logistic Regression have higher AUC values, with an AUC value of 0.92. Overall, the various metrics suggest that different models excel in different ways, with the most accurate model not always being the best in terms of AUC or other evaluation measures."
138,"caption: Model performance results on the test dataset.table: Model,Accuracy,Precision,Recall,F1-score,AUC, Logistic Regression,0.82,0.75,0.80,0.77,0.89, Decision Tree,0.76,0.67,0.75,0.68,0.76, Random Forest,0.85,0.81,0.84,0.83,0.91, Gradient Boosting,0.86,0.82,0.85,0.84,0.92, Neural Network,0.84,0.79,0.82,0.81,0.90","Table shows the model performance results on a test dataset using multiple evaluation metrics. Five different models were compared in terms of accuracy, precision, recall, F1-score, and AUC: Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Neural Network. From the results, the best-performing model with the highest AUC value was the Gradient Boosting model with a value of 0.92. The Random Forest model showed the second-best performance with an AUC value of 0.91. Moreover, both Gradient Boosting and Random Forest models demonstrate higher precision, recall, and F1-score than other models. Overall, the table suggests that Gradient Boosting and Random Forest may be considered as the best models for the given test dataset."
139,"caption: Evaluation performance of different models using different metrics for classification task.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.848,0.803,0.792,0.815, KNN,0.823,0.764,0.749,0.779, RF,0.874,0.836,0.828,0.845, MLP,0.862,0.821,0.805,0.837","Table presents the evaluation performance of different models based on different metrics. Four models have been evaluated, including SVM, KNN, RF and MLP. Metrics such as Accuracy, F1-Score, Precision and Recall have been used for evaluation. The results show that the best performing model in terms of accuracy is RF with a score of 0.874 while the model with the highest F1-Score (0.836) is also RF. However, SVM has the highest precision (0.792) and recall (0.815) among all the models. Therefore, depending on the desired performance metric, different models can be selected for the classification task."
140,"caption: Evaluation results of different models on a classification task using multiple metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Model A,0.86,0.87,0.88,0.86, Model B,0.82,0.80,0.85,0.77, Model C,0.75,0.78,0.74,0.83, Model D,0.89,0.91,0.88,0.93, Model E,0.83,0.85,0.81,0.89","The table above shows the performance of five different models assessed on multiple evaluation metrics: Accuracy, F1 Score, Precision, and Recall. Model D performs the best on all evaluation metrics, achieving the highest accuracy of 0.89, F1 score of 0.91, precision of 0.88, and recall of 0.93. Model A achieved the second-highest accuracy of 0.86 and F1 score of 0.87, but achieved only a precision of 0.88 and a recall of 0.86. Model B achieved the third-highest accuracy of 0.82 but showed lower performance on all other metrics compared to Model A and Model D. Model E achieved the lowest performance on all evaluation metrics. Overall, Model D demonstrates the highest performance on all evaluation metrics, making it the best-performing model among the tested models for this classification task."
141,"caption: Performance comparison of different models using multiple evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.92,0.87,0.89,0.86, Logistic Regression,0.88,0.83,0.84,0.85, Random Forest,0.93,0.88,0.92,0.84, XGBoost,0.94,0.91,0.92,0.93, K-Nearest Neighbors,0.89,0.85,0.87,0.83","The table above shows the performance of SVM, Logistic Regression, Random Forest, XGBoost, and K-Nearest Neighbors models using multiple evaluation metrics. Accuracy, F1-Score, Precision, and Recall are measures of performance that are common in classification models. Interestingly, Random Forest and XGBoost achieved the highest performance accuracy with 93% and 94%, respectively. XGBoost achieved the highest F1-Score, precision, and recall with 0.91, 0.92, and 0.93, respectively. SVM achieved the best balance between precision and recall with the F1-Score of 0.87. Based on these results, it can be concluded that XGBoost is the best-performing model among all the tested models for this specific problem."
142,"caption: Table 4: Model performance on multiple metricstable: Model,F1-score,Precision,Recall,Accuracy, Model 1,0.85,0.89,0.82,0.78, Model 2,0.89,0.82,0.96,0.89, Model 3,0.78,0.81,0.75,0.88, Model 4,0.92,0.95,0.89,0.91, Model 5,0.86,0.87,0.85,0.85","Table 4 displays the performance of multiple models on four different evaluation metrics: F1-score, Precision, Recall, and Accuracy. The table consists of five models, each evaluated on their respective metrics, with Model 4 being the top-performing model in all four metrics. Model 2 performs exceptionally well on Precision and Recall with values of 0.82 and 0.96, respectively. Model 5 also has a high F1-score of 0.86. Overall, the table provides a comprehensive view of the performance of the different models and their results on multiple metrics."
143,"caption: Table 4: Model Performance on Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1-Score, Model1,0.98,0.83,0.92,0.87, Model2,0.96,0.75,0.97,0.85, Model3,0.99,0.9,0.88,0.89, Model4,0.97,0.74,0.87,0.8, Model5,0.92,0.6,0.83,0.69","Table 4 shows the performance results of five models based on four evaluation metrics: accuracy, precision, recall, and F1-score. Model 1 achieved the highest accuracy of 0.98 and a precision of 0.83. Model 2 had the highest recall score of 0.97. Meanwhile, Model 3 recorded the best precision of 0.9. Model 4 had the highest F1-score of 0.8. Although Model 5 had the lowest performance results in all metrics, its results may be acceptable depending on the specific requirements of the study. Overall, Model 1 might have the best performance since it achieved the highest accuracy and a reasonably good precision score."
144,"caption: Table 4: Performance metrics comparison across different models.table: Model,Accuracy,Precision,Recall,F1-score, Logistic regression,0.845,0.850,0.820,0.834, Random forest,0.893,0.886,0.903,0.894, Support vector machine,0.859,0.843,0.876,0.859, Fully connected Neural Networks,0.902,0.907,0.898,0.902, Convolutional Neural Networks,0.912,0.917,0.906,0.912","Table 4 compares the performance metrics for five different models: Logistic regression, Random forest, Support vector machine, Fully connected Neural Networks, and Convolutional Neural Networks. The evaluation metrics used to compare the models are Accuracy, Precision, Recall, and F1-score. Notably, all the models achieved high accuracy scores. However, among the tested models, the Convolutional Neural Networks model achieved the highest score across all four evaluation metrics with an accuracy of 0.912, precision of 0.917, recall of 0.906, and F1-score of 0.912. These results suggest that the Convolutional Neural Networks model may be the best-performing model among the evaluated models for this dataset."
145,"caption: Model performance results based on multiple evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, Logistic,0.869,0.806,0.793,0.819, Decision Tree,0.832,0.758,0.741,0.776, Random Forest,0.896,0.853,0.834,0.872, SVM,0.854,0.801,0.785,0.818, XGBoost,0.905,0.869,0.858,0.881","The above table shows the performance evaluation metrics for five different models: Logistic Regression, Decision Tree, Random Forest, Support Vector Machine (SVM), and XGBoost. The table presents the accuracy, F1-score, precision, and recall measures for the classifiers in question. Interestingly, the Random Forest classifier achieved the highest score in three out of the four metrics (accuracy, F1-score, and recall), whereas the XGBoost classifier performed the best in terms of precision. Overall, the XGBoost classifier achieved the highest accuracy with a score of 0.905. Therefore, XGBoost could be the best-performing classifier among the tested models in this dataset."
146,"caption: Model performance comparison using different evaluation metricstable: Model,Accuracy,Precision,Recall,F1-score,AUC, LR-1,0.85,0.89,0.80,0.84,0.91, RF-5,0.87,0.88,0.85,0.86,0.92, SVM-1,0.84,0.87,0.80,0.83,0.90, KNN-7,0.83,0.86,0.77,0.80,0.88","Table above presents the evaluation metrics comparison of four different models namely logistic regression with one feature set (LR-1), random forest with five feature sets (RF-5), SVM with one feature set (SVM-1) and k-nearest neighbor with seven neighbors (KNN-7). The evaluation metrics considered are accuracy, precision, recall, F1-score and AUC. Random forest exhibited the highest performance in terms of almost all metrics. It is notable that although SVM had only one feature, it could still achieve a competitive performance compared to the other models."
147,"caption: Table 4: Performance of different models on multiple evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, LR,0.89,0.82,0.85,0.81, SVM,0.88,0.81,0.84,0.79, RF,0.90,0.83,0.86,0.81, XGB,0.91,0.84,0.88,0.80","Table 4 displays the performance of four different models on multiple evaluation metrics: accuracy, F1-score, precision, and recall. The models tested include Logistic Regression (LR), Support Vector Machine (SVM), Random Forest (RF), and XGBoost (XGB). Looking at the results, XGB achieved the highest accuracy of 0.91, followed by RF with accuracy of 0.90. In terms of F1-score, XGB had the highest result of 0.84, while RF had the highest precision score of 0.86. LR outperformed the other models with the highest recall score of 0.81. Overall, this table provides an overview of the performance of different models on multiple evaluation metrics."
148,"caption: Table 4: Model Performance Results Using Various Evaluation Metrics.table: Model,Accuracy,F1-Score,Recall, Model A,0.85,0.83,0.86, Model B,0.91,0.88,0.94, Model C,0.81,0.69,0.97, Model D,0.84,0.62,0.74, Model E,0.95,0.89,0.98","Table 4 presents the performance results of five different models using three evaluation metrics: accuracy, F1-score, and recall. Model B achieved the highest accuracy score of 0.91, followed by Model E with 0.95. For F1-score, Model A has the highest score of 0.83, while Model E has the best recall score of 0.98. Interestingly, Model C has a high recall score of 0.97, but a lower accuracy and F1-score, which may indicate overfitting or bias in the model. Overall, Model E appears to be the best-performing model in this evaluation, achieving the highest accuracy and recall score and a competitive F1-score."
149,"caption: Model performance results of different classifiers based on accuracy, F1-score, precision, and recall.table: Model,Accuracy,F1 score,Precision,Recall, Logistic,0.78,0.76,0.73,0.80, SVM,0.81,0.79,0.76,0.85, Decision Tree,0.72,0.66,0.65,0.68, Random Forest,0.82,0.80,0.83,0.77, XGBoost,0.85,0.83,0.81,0.85","The table above presents the performance results for different machine learning classifiers based on accuracy, F1-score, precision, and recall. Five models were evaluated: Logistic Regression, Support Vector Machine (SVM), Decision Tree, Random Forest, and XGBoost. Interestingly, XGBoost outperformed the other models in most of the evaluation metrics, including accuracy, F1-score, and recall. However, Random Forest had the best precision result. SVM also performed well in most metrics, except for precision, where its scores were the lowest. Overall, XGBoost may be the best-performing model based on the metrics considered in this evaluation."
150,"caption: Performance Results of Different Models on a Class-Imbalanced Datasettable: Model,Precision,Recall,F1-Score,Accuracy,Specificity, SVM,0.81,0.78,0.79,0.84,0.80, KNN,0.84,0.77,0.79,0.85,0.83, Naive Bayes,0.73,0.85,0.77,0.81,0.76, Random Forest,0.88,0.85,0.86,0.89,0.87",
151,"caption: Performance results of Model A, Model B, and Model C based on seven different evaluation metrics.table: Model A,Model B,Model C, Metric 1,0.1,0.4,0.2, Metric 2,0.3,0.2,0.5, Metric 3,0.5,0.6,0.4, Metric 4,0.7,0.3,0.8, Metric 5,0.2,0.2,0.1, Metric 6,0.1,0.3,0.6, Metric 7,0.6,0.7,0.6","Table presents the performance results of Model A, Model B, and Model C based on seven different evaluation metrics. Upon examining the table, we can observe that Model C performs better than the other two models in most of the metrics presented in the table. Specifically, Model C outperforms the other models in Metric 3 and Metric 4. On the other hand, Model B performs the worst in most of the evaluation metrics. Furthermore, it is interesting to note that Model A outperforms Model C in Metric 1, but the opposite is true for Metric 7. Overall, Model C seems to be the best performing model based on the evaluation metrics presented in the table."
152,"caption: Performance of different models using various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, LR,0.85,0.86,0.87,0.86, SVM,0.83,0.84,0.85,0.84, Random Forest,0.81,0.82,0.83,0.82, MLP,0.87,0.88,0.89,0.88, CNN,0.90,0.91,0.90,0.90","The table reports the performance of five different models - LR, SVM, Random Forest, MLP, and CNN. Four different evaluation metrics - Accuracy, Precision, Recall, and F1-score - are used to evaluate the models. Interestingly, CNN performs the best among all models with an accuracy of 0.90 and a precision score of 0.91. On the other hand, Random Forest scored the lowest among them with an accuracy of 0.81. Additionally, all models have a strong recall score, with MLP and LR leading the way. Overall, the table provides a comprehensive overview of the performance of various models using multiple metrics and can be useful for selecting the best performing model for a given task."
153,"caption: Table 4: Model performance results of different classifiers based on multiple evaluation metricstable: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.89,0.91,0.89,0.93, Logistic Regression,0.88,0.91,0.88,0.94, Random Forest,0.92,0.93,0.91,0.94, XGBoost,0.93,0.94,0.92,0.96","Table 4 presents a comparison of the performance results of different classifiers based on various evaluation metrics such as accuracy, F1 score, precision, and recall. The models compared include SVM, Logistic Regression, Random Forest, and XGBoost. The table shows that XGBoost achieved the highest accuracy of 0.93, the highest F1 score of 0.94, and the highest precision of 0.92. Random Forest also performed well with an accuracy of 0.92 and an F1 score of 0.93. SVM and Logistic Regression achieved lower overall performance, with SVM having the lowest precision of 0.89 and Logistic Regression having the lowest recall of 0.94. Overall, the comparison highlights the different strengths and weaknesses of each model for this particular dataset."
154,"caption: Model performance metrics comparison on the test dataset for five different models.table: Model,Accuracy,Precision,Recall,F1 Score,AUC-PR,AUC-ROC, Logistic Regression,0.89,0.88,0.90,0.89,0.76,0.89, Decision Tree,0.82,0.80,0.88,0.84,0.69,0.77, Random Forest,0.93,0.94,0.92,0.93,0.87,0.95, Gradient Boosting,0.91,0.91,0.91,0.91,0.83,0.93, Support Vector Machine,0.79,0.72,0.87,0.79,0.55,0.77","Table presents the performance comparison of five different models correlating to accuracy, precision, recall, F1 Score, AUC-PR and AUC-ROC. The evaluated models are Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Support Vector Machine. Interestingly, Random Forest outperformed all other models achieving highest scores in both AUC-PR and AUC-ROC. However, the Decision Tree model showed the lowest scores amongst the evaluated models. Thus, it can be concluded that the Random Forest model performed the best comparatively to the other models in the given dataset."
155,"caption: Model performance scores on different evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.82,0.77,0.82,0.74, KNN,0.78,0.69,0.81,0.60, LR,0.81,0.75,0.79,0.71, RF,0.87,0.81,0.85,0.82, MLP,0.83,0.77,0.80,0.74","The table presents the performance results of five models on different evaluation metrics, including Accuracy, F1-Score, Precision, and Recall. The models include SVM, KNN, LR, RF, and MLP. Interestingly, Random Forest (RF) was found to be the best-performing model across all evaluation metrics with an Accuracy of 0.87, F1-Score of 0.81, Precision of 0.85, and Recall of 0.82. The MLP model also performed well on all evaluation metrics with an Accuracy of 0.83, F1-Score of 0.77, Precision of 0.80, and Recall of 0.74. It is worth noting that KNN had the lowest performance scores on all evaluation metrics among the tested models. Overall, Random Forest may be a promising model for future applications on this dataset."
156,"caption: Table 4: Performance results of different models on evaluation metricstable: Model,F1 Score,Accuracy,Precision,Recall, Logistic Regression,0.825,0.865,0.870,0.820, Random Forest,0.816,0.859,0.844,0.791, Support Vector Machine,0.832,0.871,0.880,0.798, Multi-Layer Perceptron,0.812,0.857,0.837,0.792","Table 4 presents the evaluation metrics of F1 Score, Accuracy, Precision, and Recall for four models: Logistic Regression, Random Forest, Support Vector Machine, and Multi-Layer Perceptron. Interestingly, all models achieved a high level of Accuracy, with a range of scores from 0.857 - 0.871. The Support Vector Machine outperformed the other models with the highest Precision of 0.880, although Logistic Regression had the best Recall score of 0.820.  Overall, all models achieved relatively high performance in all evaluation metrics, but depending on the importance of Precision or Recall in the context of the data, one should choose the corresponding model."
157,"caption: Table 4: Model performance comparison based on multiple evaluation metrics.table: Model,Accuracy (%),Precision (%),Recall (%),F1 Score (%), Model 1,76.8,88.2,63.7,73.9, Model 2,79.1,84.5,73.1,78.4, Model 3,77.5,87.2,66.5,75.4, Model 4,80.3,85.6,76.9,80.9, Model 5,82.0,89.3,75.2,81.6","Table 4 compares the performance of five different models using multiple evaluation metrics. The models were evaluated based on their accuracy, precision, recall, and F1 score. Interestingly, although Model 5 has the highest accuracy, it is not the best-performing model overall. Model 4 outperformed the other models in precision, recall, and F1 score, despite having the second-highest accuracy. This highlights the importance of evaluating models based on multiple metrics rather than solely relying on accuracy."
158,"caption: Table 4: Model Performance on Binary Classification Task Using Different Evaluation Metricstable: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.85,0.84,0.82,0.86, Random Forest,0.88,0.87,0.85,0.89, XGBoost,0.89,0.88,0.87,0.89, Multi-Layer Perceptron,0.87,0.86,0.85,0.87","Table 4 compares the performance of four different models on a binary classification task using various evaluation metrics such as Accuracy, F1 score, Precision, and Recall. The models tested were Logistic Regression, Random Forest, XGBoost, and Multi-Layer Perceptron. Random Forest and XGBoost outperformed the other models in all four metrics. XGBoost achieved the highest accuracy of 0.89, F1 score of 0.88, precision of 0.87, and recall of 0.89. The Logistic Regression model performed the worst among the compared models with an accuracy of 0.85. Overall, Random forest and XGBoost appear to be the most promising models for this binary classification task based on the evaluation metrics considered."
159,"caption: Model performance metrics for three different classifiers on a binary classification task.table: Model,Accuracy,F1 score,Precision,Recall, Logistic regression,0.89,0.86,0.83,0.90, Random forest,0.91,0.88,0.91,0.85, XGBoost,0.92,0.89,0.89,0.89","This table presents the performance metrics results for three different classifiers: Logistic regression, Random forest and XGboost, on a binary classification task. The evaluation metrics used include Accuracy, F1 score, Precision, and Recall. Among the three classifiers, XGBoost achieved the highest accuracy of 0.92, followed by Random forest with an accuracy of 0.91, while Logistic regression achieved an accuracy of 0.89. Random forest achieved the highest F1 score and Precision score of 0.88 and 0.91 respectively, while XGBoost achieved the highest Recall score of 0.89. These results suggest that Random forest and XGBoost might be more suitable for this binary classification task compared to Logistic regression."
160,"caption: Evaluation of different models using multiple metrics.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.85,0.88,0.74,0.80, KNN,0.78,0.84,0.60,0.70, CNN,0.91,0.89,0.93,0.91, MLP,0.84,0.86,0.75,0.80","The table presents the evaluation results of multiple machine learning models using different evaluation metrics such as accuracy, precision, recall, and F1-score. The results show that the CNN model has the highest accuracy score of 0.91 and also has the highest F1-score of 0.91, indicating its superior performance in both measures. The SVM model has the highest precision score of 0.88, suggesting that it performs the best when correctly identifying instances that belong to the positive class, while the MLP model has the highest recall score of 0.75, indicating that it performs better at identifying all positive instances. Based on these results, it may be concluded that the CNN model is the best-performing model among the tested models."
161,"caption: Performance comparison of different models using various evaluation metrics.table: Model,F1-score,Accuracy,Precision,Recall, Model A,0.85,0.92,0.89,0.81, Model B,0.82,0.89,0.80,0.85, Model C,0.88,0.93,0.92,0.85, Model D,0.81,0.87,0.78,0.85, Model E,0.86,0.92,0.88,0.85","Table 1 presents the performance comparison of five different models using various evaluation metrics. The table lists the F1-score, accuracy, precision, and recall scores for each model. Interestingly, Model C has the highest F1-score, precision, and accuracy, but has a lower recall score compared to Models A and E. Model A has the highest recall score, but has a lower precision score compared to Model C. On the other hand, Model B and Model D have lower F1-scores and accuracy scores compared to other models. In conclusion, Model C may be the best-performing model among the tested models based on these evaluation metrics."
162,"caption: Comparison of Model Performance on Different Evaluation Metrics.table: Model,F1 Score,Accuracy,Precision, A,0.86,0.92,0.84, B,0.81,0.91,0.84, C,0.92,0.94,0.88, D,0.76,0.88,0.8, E,0.89,0.93,0.92","Table 4 compares the performance of five models, A, B, C, D, and E, based on multiple evaluation metrics: F1 Score, Accuracy, and Precision. Model C showed the highest F1 Score (0.92), closely followed by Model E (0.89) and Model A (0.86). Model A also showed the highest Precision (0.84), while Model E showed the highest Accuracy (0.93). Model D had the lowest F1 Score (0.76), which was also reflected in the lowest Accuracy (0.88) and lowest Precision (0.80) among all models. The results suggest that Model C and Model E are strong performers across all evaluation metrics, while Model D may require further refinement."
163,"caption: Comparison of different models based on multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score,PR-AUC,ROC-AUC, Model A,0.89,0.92,0.85,0.88,0.78,0.91, Model B,0.92,0.94,0.90,0.92,0.84,0.93, Model C,0.88,0.91,0.84,0.87,0.75,0.89, Model D,0.91,0.93,0.88,0.91,0.82,0.92","Table shows the comparison of four machine learning models (Model A, B, C, and D) based on accuracy, precision, recall, F1-Score, PR-AUC, and ROC-AUC evaluation metrics. Model B attained the highest accuracy of 0.92, while Model D attained the highest precision of 0.93 and recall of 0.88. Additionally, Model B obtained the highest F1-Score of 0.92. However, for PR-AUC and ROC-AUC, Model B only achieved 0.84 and 0.93, respectively, while Model D attained 0.82 and 0.92. Therefore, Model D might be the best performing model, considering both PR-AUC and ROC-AUC."
164,"caption: Performance results of multiple models based on different evaluation metrics.table: Metric/Model,A,B,C,D,E, Accuracy,0.91,0.87,0.89,0.92,0.88, Precision,0.92,0.79,0.81,0.86,0.90, Recall,0.94,0.93,0.90,0.87,0.89, F1,0.93,0.86,0.85,0.86,0.89, AUC,0.92,0.89,0.87,0.94,0.85","Table presents the performance results of five different models, A, B, C, D, and E, based on multiple evaluation metrics, including Accuracy, Precision, Recall, F1, and AUC. Interestingly, Model D outperformed all other models in terms of most metrics, achieving the highest scores for Accuracy (0.92), Precision (0.86), and F1 (0.86). However, Model E performed poorly compared to the other models, achieving the lowest score for AUC (0.85). Overall, Model D appears to be the best-performing model among the tested models based on the evaluation metrics in this dataset."
165,"caption: Performance metrics of different modelstable: Model Name,F1-Score,Accuracy,AUC-ROC, Model 1,0.75,0.80,0.85, Model 2,0.80,0.85,0.82, Model 3,0.82,0.87,0.75, Model 4,0.78,0.83,0.80, Model 5,0.85,0.90,0.88","The table shows the F1-Score, accuracy, and AUC-ROC performance metrics for five different models. Model 1 has the lowest F1-Score of 0.75, but the highest AUC-ROC of 0.85. Model 5 achieves the highest F1-Score of 0.85 and accuracy of 0.90, but with a slightly lower AUC-ROC of 0.88. The remaining models perform well, with F1-Scores ranging from 0.78 to 0.82 and accuracies ranging from 0.80 to 0.87. Interestingly, Model 3 has a high F1-Score and accuracy but the lowest AUC-ROC of 0.75, indicating its classification performance may be more susceptible to false positives and false negatives. Overall, the table provides insights into the strengths and weaknesses of different models and performance metrics."
166,"caption: Evaluation Metrics of Different Modelstable: Model,Precision,Recall,F1 Score,AUC, Model A,0.87,0.91,0.89,0.94, Model B,0.90,0.89,0.89,0.87, Model C,0.91,0.85,0.88,0.92, Model D,0.84,0.92,0.88,0.90","The presented table displays the evaluation metrics of four models, Model A, B, C, and D. The table reports precision, recall, F1 Score, and AUC. Notably, Model C outperforms other models in precision with a score of 0.91, while Model B shows the highest recall score at 0.89. Interestingly, Model A and Model C exhibit the same F1 Score of 0.89, even though they have different precision and recall values. Furthermore, Model A shows the highest AUC with a score of 0.94. These results suggest that Model A and Model C are strong performers with high F1 Scores, even though they have different strengths in precision and recall."
167,"caption: Model evaluation results using multiple metrics.table: Model,Precision,Recall,F1-Score,AUC-ROC, model1,0.79,0.63,0.70,0.85, model2,0.82,0.70,0.75,0.87, model3,0.84,0.74,0.79,0.89, model4,0.85,0.78,0.81,0.90, model5,0.88,0.82,0.84,0.91, model6,0.89,0.84,0.86,0.92","The table above presents the evaluation metrics of six different models based on Precision, Recall, F1-Score, and AUC-ROC. We observe that model6 has the highest values for all metrics, demonstrating it as the best-performing model. Model1 and Model2 perform relatively poorly in terms of recall, while model5 and model6 have high values for all metrics, implying that they may be reliable models for the dataset. Overall, the F1-Score is relatively high in all models, indicating reasonable performance. These results can be used to determine which model is appropriate for further use."
168,"caption: Comparison of Classification Models.table: Model Name,Accuracy,F1 Score,Recall,Precision, Logistic Regression,0.872,0.873,0.875,0.870, Random Forest,0.903,0.905,0.906,0.904, K-Nearest Neighbors,0.842,0.838,0.837,0.841, Support Vector M.,0.882,0.883,0.884,0.881, Neural Network,0.896,0.897,0.898,0.894","The table presents the performance of different classification models in terms of their accuracy, F1 score, recall, and precision metrics. The models included in the table are Logistic Regression, Random Forest, K-Nearest Neighbors, Support Vector Machine, and Neural Network. Interestingly, Random Forest outperformed the other models in all evaluation metrics, achieving the highest accuracy, F1 score, recall, and precision. Logistic Regression and Support Vector Machine came second in terms of their performance, while K-Nearest Neighbors seems to be the worst-performing model among the tested models. These results suggest that Random Forest may be the best model to consider for the classification task."
169,"caption: Model performance using different evaluation metricstable: Model,Accuracy,Precision,Recall,F1-score, SVM,0.98,0.96,0.87,0.91, KNN,0.94,0.89,0.85,0.87, Naive Bayes,0.88,0.79,0.92,0.85, Decision Tree,0.95,0.86,0.91,0.88, Random Forest,0.99,0.97,0.93,0.94","The table presents the performance results of five different machine learning models. These models are evaluated based on four different performance metrics: Accuracy, Precision, Recall, and F1-score. The SVM and Random Forest models achieved the highest accuracy of 0.98 and 0.99, respectively. However, Random Forest also attained the highest F1-score of 0.94. On the other hand, Naive Bayes achieved the highest recall value of 0.92, but had low precision and accuracy scores. The performance of Decision Tree and KNN models were moderately better but were not as high as SVM, Random Forest, or Naive Bayes."
170,"caption: Model performance of different classification models based on various evaluation metrics.table: Models,Accuracy,F1-score,Precision,Recall, Model A,0.89,0.80,0.78,0.83, Model B,0.87,0.75,0.82,0.69, Model C,0.92,0.87,0.86,0.89, Model D,0.86,0.74,0.72,0.77, Model E,0.90,0.82,0.80,0.85","The table displays the performance results of five different classification models (Model A, Model B, Model C, Model D, and Model E) based on four different evaluation metrics: Accuracy, F1-score, Precision, and Recall. Interestingly, Model C outperforms the other models in all metrics, achieving an Accuracy of 0.92, F1-score of 0.87, Precision of 0.86, and Recall of 0.89. Model A and Model E also perform relatively well compared to the others in terms of Accuracy and Recall, respectively. Conversely, Model D performs the worst in all metrics, particularly with a recall of 0.77. The table provides a clear comparison of the different models based on different evaluation metrics, revealing which model performs the best overall."
171,"caption: Performance comparison of multiple models using different evaluation metrics.table: Models,Accuracy,Precision,Recall,F1 Score, Model A,0.95,0.93,0.92,0.93, Model B,0.89,0.91,0.86,0.88, Model C,0.92,0.89,0.93,0.91, Model D,0.93,0.85,0.95,0.89, Model E,0.91,0.92,0.90,0.91","The table presents the performance comparison of five different models, Model A, Model B, Model C, Model D, and Model E. The models are evaluated based on four different evaluation metrics: accuracy, precision, recall, and F1 score. Model A achieves the highest accuracy of 0.95 and the highest precision of 0.93, while Model D achieves the highest recall of 0.95. However, Model E exhibits the most balanced performance with high values for all four metrics and an F1 score of 0.91, which is only slightly lower than that of Model A. Overall, the table suggests that Model E may be the best-performing model among the five evaluated models, as it achieves high performance across all evaluation metrics."
172,"caption: Comparison of model performance on the dataset using multiple evaluation metrics.table: Model,Metric,Value, SVM,Accuracy,0.89, Decision Tree,Accuracy,0.76, Naive Bayes,Accuracy,0.91, Random Forest,Accuracy,0.95, MLP,Accuracy,0.93, F1,0.78, Precision,0.87, Recall,0.72, CNN,Accuracy,0.94, F1,0.84, Precision,0.91, Recall,0.79","The table shows the performance of different models on the dataset. Five models were evaluated using the accuracy metric, where Random Forest achieved the highest accuracy of 0.95. SVM and MLP were also relatively accurate, with accuracies of 0.89 and 0.93, respectively. The CNN model was able to achieve an accuracy of 0.94, which is similar to Random Forest. Moreover, precision, recall, and F1 scores were reported for MLP and CNN models. The F1 score for MLP was 0.78, while for CNN, it was 0.84. These results suggest that Random Forest, MLP, and CNN showed the best performance among the tested models on this dataset."
173,"caption: Model performance comparison based on accuracy, F1-score, and AUC evaluation metrics.table: Model,Accuracy,F1-score,AUC, Logistic regression,0.87,0.85,0.89, Decision tree,0.82,0.80,0.83, Random forest,0.90,0.89,0.92, Support vector machine,0.85,0.82,0.87, Gradient boosting,0.92,0.91,0.94","The table above displays the performance results of five different models on a classification dataset using three different evaluation metrics: Accuracy, F1-score, and AUC. The logistic regression model achieved the second highest AUC of 0.89, along with an accuracy and F1-score of 0.87 and 0.85 respectively. The decision tree model achieved the lowest performance with an AUC of 0.83, while the random forest model achieved the highest accuracy (0.90) and F1-score (0.89) overall. The highest AUC was achieved by the gradient boosting model with a score of 0.94. These results suggest that different models perform differently depending on the evaluation metric used and that model selection should depend on the evaluation metric priorities."
174,"caption: Model performance results using different evaluation metricstable: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.85,0.87,0.82,0.84, Random Forest,0.92,0.93,0.91,0.92, XGBoost,0.93,0.94,0.93,0.93, Support Vector Machines,0.81,0.76,0.89,0.82, Multilayer Perceptron,0.89,0.89,0.89,0.89","The table above shows the model performance results of five different models based on four evaluation metrics: accuracy, precision, recall, and F1-score. Random Forest and XGBoost have the highest accuracy, precision, and F1-score values with accuracy of 0.92 and 0.93, precision of 0.93 and 0.94, and F1-score of 0.92 and 0.93, respectively. The Logistic Regression model shows good precision and recall values with precise results, while the Support Vector Machines model has a higher recall value and lower precision value. The Multilayer Perceptron model shows consistent performance across all four evaluation metrics. Overall, Random Forest and XGBoost models perform the best among the tested models for this dataset."
175,"caption: Performance comparison of different models based on evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall,AUC, Model 1,0.87,0.85,0.89,0.82,0.93, Model 2,0.89,0.88,0.92,0.84,0.95, Model 3,0.82,0.78,0.8,0.78,0.87, Model 4,0.91,0.89,0.92,0.87,0.94, Model 5,0.86,0.84,0.87,0.8,0.92","Table presents a comparison of the performance of five different models based on five evaluation metrics, i.e., Accuracy, F1-score, Precision, Recall, and AUC. Among all models, Model 4 has the highest performance scores in all evaluation metrics, achieving the highest accuracy (0.91), F1-score (0.89), precision (0.92), recall (0.87), and AUC (0.94). Model 2 shows the second-best performance overall with an accuracy score of 0.89, a F1-score of 0.88 and AUC of 0.95. Meanwhile, Model 3 has the lowest performance scores in all evaluation metrics. These results indicate that Models 4 and 2 may be better choices than the other models based on the given dataset, problem, and evaluation metrics."
176,"caption: Table 4: Performance comparison of five different models.table: Model,F1-Score,Recall,Precision,Accuracy, Model A,0.75,0.80,0.71,0.80, Model B,0.80,0.85,0.78,0.83, Model C,0.72,0.90,0.60,0.76, Model D,0.85,0.82,0.88,0.87, Model E,0.78,0.76,0.80,0.81","Table 4 presents the performance comparison of five different models evaluated through four different metrics: F1-Score, Recall, Precision, and Accuracy. Model D performs the best in all evaluation metrics with the highest F1-Score of 0.85, Recall of 0.82, Precision of 0.88, and Accuracy of 0.87, while Model C has the lowest F1-Score of 0.72. Interestingly, Model E has a precision of 0.80, the second-best precision score after Model D, but has lower scores in the remaining evaluation metrics. Overall, based on the given metrics, Model D can be considered the best-performing model among the tested models."
177,"caption: Model performance results based on multiple evaluation metricstable: Model,F1-score,Accuracy,Recall,Precision, SVM,0.89,0.91,0.88,0.91, MLP,0.86,0.88,0.85,0.87, RF,0.91,0.93,0.90,0.92, LR,0.83,0.86,0.83,0.85","Table 4 presents the performance results of four different models based on multiple evaluation metrics: F1-score, accuracy, recall, and precision. The models include SVM, MLP, RF, and LR. Interestingly, RF outperformed all other models in all evaluation metrics with the highest F1-score of 0.91, highest accuracy of 0.93, highest recall of 0.90, and highest precision of 0.92. SVM performed second best with an F1-score of 0.89, accuracy of 0.91, recall of 0.88, and precision of 0.91. LR, on the other hand, performed the worst among the tested models with an F1-score of 0.83, accuracy of 0.86, recall of 0.83, and precision of 0.85. Overall, RF is the best-performing model among the tested models for this dataset based on all evaluation metrics."
178,"caption: Model performance based on various evaluation metrics for a binary classification task.table: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.87,0.83,0.85,0.82, Random Forest,0.89,0.85,0.89,0.82, SVM,0.84,0.81,0.79,0.83, Naive Bayes,0.78,0.73,0.72,0.75, KNN,0.80,0.77,0.76,0.79",
179,"caption: Model Performance for Different Algorithmstable: Model,Precision,Recall,F1 Score, SVM,0.95,0.78,0.85, KNN,0.83,0.92,0.87, Naive Bayes,0.7,0.99,0.81, Decision Tree,0.88,0.88,0.88, Random Forest,0.98,0.89,0.93","Table presents the performances of five different models on a binary classification task with multiple evaluation metrics such as precision, recall, and F1 score. The models evaluated in the table include SVM, KNN, Naive Bayes, Decision Tree, and Random Forest. Interestingly, Random Forest has the best precision result of 0.98, which is higher than the other models. However, KNN outperforms other models in recall and F1 score, which have values of 0.92 and 0.87, respectively. SVM has the second-best precision and recall results with values of 0.95 and 0.78, respectively. Therefore, the best model depends on the importance of precision, recall, or F1 score for the particular problem at hand."
180,"caption: Table 4: Evaluation metrics on multiple models.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.89,0.92,0.86,0.89, Decision Tree,0.82,0.80,0.81,0.80, Random Forest,0.92,0.94,0.90,0.92, Gradient Boosting,0.85,0.86,0.84,0.85, KNN,0.81,0.77,0.80,0.78","Table 4 displays the performance results of multiple models on different evaluation metrics. The models considered in the table include SVM, Decision Tree, Random Forest, Gradient Boosting, and KNN. The evaluation metrics used to determine the model performance include accuracy, precision, recall, and F1-score. Interestingly, the Random Forest model achieved the highest performance scores in all the metrics. The results show that the Random Forest model achieved an accuracy of 0.92, precision of 0.94, recall of 0.90, and an F1-score of 0.92, making it the best-performing model among the tested models. However, other models show strong results in specific metrics, e.g., SVM achieved the highest precision score."
181,"caption: Performance of different machine learning models on the classification task.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic regression,0.85,0.89,0.79,0.84, Decision tree,0.82,0.83,0.81,0.82, Naive Bayes,0.78,0.76,0.82,0.79, Support vector machines,0.86,0.87,0.84,0.85, Random forest,0.87,0.88,0.86,0.87, Gradient boosting,0.88,0.89,0.87,0.88","The table presents the performance results of different machine learning models on a classification task measured by multiple evaluation metrics, such as accuracy, precision, recall, and F1-Score. Six models are compared in this table: Logistic regression, Decision tree, Naive Bayes, Support vector machines, Random forest, and Gradient boosting. Interestingly, the models seem to perform relatively similar in terms of accuracy, with Gradient boosting having the highest accuracy of 0.88. However, when considering precision, recall, and F1-score together, Random forest and Gradient boosting stand out as the top-performing models. Both models achieve a precision score of 0.88 and above, while maintaining high recall and F1-score values."
182,"caption: Model performance metrics on classification task.table: Model,Accuracy,Precision,Recall,F1-Score, Model A,0.85,0.89,0.82,0.85, Model B,0.78,0.80,0.76,0.77, Model C,0.91,0.93,0.89,0.91, Model D,0.79,0.76,0.82,0.79, Model E,0.88,0.91,0.87,0.88","The table presents the performance metrics of five models (Model A, Model B, Model C, Model D, and Model E) on a classification task, which include accuracy, precision, recall, and F1-score. Interestingly, Model C achieved the highest accuracy of 0.91 and had the highest precision of 0.93 and F1-score of 0.91, suggesting that it may be the best model for this task. However, Model A achieved the highest recall of 0.82 among all models. Therefore, depending on the priority of the evaluation metric, either Model C or Model A can be considered as the best-performing model for this task."
183,"caption: Performance results of different models based on multiple evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall,AUC Score,PR Score, Logistic Regression,0.85,0.8478,0.8573,0.8621,0.9312,0.8616, Decision Tree,0.79,0.7843,0.7812,0.7891,0.8719,0.7894, Random Forest,0.91,0.9087,0.9261,0.8914,0.9675,0.9158, Gradient Boosting,0.88,0.882,0.8935,0.8712,0.9431,0.8925, Convolutional Neural Network,0.93,0.9276,0.9367,0.9189,0.9784,0.9335","The table presents the performance results of five models on multiple evaluation metrics: Accuracy, F1 Score, Precision, Recall, AUC Score, and PR Score. The models include Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Convolutional Neural Network. Interestingly, the Convolutional Neural Network model has the highest accuracy score of 0.93, followed by Random Forest with a score of 0.91. Random Forest had the highest AUC score of 0.9675, while Convolutional Neural Network had the highest PR Score of 0.9335. These results show that different models perform differently across different evaluation metrics, and choosing the right model requires a careful consideration of the nature of the problem and the relevant metrics."
184,"caption: Model performance comparison based on different evaluation metrics.table: Model,F1-Score,Precision,Recall,Accuracy, Logistic Regression,0.73,0.76,0.70,0.78, Random Forest,0.78,0.81,0.75,0.81, Support Vector Machine,0.72,0.75,0.69,0.77, Naive Bayes,0.64,0.68,0.60,0.70, Multi-Layer Perceptron,0.79,0.80,0.78,0.82","The table summarizes the performance of five models, namely Logistic Regression, Random Forest, Support Vector Machine, Naive Bayes, and Multi-Layer Perceptron, based on four evaluation metrics: F1-Score, Precision, Recall, and Accuracy. The table shows that Random Forest scored the highest in all evaluation metrics except precision where Multi-Layer Perceptron scored slightly higher. Interestingly, Naive Bayes performed poorly in comparison to other models in all evaluation metrics. The results suggest that Random Forest might be the best option among the tested models for this task."
185,"caption: Table 4: Model evaluation using different performance metrics for 5 different models.table: Model,Accuracy,Precision,Recall,F1-Score, Model 1,0.85,0.82,0.84,0.83, Model 2,0.87,0.83,0.85,0.84, Model 3,0.88,0.86,0.87,0.86, Model 4,0.84,0.81,0.82,0.81, Model 5,0.89,0.88,0.89,0.88","Table 4 presents the evaluation results of five different models using four different performance metrics: accuracy, precision, recall, and F1-score. The table shows that Model 5 achieved the highest accuracy of 0.89 while Model 1 achieved the lowest accuracy of 0.85. Considering the Precision and Recall metrics, Model 3 performed the best with a precision of 0.86 and a recall of 0.87. F1-Score which is the harmonic mean of precision and recall is highest for Model 5 with a score of 0.88 that obtained the highest accuracy. Therefore, based on the presented evaluation metrics, Model 5 might be the best performing model among the tested models."
186,"caption: Comparison of different machine learning models on the classification task.table: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.84,0.85,0.82,0.83, Random Forest,0.87,0.87,0.88,0.87, XGBoost,0.86,0.86,0.86,0.86, Decision Tree,0.79,0.80,0.79,0.78, Naive Bayes,0.77,0.79,0.73,0.72","This table presents the performance results of five different machine learning models on a classification task measured using multiple evaluation metrics: Accuracy, Precision, Recall, and F1-score. The models include Logistic Regression, Random Forest, XGBoost, Decision Tree, and Naive Bayes. The table reveals that Random Forest achieved the highest Accuracy, Precision, and F1-score compared to the other models, with an Accuracy of 0.87, Precision of 0.87, and F1-score of 0.87. Logistic Regression also performed well, achieving an overall Accuracy of 0.84. On the other hand, Naive Bayes achieved the lowest performance, failing to achieve an F1-score of 0.75 or above."
187,"caption: Table 4: Model performance results using different evaluation metricstable: Model,Acc,F1,PR-AUC,ROC-AUC, Logistic Regression,0.853,0.809,0.756,0.914, Decision Tree,0.839,0.749,0.703,0.776, K-Nearest Neighbors,0.813,0.717,0.651,0.768, Random Forest,0.889,0.849,0.802,0.974, Gradient Boosting,0.902,0.864,0.830,0.976, Support Vector Mach.,0.857,0.810,0.774,0.942","Table 4 exhibits the model performance results across six models - Logistic Regression, Decision Tree, K-Nearest Neighbors, Random Forest, Gradient Boosting, and Support Vector Machine. The table displays the overall accuracy, F1-score, PR-AUC, and ROC-AUC metrics for different models. Interestingly, Random Forest and Gradient Boosting models performed the best in terms of all the metrics, thus demonstrating reliable classification performance. The Decision Tree model, although achieved lower overall accuracy, had a reasonably high F1-score. These results suggest that Random Forest and Gradient Boosting models are appropriate for this classification problem."
188,"caption: Model performance based on multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.82,0.82,0.80,0.81, Decision Tree,0.79,0.76,0.80,0.78, Random Forest,0.84,0.83,0.83,0.83, K-Nearest Neighbors,0.75,0.77,0.67,0.72, SVM,0.83,0.82,0.81,0.81","The table presents the performance results of multiple models on various evaluation metrics. The models include Logistic Regression, Decision Tree, Random Forest, K-Nearest Neighbors, and SVM. The evaluation metrics are Accuracy, Precision, Recall, and F1 Score. Interestingly, Random Forest shows the highest accuracy of 0.84. Additionally, Random Forest and Logistic Regression show high precision and recall scores, which indicates their ability to correctly identify positive and negative labels. On the other hand, K-Nearest Neighbors has a relatively low f1 score. These results suggest that Random Forest and Logistic Regression could be good models for this dataset, depending on the priorities of the evaluation metric."
189,"caption: Model performance on the classification task using different models and evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall,AUROC, Logistic regression,0.731,0.677,0.652,0.705,0.800, Support vector machines (SVM),0.728,0.674,0.648,0.702,0.795, Decision tree,0.686,0.647,0.610,0.688,0.711, XGBoost,0.788,0.747,0.719,0.777,0.849, Random forest,0.799,0.756,0.727,0.789,0.857, LightGBM,0.803,0.760,0.729,0.795,0.860","Table presents the accuracy, F1 score, precision, recall, and the area under receiver operating characteristic curve (AUROC) performance metrics of six different models on the classification task. These models include logistic regression, support vector machines (SVM), decision tree, XGBoost, random forest, and LightGBM. Interestingly, LightGBM outperformed other models with the highest values related to all five performance metrics. Specifically, the LightGBM model achieved accuracy, F1 score, precision, recall, and AUROC of 0.803, 0.760, 0.729, 0.795, and 0.860, respectively. Therefore, based on the tested models, LightGBM is the best-performing model for this classification task."
190,"caption: Performance results of different models based on classification metrics for a binary classification problem.table: Model,Accuracy,Precision,Recall,F1-Score,AUC, Logistic Regression,0.87,0.86,0.87,0.86,0.92, Decision Tree,0.82,0.81,0.84,0.82,0.87, Random Forest,0.89,0.88,0.91,0.89,0.95, XGBoost,0.91,0.90,0.92,0.91,0.96","The table above presents the performance results for different models based on a binary classification problem. The models include Logistic Regression, Decision Tree, Random Forest, and XGBoost. The evaluation metrics include Accuracy, Precision, Recall, F1-Score, and AUC. Interestingly, Random Forest and XGBoost outperform the other models in most metrics, whereas Logistic Regression has the lowest performance in terms of all metrics. Of the models tested, XGBoost achieved the highest AUC score of 0.96, which could make it the preferred model for this binary classification problem."
191,"caption: Model performance on the classification task using multiple evaluation metrics.table: Model,Precision,Recall,F1 Score,Accuracy, Logistic Regression,0.91,0.93,0.92,0.94, Decision Tree,0.84,0.81,0.82,0.87, Random Forest,0.93,0.95,0.94,0.96, Support Vector Machine,0.88,0.92,0.90,0.91, Neural Network,0.93,0.94,0.94,0.95","The table shows the performance of five different models on a binary classification task. The models are Logistic Regression, Decision Tree, Random Forest, Support Vector Machine, and Neural Network. The performance of each model is measured using multiple evaluation metrics including Precision, Recall, F1 Score, and Accuracy. Interestingly, Random Forest achieved the highest performance results in all evaluation metrics with a Precision of 0.93, Recall of 0.95, F1 Score of 0.94 and Accuracy of 0.96. Therefore, we can infer that for this classification task, Random Forest outperforms the other models. However, the Neural Network model also displayed high performance results with a Precision of 0.93, Recall of 0.94, F1 Score of 0.94, and Accuracy of 0.95."
192,"caption: Model performance evaluation using multiple evaluation metrics.table: Model Name,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.82,0.79,0.83,0.76, Decision Tree,0.78,0.70,0.77,0.64, Random Forest,0.85,0.81,0.86,0.76, Support Vector Machine,0.83,0.79,0.85,0.73, Naive Bayes,0.76,0.67,0.68,0.71",
193,"caption: Performance metrics of different models on a binary classification task.table: Model,F1-Score,Accuracy,Precision,Recall, Logistic Regression,0.874,0.893,0.852,0.899, Random Forest,0.910,0.920,0.898,0.923, Support Vector Machine,0.846,0.871,0.832,0.861, Multi-layer Perceptron,0.892,0.902,0.888,0.896, K-Nearest Neighbors,0.828,0.821,0.856,0.801","Table above displays the comparison of different supervised machine learning models based on various evaluation metrics, such as F1-Score, Accuracy, Precision, and Recall, for a binary classification task. Interestingly, Random Forest achieved the highest F1-score of 0.91, while Logistic Regression achieved the highest Precision of 0.852 and SVM achieved the highest Recall of 0.861. It's also worth noting that K-Nearest Neighbors achieved the lowest F1-score, despite having the highest Precision and lowest Recall among all the tested models. Overall, Random Forest has the best performance for this binary classification task."
194,"caption: Results of different models on evaluation metricstable: Model,Accuracy,F1-Score,Recall,Precision, SVM,0.87,0.83,0.85,0.82, Random Forest,0.88,0.84,0.86,0.83, Naive Bayes,0.73,0.59,0.48,0.76, Decision Tree,0.79,0.75,0.72,0.78, Logistic Regression,0.85,0.82,0.83,0.82","The table presents the model performance results on multiple evaluation metrics: Accuracy, F1-Score, Recall, and Precision. Five models: SVM, Random Forest, Naive Bayes, Decision Tree, and Logistic Regression are evaluated. The results demonstrate that Random Forest has the highest accuracy and F1-Score results among the tested models with 0.88 and 0.84 respectively. SVM, Logistic Regression, and Decision Tree follow it in terms of overall performance, while Naive Bayes has the lowest results among them. Furthermore, the results suggest that different models may excel in different evaluation metrics, highlighting the importance of considering multiple metrics when evaluating models."
195,"caption: Classification model performance based on different evaluation metricstable: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.95,0.92,0.89,0.90, Random Forest,0.93,0.91,0.87,0.88, K-Nearest Neighbors,0.91,0.88,0.83,0.84, Support Vector Machine,0.92,0.89,0.83,0.85","Table displays the evaluation metrics for four classification models: Logistic Regression, Random Forest, K-Nearest Neighbors, and Support Vector Machine. The models' performance is based on the evaluation metrics of Accuracy, Precision, Recall, and F1 Score. Interestingly, all models perform similarly in terms of accuracy, with the Logistic Regression model achieving the highest accuracy of 0.95. However, when considering other evaluation metrics such as Precision, Recall, and F1 Score, the Logistic Regression and Random Forest models perform better than the other models. The Logistic Regression model has the highest Precision and Recall, while the Random Forest model has the highest F1 Score. Overall, the Logistic Regression and Random Forest models are noteworthy in this classification task."
196,"caption: Evaluation results of different models. The table lists five models (Model A-E) and their performance results on multiple evaluation metrics including F1 Score, Accuracy, Precision, Recall and AUC.table: Model,F1 Score,Accuracy,Precision,Recall,AUC, Model A,0.86,0.92,0.91,0.82,0.95, Model B,0.82,0.89,0.88,0.76,0.92, Model C,0.78,0.87,0.83,0.74,0.91, Model D,0.85,0.91,0.86,0.84,0.94, Model E,0.90,0.93,0.91,0.89,0.96","Table presents the evaluation results of different models on multiple evaluation metrics. Model E achieved the highest F1 score (0.90), accuracy (0.93), and AUC (0.96) among all models, while Model C achieved the lowest F1 score (0.78) and accuracy (0.87). Interestingly, Model B achieved a higher Precision score (0.88) compared to Model A (0.91), despite its lower F1 Score. Overall, Model E appears to be the best-performing model based on the evaluation metrics listed in the table."
197,"caption: Performance metrics of multiple models on evaluation data.table: Model,Accuracy,F1-score,Precision,Recall, Model A,0.89,0.87,0.91,0.85, Model B,0.84,0.80,0.86,0.75, Model C,0.92,0.90,0.93,0.87, Model D,0.78,0.74,0.82,0.68, Model E,0.88,0.85,0.89,0.80","Table presents the performance metrics of five different models, including accuracy, F1-score, precision, and recall. While Model C has the highest accuracy (0.92), it's interesting that it has the lowest recall (0.87). Model A has the highest precision (0.91) but a slightly lower recall (0.85). Model E has a good balance between precision and recall, with the highest F1-score (0.85) while maintaining a precision of 0.89 and recall of 0.80. On the other hand, Model D has the lowest performance in accuracy, F1-score, and recall, indicating the worst performance among the tested models. Overall, Model E seems to be the best-performing model in all evaluation metrics."
198,"caption: Comparison of model performance using different evaluation metrics.table: Models,Accuracy,F1-score,Precision,Recall, Model A,0.965,0.959,0.965,0.957, Model B,0.970,0.964,0.968,0.969, Model C,0.967,0.961,0.971,0.957, Model D,0.969,0.963,0.967,0.970, Model E (ensemble),0.978,0.973,0.977,0.972","Table above shows the performance of five different models (Model A-E) based on four different evaluation metrics (accuracy, F1-score, precision, and recall). It is interesting to note that Model E, which is an ensemble of previous models, outperformed all other models in all of the evaluation metrics. Therefore, it can be concluded that the ensemble model, Model E, is the best model among the evaluated models in this study. However, it is worth emphasizing that the difference in performance between Model E and Model D is very small, which suggests that both models might be equally effective for practical purposes."
199,"caption: Model performance evaluation results for different machine learning algorithms.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.83,0.82,0.85,**0.91**, LR,**0.86**,**0.85**,**0.89**,0.87, KNN,0.59,0.57,0.62,0.56, NB,0.71,0.68,0.77,0.63, DT,0.79,0.77,0.81,0.75","The table presents the performance evaluation results of five machine learning algorithms on a given dataset using four different evaluation metrics: Accuracy, F1-Score, Precision, and Recall. The highest performance results are highlighted in bold show that for Accuracy and F1-score, LR outperforms the other four models, whereas for Precision and Recall, SVM outperforms the other models with 0.91 recall score. Also, it is notable that KNN has the lowest performance among these models. These results suggest that choosing the right ML algorithm and parameter tuning can lead to significant improvements in model performance."
200,"caption: Table 4: Model Evaluation Metrics Results for Different Approaches.table: Model,Accuracy,Precision,Recall,F1-Score, Random Forest,0.897,0.918,0.846,0.880, Gradient Boosting Tree,0.893,0.912,0.855,0.882, Logistic Regression,0.867,0.878,0.835,0.855, Support Vector Machine,0.845,0.863,0.813,0.837, Neural Network,0.890,0.899,0.868,0.882","Table 4 presents the evaluation metrics for different models including Accuracy, Precision, Recall, and F1-Score. The models consisted of Random Forest, Gradient Boosting Tree, Logistic Regression, Support Vector Machine, and Neural Network. Interestingly, Random Forest and Gradient Boosting Tree models have the highest Accuracy of 0.897 and 0.893, respectively. However, the Precision of the models can be varied based on the performance criteria. For instance, the random forest model has the highest Precision, Recall, and F1-Score with 0.918, 0.846, 0.880, respectively, among all the models. Overall, the results show that the random forest model may be the most suitable model for this dataset based on the evaluation metrics used."
201,"caption: Evaluation results of different classification models based on Accuracy, F1-Score, Precision, and Recall metrics.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.75,0.70,0.78,0.64, KNN,0.70,0.60,0.65,0.56, Naive Bayes,0.65,0.45,0.57,0.38, Decision Tree,0.72,0.67,0.69,0.65, Multi-layer Perceptron,0.78,0.75,0.80,0.70","The table presents the evaluation results of five different classification models based on four evaluation measures, namely, Accuracy, F1-Score, Precision, and Recall. SVM and Multi-layer Perceptron achieved the highest accuracy results of 0.75 and 0.78, respectively. Meanwhile, Multi-layer Perceptron had the highest F1-Score and Precision of 0.75 and 0.80, respectively. For Recall, the Decision Tree and KNN models had the highest results of 0.65 and 0.56, respectively. In summary, the Multi-layer Perceptron model appears to be the best-performing model overall with the highest accuracy, F1-score, and precision results among the tested models."
202,"caption: Performance results of different classification models on the datasettable: Model,Accuracy,F1-score,Recall,Precision, Logistic Regression,0.858,0.857,0.857,0.861, Random Forest,0.892,0.893,0.890,0.901, KNN,0.826,0.826,0.826,0.828, SVM,0.858,0.858,0.858,0.859, XGBoost,0.903,0.903,0.903,0.904, LightGBM,0.892,0.892,0.892,0.895",
203,"caption: Performance Evaluation Table for Different Machine Learning Modelstable: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.89,0.88,0.87,0.87, Decision Tree,0.84,0.83,0.80,0.81, Random Forest,0.92,0.92,0.92,0.92, Gradient Boosting,0.93,0.94,0.90,0.91, Support Vector Machine,0.87,0.87,0.84,0.84","The table compares the performance of five different machine learning models - Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Support Vector Machine - on a given dataset. The evaluation metrics include Accuracy, Precision, Recall, and F1-Score. Random Forest and Gradient Boosting demonstrated the highest performance for Accuracy and F1-Score, with scores of 0.92 and 0.93, respectively. Logistic Regression, Decision Tree, and Support Vector Machine demonstrated moderate performance for each of the metrics, with Decision Tree having the lowest performance. Interestingly, although the models were relatively close in Accuracy, there are substantial differences when considering other evaluation metrics. Therefore, it is essential to examine multiple metrics when selecting a model for a particular use case."
204,"caption: Model Performance Tablestable: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.78,0.64,0.82,0.54, KNN,0.72,0.54,0.67,0.45, Naive Bayes,0.65,0.43,0.59,0.36, Decision Tree,0.80,0.68,0.75,0.63, Random Forest,0.85,0.78,0.81,0.75","The table displays the performance results of different classification models through various evaluation metrics. Five models including SVM, K-Nearest Neighbors, Naive Bayes, Decision Tree, and Random Forest are tested for their accuracy, F1-Score, Precision, and Recall. Interestingly, from the accuracy column, Random Forest is the best performing model with 0.85, followed by Decision Tree with 0.8. Naive Bayes has the lowest accuracy at 0.65. From F1-Score, Precision, and Recall scores, it is evident that the Random Forest model outperforms all others with a score of 0.78 for F1-Score, 0.81 for Precision, and 0.75 for Recall, respectively. However, SVM has the best Precision score at 0.82."
205,"caption: Performance evaluation of different models using various metrics.table: Model,F1-score,Precision,Recall,Accuracy, SVM,0.76,0.78,0.74,0.81, KNN,0.83,0.85,0.81,0.87, Decision Tree,0.82,0.80,0.84,0.79, Random Forest,0.87,0.88,0.85,0.90, XGBoost,0.89,0.88,0.91,0.92","The table presents the performance evaluation of five different models based on multiple evaluation metrics, including F1-score, precision, recall, and accuracy. The models included in the table are SVM, KNN, Decision Tree, Random Forest, and XGBoost. It is observed that XGBoost achieved the highest overall performance among the models, scoring an F1-score of 0.89, precision of 0.88, recall of 0.91, and accuracy of 0.92, while Random Forest and KNN also showed good performance. On the other hand, SVM and Decision tree models lacked performance in terms of F1-score and accuracy. Overall, the table guides on selecting the appropriate model based on the evaluation metrics required for the problem at hand."
206,"caption: Model performance comparison based on different evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.85,0.87,0.84,0.90, KNN,0.81,0.83,0.85,0.82, Decision Tree,0.79,0.81,0.77,0.86, Random Forest,0.89,0.91,0.89,0.92, XGBoost,0.91,0.93,0.93,0.93","The table presents the performance evaluation results of five models: SVM, KNN, Decision Tree, Random Forest, and XGBoost. The evaluation metrics include Accuracy, F1 Score, Precision, and Recall. Each model has different results for each evaluation metric. Interestingly, XGBoost outperformed the other models in all metrics with an accuracy of 0.91, F1 score of 0.93, precision of 0.93, and recall of  0.93. Random Forest also performed well with an accuracy of 0.89 and an F1 score of 0.91. SVM and KNN obtained slightly lower scores, while Decision Tree performed the worst with an accuracy of 0.79 and an F1 score of 0.81. Therefore, it can be inferred that XGBoost is the most suitable model for the given dataset based on these evaluation metrics."
207,"caption: Model performance on evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score,AUC-ROC,Bayesian AUC, SVM,0.89,0.92,0.80,0.85,0.92,0.78, LogReg,0.92,0.93,0.90,0.91,0.93,0.84, Random Forest,0.93,0.95,0.88,0.91,0.95,0.86, KNN,0.85,0.87,0.73,0.76,0.89,0.72","The table above 'Model performance on evaluation metrics' summarises the evaluation metrics of four different models: SVM, LogReg, Random Forest, and KNN. The table includes various metrics, including accuracy, precision, recall, F1-score, AUC-ROC, and Bayesian AUC. Notably, Random Forest outperforms the other models in terms of accuracy, with a score of 0.93 and precision with a score of 0.95. However, the model's recall metric was lower with a score of 0.88, resulting in an F1-score of 0.91. Logistic regression produces the highest F1-score and Bayesian AUC out of the four models with scores of 0.91 and 0.84, respectively. This table would be useful for selecting the best model based on a specific evaluation metric."
208,"caption: Performance results of different models with different evaluation metrics.table: Model,F1-score,Precision,Recall,Accuracy, Model A,0.84,0.87,0.81,0.90, Model B,0.82,0.85,0.81,0.87, Model C,0.86,0.81,0.91,0.89, Model D,0.88,0.79,0.99,0.84, Model E,0.90,0.82,1.00,0.85","The table presents the performance results of five different models - Model A through Model E - with four different evaluation metrics: F1-score, Precision, Recall, and Accuracy. Model E achieved the highest F1-score of 0.90, while Model D achieved the highest Precision of 0.79. On the other hand, Model E achieved perfect Recall and the second-highest Accuracy, but Model A achieved the highest Accuracy of 0.90. These differences in performance demonstrate that no single model outperforms all others in all evaluation metrics. Rather, researchers should choose the model that best meets the requirements of their particular research question."
209,"caption: Performance of different models based on various evaluation metrics.table: Model,Metric,Accuracy,F1-Score,Precision,Recall, SVM,Train,0.9302,0.9084,0.9363,0.8824, SVM,Test,0.8706,0.8722,0.8905,0.8545, Decision Tree,Train,0.8275,0.8099,0.8028,0.8171, Decision Tree,Test,0.7451,0.7229,0.7043,0.7433, Random Forest,Train,0.8888,0.8749,0.8653,0.9073, Random Forest,Test,0.7862,0.7631,0.7278,0.9156, XGBoost,Train,0.8888,0.8753,0.8505,0.9083, XGBoost,Test,0.7647,0.7469,0.7339,0.7619",
210,"caption: The Performance Results of Different Machine Learning Models on the Test Set.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.89,0.91,0.87,0.89, Random Forest,0.91,0.93,0.89,0.91, K-Nearest Neighbor,0.87,0.88,0.84,0.86, Decision Tree,0.85,0.87,0.80,0.83, Gradient Boosting,0.92,0.94,0.90,0.92","The table presents the performance results of five machine learning models on the test set using multiple evaluation metrics, including Accuracy, Precision, Recall, and F1-Score. The best-performing model based on the F1-Score was the Gradient Boosting model, achieving an F1-Score of 0.92. The SVM model achieved the highest accuracy (0.89) and precision (0.91), while the Random Forest model achieved the highest recall (0.89). Interestingly, the Decision Tree model had the lowest performance on all metrics but was still able to achieve an overall accuracy of 0.85."
211,"caption: Table 4. Model performance using different evaluation metricstable: Model,Accuracy,Precision,Recall,F1 Score, Model A,0.92,0.93,0.91,0.92, Model B,0.89,0.91,0.83,0.87, Model C,0.94,0.92,0.96,0.94, Model D,0.86,0.82,0.88,0.85, Model E,0.95,0.96,0.94,0.95","Table 4 displays the model performance of five different models evaluated using multiple evaluation metrics. The performance metrics reported in the table include accuracy, precision, recall, and F1 score. Among the models, Model E had the highest accuracy, precision, and F1 score, while Model C had the highest recall. Interestingly, Model B had the lowest recall, despite having the second-highest accuracy score. These results suggest that while Model B may perform well on correctly classifying majority classes, it may have limitations in correctly classifying minority classes as reflected in its relatively low recall. Overall, the evaluation metrics used in this table provide a comprehensive overview of the models’ strengths and weaknesses."
212,"caption: Evaluation metrics of multiple modelstable: Model,Accuracy,F1-score,Precision,Recall, Model 1,0.92,0.93,0.94,0.92, Model 2,0.89,0.88,0.92,0.85, Model 3,0.95,0.94,0.93,0.95, Model 4,0.91,0.88,0.90,0.87","The table presents the evaluation metrics results of multiple models based on four different evaluation metrics. The models include Model 1, Model 2, Model 3, and Model 4, which were evaluated based on their accuracy, F1-score, precision, and recall.  It is interesting to note that Model 3 has the highest accuracy, F1-score, and recall, even though its precision score is lower than Model 1 and Model 2. In contrast, Model 2 has the lowest accuracy, F1-score, and recall among the models. The presented results may be useful in determining which model to choose based on specific evaluation metrics."
213,"caption: Model Performance on Binary Classification Tasktable: Model,Accuracy,F1-Score,Precision,Recall,AUROC, Logistic Regression,0.86,0.85,0.87,0.85,0.91, SVM,0.87,0.86,0.88,0.86,0.92, Random Forest,0.88,0.87,0.89,0.87,0.93, XGBoost,0.89,0.88,0.90,0.88,0.94, MLP,0.90,0.89,0.91,0.89,0.95","The table presents the evaluation results of different machine learning models on a binary classification task. The models were evaluated using multiple performance metrics, including accuracy, F1-Score, precision, recall, and AUROC. The results show that all models had excellent performance across different metrics. Interestingly, MLP achieved the highest score in all metrics, showing the best overall performance among the models. It achieved an accuracy of 0.90, F1-Score of 0.89, precision of 0.91, recall of 0.89, and an AUROC of 0.95. Therefore, we can conclude that MLP is the best-performing model for this binary classification task."
214,"caption: Comparison of various models with different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, LogReg,0.85,0.80,0.90,0.85, SVM,0.83,0.76,0.89,0.82, KNN,0.80,0.72,0.85,0.78, RF,0.88,0.84,0.91,0.87, XGB,0.87,0.83,0.90,0.86","The table above shows the performance comparison of five different models: Logistic Regression (LogReg), Support Vector Machines (SVM), K-Nearest Neighbors (KNN), Random Forest (RF), and Extreme Gradient Boosting (XGB). The models are evaluated on multiple performance metrics, including accuracy, precision, recall, and F1-score. From this table, we can observe that Random Forest and XGB outperformed the other models in all evaluation metrics. RF had an accuracy of 0.88, precision of 0.84, recall of 0.91, and F1-score of 0.87. On the other hand, XGB had an accuracy of 0.87, precision of 0.83, recall of 0.90, and F1-score of 0.86. Therefore, both Random Forest and XGB may be good performing models for this dataset."
215,"caption: Model performance results of different classification models based on multiple evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall,ROC-AUC, Logistic Regression,0.76,0.77,0.79,0.76,0.83, Random Forest,0.80,0.81,0.83,0.80,0.85, Gradient Boosting,0.81,0.81,0.82,0.81,0.87, Support Vector Machine (SVM),0.71,0.72,0.75,0.71,0.79, Multi-layer Perceptron (MLP),0.79,0.79,0.80,0.79,0.84","The presented table compares the performance results of different classification models based on multiple evaluation metrics including accuracy, F1-score, precision, recall, and ROC-AUC. The analyzed models include Logistic Regression, Random Forest, Gradient Boosting, SVM, and MLP. Interestingly, Gradient Boosting model outperformed the other models with the highest ROC-AUC of 0.87, while SVM achieved the lowest ROC-AUC of 0.79. Based on other evaluation metrics, Random Forest and MLP, respectively, achieved the highest and second-highest results in most of the metrics. Therefore, Random Forest and MLP can be considered the second and third best models, respectively, for this dataset."
216,"caption: Model Performances using different evaluation metrics.table: Model,Accuracy,Sensitivity,Specificity,Precision,F1 Score, SVM,0.92,0.81,0.96,0.85,0.83, KNN,0.85,0.78,0.90,0.72,0.75, Naive Bayes,0.78,0.63,0.89,0.57,0.59, Logistic Regression,0.83,0.75,0.89,0.69,0.72","The table shows the performance results of four different models, SVM, KNN, Naive Bayes, and Logistic Regression, evaluated with five different metrics: Accuracy, Sensitivity, Specificity, Precision, and F1 Score. Interestingly, SVM performed the best in terms of accuracy, achieving an accuracy of 0.92. However, Naive Bayes performed particularly poorly, producing the lowest scores for all of the metrics except for sensitivity. These results indicate that SVM might be the best model to use when the highest accuracy is necessary, while Naive Bayes could be an option when sensitivity is more important than other metrics."
217,"caption: Evaluation metrics for different modelstable: Model,Accuracy,Precision,Recall,F1-score, Model A,0.82,0.81,0.83,0.82, Model B,0.84,0.85,0.82,0.83, Model C,0.83,0.80,0.86,0.83, Model D,0.81,0.79,0.83,0.81, Model E,0.85,0.87,0.86,0.85","Table presents the evaluation metrics for different models, including Accuracy, Precision, Recall, and F1-score. The different models (Model A to E) were assessed on the same dataset. Interestingly, Model E has the highest overall performance, achieving an Accuracy of 0.85, Precision of 0.87, Recall of 0.86, and F1-score of 0.85. Model B and Model C had comparable overall performances achieving Accuracy scores of 0.84 and 0.83, respectively. However, Model B had the highest Precision score of 0.85, while Model C achieved the highest Recall score of 0.86. These results suggest that there are variations in the performance of different models evaluated on the same dataset, indicating that hyperparameter tuning or a combination of multiple models may further improve the overall performance."
218,"caption: Table 4: Performance metrics of different classification models on the datasettable: Model,Precision,Recall,F1-score,AUC, SVM,0.89,0.85,0.87,0.95, Logistic Regression,0.86,0.94,0.90,0.97, Random Forest,0.92,0.88,0.90,0.93, XGBoost,0.93,0.86,0.89,0.95",
219,"caption: Model Evaluation Results for Different Algorithmstable: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.87,0.83,0.78,0.89, Random Forest,0.92,0.90,0.86,0.95, Support Vector Machine,0.85,0.81,0.79,0.82, Neural Network,0.89,0.87,0.83,0.91, K-Nearest Neighbors,0.88,0.85,0.81,0.89","The table presents the evaluation results of five different models using multiple performance metrics: Accuracy, F1 score, precision, and recall. The models include Logistic Regression, Random Forest, Support Vector Machine, Neural Network, and K-Nearest Neighbors. Interestingly, Random Forest has the highest accuracy (0.92) and F1 Score (0.90), followed by Neural Network (0.89) and Logistic Regression (0.87). However, Support Vector Machine achieves the best precision score (0.79), while Random Forest achieves the best recall score (0.95). The table suggests that Random Forest may be the best-performing model among the tested models for this dataset, considering the overall performance results."
220,"caption: Model Metrics Comparisontable: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.85,0.88,0.85,0.86, Random Forest,0.87,0.89,0.87,0.88, Decision Tree,0.81,0.82,0.81,0.81, Support Vector Machine,0.84,0.86,0.84,0.85, K-Nearest Neighbors,0.79,0.81,0.79,0.80","The table compares the performance of five different models based on four evaluation metrics: accuracy, precision, recall, and F1-score. The models include Logistic Regression, Random Forest, Decision Tree, SVM, and K-Nearest Neighbors. Interestingly, Random Forest outperforms the other models in accuracy, precision, recall, and F1-score with values of 0.87, 0.89, 0.87, and 0.88, respectively. Logistic Regression also provides satisfying results with the second-highest accuracy and F1-score. On the other hand, K-Nearest Neighbors has the lowest performance compared to other models. The results of this study provide useful insights for selecting the appropriate model for the given dataset."
221,"caption: Evaluation results of multiple different models using multiple performance metrics.table: Model,MAE,Root Mean Squared Error (RMSE),R-Squared (R2), Model 1,2.1,3.5,0.87, Model 2,3.0,4.2,0.71, Model 3,1.6,2.9,0.94, Model 4,5.2,6.7,0.49, Model 5,2.8,4.3,0.76","Table 1 presents the evaluation results of multiple different models using multiple performance metrics: Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and R-squared (R2). Model 3 was the best-performing model, achieving the lowest MAE of 1.6 and RMSE of 2.9, as well as the highest R2 of 0.94. On the other hand, Model 4 performed the worst with MAE of 5.2, RMSE of 6.7, and R2 of 0.49. Interestingly, Model 2 had a relatively high MAE of 3.0 and low R2 of 0.71, while Model 5 achieved a lower MAE of 2.8 but a similarly low R2 of 0.76. Overall, the models have varying performance results depending on the metrics used, indicating the importance of choosing appropriate evaluation metrics based on the specific application."
222,"caption: Comparison of the performance of various classification models based on accuracy, precision, recall, and F1-score.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.825,0.78,0.88,0.83, Naive Bayes,0.742,0.68,0.68,0.68, Decision Tree,0.780,0.74,0.79,0.76, Random Forest,0.855,0.85,0.80,0.82, XGBoost,0.870,0.87,0.86,0.86","Table presents the performance results of five different models, SVM, Naive Bayes, Decision Tree, Random Forest, and XGBoost, on classification task evaluation metrics including Accuracy, Precision, Recall, and F1-score. Among the models, XGBoost achieved the highest accuracy (0.870) while Random Forest showed the highest precision (0.85) and SVM showed the highest recall (0.88). However, when evaluating models based on both recall and precision, XGBoost model achieved the highest F1-score (0.86), while Naive Bayes showed the lowest performance across all metrics with 0.742 accuracy and 0.68 precision, recall, and F1-score."
223,"caption: Model performance results of different models based on multiple evaluation metrics.table: Model,F1-Score,Accuracy,Specificity,Sensitivity, Logistic Regression,0.83,0.84,0.808,0.871, Random Forest,0.85,0.86,0.847,0.856, Support Vector Machine,0.86,0.81,0.835,0.788, Decision Tree,0.74,0.73,0.784,0.708, Naive Bayes,0.62,0.59,0.617,0.583","Table presents the F1-Score, Accuracy, Specificity, and Sensitivity of different models: Logistic Regression, Random Forest, Support Vector Machine, Decision Tree, and Naive Bayes. Interestingly, the Support Vector Machine model achieved the highest F1-Score of 0.86 while the Random Forest model achieved the highest accuracy value of 0.86. The Support Vector Machine model also achieved the highest specificity value of 0.835 while the Logistic Regression model scored the highest sensitivity value of 0.871. Overall, it appears that the Support Vector Machine model outperformed the others in the majority of evaluation metrics. However, a combined consideration of all evaluation metrics may be required to choose the most appropriate model."
224,"caption: Performance of Machine Learning Modelstable: Model,Accuracy,Recall,F1 Score,Specificity, SVM,0.806,0.605,0.695,0.913, NB,0.768,0.859,0.807,0.594, RF,0.898,0.812,0.853,0.949, KNN,0.748,0.456,0.567,0.954, MLP,0.856,0.723,0.783,0.928","The table displays the performance results for five different machine learning models - SVM, NB, RF, KNN, and MLP. The evaluation metrics used are Accuracy, Recall, F1 Score, and Specificity. Interestingly, RF outperforms all the other models with a high accuracy of 0.898, recall of 0.812, F1 Score of 0.853, and specificity of 0.949. SVM has the highest specificity of 0.913, while NB has the highest recall of 0.859. KNN has the lowest accuracy of 0.748, while MLP has the highest accuracy of 0.856. Overall, RF seems to be the best-performing model among the tested models in this dataset for all evaluation metrics."
225,"caption: Comparison of model performance on evaluation metricstable: ```, Model,Accuracy,Precision,Recall,F1-Score,AUC-ROC, Model 1,0.95,0.88,0.93,0.90,0.99, Model 2,0.92,0.91,0.81,0.86,0.97, Model 3,0.84,0.70,0.67,0.68,0.80, Model 4,0.96,0.94,0.94,0.94,0.98, Model 5,0.89,0.76,0.83,0.77,0.88","In Table 1, the performance of five different models was evaluated based on various metrics such as accuracy, precision, recall, F1-score, and AUC-ROC. Model 1 achieved the highest accuracy of 0.95, followed by Model 4 with an accuracy of 0.96. Model 2 achieved the best precision of 0.91 and the worst recall of 0.81. Both Model 1 and Model 4 scored high on recall, achieving a score of 0.93. Model 4 achieved the highest F1-score of 0.94. In terms of AUC-ROC, Model 1 achieved the highest score of 0.99, followed by Model 4 with a score of 0.98. Model 3 scored the lowest on all metrics, indicating poor performance overall. Overall, Model 1 and Model 4 outperform the other models based on these metrics."
226,"caption: Comparison of Different Models with Multiple Evaluation Metricstable: Model Name,Accuracy,Precision,Recall,F1 Score,AUC Score, Logistic Regression,0.875,0.889,0.823,0.855,0.925, Naive Bayes,0.779,0.720,0.712,0.691,0.826, Decision Tree,0.656,0.684,0.478,0.529,0.632, Random Forest,0.891,0.887,0.871,0.879,0.935, XGBoost,0.906,0.886,0.912,0.898,0.942","The table presents the performance of five different models in terms of multiple evaluation metrics. The models included are Logistic Regression, Naive Bayes, Decision Tree, Random Forest, and XGBoost. Metrics reported include accuracy, precision, recall, F1 score, and AUC score. Interestingly, XGBoost and Random Forest models showed the best performance scores with high AUC and F1 scores. This table highlights the importance of evaluating models based on multiple evaluation metrics rather than focusing on only one."
227,"caption: Table 4: Model Performance on Binary Classification Tasktable: Model,Accuracy,F1 Score,Precision,Recall, Decision tree,0.75,0.64,0.65,0.64, Random Forest,0.85,0.80,0.82,0.79, Gradient Boosting,0.83,0.77,0.79,0.75, Logistic Regression,0.72,0.60,0.61,0.60, Support Vector,0.69,0.57,0.59,0.56",
228,"caption: Table 4: Evaluation metrics of different modelstable: Model,Accuracy,F1-score,Recall,Precision, Model 1,0.85,0.8,0.9,0.75, Model 2,0.91,0.88,0.9,0.87, Model 3,0.82,0.78,0.85,0.76, Model 4,0.93,0.91,0.92,0.89, Model 5,0.87,0.84,0.88,0.81","Table 4 shows the evaluation metrics of five different models: Model 1, Model 2, Model 3, Model 4, and Model 5. The table displays the accuracy, F1-score, recall, and precision of each model. Notably, Model 4 has the highest accuracy, F1-score, and recall among the five models. Model 2 has the highest precision. This suggests that Model 4 may be the best-performing model for this particular task, but precision may be prioritized over recall for Model 2. Overall, this table provides a clear comparison of model performance, allowing for informed model selection based on specific needs and priorities."
229,"caption: Model performance using multiple metrics.table: Model,Precision,Recall,F1-Score,Accuracy, Model A,0.85,0.88,0.87,0.89, Model B,0.76,0.95,0.84,0.83, Model C,0.91,0.74,0.82,0.92, Model D,0.82,0.91,0.86,0.84",
230,"caption: Comparison of different models based on accuracy, F1-Score, precision, and recall.table: Model,Accuracy,F1-Score,Precision,Recall, Model A,0.87,0.86,0.89,0.84, Model B,0.85,0.83,0.86,0.81, Model C,0.89,0.88,0.90,0.87, Model D,0.83,0.81,0.84,0.79, Model E,0.91,0.90,0.92,0.88","Table shows a comparison of Model A, B, C, D, and E based on their accuracy, F1-Score, precision, and recall. It is evident that Model E shows the highest performance score across all metrics. It achieved 0.91 accuracy, 0.90 F1-score, 0.92 precision and 0.88 recall, which is the best among all the models. However, if we consider only the F1-Score metric, Model C achieved a close score of 0.88 and is the second-best performer. On the other hand, Model D has the lowest scores on all metrics, and Model B's scores are also lower than the others. Overall, this table establishes Model E as the best performer and Model D as the least performer among all the tested models."
231,"caption: Model evaluation metrics and performance results for different classifiers.table: Model,Accuracy (%),F1-Score,Sensitivity,Specificity, SVM,80.5,0.81,0.79,0.82, Logistic Reg.,76.2,0.73,0.71,0.76, Random Forest,82.6,0.83,0.82,0.84, KNN,68.7,0.6,0.57,0.71","Table 4 presents model evaluation metrics for four different classifiers, including SVM, Logistic Regression, Random Forest, and KNN. The classifiers' performances were evaluated based on the accuracy, F1-score, sensitivity, and specificity metrics. Random Forest shows the highest accuracy of 82.6%, followed by SVM with 80.5%. KNN, on the other hand, demonstrates the lowest accuracy of 68.7%. Additionally, the Random Forest algorithm has the highest F1-score of 0.83, while the Logistic Regression model has the lowest F1-score of 0.73. Notably, the sensitivity metric for all models is relatively close. SVM has the highest specificity of 0.82, and KNN has the lowest specificity of 0.71."
232,"caption: Table 4: Performance comparison of various models using different evaluation metrics.table: Model,Accuracy,F1 Score,AUC, Model A,0.85,0.83,0.92, Model B,0.87,0.84,0.91, Model C,0.83,0.81,0.89, Model D,0.89,0.88,0.95, Model E,0.91,0.90,0.93","Table 4 presents a comparison of several models based on their performance using different evaluation metrics, including Accuracy, F1 score, and AUC. The table includes five models labeled as Model A, Model B, Model C, Model D, and Model E. The Accuracy metric indicates how many predictions the model gets correctly, and the F1 score metric is the harmonic mean of the precision and recall. AUC represents the model's ability to classify data accurately. Model E had the highest accuracy of 0.91, while Model D had the highest F1 score of 0.88. Model D, again, had the highest AUC of 0.95, showing its robustness and effectiveness in performance. Model C had a lower performance compared to the other models in all the metrics evaluated."
233,"caption: Performance comparison of different models on the classification task.table: Model,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.85,0.84,0.87,0.81, Decision Tree,0.79,0.78,0.81,0.76, Random Forest,0.88,0.87,0.89,0.86, Gradient Boosting,0.89,0.88,0.90,0.86, XGBoost,0.90,0.89,0.91,0.88","The table presents the model performance comparison on a classification task using Accuracy, F1-Score, Precision, and Recall as evaluation metrics. The table presents the results of 5 different models, including Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and XGBoost. It can be observed that Gradient Boosting and XGBoost outperformed other models with an accuracy of 0.89 and 0.90, respectively. Similarly, XGBoost demonstrated the highest F1-Score of 0.89. Moreover, XGBoost also showed superior precision and recall values with 0.91 and 0.88, respectively. The overall results indicate that XGBoost model performs better than other tested models on the given classification task."
234,"caption: Model performance on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.87,0.89,0.79,0.84, RF,0.88,0.91,0.81,0.85, LR,0.90,0.93,0.83,0.88, MLP,0.89,0.92,0.82,0.86, KNN,0.82,0.81,0.92,0.86","Table presents the evaluation metrics of Accuracy, Precision, Recall and F1-score of five different models: SVM, RF, LR, MLP, and KNN. SVM and Random Forest show the highest accuracy scores of 0.87 and 0.88, respectively. However, Logistic Regression (LR) has superior performance regarding Precision (0.93) and F1-Score (0.88). MLP has a robust Precision of 0.92 as well but has a lower Recall of 0.82 compared to LR. K-Nearest Neighbors (KNN) model has a high recall score of 0.92 but comparatively low Precision and F1-score of 0.81 and 0.86, respectively. Therefore, the Logistic Regression Model shows the best overall performance in the table."
235,"caption: Performance evaluation of different models using diverse evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, Model 1,0.91,0.93,0.91,0.95, Model 2,0.89,0.92,0.88,0.96, Model 3,0.93,0.94,0.94,0.94, Model 4,0.87,0.89,0.90,0.88, Model 5,0.90,0.91,0.92,0.91","Table 1 presents an evaluation of the performance of five different models using multiple evaluation metrics. The evaluation metrics consist of accuracy, F1-score, precision, and recall. The table shows that the best accuracy and recall scores were achieved by Model 3 with a score of 0.93 and 0.94, respectively. Model 1 had the best precision with a score of 0.91. Interestingly, Model 3 had the highest F1-score of 0.94, having the best overall performance across all evaluation metrics. However, Model 2 had the lowest scores for all metrics, indicating the need for further optimization."
236,"caption: Table 4: Model Evaluation Metrics Comparison.table: Model,F1 Score (Class 0),F1 Score (Class 1),Accuracy,Precision (Class 0),Precision (Class 1),Recall (Class 0),Recall (Class 1), M1,0.88,0.55,0.75,0.91,0.40,0.85,0.68, M2,0.76,0.78,0.77,0.60,0.91,0.89,0.67, M3,0.83,0.72,0.81,0.80,0.77,0.86,0.60, M4,0.90,0.62,0.84,0.92,0.50,0.88,0.61, M5,0.86,0.70,0.83,0.78,0.83,0.94,0.50","Table 4 compares the performance of five models across various evaluation metrics, including F1 Score, Accuracy, Precision, and Recall. The table shows the model's F1 score for class 0 and class 1. Moreover, the Precision, Recall, and Accuracy for class 0 and class 1 are also presented. The column headers represent the evaluation metrics, and the model names appear in the first column. Notably, M4 achieved the highest F1 score of 0.90 for class 0, while M2 achieved the highest F1 score of 0.78 for class 1. M1 had the highest Precision score of 0.91 for class 0, while M2 had the highest Precision score of 0.91 for class 1. Furthermore, M5 had the highest Recall score of 0.94 for class 0, while M1 had the highest Recall score of 0.68 for class 1. Finally, M4 had the highest accuracy of 0.84."
237,"caption: Performance of different classification models on the dataset.table: Model,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.85,0.80,0.78,0.82, Support Vector Machine,0.87,0.82,0.83,0.81, Random Forest,0.89,0.87,0.86,0.88, Naive Bayes,0.78,0.72,0.70,0.74",
238,"caption: Table 4: Model performances based on Accuracy, F1-Score, and MCC.table: Model,Accuracy,F1-Score,MCC, SVM,0.81,0.82,0.62, KNN,0.67,0.52,0.29, RF,0.91,0.91,0.78, DNN,0.87,0.88,0.72, NB,0.65,0.66,0.31","Table 4 provides a comparison of model performances based on accuracy, F1-Score, and MCC. The models examined in this table are SVM, KNN, RF, DNN, and NB. The table demonstrates that the RF model has the highest accuracy score of 0.91, with corresponding F1-Score and MCC scores of 0.91 and 0.78, respectively. On the other hand, the KNN model has the lowest accuracy, F1-Score, and MCC scores of 0.67, 0.52, and 0.29, respectively. Interestingly, the SVM model shows a high F1-Score of 0.82 but lower accuracy and MCC scores of 0.81 and 0.62, respectively. The DNN model scored well in all metrics, with an accuracy of 0.87, F1-Score of 0.88, and MCC of 0.72, illustrating a reliable model for classification. It is clear from Table 4 that the RF model performs best overall."
239,"caption: Table 4: Model performances with different evaluation metricstable: Model,Accuracy,F1,Recall,Precision, SVM,0.82,0.81,0.85,0.77, K-NN,0.80,0.80,0.80,0.81, Naive Bayes,0.78,0.75,0.76,0.75, Decision Tree,0.87,0.85,0.85,0.88, Random Forest,0.91,0.90,0.89,0.92","Table 4 shows the evaluation of different classifiers with multiple metrics, including Accuracy, F1, Recall, and Precision. The highest performance is reported for the Random Forest classifier with an accuracy score of 0.91. It also outperforms the other classifiers with an F1 score of 0.90, Recall score of 0.89, and Precision score of 0.92. The Decision Tree model shows good performance with an accuracy score of 0.87 and an F1 score of 0.85. The SVM model has a marginally lower accuracy score of 0.82 but performs well with an F1 score of 0.81. K-NN and Naive Bayes classifiers had lower accuracy scores than the others, at 0.80 and 0.78, respectively."
240,"caption: Performance metrics comparison of different models.table: Model,Accuracy,F1-Score,Precision,Recall, Model A,0.85,0.83,0.82,0.85, Model B,0.87,0.85,0.87,0.83, Model C,0.83,0.81,0.79,0.83, Model D,0.84,0.82,0.85,0.80","The table presents the evaluation metrics' results of multiple models: Model A, Model B, Model C, and Model D. The evaluation metrics include Accuracy, F1-Score, Precision, and Recall. Interestingly, Model B has the highest accuracy of 0.87 followed closely by Model A with 0.85 of accuracy. On the other hand, Model C has the lowest accuracy with 0.83. Similarly, Model B shows the highest F1-Score of 0.85, whereas Model A shows the highest precision of 0.82. Model D had the best recall score at 0.80. In conclusion, the performance of the four models varies, and the selection of a model depends on the evaluation metric of interest."
241,"caption: Model performance summary for different models based on multiple evaluation metrics.table: Model,Precision,Recall,F1-score,Accuracy, Logistic Regression,0.73,0.70,0.70,0.74, Decision Tree,0.76,0.62,0.63,0.69, K-Nearest Neighbor,0.78,0.70,0.70,0.77, Random Forest,0.76,0.79,0.78,0.79, Support Vector Machines,0.69,0.81,0.74,0.70",
242,"caption: Evaluation metrics of different classification modelstable: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.82,0.80,0.83,0.81, Decision Tree,0.73,0.73,0.74,0.73, Random Forest,0.89,0.88,0.90,0.89, KNN,0.67,0.60,0.68,0.63, SVM,0.85,0.84,0.87,0.85","The table presents a comparison of the performances of five different classification models using various evaluation metrics. The models' performances were evaluated based on Accuracy, Precision, Recall, and F1-score. The Random Forest model performed the best with an accuracy of 0.89. Meanwhile, the Logistic Regression model had the highest precision and recall scores, both at 0.80 and 0.83, respectively. However, it is worth noting that the accuracy of the KNN model was the lowest among those tested at 0.67. Overall, these results suggest that the Random Forest model has the best compromise between accuracy, precision, recall, and F1-score."
243,"caption: Performance comparison of different models on the test set.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regress,0.92,0.89,0.93,0.86, Random Forest,0.91,0.87,0.92,0.83, SVM,0.91,0.87,0.91,0.85, Naive Bayes,0.89,0.83,0.88,0.79","The table presents a performance comparison of Logistic Regression, Random Forest, Support Vector Machine (SVM), and Naive Bayes models on a test dataset. The models performance is evaluated using accuracy, F1 score, precision, and recall. Interestingly, all models show high accuracy levels ranging from 0.89 to 0.92. The Logistic Regression shows the highest accuracy score of 0.92 and the highest F1 score of 0.89 among all models. The SVM model achieved the highest precision score of 0.91, while the Random Forest model had the highest recall score of 0.83."
244,"caption: Table 4: Model Performance Metrics Comparisontable: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.71,0.79,0.83,0.81, Decision Tree,0.62,0.65,0.63,0.64, Random Forest,0.79,0.76,0.86,0.81, Gradient Boosting,0.78,0.75,0.83,0.79, Support Vector Machines,0.65,0.71,0.79,0.74","Table 4 compares five different models' performance evaluation metrics solely based on accuracy, precision, recall, and F1-score. The models examined are Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Support Vector Machines (SVM). The Random Forest model had the highest accuracy score of 0.79, followed closely by Gradient Boosting with an accuracy score of 0.78. The SVM model attained the highest recall score of 0.79, while Logistic Regression achieved the highest precision score of 0.79. Overall, Random Forest offers the best F1-score of 0.81 among all presented models."
245,"caption: Different models comparison based on multiple evaluation metrics.table: Model,Accuracy,F1-Score,AUROC-AUC,PR-AUC, Logistic Regression,0.88,0.85,0.92,0.87, Decision Tree,0.82,0.81,0.85,0.77, Random Forest,0.91,0.89,0.94,0.91, K-Nearest Neighbors,0.82,0.80,0.87,0.82, Support Vector Machine,0.90,0.88,0.93,0.90","The table above presents a comparison of different models based on accuracy, F1-Score, AUROC-AUC, and PR-AUC evaluation metrics. The table includes Logistic Regression, Decision Tree, Random Forest, K-Nearest Neighbors, and Support Vector Machine models. According to the results, the Random Forest model performs the best among all the models across all evaluation metrics with an accuracy of 0.91, F1-Score of 0.89, AUROC-AUC of 0.94 and PR-AUC of 0.91. The table also shows that the Logistic Regression model has the second-best performance overall. Finally, we can see that the Decision Tree model exhibits lower performance than the other models based on different evaluation metrics."
246,"caption: Performance comparison of different machine learning models based on multiple metrics.table: Model,Accuracy,Precision,Recall,F1-score, LR,0.85,0.84,0.87,0.85, SVM,0.84,0.83,0.85,0.84, RF,0.87,0.86,0.89,0.87, XGB,0.89,0.87,0.92,0.89, DNN,0.88,0.85,0.91,0.88","Table presents a performance comparison of different machine learning models based on accuracy, precision, recall and F1-score. The models include Logistic Regression(LR), Support Vector Machine(SVM), Random forest(RF), XGBoost(XGB), and Deep Neural Network (DNN). The table shows that the XGB model is the most accurate (0.89). However, the RF model achieved the highest F1-score (0.87), thus providing the best balance of precision and recall. The LR and SVM models demonstrate similar performance, with accuracy and F1-score of 0.85 and 0.84 for LR, and 0.84 and 0.84 for SVM, respectively. The DNN model achieved the highest precision value (0.85)."
247,"caption: Model comparison based on multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, SVM,0.85,0.80,0.75,0.77, KNN,0.72,0.68,0.56,0.59, RF,0.91,0.92,0.89,0.90, MLP,0.89,0.86,0.83,0.84, NB,0.79,0.70,0.61,0.64, DT,0.82,0.77,0.71,0.73","The table presents the comparison of different models based on multiple evaluation metrics, including Accuracy, Precision, Recall, and F1 Score. The table encompasses SVM, KNN, RF, MLP, NB, and DT models' performances evaluated on the same dataset and testing methodology. Interestingly, the RF model demonstrated the best performance in terms of accuracy, precision, and F1 score with 0.91, 0.92, and 0.90, respectively. However, the MLP model has outperformed all other models with a recall score of 0.83. Overall, the table highlights the difference in model performances based on different metrics, indicating no single model is superior to others under every circumstance."
248,"caption: Table 4: Model performance comparison based on multiple evaluation metricstable: Model,Accuracy,Precision,Recall,F1, Decision Tree,0.85,0.85,0.83,0.83, Naive Bayes,0.81,0.82,0.77,0.78, Random Forest,0.92,0.93,0.91,0.92, Support Vector Machine,0.89,0.87,0.87,0.87, Logistic Regression,0.91,0.90,0.90,0.90, Gradient Boosting,0.93,0.94,0.93,0.94","Table 4 presents a performance comparison of six different models based on multiple evaluation metrics, namely Accuracy, Precision, Recall, and F1-score. The models in the table are Decision Tree, Naive Bayes, Random Forest, Support Vector Machine, Logistic Regression, and Gradient Boosting. All models were evaluated on the same dataset. Interestingly, the Gradient Boosting model outperformed all other models with the highest scores for Accuracy, Precision, Recall, and F1-score, at 0.93, 0.94, 0.93, and 0.94, respectively. The Random Forest and Logistic Regression models also show promising results, achieving an overall accuracy of 0.92 and 0.91, respectively."
249,"caption: Table 4: Performance of different models based on multiple evaluation metricstable: Model,F1-score,Precision,Recall,ROC-AUC,PR-AUC, Model A,0.83,0.76,0.92,0.89,0.77, Model B,0.79,0.81,0.78,0.86,0.68, Model C,0.75,0.69,0.83,0.81,0.62, Model D,0.86,0.79,0.95,0.93,0.84, Model E,0.88,0.88,0.88,0.91,0.84","Table 4 shows the performance of multiple models based on different evaluation metrics. The table presents F1-score, Precision, Recall, ROC-AUC, and PR-AUC results for each model. Model D shows the highest F1-score of 0.86, Precision of 0.79, and Recall of 0.95, indicating its higher accuracy in identifying the positive cases. On the other hand, Model E displays the highest ROC-AUC and PR-AUC scores of 0.91 and 0.84, indicating its better ability to distinguish true positive cases from false positives. Moreover, models A, B, and C show relatively close performance results, but their accuracy varies depending on the metric."
250,"caption: Table 4: Performance of different models in terms of accuracy, precision, recall, and F1-scoretable: Model,Accuracy,Precision,Recall,F1-score, Model A,0.85,0.86,0.87,0.85, Model B,0.81,0.79,0.80,0.79, Model C,0.89,0.89,0.91,0.89, Model D,0.83,0.82,0.84,0.83, Model E,0.87,0.88,0.85,0.86","The table presents the evaluation of different models based on multiple performance metrics, including Accuracy, Precision, Recall, and F1-score. Model A achieved the highest accuracy of 0.85, while Model C had the greatest Precision of 0.89. Moreover, Model C has the highest Recall of 0.91, with a good balance between Precision and Recall, as evidenced by the F1-score of 0.89. Interestingly, Model E has the highest Precision and F1-score of 0.88 and 0.86, respectively. Finally, Model B has the lowest performance in all metrics, with an accuracy of 0.81."
251,"caption: Table 4: Model Performance Evaluations on Test Data: Accuracy(%), F1 Score, Precision, Recall.table: Model Name,Accuracy,F1 Score,Precision,Recall, Random Forest,0.85,0.84,0.86,0.87, Logistic,0.82,0.81,0.83,0.82, Naive Bayes,0.75,0.73,0.72,0.79, KNN,0.81,0.80,0.78,0.81","Table 4 summarizes the performance of four machine learning models on a test dataset. The models' evaluation metrics include Accuracy, F1 Score, Precision, and Recall. The Random Forest model achieved the highest Accuracy score of 0.85 and the highest Recall score of 0.87. However, the model with the highest F1 Score and Precision was the Logistic Regression model with scores of 0.81 and 0.83, respectively. While the Naive Bayes model shows a lower performance compared to the Random Forest and Logistic models, it achieved the highest Precision score of 0.72. Finally, the KNN model lies between the Random Forest and Logistic Regression models in terms of performance."
252,"caption: Model performance comparison based on different evaluation metrics.table: Model,Precision,Recall,F1-Score,Accuracy, Model A,0.85,0.80,0.82,0.90, Model B,0.80,0.85,0.82,0.89, Model C,0.87,0.77,0.81,0.91, Model D,0.76,0.92,0.83,0.88, Model E,0.91,0.79,0.84,0.92",Table: Model performance comparison based on different evaluation metrics.
253,"caption: Comparison of different classification models based on evaluation metrics.table: Model,F1 score,Accuracy,Precision,Recall, Logistic Regression,0.78,0.83,0.81,0.75, Decision Tree,0.76,0.81,0.75,0.78, Random Forest,0.84,0.87,0.83,0.85, Naive Bayes,0.65,0.71,0.68,0.62, K-nearest Neighbor,0.72,0.78,0.80,0.66","Table presents the comparison of various classification models based on their evaluation metrics, namely F1 score, accuracy, precision, and recall. The models tested were Logistic Regression, Decision Tree, Random Forest, Naive Bayes, and K-nearest Neighbor. The Random Forest model performed the best with an F1 score of 0.84, an accuracy score of 0.87, and precision and recall scores of 0.83 and 0.85, respectively. Logistic Regression and Decision Tree models have similar performance, whereas Naive Bayes performed the worst in terms of all evaluation metrics except precision. Interestingly, the K-nearest Neighbor model shows the highest precision score of 0.80 dispite a relatively low recall score of 0.66."
254,"caption: Evaluation Metrics for Different Modelstable: Model,Accuracy,F1-score,Precision,Recall, SVM,0.90,0.89,0.91,0.89, KNN,0.82,0.81,0.78,0.87, Naive Bayes,0.70,0.68,0.72,0.67, Decision Tree,0.85,0.84,0.81,0.87, Random Forest,0.87,0.86,0.83,0.90","Table exhibits the comparison of different models' classification performance in terms of several evaluation metrics: Accuracy, F1-score, Precision, and Recall. The precision refers to the proportion of true positives amongst the predicted positives by the model. The Recall refers to the proportion of actual positives that were correctly identified by the model. The SVM model showed the highest accuracy of 0.90 and precision of 0.91, while the KNN model showed the highest recall of 0.87. Notably, the Random Forest model's F1-score is the highest amongst all models with 0.86, closely followed by the SVM with an F1-score of 0.89. It is worth noting that the performance of the Naive Bayes model was the poorest amongst the models evaluated."
255,"caption: Model performances of different algorithms using various evaluation metrics.table: Model,Accuracy,F1-score,PR-AUC,ROC-AUC, Random Forest,0.930,0.932,0.840,0.918, Decision Tree,0.872,0.869,0.695,0.755, Support Vector,0.912,0.912,0.759,0.854, Logistic Regress,0.921,0.922,0.802,0.891, KNN,0.903,0.903,0.766,0.834","Table presents a comparison of different models' performances using common classification metrics such as Accuracy, F1-score, PR-AUC, and ROC-AUC. The table displays the results of the Random Forest, Decision Tree, Support Vector, Logistic Regression, and K Nearest Neighbor (KNN) models. The Random Forest achieved the highest accuracy (0.930) and F1-score (0.932), while the Decision Tree model performed poorly compared to other models, with the lowest PR-AUC (0.695) and ROC-AUC (0.755) scores. Interestingly, among the models, the Logistic Regression outperformed the rest for PR-AUC (0.802) and ROC-AUC (0.891) scores. Overall, the table demonstrates that different models can show significantly different performances for various evaluation metrics."
256,"caption: Performance results of multiple models using different evaluation metrics.table: Model,Precision,Recall,F1-Score,Accuracy, Logistic Regression,0.85,0.88,0.86,0.87, Random Forest,0.93,0.92,0.92,0.92, Support Vector Machine,0.82,0.89,0.85,0.85, Neural Network,0.90,0.86,0.88,0.87","The table presents the performance results of four different models using multiple evaluation metrics, including Precision, Recall, F1-Score, and Accuracy. The Logistic Regression model achieved the highest Precision score of 0.85, while Random Forest had the highest F1-Score of 0.92 and Recall of 0.92. Interestingly, although the Support Vector Machine had the lowest Precision score of 0.82, it had the highest Accuracy of 0.85. Finally, the Neural Network model achieved a high Precision score of 0.90 and a relatively high Accuracy score of 0.87. Overall, these results suggest that different models perform differently depending on the evaluation metrics adopted."
257,"caption: Comparison of multiple models based on different evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, Model A,0.87,0.87,0.86,0.88, Model B,0.84,0.85,0.84,0.87, Model C,0.88,0.84,0.86,0.82","Table above presents a comparison of Model A, Model B, and Model C based on different evaluation metrics, including Accuracy, F1-score, Precision, and Recall. Model A achieves the highest accuracy of 0.87, followed by Model C with an accuracy of 0.88. However, Model C records the lowest F1-score of 0.84 compared to Model A's 0.87 and Model B's 0.85. Similarly, Model B demonstrates the highest Precision of 0.84 and Recall of 0.87 compared to Model A and Model C. Overall, Model A shows an excellent performance across all metrics, achieving a high accuracy score of 0.87, a high F1-score of 0.87, and relatively high precision and recall scores of 0.86 and 0.88, respectively."
258,"caption: Table 4: Model performance using multiple evaluation metrics.table: Model,Accuracy,Precision,Recall, Logistic Regression,0.82,0.84,0.79, Random Forest,0.88,0.90,0.85, Gradient Boosting,0.90,0.89,0.92, K-Nearest Neighbors,0.85,0.84,0.88, Support Vector Machines,0.87,0.85,0.91","This table (Table 4) presents the evaluation metrics for five different models: Logistic Regression, Random Forest, Gradient Boosting, K-Nearest Neighbors, and Support Vector Machines. The evaluation metrics include Accuracy, Precision, and Recall. The Random Forest model had the highest Accuracy score of 0.88, while Gradient Boosting model shows the highest Recall score of 0.92. Interestingly, K-Nearest Neighbors model exhibits the lowest Precision score of 0.84, while Logistic Regression model shows the highest Precision score of 0.84. Overall, this table demonstrates the diverse performance results of different models using multiple evaluation metrics, providing useful information in selecting the best model for a particular task."
259,"caption: Table 4: Model Evaluation Metrics for Different Modelstable: Model,Accuracy,F1-score,Precision,Recall, LogReg,0.92,0.92,0.92,0.92, SVM,0.93,0.93,0.93,0.93, RF,0.90,0.90,0.89,0.92, XGBoost,0.92,0.92,0.92,0.92","Table 4 displays the evaluation metrics of different models. The models include logistic regression (LogReg), support vector machine (SVM), random forest (RF), and XGBoost. The evaluation metrics consist of accuracy, F1-score, precision, and recall. The LogReg model achieved the highest accuracy and F1-score of 0.92. Similarly, the SVM and XGBoost models performed well, achieving an accuracy, F1-score, precision, and recall of 0.93. The RF model performed well in recall but had comparatively low precision. Overall, the table suggests that the SVM and XGBoost models performed the best based on the metrics evaluated."
260,"caption: Table 4: Model evaluation based on accuracy, recall, precision, and F1-score.table: Model,Accuracy,Recall,Precision,F1-score, Model A,0.86,0.72,0.92,0.81, Model B,0.92,0.69,0.95,0.80, Model C,0.78,0.61,0.83,0.71, Model D,0.91,0.72,0.94,0.81, Model E,0.87,0.73,0.89,0.80","Table 4 compares the performance of five different models based on their accuracy, recall, precision, and F1-score. Model A scored 0.86 in accuracy, 0.72 in recall, 0.92 in precision, and 0.81 in F1-score. Model B scored the highest in accuracy, achieving 0.92, but had a lower recall score of 0.69. Model D had the highest precision score of 0.94 and scored well in recall and F1-score as well. Model E had a balanced performance, with an accuracy score of 0.87 and a high recall score of 0.73. In contrast, Model C had the lowest scores in all evaluation metrics."
261,"caption: Evaluation Metrics of different classification modelstable: Model,Precision(avg),Recall(avg),F1-score(avg),ROC-AUC,PR-AUC, SVM,0.84,0.85,0.83,0.79,0.76, Random Forest,0.85,0.87,0.83,0.84,0.80, AdaBoost,0.83,0.86,0.82,0.76,0.72, XGBoost,0.87,0.89,0.86,0.85,0.81, Logistic Regression,0.81,0.84,0.80,0.72,0.68","The table above compares different classification models using multiple evaluation metrics- precision, recall, F1-score, ROC-AUC, and PR-AUC. The models include SVM, Random Forest, Adaboost, XGBoost, and Logistic Regression. The table indicates that XGBoost shows the best performance in most metrics, with the highest precision of 0.87 and recall of 0.89, and the highest F1-score of 0.86. The model also has the highest ROC-AUC of 0.85 and PR-AUC of 0.81. However, the Random Forest model has a higher precision of 0.85, and most of the models have a relatively similar recall metric. The Logistic Regression has the lowest performance results with a maximum precision of 0.81 and recall of 0.84."
262,"caption: Model performance based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score,AUC, Logistic Regression,0.84,0.85,0.79,0.82,0.89, Decision Tree,0.76,0.71,0.81,0.75,0.83, Random Forest,0.88,0.87,0.89,0.88,0.94, Support Vector,0.82,0.84,0.76,0.80,0.88","The table presents the performance of different models on multiple evaluation metrics, including Accuracy, Precision, Recall, F1 Score, and AUC. The Logistic Regression model achieved the highest accuracy of 0.84, while the Random Forest model attained the highest AUC score of 0.94. The Random Forest model also performed significantly well in Precision and Recall metrics scoring 0.87 and 0.89, respectively. On the other hand, the Decision Tree model produced the lowest scores on all metrics, indicating its poor performance. The Support Vector machine scored the second-highest AUC and Precision scores, making it a decent performing model overall."
263,"caption: Table 4: Model Evaluation Metricstable: Model name,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.80,0.76,0.63,0.68, Decision Tree,0.82,0.83,0.78,0.80, K-NN,0.75,0.63,0.76,0.65, Random Forest,0.85,0.84,0.86,0.85, SVM,0.78,0.72,0.71,0.71","Table 4 shows the evaluation metrics for five different models: Logistic Regression, Decision Tree, K-NN, Random Forest, and SVM. The metrics include Accuracy, Precision, Recall, and F1-score. Among all the models, Random Forest performed the best with an accuracy of 0.85 and an F1-score of 0.85, while the Decision Tree model has the best precision of 0.83. The K-NN has the worst performance across all the metrics, especially in precision and F1-score, which both score 0.65. Interestingly, the Decision Tree and Random Forest models have relatively better recall and precision. Finally, the Logistic Regression model is outperformed by the other models across all the performance metrics."
264,"caption: Table 4: Models' evaluation metrics scores including accuracy, precision, recall, F1-score, AUC-ROC, and AUC-PR.table: Model,Accuracy,Precision,Recall,F1-Score,AUC-ROC,AUC-PR, SVM,0.91,0.88,0.82,0.85,0.95,0.83, RF,0.92,0.90,0.86,0.88,0.96,0.87, LR,0.87,0.83,0.75,0.74,0.92,0.77, MLP,0.93,0.90,0.87,0.88,0.97,0.89",
265,"caption: Table 1. Model performances based on different evaluation metricstable: Model,Accuracy,F1-Score,Precision,Recall, Model 1,0.73,0.75,0.72,0.78, Model 2,0.84,0.83,0.85,0.81, Model 3,0.77,0.68,0.75,0.63, Model 4,0.91,0.92,0.90,0.93","Table 1 presents the performance of multiple models on four different evaluation metrics, namely Accuracy, F1-Score, Precision, and Recall. Model 1 achieved an Accuracy of 0.73, an F1-Score of 0.75, a Precision of 0.72, and a Recall of 0.78. Model 2 achieved the highest Accuracy of 0.84 and a Precision of 0.85. However, Model 4 achieved the highest F1-Score of 0.92 and a Recall of 0.93 with the second-highest values for Accuracy and Precision. Interestingly, Model 3 had the lowest performance for all evaluation metrics except Precision, where it outperformed Model 1 and Model 2."
266,"caption: Table 4: Model performance on classification task using different evaluation metricstable: Model,Accuracy,Precision,Recall,F1-score, SVM,0.85,0.82,0.89,0.85, Logistic Regression,0.78,0.71,0.91,0.80, Decision Tree,0.72,0.66,0.74,0.70, Random Forest,0.89,0.91,0.87,0.89, XGBoost,0.91,0.92,0.89,0.91",
267,"caption: Table 4: Model performances of various classifiers based on different evaluation metrics.table: Model,Accuracy,F1-Score,Recall,Precision, Logistic Regression,0.87,0.87,0.85,0.91, Support Vector Machine,0.86,0.81,0.78,0.84, K-Nearest Neighbors,0.80,0.78,0.66,0.94, Decision Tree,0.84,0.77,0.72,0.83, Random Forest,0.91,0.92,0.92,0.91, XGBoost,0.89,0.89,0.86,0.92","Table 4 compares multiple classifiers' performances in terms of accuracy, F1-score, recall, and precision. The table includes Logistic Regression, Support Vector Machine, K-Nearest Neighbors, Decision Tree, Random Forest, and XGBoost models. Each model's evaluation metrics are presented clearly, with Random Forest having the highest accuracy (0.91) and F1-score (0.92). In contrast, the K-Nearest Neighbors model had the lowest performance with an accuracy of 0.80. Interestingly, Logistic Regression had the highest precision score at 0.91, while support Vector Machine had the lowest precision score of 0.84. Overall, the Random Forest model appears to have the best performance across the metrics evaluated."
268,"caption: Evaluation metrics for different modelstable: Model,F1-score,Precision,Recall,Accuracy, Model A,0.91,0.92,0.89,0.94, Model B,0.85,0.87,0.82,0.86, Model C,0.88,0.84,0.93,0.87, Model D,0.93,0.91,0.96,0.93, Model E,0.78,0.79,0.76,0.8","The table shows a comparison of different models evaluated using four different evaluation metrics, i.e., F1-score, Precision, Recall, and Accuracy. The table exhibits Model A through Model E and their corresponding evaluation metrics. Notably, Model D obtained the highest F1-score (0.93) and Recall (0.96) among all models. Model A has the highest Precision (0.92) and Accuracy (0.94). Model C has a relatively high Recall score (0.93) while maintaining a decent F1-score (0.88). Model E shows the lowest performance across all evaluation metrics. The table comparison provides a clear overview of the models' performance, demonstrating which model achieved the best performance across the different evaluation metrics."
269,"caption: Model performance for different evaluation metricstable: Model,Accuracy,F1 Score,Precision,Recall, Decision Tree,0.756,0.760,0.783,0.736, Random Forest,0.835,0.838,0.861,0.819, SVM,0.812,0.814,0.853,0.781, MLP,0.876,0.877,0.900,0.855","The table represents model performances for different evaluation metrics, including accuracy, F1 score, precision, and recall. Four different models are compared based on the computed metrics. The Decision Tree model achieved an accuracy of 0.756, while its F1 score is 0.760, precision is 0.783, and recall is 0.736. The Random Forest model achieved an accuracy of 0.835, F1 score of 0.838, precision of 0.861, and recall of 0.819. SVM showed an accuracy of 0.812, F1 score of 0.814, precision of 0.853, and recall of 0.781. Lastly, the MLP model recorded the highest accuracy of 0.876, F1 score of 0.877, precision of 0.900, and recall of 0.855. Based on the table, the MLP model shows the best performance with the highest accuracy, precision, and F1 score."
270,"caption: Comparison of different models based on multiple evaluation metricstable: Model,F1-Score,Precision,Recall,Specificity,Accuracy, Model 1,0.823,0.864,0.785,0.910,0.845, Model 2,0.874,0.891,0.858,0.923,0.886, Model 3,0.812,0.842,0.784,0.900,0.836, Model 4,0.902,0.919,0.886,0.936,0.899","The table above presents a comparison of different models based on F1-Score, Precision, Recall, Specificity, and Accuracy evaluation metrics. Model 4 scores the best F1-Score, Precision, Recall, Specificity, and Accuracy results with scores of 0.902, 0.919, 0.886, 0.936, and 0.899, respectively. Model 2 also yielded a high overall performance score, with an F1-Score of 0.874, Precision of 0.891, Recall of 0.858, Specificity of 0.923 and Accuracy of 0.886. Conversely, models 1 and 3 showed lower performance in most metrics than model 4 or 2."
271,"caption: Comparison of different models using different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.75,0.70,0.80,0.74, Naive Bayes,0.65,0.61,0.78,0.68, Random Forest,0.82,0.93,0.75,0.83, Multi-layer Perceptron,0.76,0.71,0.77,0.74, Logistic Regression,0.73,0.78,0.65,0.71","The table presents a comparison of different models using multiple evaluation metrics, including Accuracy, Precision, Recall, and F1-score. The evaluated models are SVM, Naive Bayes, Random Forest, Multi-layer Perceptron, and Logistic Regression. The best performing model for Accuracy is Random Forest with a score of 0.82, followed by SVM at 0.75. For Precision, Random Forest tops the list with a score of 0.93, while Logistic Regression follows with 0.78. Naive Bayes obtains the highest score for Recall with 0.78, while SVM scores highest for F1-score with 0.74. The different performances of the models in various evaluation metrics highlight the importance of considering multiple evaluation metrics when selecting the best-performing model."
272,"caption: Table 4: Model performances based on multiple evaluation metrics.table: Model,Accuracy,F1 score,Recall,Precision, Logistic regression,0.74,0.70,0.60,0.83, Random Forest,0.76,0.72,0.62,0.86, Support Vector Machine,0.68,0.65,0.55,0.79, Naive Bayes,0.69,0.66,0.57,0.80, K-Nearest Neighbor,0.65,0.63,0.54,0.77","Table 4 presents five models' performances based on multiple evaluation metrics. The evaluation metrics include Accuracy, F1 Score, Recall, and Precision. The models are Logistic regression, Random Forest, Support Vector Machine, Naive Bayes, and K-Nearest Neighbor. Notably, Random forest and Logistic Regression models outperformed the other models in Accuracy, F1 score, and Precision with a maximum Accuracy of 0.76 and F1 score of 0.72. However, the Random forest model stands out for Recall with 0.62 and has the highest Recall. Naive Bayes model scored the highest Recall with 0.80 but stood last in other evaluation metrics. The Support Vector Machine showed the lowest Accuracy score of 0.68, implying its unsuitability for the classification task in this study."
273,"caption: Performance of different models on sentiment analysis task.table: Model,Precision,Recall,F1-Score,AUC, Logistic Regression,0.824,0.901,0.853,0.908, Naïve Bayes,0.708,0.872,0.775,0.836, Random Forest,0.876,0.932,0.904,0.943, k-NN,0.820,0.853,0.836,0.869, SVM,0.895,0.896,0.895,0.936","The table above provides a comparison of the performance of five different models (Logistic Regression, Naïve Bayes, Random Forest, k-NN, and SVM) on the sentiment analysis task. The models were evaluated based on four metrics: Precision, Recall, F1-Score, and AUC. The Random Forest model performed the best overall with the highest values in all metrics, achieving 0.876 for Precision, 0.932 for Recall, 0.904 for F1-Score, and 0.943 for AUC. The SVM model came in second, with the third-best performance in Recall and F1-Score. The Naïve Bayes model had the lowest scores among all the models, with the lowest values in all metrics."
274,"caption: Comparison of various models based on different evaluation metricstable: Model,Accuracy,F1 score,Precision,Recall, CNN,0.87,0.88,0.86,0.90, RNN,0.83,0.82,0.84,0.81, NB,0.70,0.44,0.68,0.32, SVM,0.91,0.92,0.91,0.92","Table X compares multiple models based on different evaluation metrics. The models include Convolutional Neural Network (CNN), Recurrent Neural Network (RNN), Naive Bayes classifier (NB), and Support Vector Machine (SVM). The table presents the accuracy, F1 score, precision, and recall for each model. SVM exhibits the best performance across all metrics with an accuracy of 0.91, F1 score of 0.92, precision of 0.91, and recall of 0.92. CNN and RNN had similar performances on all metrics, while NB's performance was significantly lower than the other models, especially in recall."
275,"caption: Table 4: Performance comparison of various models based on different evaluation metrics.table: Model Name,Accuracy Score,Precision Score,Recall Score,F1-Score, Model 1,0.85,0.83,0.89,0.86, Model 2,0.78,0.86,0.66,0.74, Model 3,0.91,0.92,0.90,0.91, Model 4,0.77,0.80,0.74,0.77, Model 5,0.95,0.97,0.94,0.95","Table 4 presents the comparison of the performance of multiple models based on different evaluation metrics. The table displays Accuracy Score, Precision Score, Recall Score, and F1-Score of various models. It is observed that Model 5 achieved the highest Accuracy Score of 0.95 and F1-Score of 0.95, whereas Model 2 attained the lowest Accuracy Score of 0.78 and F1-Score of 0.74. On the other hand, Model 3 achieved the highest Precision Score of 0.92, and Model 2 obtained the lowest Precision Score of 0.86. Further analysis reveals that Model 1 and Model 4 performed closely in terms of all evaluation metrics."
276,"caption: Performance comparison of different models based on multiple evaluation metrics.table: Models,F1 Score,Precision,Recall,AUC, Model A,0.86,0.92,0.81,0.93, Model B,0.89,0.83,0.96,0.95, Model C,0.82,0.94,0.73,0.91, Model D,0.91,0.89,0.94,0.97","The table presents a comparison of four different models based on multiple evaluation metrics. The models' performance is measured using F1 Score, Precision, Recall, and AUC evaluation metrics. Model D achieves the highest F1 Score of 0.91, outperforming the other models. Model A has the highest precision of 0.92, and Model B has the highest recall of 0.96. Model D also has the highest AUC of 0.97, indicating its superior overall performance. The table demonstrates that Model D is the best performing model based on all the evaluation metrics."
277,"caption: Table 4: Comparison of multiple models on three different evaluation metrics.table: Model Name,Metric Name 1,Metric Name 2,Metric Name 3, Model 1,0.85,0.73,0.66, Model 2,0.64,0.57,0.53, Model 3,0.71,0.52,0.48, Model 4,0.90,0.80,0.73, Model 5,0.82,0.69,0.62","Table 4 provides a comparison of five different models based on three different evaluation metrics. The evaluation metrics are represented by Metrics Name 1, Metrics Name 2, and Metrics Name 3. From the table, it is observed that Model 4 has the best performance on all three metrics, while Model 2 has the lowest. Interestingly, Model 1 has a high score on the first metric, but its scores drop significantly on the other two. From the presented data, we can also observe that the range between highest and lowest scores among all models is relatively significant on all evaluated metrics."
278,"caption: Model performances with multiple evaluation metrics.table: Model,Accuracy,F1 Score,Recall,Precision, SVM,0.92,0.91,0.90,0.93, Random Forest,0.88,0.85,0.83,0.87, Decision Tree,0.84,0.82,0.81,0.83, Logistic Regression,0.79,0.76,0.74,0.78, Naive Bayes,0.72,0.69,0.66,0.73","The above table presents the evaluation metrics, including Accuracy, F1 Score, Recall, and Precision, of five different models. The models include SVM, Random Forest, Decision Tree, Logistic Regression, and Naive Bayes. Interestingly, the SVM model achieved the highest accuracy of 0.92, while the Random Forest model showed the highest Precision of 0.87 and highest Recall of 0.83. The Naive Bayes model had the lowest Accuracy, F1 Score, Recall, and Precision. It seems that the SVM model has the best overall performance, as it has achieved the highest Accuracy, F1 Score, Recall, and a close value of Precision."
279,"caption: Model performances across multiple evaluation metricstable: Model,Precision,Recall,F1-score,Accuracy, Model A,0.85,0.92,0.88,0.89, Model B,0.78,0.81,0.79,0.84, Model C,0.92,0.88,0.90,0.92, Model D,0.76,0.65,0.70,0.79, Model E,0.87,0.83,0.85,0.87","The table above presents the model performances of five different models using four commonly used evaluation metrics, including precision, recall, F1-score, and accuracy. Model A and Model C showed excellent performances across all metrics, achieving precision scores of 0.85 and 0.92, respectively, along with high values in recall, F1-score, and accuracy, which makes both models the most performing ones. Model E has also shown to be a feasible choice with an accuracy score of 0.87 and precision score above 0.8. The remaining models have varying degrees of performance, with Model B demonstrating moderate accuracy and F1-score, and Model D exhibiting relatively lower precision and recall scores. Overall, this table provides useful insights into the performance of different models in handling the task at hand."
280,"caption: Comparison of different machine learning models based on multiple evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, Logistic regression,0.75,0.68,0.86,0.56, Decision tree,0.72,0.65,0.78,0.56, Random forest,0.84,0.81,0.92,0.72, K-nearest neighbors,0.65,0.59,0.71,0.51, Support vector machine,0.79,0.73,0.88,0.62","The table presents a comparison of different machine learning models' performances based on various evaluation metrics such as Accuracy, F1-score, Precision and Recall. The different models included in the table are Logistic regression, Decision tree, Random forest, K-nearest neighbors, and Support vector machine. Notably, the Random forest model was the best performing model for all evaluation metrics except Precision, where the Logistic regression model had better performance. The K-nearest neighbors model had the poorest performance across all evaluation metrics. It's interesting to note that the Decision tree model had better Recall than the Support vector machine despite its lower accuracy score."
281,"caption: Comparison of different models based on evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Model A,0.94,0.95,0.93,0.98, Model B,0.91,0.88,0.93,0.84, Model C,0.89,0.86,0.86,0.87, Model D,0.92,0.91,0.89,0.93, Model E,0.94,0.94,0.93,0.94",
282,"caption: Performance of different models on the given dataset.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.876,0.809,0.827,0.792, Decision Tree,0.810,0.754,0.788,0.722, Logistic Regression,0.852,0.796,0.816,0.778, GradientBoostingClassifier,0.895,0.830,0.845,0.816, MLPClassifier,0.908,0.864,0.858,0.871, Random Forest,0.901,0.855,0.864,0.846","The table presents the evaluation metrics of six machine learning models (SVM, Decision Tree, Logistic Regression, GradientBoostingClassifier, MLPClassifier, and Random Forest) trained on the same given dataset. The evaluation metrics include Accuracy, F1-score, Precision, and Recall. Notably, MLPClassifier achieved the highest accuracy of 0.908, while the Decision Tree model performed the lowest with an accuracy score of 0.81. Interestingly, GradientBoostingClassifier achieved the highest F1-score (0.83), Precision (0.845), and Recall (0.816) values, while the Random Forest model had the second-best performance in all metrics. These results suggest that the GradientBoostingClassifier and MLPClassifier models might perform better than other models for this dataset."
283,"caption: Table 4: Performance comparison of multiple different models on multiple evaluation metrics.table: Model,Accuracy,Recall,Precision,F1 Score, Model A,0.85,0.82,0.87,0.84, Model B,0.83,0.85,0.78,0.80, Model C,0.87,0.89,0.83,0.86, Model D,0.82,0.80,0.85,0.82, Model E,0.86,0.84,0.88,0.86","Table 4 presents a performance comparison of multiple different models on various evaluation metrics, including accuracy, recall, precision, and F1 score. The table shows that Model C has the highest accuracy score of 0.87, and the highest recall score of 0.89. Model E has the highest precision score of 0.88, and the highest F1 score of 0.86. On the other hand, Model D has the lowest accuracy and F1 score, while Model B has the lowest recall and precision score. The table demonstrates the importance of comparing models across different evaluation metrics to obtain a comprehensive understanding of their performance."
284,"caption: Performance comparison of different models using multiple evaluation metrics.table: Model Name,Precision,Recall,F1-Score,Balanced Accuracy, Model 1,0.85,0.79,0.82,0.78, Model 2,0.71,0.90,0.80,0.73, Model 3,0.80,0.75,0.77,0.76, Model 4,0.92,0.82,0.87,0.81","Table 1 shows the performance comparison of four different models based on multiple evaluation metrics. The evaluation metrics included in the table are precision, recall, F1-score, and balanced accuracy. Model 1 achieved the highest precision score of 0.85, while Model 4 achieved the highest recall score of 0.82. Model 4 also outperformed the other three models in terms of F1-score, with a score of 0.87. Interestingly, Model 2 achieved the highest balanced accuracy score of 0.73 despite having the lowest precision score in the table. Overall, the table provides a comprehensive comparison of the model's performances based on multiple evaluation metrics."
285,"caption: Table 4: Performance comparison of different models using various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1, Logistic regression,0.89,0.92,0.87,0.89, SVM (linear kernel),0.92,0.90,0.94,0.92, SVM (polynomial kernel),0.85,0.86,0.80,0.83, Random Forest,0.95,0.97,0.93,0.95, K-Nearest Neighbors,0.88,0.87,0.88,0.87","Table 4 presents a comparison of different models based on their performance evaluated using multiple metrics. The table includes Logistic regression, SVM with linear kernel, SVM with a polynomial kernel, Random Forest, and K-Nearest Neighbors models. Each model's accuracy, precision, recall, and F1 score values are reported. The Random Forest model shows the highest accuracy of 0.95, while the SVM with linear kernel model demonstrates the highest precision of 0.90 and the highest recall of 0.94 among the compared models. The table suggests the Random Forest model as the best performer, demonstrating the highest accuracy and F1 score of 0.95."
286,"caption: Comparison of Model Performances based on Different Metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Model A,0.76,0.72,0.82,0.64, Model B,0.82,0.78,0.77,0.8, Model C,0.84,0.8,0.84,0.77, Model D,0.78,0.74,0.82,0.68, Model E,0.85,0.82,0.83,0.81","The table above shows the comparison of different models based on different evaluation metrics such as accuracy, F1 score, precision, and recall. Model B achieved the highest accuracy of 0.82, while Model E performed the best in the F1 score metric, with a score of 0.82. The highest precision score was attained by Model C scoring 0.84, whereas the highest recall score was achieved by Model B with a score of 0.8. Interestingly, Model A had the lowest score in all metrics, despite having a satisfactory accuracy score of 0.76. Overall, Model E appears to be the best model based on the variety of evaluation metrics presented."
287,"caption: Table 4: Comparison of multiple classifiers on different performance metrics.table: Model,Accuracy,F1-Score,Precision,Recall, Logistic Reg,0.78,0.76,0.78,0.75, SVM (linear),0.74,0.7,0.73,0.71, SVM (RBF),0.71,0.69,0.7,0.68, Random Forest,0.82,0.81,0.82,0.8, Gradient Boost,0.8,0.79,0.8,0.78, MLP,0.77,0.75,0.76,0.74","Table 4 compares the performance of six different classifiers on multiple performance metrics. The table exhibits the classifier models' Accuracy, F1-Score, Precision, and Recall. Notably, the best-performing model for Accuracy is Random Forest with a score of 0.82. The Random Forest also had the best F1-Score of 0.81, Precision of 0.82, and Recall of 0.8. Gradient boost comes second in the ranking with Accuracy score of 0.8, F1-Score of 0.79, Precision of 0.8, and Recall of 0.78. Conversely, SVM RBF had the lowest Accuracy, F1-Score, Precision, and Recall scores of 0.71, 0.69, 0.7, and 0.68 respectively. It is also revealed that Logistic Regression achieved the highest precision score of 0.78, while SVM (linear) has the highest Recall of 0.71."
288,"caption: Table 4: Performance comparison of different classification models.table: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.85,0.88,0.85,0.91, Random Forest,0.89,0.91,0.90,0.93, Decision Tree,0.81,0.84,0.83,0.86, Naive Bayes,0.77,0.81,0.79,0.83, SVM,0.86,0.89,0.87,0.92, MLP,0.90,0.92,0.91,0.95","Table 4 displays a performance comparison of six different machine learning models based on multiple evaluation metrics, including accuracy, F1-score, precision, and recall. The table shows that MLP outperforms all the other models with the highest accuracy of 0.90 and F1-score of 0.92. Random Forest also shows a good level of performance with an accuracy of 0.89 and an F1-score of 0.91. The Decision Tree model has the lowest accuracy and F1-score among all the models. Overall, MLP and Random Forest models look promising based on their performance for the dataset under consideration."
289,"caption: Table 4: Comparative evaluation of several models using different evaluation metricstable: Model Name,F1 Score,Accuracy,Recall,Precision,AUC, SVM,0.80,0.75,0.79,0.82,0.78, Random Forest,0.78,0.76,0.75,0.81,0.77, KNN,0.76,0.71,0.72,0.80,0.61, Logistic Regression,0.85,0.79,0.82,0.88,0.80, Naive Bayes,0.72,0.69,0.68,0.77,0.70, Decision Tree,0.72,0.70,0.73,0.68,0.69","Table 4 provides the comparative evaluation of several models' performance using different evaluation metrics. The models tested in this research are SVM, Random Forest, KNN, Logistic Regression, Naive Bayes, and Decision Tree. The evaluation metrics used in this study include F1 Score, Accuracy, Recall, Precision, and AUC. The table reveals that the logistic regression had the best F1 score of 0.85 and Precision of 0.88. The SVM model shows the best AUC of 0.78, with a high Recall score of 0.79. Also, the logistic regression model had the highest accuracy of 0.79, followed by Random Forest's accuracy of 0.76. KNN, Decision Tree, and Naive Bayes had the lowest scores for all evaluation metrics, indicating that they may not be the best fit for this task."
290,"caption: Performance of Different Modelstable: Model,Accuracy,F1 Score,Recall,Precision, SVM,0.87,0.87,0.87,0.88, Random Forest,0.84,0.84,0.83,0.85, Decision Tree,0.72,0.73,0.76,0.70, Gradient Boost,0.90,0.90,0.91,0.90","The table outlines the performance of four different models for a binary classification problem. The table includes accuracy, F1 score, recall, and precision for each model. The SVM model performs the best with an accuracy of 0.87 and F1 score of 0.87, closely followed by Gradient Boost with an accuracy of 0.90 and F1 score of 0.90. The Decision Tree model performs the worst with an accuracy of only 0.72 but has a high recall of 0.76. Interestingly, the SVM and Random Forest overperformed in precision compared to recall, and Gradient Boost overperformed in recall over precision."
291,"caption: Model evaluation metrics for different modelstable: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.85,0.84,0.86,0.83, KNN,0.79,0.77,0.78,0.80, Random Forest,0.91,0.91,0.92,0.91, XGBoost,0.89,0.88,0.87,0.91, Neural Network,0.87,0.86,0.88,0.85","The table presents performance evaluation metrics for SVM, KNN, Random Forest, XGBoost, and Neural Network models. The evaluation metrics included in the table are accuracy, F1 score, precision, and recall. Out of all models, Random Forest performed the best with an accuracy of 0.91, F1 score of 0.91, precision of 0.92, and recall of 0.91. SVM outperformed the rest with the highest precision score of 0.86. On the other hand, KNN achieved the lowest accuracy score of 0.79, while the Neural Network model returned slightly better results with an accuracy score of 0.87. Overall, the table showcases the different performance results obtained for different models, highlighting each model's strengths and weaknesses."
292,"caption: Model Performance by Multiple Metricstable: Metric,Model 1,Model 2,Model 3,Model 4,Model 5, Accuracy,0.9,0.78,0.82,0.91,0.88, AUC,0.99,0.75,0.81,0.87,0.90, F1-Score,0.91,0.64,0.72,0.88,0.85, Recall,0.89,0.56,0.71,0.87,0.82","The table illustrates the performance of five different models across multiple evaluation metrics, including Accuracy, AUC, F1-Score, and Recall. Model 1 showcases the best results in all metrics, achieving an accuracy score of 0.9, AUC of 0.99, F1-Score of 0.91, and recall of 0.89. Model 4 also demonstrates outstanding performance, with an accuracy score of 0.91 and an AUC score of 0.87, but falls slightly behind in F1-Score and recall values. Model 5 also performs commendably with an accuracy score of 0.88 and a relatively high AUC score of 0.90. The remaining models (2 and 3) perform below average across all metrics."
293,"caption: Table 4: Comparison of multiple models based on various evaluation metrics.table: Model Name,Precision,Recall,F1 Score,Accuracy, SVM,0.85,0.93,0.89,0.86, Random Forest,0.83,0.92,0.87,0.85, KNN,0.81,0.88,0.85,0.81, Naive Bayes,0.75,0.95,0.84,0.76, Decision Trees,0.79,0.82,0.80,0.77","Table 4 compares the performance of five different models based on various evaluation metrics. The models include SVM, Random Forest, KNN, Naive Bayes, and Decision Trees. The table demonstrates the precision, recall, F1 Score, and accuracy of each model evaluated using the same dataset. Among the models, SVM performed the best in precision, recall, and F1 Score, achieving scores of 0.85, 0.93, and 0.89, respectively. Naive Bayes, on the other hand, shows the highest recall score of 0.95. The accuracy results indicate that SVM has the highest accuracy with a score of 0.86, followed closely by Random Forest at 0.85. Overall, the table provides an insightful comparison of the models' performance on the given dataset."
294,"caption: Comparison of model performance using different evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall,AUC-ROC, LR,0.863,0.867,0.804,0.940,0.926, SVM,0.880,0.854,0.834,0.872,0.904, KNN,0.832,0.817,0.721,0.862,0.843, RF,0.902,0.895,0.856,0.938,0.952, XGB,0.885,0.880,0.809,0.964,0.925","The presented table compares the performances of five different models using different evaluation metrics. The models include Logistic Regression (LR), Support Vector Machine (SVM), K-Nearest Neighbors (KNN), Random Forest (RF), and XGBoost (XGB). The evaluation metrics include Accuracy, F1-score, Precision, Recall, and AUC-ROC. Notably, the Random Forest model shows the highest Accuracy, F1-score, Precision, and Recall with scores of 0.902, 0.895, 0.856, and 0.938, respectively. The XGBoost model's Precision score of 0.809 is the lowest among all models. Nonetheless, it achieves a very high Recall score of 0.964, second to Random Forest. Also, the Random Forest model achieves the highest AUC-ROC score of 0.952, while the SVM model has the lowest score of 0.904."
295,"caption: Table 4: Performance of Different Models on Evaluation Metrics.table: Model Name,Accuracy,F1-Score,Precision,Recall, Model_1,0.85,0.84,0.87,0.81, Model_2,0.82,0.85,0.81,0.9, Model_3,0.89,0.87,0.84,0.92, Model_4,0.86,0.83,0.9,0.77","Table 4 shows the performance of four different models on multiple evaluation metrics such as accuracy, F1-score, precision, and recall on the same testing dataset. Model_3 achieved the highest accuracy score of 0.89, while Model_2 obtained the highest F1-score of 0.85. On the other hand, Model_4 got the highest precision score of 0.90 but had a low recall score of 0.77, and Model_3 had the highest recall score of 0.92 but the lowest precision score of 0.84. Therefore, the choice of the appropriate model depends on the evaluation metric's requirement."
296,"caption: Model evaluation metrics for different classifiers on the test dataset.table: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.81,0.82,0.80,0.81, Random Forest,0.88,0.88,0.88,0.88, Support Vector Machine,0.79,0.79,0.81,0.80, Decision Tree,0.82,0.81,0.83,0.82, Neural Network,0.76,0.76,0.75,0.75","The above table shows the evaluation metrics' results for different machine learning models on the test dataset. The evaluated classifiers include Logistic Regression, Random Forest, Support Vector Machine, Decision Tree, and Neural Network. The models were evaluated using accuracy, precision, recall, and F1-score metrics. Random Forest recorded the highest accuracy, precision, recall, and F1-score values of 0.88 each, suggesting the classifier performed well across instances in the test dataset. Logistic Regression was the second-best performing model, attaining accuracy, precision, recall, and F1-scores of 0.81. The Support Vector Machine recorded the least performance, with the lowest precision and accuracy of 0.79."
297,"caption: Model Performance on Classification Tasktable: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.75,0.73,0.59,0.65, SVM,0.78,0.79,0.61,0.69, KNN,0.72,0.68,0.65,0.61, Neural Network,0.81,0.81,0.67,0.73, Random Forest,0.85,0.81,0.78,0.79",
298,"caption: Performance Metrics for Different Modelstable: Model name,F1-score,Accuracy,Precision,Recall,AUC, Model 1,0.88,0.78,0.85,0.91,0.72, Model 2,0.79,0.82,0.91,0.70,0.79, Model 3,0.96,0.95,0.97,0.94,0.88, Model 4,0.82,0.79,0.79,0.85,0.76, Model 5,0.91,0.89,0.87,0.93,0.81","The table presents the comparison of five different models, namely Model 1 through Model 5, based on multiple evaluation metrics. The table includes the models' F1-score, accuracy, precision, recall, and AUC, which were obtained through training and testing on the same dataset. The performance results show Model 3 as the best-performing model, with the highest F1-score of 0.96, accuracy of 0.95, precision of 0.97, recall of 0.94, but with a lower AUC score of 0.88. Model 2 shows the second-best performance, with the highest AUC of 0.79, but the lowest F1-score of 0.79. Overall, the table presents an interesting example of how model performance can vary based on different evaluation metrics."
299,"caption: Model evaluation metrics for Models A, B, and C.table: Model,Accuracy,Precision,Recall,F1-Score, Model A,0.89,0.86,0.90,0.88, Model B,0.87,0.89,0.84,0.86, Model C,0.92,0.93,0.91,0.92","Table above presents evaluation metrics for Models A, B, and C, including accuracy, precision, recall, and F1-Score. Model C has the best performance across all metrics, achieving the highest accuracy of 0.92, precision of 0.93, recall of 0.91, and F1-Score of 0.92. Model A has the next best performance with an accuracy of 0.89, precision of 0.86, recall of 0.90, and F1-Score of 0.88. Model B has the lowest performance among the three models, with an accuracy of 0.87, precision of 0.89, recall of 0.84, and F1-Score of 0.86. Overall, these results suggest that Model C is the best model for this particular task."
300,"caption: Comparison of five machine learning models on different evaluation metricstable: Model,Precision,Recall,F1-score,ROC-AUC, Logistic Regression,0.75,0.63,0.68,0.80, Naive Bayes,0.82,0.57,0.67,0.74, Random Forest,0.84,0.79,0.81,0.87, K-Nearest Neighbors,0.79,0.62,0.68,0.72, Support Vector Machines,0.74,0.65,0.68,0.82",
301,"caption: Performance comparison of multiple models using different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Model A,0.80,0.75,0.85,0.80, Model B,0.85,0.80,0.90,0.85, Model C,0.75,0.70,0.80,0.74, Model D,0.89,0.86,0.91,0.88, Model E,0.90,0.91,0.88,0.89","The table above provides the model performances of five different models - Model A, Model B, Model C, Model D, and Model E - using different evaluation metrics such as Accuracy, Precision, Recall, and F1 score. From the table, it is evident that Model E achieved the highest accuracy score of 0.90. Simultaneously, Model D obtained the highest Precision score of 0.86 and Recall score of 0.91. Model E also obtained the highest F1 Score of 0.89. Although Model A obtained the lowest accuracy score of 0.80, it achieved a balanced Precision and Recall score of 0.75 and 0.85, respectively. In contrast, Model C had the lowest performance in all evaluation metrics except for Recall."
302,"caption: Table 4: Model performances based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.85,0.74,0.62,0.67, Naive Bayes,0.81,0.68,0.74,0.66, Decision Tree,0.86,0.76,0.65,0.69, Random Forest,0.89,0.78,0.70,0.73, XGBoost,0.91,0.81,0.76,0.78","Table 4 shows the performances of different models based on multiple evaluation metrics, including accuracy, precision, recall, and F1-score. The models compared in the table are Logistic Regression, Naive Bayes, Decision Tree, Random Forest, and XGBoost. Notably, the XGBoost model showed the highest accuracy with a score of 0.91, while also achieving the highest scores in all other evaluation metrics - precision (0.81), recall (0.76), and F1-score (0.78). The Random Forest model stands out as a close second performer with accuracy of 0.89 and good scores across all the evaluation metrics."
303,"caption: Comparison of different models' performance using multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.86,0.82,0.89,0.85, Random Forest,0.91,0.89,0.92,0.90, SVM,0.88,0.81,0.94,0.87, Naive Bayes,0.79,0.76,0.83,0.79, KNN,0.82,0.76,0.87,0.81","Table presents the comparison of different models' performance using various evaluation metrics such as accuracy, precision, recall, and F1-score. The models included are Logistic Regression, Random Forest, SVM, Naive Bayes, and KNN. Notably, all models were tested and evaluated using the same dataset. The Random Forest model achieved the highest accuracy of 0.91, while the Naive Bayes model has the lowest accuracy of 0.79. However, Naive Bayes had the highest precision score of 0.76, whereas Random Forest had the highest recall score of 0.92. The F1 score of all models ranges between 0.79 to 0.90, with the Random Forest model's F1 score being the highest with 0.90."
304,"caption: Model performance comparison based on evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.856,0.857,0.861,0.853, RF,0.884,0.885,0.887,0.882, MLP,0.835,0.834,0.838,0.831, KNN,0.811,0.812,0.817,0.807, NB,0.775,0.773,0.783,0.763",
305,"caption: Table 4: Comparison of classification models' performances.table: Model,F1-score,Precision,Recall,Accuracy, SVM,0.85,0.82,0.88,0.75, KNN,0.69,0.66,0.73,0.54, Random Forest,0.91,0.88,0.94,0.83, Naive Bayes,0.57,0.76,0.45,0.61, MLP,0.89,0.86,0.92,0.78","Table 4 provides a comparison of classification models' performances based on multiple evaluation metrics - F1-score, precision, recall and, accuracy. The table presents SVM, KNN, Random Forest, Naive Bayes, and MLP models' performances. Among the models, Random Forest achieved the highest F1-score, precision, and recall, with a score of 0.91, 0.88, and 0.94, respectively. On the contrary, Naive Bayes model achieved the lowest scores in most of the metrics except for precision where it outperformed KNN. Overall, the Random Forest and MLP models produced higher scores than the other models in all metrics except for recall. The table aids in the selection process of classification models for various applications."
306,"caption: The performance of different models based on different evaluation metricstable: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.873,0.886,0.844,0.932, K-Nearest Neighbor,0.857,0.879,0.825,0.940, Decision Tree,0.825,0.854,0.812,0.900, Random Forest,0.904,0.917,0.896,0.940, XGBoost,0.928,0.939,0.920,0.960","Table presents multiple models' performance results based on different evaluation metrics. The models' performances were evaluated based on accuracy, F1-score, precision, and recall. The table exhibits Logistic Regression, K-Nearest Neighbor, Decision Tree, Random Forest, and XGBoost models' performance percentages based on these evaluation metrics. Notably, XGBoost model shows the best result on all evaluation metrics with the highest accuracy (0.928), F1-score (0.939), precision (0.920), and recall (0.960). In contrast, the Decision Tree model shows the worst performance on all evaluation metrics. Overall, this table highlights the differences in models' performances and the importance of selecting the right evaluation metrics for specific tasks."
307,"caption: Table 4: Performance results of different models using various evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.86,0.87,0.90,0.84, Logistic Regression,0.83,0.84,0.87,0.81, Random Forest,0.88,0.88,0.91,0.86, XGBoost,0.89,0.89,0.91,0.87","Table 4 displays the results of four different models using various evaluation metrics, including Accuracy, F1-score, Precision, and Recall. The table reveals that XGBoost achieved the highest Accuracy, F1-score, Precision, and Recall among all models, obtaining a score of 0.89, which is the best across all metrics. However, SVM and Random Forest models also show promising results, with both achieving high scores across all metrics. One interesting observation is that though Logistic Regression didn't have the highest performance, it still performed reasonably well, with an accuracy of 0.83 and an F1-score of 0.84."
308,"caption: Performance comparison of different models based on different evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Model 1,0.94,0.93,0.97,0.89, Model 2,0.88,0.87,0.94,0.81, Model 3,0.92,0.90,0.91,0.92, Model 4,0.91,0.89,0.92,0.87, Model 5,0.95,0.94,0.96,0.92",
309,"caption: Table 4. Performance Metrics for Different Modelstable: Model,Accuracy,F1 score,Precision,Recall, Logistic Regression,0.81,0.73,0.72,0.76, Random Forest,0.83,0.75,0.76,0.74, SVM,0.79,0.71,0.70,0.79, KNN,0.76,0.68,0.67,0.75, XGBoost,0.85,0.77,0.79,0.76, LightGBM,0.82,0.74,0.74,0.75, Multilayer Perceptron,0.80,0.72,0.73,0.70","Table 4 shows different models' performance with multiple evaluation metrics, including accuracy, F1 score, precision, and recall. The Logistic Regression model achieved an accuracy of 0.81, a F1 score of 0.73, precision of 0.72, and a recall of 0.76. The Random Forest model performed the best, achieving an accuracy of 0.83 and an F1 score of 0.75. The XGBoost model obtained the highest precision score with 0.79, although its accuracy and F1 score were slightly lower than the Random Forest model. Interestingly, the LightGBM model showed the highest precision and recall scores, with both values tied at 0.74. Overall, the Random Forest model had the best performance across all metrics evaluated."
310,"caption: Table 4: Performance results of multiple models based on evaluation metrics.table: Model Name,Precision,Recall,F1-score,MCC, Random Forest,0.96,0.94,0.95,0.95, XGBoost,0.92,0.97,0.94,0.93, Logistic Regression,0.87,0.91,0.89,0.85, Decision Tree,0.94,0.92,0.93,0.93, K-NN,0.87,0.89,0.88,0.84","Table 4 presents multiple models' performance results using different evaluation metrics, including Precision, Recall, F1-score, and MCC. The table's models include Random Forest, XGBoost, Logistic Regression, Decision Tree, and K-NN. From the table, the Random Forest model outperformed the other models in terms of Precision (0.96), Recall (0.94), F1-score (0.95), and MCC (0.95). However, the XGBoost model achieved the highest Recall score of 0.97, while the Logistic Regression model had the lowest performance score according to MCC with 0.85. Overall, the table shows a comparison of the models and their performance based on different evaluation metrics."
311,"caption: Table 4: Performance metrics of different classification models on the test dataset.table: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.8,0.7,0.9,0.78, Random Forest,0.85,0.75,0.87,0.80, K-Nearest Neighbor,0.77,0.68,0.80,0.73, Support Vector,0.83,0.72,0.90,0.80","Table 4 presents the performance metrics of different classification models on the test dataset. The table includes four different models, namely the Logistic Regression, Random Forest, K-Nearest Neighbor, and Support Vector. The model performances were evaluated based on four different evaluation metrics, which are Accuracy, Precision, Recall, and F1-score. The Random Forest model had the highest accuracy of 0.85, while the Support Vector model had the highest Precision of 0.72. On the other hand, the K-Nearest Neighbor model had the highest Recall of 0.80, and the Logistic Regression model achieved the highest F1-score of 0.78. Overall, the Random Forest model achieved the best performance with decent scores across all the metrics."
312,"caption: Model Performance on Classifying Spam Messagestable: Model,Accuracy,F1 Score,Precision,Recall, Random Forest,0.85,0.85,0.87,0.83, Support Vector Machine,0.79,0.79,0.80,0.78, Logistic Regression,0.83,0.83,0.84,0.81, Naive Bayes,0.70,0.70,0.74,0.68","Table presents a comparison of different models' classification performance on spam messages. The models' evaluation metrics include accuracy, F1 score, precision, and recall. Random Forest outperformed other models with the highest score of accuracy (0.85), F1 score (0.85), and precision (0.87) despite having lower recall (0.83) than Logistic Regression's (0.81). The Support Vector Machine had the lowest score of accuracy (0.79) among the models. Surprisingly, Naive Bayes had the lowest but a competitive score of accuracy (0.70) and F1 score (0.70). These results could suggest the random forest model as the most effective for classifying spam messages."
313,"caption: Performance comparison of different modelstable: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.82,0.78,0.83,0.73, Decision Tree,0.76,0.71,0.73,0.71, Random Forest,0.87,0.85,0.88,0.82, K-Nearest Neighbors,0.79,0.75,0.76,0.77, SVM,0.84,0.81,0.85,0.80","The table above shows the performance results of various classification models based on multiple evaluation metrics like accuracy, F1 score, precision, and recall. Five different models, including Logistic Regression, Decision Tree, Random Forest, K-Nearest Neighbors, and SVM, were tested, and their corresponding performance results were reported. Among all the models, Random Forest model had the highest accuracy (0.87) and F1 score (0.85). However, Logistic Regression had the highest precision (0.83), whereas SVM had the best recall (0.80). The Decision Tree model performed the lowest across all evaluation metrics."
314,"caption: Table showing the performance results of three different models across three evaluation metrics.table: Model,Metric,Result1,Result2,Result3, Model1,Metric1,0.76,0.83,0.95, Model1,Metric2,0.85,0.94,0.89, Model1,Metric3,0.92,0.75,0.69, Model2,Metric1,0.78,0.90,0.97, Model2,Metric2,0.92,0.85,0.79, Model2,Metric3,0.87,0.78,0.62, Model3,Metric1,0.85,0.86,0.93, Model3,Metric2,0.96,0.90,0.85, Model3,Metric3,0.72,0.82,0.59","The table presents three distinct models' performance results across three various evaluation metrics. The metrics used in this table include Metric1, Metric2, and Metric3. We can see that each model has a diverse performance with some models excelling in some metrics compared to others. For example, Model2 recorded the highest score of 0.97 in Metric1, while Model3 had the highest score of 0.96 in Metric2. Conversely, Model1 had the highest score in Metric3, with a score of 0.92. Overall, it is clear that each model performs differently in different metrics, and this information can be used to make a more informed decision on which model is best suited for a particular task."
315,"caption: Model performance using different evaluation metricstable: Model,Accuracy,F1-score,Precision,Recall, SVM,0.89,0.87,0.88,0.88, KNN,0.87,0.85,0.84,0.86, DNN,0.91,0.90,0.92,0.89, RF,0.90,0.88,0.91,0.86, Naive Bayes,0.85,0.83,0.82,0.85","Table presents the model performance evaluated using different evaluation metrics. SVM, KNN, DNN, RF, and Naive Bayes models' accuracy, F1-score, precision, and recall results are presented in the table. DNN performed better regarding accuracy, scoring 0.91, whereas KNN scored the lowest with 0.87. Regarding F1-score, DNN also performed best with a score of 0.90. The model with the highest precision was DNN, scoring 0.92, while Naive Bayes achieved the lowest precision score. Finally, the recall score was highest for SVM and Naive Bayes with 0.88 and 0.85, respectively, and DNN had the lowest recall score. Overall, the DNN model outperformed other models in accuracy, F1-score, and precision metrics, while SVM and Naive Bayes models performed well in recall metrics."
316,"caption: Table 4: The performance metrics of different algorithms on a classification tasktable: Model,Accuracy,F1-score,Precision,Recall, LogReg,0.89,0.91,0.93,0.89, KNN,0.82,0.80,0.85,0.76, SVM,0.91,0.92,0.95,0.90, Decision Tree,0.85,0.87,0.84,0.93, Random Forest,0.92,0.93,0.92,0.93, XGBoost,0.94,0.95,0.94,0.96","Table 4 compares six different algorithms' performances on a classification task. The table showcases the accuracy, F1-score, precision, and recall achieved by each of the algorithms, namely LogReg, KNN, SVM, Decision Tree, Random Forest, and XGBoost. Among all the models, XGBoost outperformed the rest with the highest accuracy (0.94), F1-score (0.95), precision (0.94), and recall (0.96). Random Forest showcased the second-best performance, with an accuracy of 0.92 and F1-score of 0.93. Interestingly, although SVM exhibited the third-highest accuracy (0.91), it had the highest precision (0.95), while the Decision Tree model highest recall (0.93). KNN performed relatively poorly compared to other models with the lowest accuracy of 0.82 and F1-score of 0.80."
317,"caption: Table 4: Model performance on classification task based on different evaluation metrics.table: Model Name,Accuracy,Precision,Recall,F1-Score, Logistic Regression,91.4%,0.897,0.949,0.922, Naive Bayes,85.8%,0.801,0.890,0.844, Support Vector Machine,94.2%,0.923,0.958,0.940, Random Forest,96.8%,0.976,0.967,0.972, Multi-layer Perceptron,92.5%,0.908,0.921,0.914","Table 4 presents the performance of different models on a classification task using multiple evaluation metrics, including Accuracy, Precision, Recall, and F1-Score. The models are Logistic Regression, Naive Bayes, Support Vector Machine (SVM), Random Forest, and Multi-layer Perceptron (MLP). The table demonstrates that the Random Forest model performed the best, achieving the highest accuracy of 96.8% and F1-Score of 0.972. The SVM model also performed well and achieved an accuracy of 94.2% and F1-Score of 0.940. Notably, the Naive Bayes model had the lowest accuracy and F1-score among all the models."
318,"caption: Table 4: Model performance comparison based on different evaluation metrics.table: Model Name,Accuracy,Precision,Recall,F1-Score, Model 1,0.72,0.69,0.71,0.70, Model 2,0.84,0.81,0.83,0.82, Model 3,0.78,0.77,0.79,0.78, Model 4,0.90,0.88,0.89,0.89, Model 5,0.68,0.72,0.65,0.68","Table 4 presents the comparison of multiple models based on different evaluation metrics such as Accuracy, Precision, Recall, and F1-Score. The models' names are mentioned in the first column, and their corresponding performance results are mentioned in the following columns. Among the models, Model 4 shows the best performance in all evaluation metrics, achieving an accuracy of 0.90, precision of 0.88, recall of 0.89, and F1-Score of 0.89. Model 2 and Model 3 also performed well, achieving an accuracy of 0.84 and 0.78, respectively. Interestingly, Model 5 demonstrated a contradicting result. It has the lowest accuracy of 0.68, but the highest precision of 0.72 and lowest recall of 0.65, resulting in an F1-Score of 0.68."
319,"caption: Model Performance Metricstable: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.85,0.83,0.88,0.78, Decision Tree,0.81,0.8,0.81,0.83, Random Forest,0.89,0.88,0.91,0.85, KNN,0.78,0.77,0.8,0.75, SVM,0.87,0.85,0.88,0.83","Table presents the model performance metrics of five different classification models trained and tested on the same dataset. It shows the models' accuracy, F1 score, precision, and recall. The results represent a substantial variation in the performance of the models. The Random Forest model performs the best in all evaluation metrics, with the highest accuracy, F1 score, precision, and recall. The Logistic Regression model had the second-best overall performance and achieved the highest precision, while SVM had the highest recall and performed the 3rd best. Notably, the KNN model had the poorest performance across all metrics."
320,"caption: Model Performance on Classification of Text Datatable: Model,Accuracy,F1 Score,Precision,Recall, Naive Bayes,0.872,0.874,0.878,0.872, Logistic Reg.,0.916,0.917,0.918,0.916, Decision Tree,0.847,0.845,0.852,0.847, Random Forest,0.936,0.936,0.937,0.936, K-Nearest Neigh,0.905,0.907,0.905,0.905","This table shows the performance comparison of classifiers - Naive Bayes, Logistic Regression, Decision Tree, Random Forest, and K-Nearest Neighbors - based on multiple evaluation metrics, including accuracy, F1 Score, Precision, and Recall. Here, Random Forest achieved the highest accuracy score of 0.936, closely followed by Logistic Regression with a score of 0.916. Interestingly, Random Forest, Logistic Regression and K-Nearest Neighbors achieved the highest F1 Score with a score of 0.936. The Precision and Recall scores show relatively good performance for all models, with Random Forest producing the highest Precision score of 0.937 and Naive Bayes having the highest Recall score of 0.872."
321,"caption: Performance comparison of Model1, Model2, and Model3 on various evaluation metrics.table: Metric/Model,Model1,Model2,Model3, Precision,0.82,0.79,0.84, Recall,0.88,0.92,0.87, F1-Score,0.85,0.85,0.85, ROC-AUC,0.92,0.89,0.93, PR-AUC,0.78,0.81,0.79","The table compares the performance of Model1, Model2 and Model3 based on different evaluation metrics, including precision, recall, F1-score, ROC-AUC, and PR-AUC. Overall, Model3 appears to be the best-performing model across the evaluation metrics. Model3 had the highest precision score of 0.84, followed closely by Model2 with a precision score of 0.79. Similarly, Model2 had the highest recall score of 0.92 compared to the other models. The F1-Scores are relatively close for all models, hovering around 0.85. On the other hand, Model3 had the highest ROC-AUC and PR-AUC scores, with ROC-AUC of 0.93 and PR-AUC of 0.79. Conversely, Model1 had the lowest PR-AUC score of 0.78. In conclusion, Model3 appears to be the best-performing model according to the evaluation metrics used in the comparison."
322,"caption: Table 4: The performance of different modelstable: Model,Accuracy (%),Precision (%),Recall (%),F1-score, Logistic Regression,93.4,93.2,93.6,93.4, Decision tree,87.2,83.5,92.7,87.7, K-Nearest Neighbors,88.9,91.2,84.6,87.8, Random Forest,92.8,94.3,91.2,92.6, SVM (linear),93.9,93.7,93.9,93.7","Table 4 illustrates the classification results of different models with multiple evaluation metrics. The models listed include Logistic Regression, Decision tree, K-Nearest Neighbors, Random Forest, and SVM (linear) models. The evaluation metrics used is Accuracy, Precision, Recall, and F1-score. Notably, the SVM (linear) model achieved the best accuracy of 93.9%, while the Logistic Regression model achieved a relatively higher recall of 93.6%. Additionally, the Random Forest model had the highest precision of 94.3%. The Decision tree model achieved high precision and F1-score of 83.5% and 87.7%, respectively. Therefore, the table shows that the choice of model can significantly impact the classification performance."
323,"caption: Table 4: Comparison of Accuracy, Precision, Recall, and F1-Score across different models.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.89,0.83,0.92,0.87, Naïve Bayes,0.82,0.72,0.94,0.82, Random Forest,0.94,0.96,0.94,0.95, Decision Tree,0.88,0.92,0.86,0.88, Support Vector Machines,0.93,0.93,0.93,0.93","Table 4 demonstrates a comparison of the evaluation metrics, including Accuracy, Precision, Recall, and F1-Score, across five different models, namely Logistic Regression, Naïve Bayes, Random Forest, Decision Tree, and Support Vector Machines (SVM). The models were evaluated based on a dataset of the same size with the same features. The Random Forest model shows the highest accuracy of 0.94, and it also had the highest precision and F1-Score. The SVM model had the highest recall score of 0.93. The Naïve Bayes model had the lowest accuracy and F1-Score of 0.82. Overall, the Random Forest and SVM models performed well across all evaluation metrics."
324,"caption: Performance comparison of different models based on multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 score, ModelA,0.89,0.86,0.90,0.88, ModelB,0.91,0.92,0.89,0.91, ModelC,0.87,0.94,0.83,0.88, ModelD,0.93,0.91,0.95,0.93","The table presents a performance comparison of four different models, namely ModelA, ModelB, ModelC, and ModelD. The models' performance has been evaluated using multiple evaluation metrics such as Accuracy, Precision, Recall, and F1 score. The table exhibits that ModelD outperforms all other models, achieving the highest overall performance with the highest Accuracy (0.93), Precision (0.91), Recall (0.95), and F1 score (0.93). ModelB displays the second-best performance with an accuracy of 0.91 and the highest Precision (0.92). Meanwhile, ModelC had the lowest accuracy of 0.87 and the lowest Recall performance of 0.83. Overall, the table provides insights on different models' performance based on various evaluation metrics, highlighting ModelD as the best performing model."
325,"caption: Model performance summary using multiple evaluation metricstable: Model,Accuracy,F1-score,Precision,Recall, Logisitic Regression,0.81,0.78,0.65,0.962, SVM (linear),0.79,0.77,0.62,0.936, Random Forest,0.84,0.81,0.72,0.934, K-NN (k=3),0.73,0.54,0.69,0.441, Naive Bayes,0.66,0.48,0.38,0.656, Decision Tree,0.79,0.78,0.69,0.905","Table summary presents the comparison of different machine learning models based on their performance using multiple evaluation metrics, such as accuracy, F1-score, precision, recall. The table is based on a dataset with a binary classification problem and shows the scores for six classifiers, including Logistic Regression, SVM (linear), Random Forest, K-NN (k=3), Naive Bayes, and Decision Tree. Random Forest obtained the highest accuracy of 0.84, followed by Logistic Regression at 0.81. The highest F1-score is 0.81, which is also achieved by Random Forest. From the table, it is evident that K-NN and Naive Bayes performed the worst in all metrics."
326,"caption: Comparison of Model Performance on Test Data Evaluation Metrics.table: Model Name,Precision Score,Recall Score,F1 Score,Accuracy Score, Logistic Regression,0.86,0.72,0.78,0.76, Random Forest,0.92,0.85,0.88,0.89, K-Nearest Neighbor,0.79,0.61,0.69,0.66, Gradient Boosting,0.93,0.70,0.80,0.84, Support Vector Machines,0.75,0.41,0.53,0.60","The table above highlights the evaluation of the performance of five different models, including Logistic Regression, Random Forest, K-Nearest Neighbor, Gradient Boosting, and Support Vector Machines. The models were evaluated based on multiple evaluation metrics comprising Precision Score, Recall Score, F1 Score, and Accuracy Score. Among the models, Random Forest recorded the highest Precision, Recall, and F1 Score, with 0.92, 0.85, and 0.88, respectively. Additionally, Gradient Boosting has the highest accuracy score of 0.84, followed by Logistic Regression with 0.76 accuracy. K-Nearest Neighbor has the lowest performance record across the significant metrics, with 0.79 Precision and 0.61 Recall scores."
327,"caption: Table 4: Performance results of different machine learning models.table: Model,Accuracy,Precision,Recall,F1-Score, LogReg,0.85,0.84,0.88,0.86, SVM,0.82,0.80,0.84,0.82, RF,0.87,0.87,0.88,0.87, NN,0.88,0.88,0.85,0.86","Table 4 shows the performance results of different machine learning models based on multiple evaluation metrics. The models present in the table include LogReg, SVM, RF, and NN. The evaluation metrics include Accuracy, Precision, Recall, and F1-Score. Interestingly, the Random Forest (RF) model managed to attain the highest accuracy result of 0.87. In terms of the F1-Score metric, both the LogReg and RF models scored 0.86 F1-Score, which is the highest in the table. Additionally, the NN model showed high accuracy and Precision results but performed poorly in Recall. Overall, the table showcases various machine learning models that achieved different performance results on the same dataset based on different evaluation metrics."
328,"caption: Table 4: Model performance evaluation based on precision, recall, and F1-score.table: Model,Precision,Recall,F1-score, SVM,0.83,0.76,0.79, KNN,0.76,0.73,0.75, Naive Bayes,0.65,0.80,0.70, Decision Tree,0.63,0.60,0.61","Table 4 displays the models' performance evaluations based on precision, recall, and F1-score. The table contains SVM, KNN, Naive Bayes, and Decision Tree models and their respective evaluation metrics' results. Notably, all models were trained and evaluated on the same dataset. The SVM model has achieved the highest precision of 0.83, while Naive Bayes achieved the highest recall of 0.80. Finally, compared to other models, KNN has gained the highest (0.75) F1-score, while the Decision Tree model has performed less optimally for all evaluation metrics."
329,"caption: Table 4: Evaluation metrics for different modelstable: Model,Precision,Recall,F1 Score, SVM,0.844,0.830,0.836, Random Forest,0.853,0.838,0.845, Naïve Bayes,0.783,0.803,0.783, Decision Tree,0.855,0.846,0.846, Logistic Regression,0.822,0.813,0.805","Table 4 displays the classification results of five different models, SVM, Random Forest, Naïve Bayes, Decision Tree, and Logistic Regression, using different evaluation metrics including Precision, Recall, and F1 Score. The table shows that the best performing model varies with each metric. The Decision Tree model yielded the highest Precision score of 0.855, while the Random Forest model had the highest Recall score of 0.838. On the other hand, the SVM model achieved the highest F1 Score of 0.836. Overall, the table highlights that the model performances are dependent on the evaluation metric used."
330,"caption: Table 4: Model evaluation metrics comparison for five different models.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.87,0.91,0.84,0.87, KNN,0.79,0.80,0.85,0.83, Decision Tree,0.83,0.84,0.82,0.82, Random Forest,0.90,0.92,0.90,0.90, Naive Bayes,0.74,0.63,0.90,0.71",
331,"caption: Model Performance Metricstable: Model,Accuracy,Precision,Recall,F1 Score, SVM,0.83,0.83,0.83,0.83, KNN,0.72,0.75,0.65,0.70, Naïve Bayes,0.78,0.80,0.73,0.76, Decision Tree,0.81,0.82,0.81,0.81, Random Forest,0.87,0.88,0.86,0.87",
332,"caption: Performance comparison of multiple models using evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, SVM,0.92,0.89,0.94,0.91, Random Forest,0.91,0.88,0.92,0.90, XGBoost,0.89,0.85,0.91,0.88, Naive Bayes,0.86,0.80,0.89,0.84, Decision Tree,0.83,0.78,0.84,0.81","The table compares the performances of multiple models based on different evaluation metrics such as Accuracy, Precision, Recall, and F1 Score. The models evaluated in the table are SVM, Random Forest, XGBoost, Naive Bayes, and Decision Tree. The results illustrate that SVM performs the best in Accuracy (0.92) and Recall (0.94) among all models. However, Naive Bayes has the lowest accuracy with 0.86. In terms of Precision, SVM has the highest score of 0.89, but the Naive Bayes model performed poorly with the Precision score of 0.80. Interestingly, the best F1 score is obtained by the SVM model with 0.91, which is higher than the rest of the models in the table."
333,"caption: Model comparison results of different algorithms using multiple classification metrics.table: Model,Accuracy,Balanced Accuracy,Precision,Recall,Specificity,F1 Score, RF,0.96,0.96,0.96,0.95,0.98,0.95, XGB,0.94,0.94,0.93,0.95,0.92,0.94, SVM,0.89,0.89,0.90,0.87,0.91,0.88, MLP,0.93,0.93,0.93,0.93,0.94,0.93, NB,0.84,0.84,0.82,0.87,0.81,0.82","Table 1 shows a comparison of five models, RF, XGB, SVM, MLP, and NB, using different evaluation metrics such as accuracy, balanced accuracy, precision, recall, specificity, and F1 score. The table indicates that the RF model achieved the highest accuracy and balanced accuracy score with 0.96. In terms of precision and F1 score, the MLP model achieved the highest score of 0.93, indicating high prediction accuracy. On the other hand, SVM and NB models achieved relatively lower precision and recall scores compared to other models. The specificity metric demonstrates that the RF and MLP models performed better in correctly identifying negative instances."
334,"caption: Table 4: Comparison of different models based on evaluation metrics for binary classificationtable: Model Name,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.75,0.60,0.63,0.61, Decision Tree,0.81,0.74,0.82,0.76, Random Forest Classifier,0.89,0.77,0.92,0.84, Support Vector Machine,0.68,0.56,0.45,0.47, K-Nearest Neighbors,0.83,0.69,0.91,0.79","Table 4 presents a comparison of different models based on their evaluation metrics for binary classification. Logistic Regression, Decision Tree, Random Forest Classifier, Support Vector Machine, and K-Nearest Neighbors models are evaluated based on Accuracy, Precision, Recall, and F1-Score. The Random Forest Classifier achieved the highest accuracy score of 0.89 and F1-Score of 0.84, while the Decision Tree model obtained the highest precision of 0.74, and K-Nearest Neighbors had the highest recall score of 0.91. Surprisingly, the Logistic Regression model achieved the lowest scores in all the evaluation metrics."
335,"caption: Table 4: Model performances based on multiple evaluation metrics comparison.table: Model,Precision,Recall,F1,Accuracy, Logistic Regression,0.87,0.94,0.90,0.882, Random Forest,0.91,0.96,0.93,0.919, Decision Tree,0.82,0.89,0.85,0.856, SVM,0.92,0.95,0.93,0.921, XGBoost,0.94,0.97,0.95,0.941","Table 4 compares different models' performances based on multiple evaluation metrics, including Precision, Recall, F1, and Accuracy. The evaluated models include Logistic Regression, Random Forest, Decision Tree, SVM, and XGBoost. Notably, all models were trained and tested on the same dataset. It is observed that all models have achieved high precision and recall scores, with the XGBoost model achieving the highest precision and recall scores of 0.94 and 0.97, respectively. Overall, XGBoost has demonstrated the best performance by achieving the highest F1 score of 0.95 and Accuracy of 0.941."
336,"caption: Performance comparison of different models using multiple metrics.table: Model Name,Balanced Accuracy,F1-Score,AUC,Matthews Correlation Coefficient, Model A,0.74,0.72,0.80,0.68, Model B,0.81,0.79,0.88,0.77, Model C,0.76,0.74,0.81,0.71, Model D,0.79,0.77,0.86,0.75","Table 4 compares the performance of different models using different evaluation metrics. The models' balanced accuracy, F1-score, AUC, and Matthews Correlation Coefficient are presented in the table. Model B performed the best, achieving the highest values in all the metrics. Notably, Model A had the lowest scores in all the metrics, while Model C had relatively low F1-score and Matthews Correlation Coefficient values. Model D showed similar performance compared to Model B, except for lower AUC value. The table demonstrates that Model B outperforms all other models considered based on the metrics used."
337,"caption: Performance comparison of different classification models with multiple evaluation metricstable: Model,Accuracy,F1 Score,Precision,Recall, Random Forest,0.94,0.94,0.94,0.96, Support Vector Machine,0.92,0.91,0.89,0.93, Naive Bayes,0.85,0.81,0.80,0.82, Logistic Regression,0.90,0.89,0.88,0.90","This table presents the performance comparison of Random Forest, Support Vector Machine, Naive Bayes, and Logistic Regression models using multiple evaluation metrics, including accuracy, F1 score, precision, and recall. Notably, the Random Forest model achieved the highest accuracy of 0.94 and F1 score of 0.94, closely followed by the Logistic Regression model with an accuracy of 0.90 and F1 score of 0.89. The Naive Bayes model had the lowest accuracy of 0.85, while the Support Vector Machine achieved a reasonable accuracy of 0.92. Additionally, all models had relatively high precision and recall scores, indicating the models' ability to make accurate positive and negative predictions. Overall, the results suggest that the Random Forest and Logistic Regression models may be the most suitable models for classification tasks."
338,"caption: Performance comparison of four different models using multiple evaluation metrics.table: Model Name,Precision,Recall,F1-Score,Accuracy,AUC, Model 1,0.81,0.90,0.85,0.83,0.90, Model 2,0.87,0.79,0.83,0.85,0.86, Model 3,0.75,0.91,0.82,0.77,0.80, Model 4,0.91,0.83,0.86,0.88,0.92","Table above illustrates a comparison of four different models based on Precision, Recall, F1-Score, Accuracy, and AUC evaluation metrics. All models were evaluated on the same dataset. Notably, Model 1 exhibited the highest AUC of 0.90, while the Model 4 yielded the best Precision and F1-Score scores. Model 3 showcases the highest Recall score of 0.91, and Model 2 performs well concerning Accuracy. Such a table helps to identify the strengths of each model based on different evaluation metrics and assists in selecting the best model for a specific task."
339,"caption: Comparison of different models' accuracy, F1-score, precision, and recall.table: Model,Accuracy,F1-Score,Precision,Recall, Model A,80.5%,0.73,0.68,0.79, Model B,77.2%,0.67,0.62,0.72, Model C,83.1%,0.77,0.86,0.70, Model D,76.4%,0.63,0.58,0.69, Model E,85.6%,0.81,0.78,0.85","The table compares the accuracy, F1-score, precision, and recall of five different models. Model E shows the best overall performance with the highest accuracy (85.6%), F1-score (0.81), and recall (0.85). Interestingly, Model C has a high precision score (0.86), while having a lower recall score (0.70). Model A and Model E have similar recall scores (0.79 and 0.85), but Model E has a higher F1-score and accuracy than Model A. Additionally, Model B and Model D exhibit lower overall performance metrics."
340,"caption: Comparison of Different Classification Models Based on Different Evaluation Metrics.table: Model,F1-Score,G-Mean,Precision,Recall,AUC-ROC, SVM,0.88,0.87,0.92,0.85,0.93, Random Forest,0.82,0.82,0.85,0.80,0.89, KNN,0.62,0.55,0.70,0.56,0.61, Naive Bayes,0.78,0.72,0.81,0.76,0.81, XGBoost,0.84,0.83,0.87,0.81,0.90","The presented table compares different classification models based on their F1-Score, G-Mean, Precision, Recall, and AUC-ROC. The different models included are SVM, Random Forest, K-Nearest Neighbors (KNN), Naive Bayes, and XGBoost. The table shows that SVM has the highest F1-Score (0.88), Precision (0.92), and AUC-ROC (0.93) among all models, followed by XGBoost with the second-highest AUC-ROC (0.90). However, Random Forest slightly outperforms XGBoost with the highest G-Mean (0.82) score. Interestingly, Naive Bayes has the highest Recall score (0.76) despite being outperformed by few models in other metrics. Compared to SVM, KNN has a lower F1-Score (0.62), G-Mean (0.55), and AUC-ROC (0.61) but has a relatively higher Precision score (0.70). Overall, the table shows that different models perform differently based on different evaluation metrics and that selecting the best model for a given problem requires evaluating the models based on several metrics."
341,"caption: Model performance comparison using accuracy, F1-score, precision, and recall evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.89,0.91,0.90,0.92, Naive Bayes,0.85,0.87,0.84,0.91, Decision Tree,0.91,0.92,0.93,0.91, Random Forest,0.93,0.94,0.94,0.95, XGBoost,0.94,0.95,0.95,0.95","The table compares the performance results of five different models using commonly used evaluation metrics: accuracy, F1-score, precision, and recall. The models used in the comparison are Logistic Regression, Naive Bayes, Decision Tree, Random Forest, and XGBoost. The highest performance results were observed in the XGBoost model, exhibiting an accuracy, F1-score, precision, and recall of 0.94, 0.95, 0.95, and 0.95, respectively. It is also noteworthy that the Random Forest model has very similar and competitive results to XGBoost, while Logistic Regression was slightly below in performance compared to the remaining models. The Naive Bayes model had the lowest performance among all models examined."
342,"caption: Performance of different machine learning modelstable: Model,Precision,Recall,F1-score,Accuracy, Logistic Regression,0.89,0.78,0.83,0.85, Random Forest,0.94,0.88,0.91,0.92, Naive Bayes,0.77,0.65,0.71,0.75, SVM,0.92,0.85,0.88,0.89","The table presents the performance results of four different machine learning models: Logistic Regression, Random Forest, Naive Bayes, and SVM. The models were evaluated using multiple metrics, including Precision, Recall, F1-score, and Accuracy. The Random Forest model shows the best performance on all metrics, achieving a high Precision of 0.94, a Recall of 0.88, an F1-score of 0.91, and an Accuracy of 0.92. Conversely, the Naive Bayes model achieved the lowest performance scores on all metrics, presenting a Precision of 0.77, a Recall of 0.65, an F1-score of 0.71, and an Accuracy of 0.75. SVM and Logistic Regression models had similar and decent performances, with SVM performing better in terms of Precision and F1-score, whereas Logistic Regression showed better performance in terms of Recall and Accuracy."
343,"caption: Table 4: Performance of different models based on different evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.82,0.77,0.75,0.79, Logistic Regression,0.79,0.74,0.72,0.77, Random Forest,0.87,0.83,0.81,0.86, XGBoost,0.89,0.85,0.83,0.87","Table 4 shows the performance of four different models based on different evaluation metrics. The table exhibits the accuracy, F1-score, precision, and recall scores for Support Vector Machine (SVM), Logistic Regression, Random Forest, and XGBoost models. Notably, all models were trained and tested on the same dataset. The XGBoost model achieved the highest accuracy of 0.89, followed by Random Forest with an accuracy of 0.87, which suggests that both models predict accurately. However, the XGBoost model outperformed the Random Forest model in F1-score, Precision, and Recall. SVM and Logistic Regression models show less impressive performance in comparison, achieving lower scores across all metrics."
344,"caption: Table 4: Model performance based on different evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall,Specificity, SVM,0.78,0.72,0.68,0.77,0.81, Random Forest,0.85,0.79,0.82,0.76,0.88, Logistic Regression,0.81,0.74,0.71,0.78,0.83, Naive Bayes,0.70,0.64,0.66,0.62,0.76, Decision Tree,0.72,0.68,0.74,0.63,0.82","Table 4 presents the accuracy, F1 score, precision, recall, and specificity performance results of five different models: SVM, Random Forest, Logistic Regression, Naive Bayes, and Decision Tree. All models were evaluated on the same dataset with five-fold cross-validation. Interestingly, the Random Forest model showed the best accuracy with a score of 0.85 followed by Logistic Regression with a score of 0.81. In contrast, Naive Bayes had the lowest accuracy of 0.70. Additionally, the Random Forest model achieved the best F1 score, precision, and specificity with scores of 0.79, 0.82, and 0.88, respectively, and the Decision Tree model showed the best recall with a score of 0.63."
345,"caption: Table 4: Comparison of multiple model performance with multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.830,0.835,0.800,0.815, KNN,0.820,0.810,0.780,0.795, RF,0.860,0.865,0.825,0.840, Adaboost,0.870,0.880,0.840,0.855, XGBoost,0.880,0.890,0.865,0.875","Table 4 shows the comparison of different models, including SVM, KNN, Random Forest (RF), Adaboost, and XGBoost's performance, evaluated on four evaluation metrics, including Accuracy, Precision, Recall, and F1-score. The RF model demonstrates the highest Accuracy of 0.86, whereas the XGBoost model exhibits the best results in all other metrics, where it has the highest Precision, Recall, and F1-score with scores of 0.89, 0.865, and 0.875, respectively. Notably, the KNN model has the lowest accuracy score of 0.82. Overall, the results suggest that the performance of models varies with evaluation metrics, and XGBoost is the best performer among the models evaluated."
346,"caption: Comparison of model performances based on evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, Model A,0.85,0.82,0.90,0.76, Model B,0.88,0.85,0.92,0.79, Model C,0.82,0.80,0.71,0.92, Model D,0.90,0.88,0.89,0.87","Table 4 shows the performance comparison of four different models using four different evaluation metrics: Accuracy, F1-score, Precision, and Recall. Model B performs the best across all evaluation metrics with an accuracy of 0.88, F1-score of 0.85, precision of 0.92, and recall of 0.79. The second-best model is Model D, with an accuracy of 0.90, F1-score of 0.88, precision of 0.89, and recall of 0.87. Interestingly, Model A and Model C scored similarly on one hand. On the other hand, these two models have different strengths. Model A demonstrated higher precision and accuracy with 0.90 and 0.85, respectively. In contrast, Model C delivers higher recall with 0.92, meaning it is more senior at identifying actual positives."
347,"caption: Table 4: Evaluation metrics for different machine learning modelstable: Model,F1 Score (Class1),F1 Score (Class2),Accuracy,Precision,Recall,Area under Curve (AUC), SVM,0.81,0.69,0.78,0.84,0.81,0.815, Random Forest,0.85,0.72,0.82,0.84,0.83,0.831, Decision Tree,0.76,0.78,0.79,0.83,0.79,0.799, Multilayer Perceptron,0.82,0.76,0.80,0.81,0.82,0.816, Logistic Regression,0.77,0.83,0.80,0.81,0.80,0.806","Table 4 evaluates the performance of five different classification models based on multiple evaluation metrics. The models include SVM, Random Forest, Decision Tree, Multilayer Perceptron, and Logistic Regression. The evaluation metrics in the table include F1 score (Class1), F1 score (Class2), Accuracy, Precision, Recall, and Area Under Curve (AUC). Interestingly, the Random Forest model shows the highest F1 score (Class1) of 0.85 than other models; however, the Logistic Regression model has the highest F1 score (Class2) of 0.83. The Multilayer Perceptron model has the highest accuracy, precision, and recall with scores of 0.80, 0.81, and 0.82, respectively. The Random Forest model also exhibits the highest AUC, while the SVM model has the lowest AUC score."
348,"caption: Table 4: Model Performances on Sentiment Analysis Task Using Different Evaluation Metricstable: Model,Acc,F1,Prec,Recall,AUC, CNN,0.80,0.76,0.84,0.71,0.85, Naive Bayes,0.72,0.63,0.88,0.49,0.60, Random Forest,0.85,0.82,0.83,0.81,0.92, Support Vector Machine,0.74,0.69,0.84,0.58,0.68, XGBoost,0.87,0.85,0.83,0.89,0.92","Table 4 shows the model performances in a sentiment analysis task measured using multiple evaluation metrics. The table includes five models, namely, CNN, Naive Bayes, Random Forest, Support Vector Machine, and XGBoost. The evaluation metrics used to assess the model's performance are accuracy, F1-score, precision, recall, and area under the ROC curve (AUC). Interestingly, Random Forest and XGBoost models show the highest accuracy of 0.85 and 0.87, respectively. XGBoost also achieves the highest F1-score, precision, and recall of 0.85, 0.83, and 0.89, respectively. However, Random Forest has the highest AUC score of 0.92."
349,"caption: Performance comparison of different models using multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, LogReg,0.87,0.86,0.89,0.87, SVM,0.85,0.83,0.86,0.85, DT,0.80,0.75,0.82,0.78, RF,0.91,0.90,0.93,0.91, XGB,0.87,0.87,0.87,0.87","The table presents the comparison of different models' performance in predicting a binary outcome. The models' accuracy, precision, recall, and F1-score are the evaluation metrics used. The Random Forest model has attained the highest accuracy (0.91) and F1-score (0.91) compared to the other models. Furthermore, it has the highest precision (0.90) and recall (0.93), indicating its ability to make accurate predictions while minimizing false positives and false negatives. The Logistic Regression model exhibited strong performance, as well, achieving an accuracy and F1-score of 0.87. In contrast, the Decision Trees model has the lowest performance in all metrics compared to the other models."
350,"caption: Table 4: Performance comparison of different models using various evaluation metricstable: Model,F1 Score,Accuracy,Recall,Precision, Logistic Regression,0.89,0.92,0.91,0.88, Decision Trees,0.72,0.84,0.75,0.69, Random Forest,0.91,0.94,0.95,0.87, XGBoost,0.93,0.95,0.95,0.92, Support Vector Machines (SVM),0.88,0.91,0.91,0.87","Table 4 summarizes the performances of several machine learning algorithms for a binary classification task. The models' performances are evaluated using F1 Score, Accuracy, Recall, and Precision metrics. The best-performed model was the XGBoost algorithm, showing the highest F1 Score, Accuracy, Recall, and Precision values of 0.93, 0.95, 0.95, and 0.92, respectively. The Random Forest model ranked second, followed by the Logistic Regression and SVM models. However, the Decision Trees model was the least performing method, indicating that it may not be suitable for this particular classification task."
351,"caption: Model performances based on evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Model 1,0.85,0.84,0.85,0.84, Model 2,0.88,0.89,0.87,0.92, Model 3,0.79,0.77,0.80,0.74, Model 4,0.91,0.91,0.90,0.93","The table illustrates the performance of four different models based on evaluation metrics such as accuracy, F1 score, precision, and recall. Model 4 demonstrates the best accuracy, F1 score, and precision, with a 0.91 score, while model 2 scored the highest recall of 0.92. Interestingly, model 1 and model 4 have the same accuracy and F1 score of 0.85 and 0.84, respectively. Moreover, the precision score for all models is relatively high, ranging from 0.87 to 0.90. These results indicate that model performances vary widely based on different evaluation metrics, and one model may not be the best for all metrics."
352,"caption: Performance of different models using various evaluation metrics.table: Model,Precision,Recall,F1-Score,PR-AUC,ROC-AUC, Logistic Regression,0.85,0.80,0.82,0.95,0.82, Random Forest,0.80,0.90,0.85,0.88,0.80, K-Nearest Neighbor,0.70,0.70,0.70,0.75,0.75, Support Vector Machine,0.90,0.82,0.85,0.92,0.88","The table presents the performance comparison of different models based on multiple evaluation metrics, including precision, recall, F1-score, PR-AUC, and ROC-AUC. The models include Logistic Regression, Random Forest, K-Nearest Neighbor, and Support Vector Machine models. Notably, the best-performing model varies depending on the evaluation metric. For instance, the Logistic Regression model has the highest precision, while the K-Nearest Neighbor model has the lowest precision among all models. Similarly, the Random Forest model had the highest recall, while the Support Vector Machine model had the lowest. The Support Vector Machine model showed the highest PR-AUC score of 0.92, whereas, the Random Forest model showed the highest F1-score of 0.85. Finally, the Support Vector Machine model showed the highest ROC-AUC of 0.88, while the Logistic Regression model showed the lowest ROC-AUC, with a score of 0.82."
353,"caption: Comparison of different models based on accuracy, precision, recall, and F1-score.table: Model Name,Accuracy,Precision,Recall,F1-Score, Model 1,0.85,0.87,0.87,0.86, Model 2,0.93,0.92,0.95,0.93, Model 3,0.91,0.89,0.94,0.91, Model 4,0.84,0.84,0.85,0.84, Model 5,0.88,0.91,0.86,0.88","Table 1 exhibits the performance metrics of five different models. The table outlines the models' accuracy, precision, recall and F1-score. Among the models, Model 2 achieved the highest performance results, having an accuracy of 0.93 and an F1-score of 0.93, respectively. Model 5 excelled in precision and achieved a score of 0.91, while Model 3 performed best in recall and achieved a score of 0.94. Interestingly, despite having the highest accuracy score, Model 2 only ranked third in terms of precision, which indicates that it might have relatively fewer true positives than other models."
354,"caption: Table 4: Model performance from different machine learning approaches based on various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.89,0.87,0.91,0.89, Random Forest,0.91,0.90,0.94,0.92, Decision Tree,0.83,0.82,0.84,0.81, XGBoost,0.92,0.93,0.91,0.92, Neural Network,0.90,0.88,0.92,0.90","Table 4 presents a comparison of different machine learning models based on various evaluation metrics, including accuracy, precision, recall, and F1-score. SVM achieved an accuracy of 0.89 with precision, recall, and F1-score as 0.87, 0.91, and 0.89, respectively. Among all the models, the Random Forest method shows the highest accuracy of 0.91 with precision, recall, and F1-score as 0.90, 0.94, and 0.92, respectively. XGBoost has the highest precision score of 0.93 and a good tradeoff among recall (0.91), accuracy (0.92), and F1-score (0.92). The Decision Tree method resulted in the lowest accuracy (0.83), precision (0.82), recall (0.84), and F1-score (0.81) among all the models. However, the Neural Network model demonstrated a good balance among all performance metrics, with an accuracy of 0.90 and precision, recall, and F1-score at 0.88, 0.92, and 0.90, respectively."
355,"caption: Performance comparison of different models with multiple evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, LogReg,0.835,0.860,0.823,0.900, SVM,0.825,0.849,0.815,0.880, RF,0.875,0.893,0.855,0.934, MLP,0.855,0.881,0.843,0.932, k-NN,0.810,0.834,0.811,0.858","This table compares the performance of five different models using multiple evaluation metrics, including accuracy, F1 score, precision, and recall. The models are LogReg, SVM, RF, MLP, and k-NN. The highest performance scores are achieved by the Random Forest (RF) model in terms of accuracy (0.875), F1 score (0.893), precision (0.855), and recall (0.934). The other models exhibit relatively similar scores for each metric, except for the k-NN model, which shows the lowest performance in all the metrics. Overall, the RF model outperforms the other models across all the evaluation metrics."
356,"caption: Performance metrics across multiple modelstable: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.83,0.78,0.86,0.72, Random Forest,0.87,0.82,0.84,0.80, XGBoost,0.85,0.80,0.88,0.73, MLP,0.87,0.82,0.84,0.80, CNN,0.81,0.76,0.81,0.72","The table displays the performance metrics of SVM, Random Forest, XGBoost, MLP, and CNN based on their accuracy, F1-score, precision, and recall. It is evident that all the models have an accuracy score greater than 80%, while the highest accuracy was achieved by the MLP model with an accuracy score of 0.87. The Random Forest model achieved the highest F1-score of 0.82, while the XGBoost model performed the best in terms of precision with a score of 0.88. The SVM model displayed a high precision score of 0.86, and the MLP and Random Forest models achieved the highest recall score of 0.80. Overall, the Random Forest, MLP, and XGBoost models showed the most consistent performance across multiple evaluation metrics."
357,"caption: Table 4: Performance comparison of different classification models on the given dataset.table: Model Name,Accuracy,Precision,Recall,F1_score, Random Forest,0.78,0.80,0.76,0.78, KNN,0.72,0.64,0.81,0.71, SVM,0.81,0.76,0.84,0.80, Decision Tree,0.71,0.70,0.69,0.69, Logistic Regression,0.79,0.74,0.79,0.75","Table 4 displays the comparison of different classification models' performances on the provided dataset. The table contains the evaluation metrics, accuracy, precision, recall, and F1_score. The Random Forest model achieved the highest accuracy with 0.78. Meanwhile, the SVM model showed the best precision and recall with 0.76 and 0.84, respectively. On the other hand, the Logistic Regression model exhibited the best F1 score with 0.75. It is essential to note that all models were trained and tested on the same dataset, and the result reflects their relative performances."
358,"caption: Table 1: Model performances based on different evaluation metricstable: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.86,0.76,0.76,0.77, K-Nearest Neighbor,0.80,0.68,0.72,0.65, Decision Tree,0.82,0.72,0.70,0.75, Random Forest,0.90,0.85,0.83,0.87, Gradient Boosting,0.92,0.89,0.87,0.91","Table 1 presents a comparison of model performances based on different evaluation metrics. The table includes five different models, namely, Logistic Regression, K-Nearest Neighbor, Decision Tree, Random Forest, and Gradient Boosting. The evaluation metrics consist of Accuracy, F1-score, Precision, and Recall. Notably, the Random Forest achieved the highest accuracy score of 0.90, while Gradient Boosting has the highest F1-score of 0.89. In terms of Precision and Recall, Gradient Boosting outperformed other models with score 0.87 and 0.91 respectively. These results indicate that models' performance can differ significantly based on the evaluation metric used, and every model's strengths and weaknesses should be considered when selecting the best model for the task at hand."
359,"caption: Model Performances on Test Datatable: Model,Accuracy,Precision,Recall,F1 Score, Decision Tree,0.86,0.86,0.85,0.85, Random Forest,0.91,0.91,0.90,0.90, K-Nearest Neighbors,0.87,0.87,0.86,0.86, Support Vector Machine,0.95,0.95,0.95,0.95, Multi-Layer Perceptron,0.93,0.93,0.92,0.92","This table shows the model performances on test data based on different evaluation metrics. The models used were Decision Trees, Random Forest, K-Nearest Neighbors, Support Vector Machine, and Multi-Layer Perceptron. The evaluation metrics included are Accuracy, Precision, Recall, and F1-Score. It is observed that Support Vector Machine achieved the highest performance results in all metrics, with an Accuracy score of 0.95 and Precision, Recall, and F1-Score of 0.95. This suggests that Support Vector Machine is the most efficient and accurate model for the given task. However, all models performed reasonably well, achieving accuracy scores above 0.85."
360,"caption: Comparison of performance metrics for different machine learning modelstable: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.94,0.89,0.91,0.90, Decision Tree,0.92,0.83,0.82,0.82, Random Forest,0.97,0.95,0.96,0.95, KNN,0.88,0.78,0.76,0.76, SVM,0.95,0.90,0.93,0.91","The table compares multiple machine learning models' performances based on different evaluation metrics, including accuracy, precision, recall, and F1 Score. The models are Logistic Regression, Decision Tree, Random Forest, KNN, and SVM. Random Forest had the best performance, achieving an accuracy of 0.97, precision of 0.95, recall of 0.96, and F1 score of 0.95. SVM achieved the highest recall of 0.93 and KNN had the lowest performance with an accuracy of 0.88 and an F1 score of 0.76. This table's information could help in identifying the best model for a given classification task based on the evaluation metric of interest."
361,"caption: A comparison of different machine learning models' performance on the binary classification tasktable: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.815,0.829,0.794,0.810, Decision Tree,0.737,0.724,0.753,0.738, K-Nearest Neighbor,0.781,0.780,0.780,0.780, Random Forest,0.872,0.884,0.858,0.871, Neural Network,0.879,0.886,0.871,0.877","The table compares the performance metrics of five different machine learning models that were trained and tested on the same binary classification dataset. The models include Logistic Regression, Decision Tree, K-Nearest Neighbor, Random Forest, and Neural Network. The table shows the accuracy, precision, recall, and F1-score for each model. The results indicate that the best-performing model is the Neural Network with an accuracy of 0.879, followed closely by the Random Forest model with 0.872. Interestingly, although Logistic Regression has the lowest recall (0.794), it scored high in both accuracy (0.815) and precision (0.829). The K-Nearest Neighbor model shows consistent performance across all metrics with an F1-score of 0.780. The Decision Tree has the lowest performance with an accuracy of 0.737, followed by an F1-score of 0.738."
362,"caption: Comparison of different models based on accuracy, F1 Score, precision and recall.table: Model,Accuracy,F1 Score,Precision,Recall, Model A,0.87,0.89,0.92,0.87, Model B,0.93,0.91,0.89,0.95, Model C,0.91,0.92,0.93,0.91","Table presents a comparison of multiple models based on accuracy, F1 score, precision, and recall evaluation metrics. The table shows three different models' performance results, namely Model A, Model B, and Model C. Model B shows the highest accuracy of 0.93 and recall of 0.95, while Model A has the highest precision of 0.92. Comparing the F1 score, Model C performed the best, achieving a score of 0.92. It is essential to bear in mind that although Model B achieved the highest accuracy and recall scores, Model A has higher precision scores that could be useful under specific circumstances."
363,"caption: Performance comparison of different classification models using various evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.95,0.87,0.92,0.89, Decision Tree,0.85,0.78,0.85,0.76, Random Forest,0.92,0.85,0.87,0.85, K-NN,0.80,0.72,0.75,0.71","The table presents the performance metrics of four different classification models, including SVM, Decision Tree, Random Forest, and K-NN. The models' performances are evaluated based on different metrics, including Accuracy, Precision, Recall, and F1-Score. Notably, the SVM model shows the best performance in all metrics except the F1-Score, where it's only second to the Random Forest model. The Random Forest model also shows good performance across all metrics. In contrast, the Decision Tree model shows the lowest performance among all models across all metrics. Overall, the results suggest the superiority of the SVM and Random Forest models in accurately classifying the dataset."
364,"caption: Table 1: Model Performance Metricstable: Model,Accuracy,Precision,Recall,F1 Score,AUC, Logistic Regression,90.2%,0.89,0.93,0.91,0.83, Random Forest,92.1%,0.91,0.92,0.92,0.89, Support Vector Machine,89.4%,0.87,0.91,0.89,0.82, XGBoost,91.7%,0.90,0.93,0.92,0.86","Table 1 depicts the model performance metrics of different classification models for a given dataset. The models include Logistic Regression, Random Forest, Support Vector Machine, and XGBoost. Multiple evaluation metrics such as Accuracy, Precision, Recall, F1 Score, and AUC are presented in the table. Interestingly, the Random Forest model exhibits the highest Accuracy of 92.1%. Meanwhile, the Support Vector Machine model presents the lowest performance metrics with an Accuracy of 89.4%, Precision of 0.87, Recall of 0.91, F1 Score of 0.89, and AUC of 0.82. Overall, the table provides insights into each model's classification performance with regard to different evaluation metrics and assists in selecting the best-performing model."
365,"caption: Table 4: Model performance for binary classification task based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score,Cohen's Kappa, SVM,0.845,0.847,0.835,0.840,0.690, Random Forest,0.837,0.848,0.815,0.830,0.670, Gradient Boosting,0.840,0.849,0.825,0.834,0.677, Artificial Neural Network,0.823,0.816,0.838,0.827,0.640, Naive Bayes,0.768,0.785,0.713,0.741,0.512","Table 4 highlights the performance of five different models for a binary classification task using different evaluation metrics. The models include SVM, Random Forest, Gradient Boosting, Artificial Neural Network, and Naive Bayes. Accuracy, Precision, Recall, F1-Score, and Cohen's Kappa have been calculated for each model. The SVM model had the highest accuracy of 0.845, and the Random Forest had the highest Precision of 0.848. Artificial Neural Network had the highest F1-Score of 0.827, and Gradient Boosting had the highest Recall of 0.825. SVM had the highest Cohen's Kappa, indicating substantial agreement between predicted and observed values (0.690). Naive Bayes showed the lowest performance in terms of all metrics."
366,"caption: Comparison of model performance using different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score,AUROC, SVM,0.819,0.825,0.805,0.814,0.883, KNN,0.789,0.785,0.756,0.770,0.848, RF,0.905,0.916,0.885,0.898,0.961, MLP,0.930,0.937,0.925,0.931,0.980",
367,"caption: Table 4: Evaluation metrics of binary classification modelstable: Model,Precision,Recall,F1-Score,Accuracy, SVM,0.86,0.92,0.89,0.90, KNN,0.81,0.88,0.85,0.87, Decision Tree,0.94,0.91,0.92,0.93, Naive Bayes,0.71,0.96,0.81,0.88, Random Forest,0.96,0.94,0.95,0.95","Table 4 displays the performance of different models used in binary classification. The evaluated models were SVM, KNN, Decision Tree, Naive Bayes, and Random Forest in terms of Precision, Recall, F1-Score, and Accuracy. The Random Forest model indicates the highest precision of 0.96, whereas the Decision Tree model showed the highest recall of 0.91. Furthermore, the Decision Tree and the Naive Bayes models achieved high F1-scores of 0.92 and 0.81, respectively. Overall, the Random Forest model showcase the best evaluation metrics among the models, with a high precision and accuracy scores of 0.96 and 0.95, respectively."
368,"caption: Performance metrics of different classification models.table: Model,Precision,Recall,F1-Score,AUC-ROC,Accuracy, Logistic Regression,0.89,0.78,0.83,0.97,0.85, Decision Tree,0.83,0.81,0.82,0.92,0.84, Random Forest,0.90,0.84,0.87,0.96,0.86, XGBoost,0.92,0.89,0.91,0.98,0.89","The table presents the performance metrics of four different classification models, namely Logistic Regression, Decision Tree, Random Forest, and XGBoost. The evaluation metrics used to compare model performance are Precision, Recall, F1-Score, AUC-ROC, and Accuracy. Notably, all the models have performed well across different evaluation metrics. However, XGBoost achieved the highest scores for all evaluation metrics, indicating that it is the best-performing model among the four. The next best-performing model is Random Forest, followed by Logistic Regression and Decision Tree models, respectively."
369,"caption: Table 4: Performance metrics comparison of different machine learning models on the classification tasktable: Model,Accuracy,F1-score,Recall,Precision, SVM,0.84,0.82,0.75,0.90, KNN,0.76,0.73,0.63,0.86, Naïve Bayes,0.62,0.58,0.75,0.47, Decision Tree,0.79,0.77,0.71,0.84, Random Forest,0.89,0.87,0.82,0.94","Table 4 presents a comprehensive comparison of different machine learning classifiers' performance on a classification task based on the accuracy, F1-score, recall, and precision metric. This table provides insights into which classifier performs better for this classification task. Notably, the Random Forest model attains the highest accuracy (0.89), F1-score (0.87), and precision (0.94) metrics, while the SVM model attains the highest recall (0.75) metric. The Naïve Bayes model achieves the lowest accuracy score (0.62), indicating that it may not be the best option for this classification task. Overall, it appears that the Random Forest model outperforms the other classifiers for this problem, given its high performance results across multiple evaluation metrics."
370,"caption: Model Performance on Test Datatable: Model,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.76,0.75,0.74,0.78, SVM,0.81,0.78,0.80,0.77, Random Forest,0.85,0.84,0.82,0.86, MLP,0.83,0.82,0.81,0.84","The table showcases the performance of four different models, namely Logistic Regression, SVM, Random Forest, and MLP, on a test dataset employing four different evaluation metrics, Accuracy, F1-Score, Precision, and Recall. The Random Forest model performs the best with an accuracy of 0.85, F1-Score of 0.84, precision of 0.82, and recall of 0.86. SVM has the second-best accuracy of 0.81. Logistic Regression has the lowest accuracy, F1-Score, and Precision scores, while MLP falls behind only in terms of accuracy, however, performs similarly to the rest of the models in other metrics."
371,"caption: Performance of Different Models on Evaluation Metricstable: Model,F1-score,Precision,Recall, Model A,0.75,0.85,0.67, Model B,0.81,0.79,0.84, Model C,0.72,0.78,0.67","Table displays the performance of three different models, Model A, Model B, and Model C, on evaluation metrics F1-score, Precision, and Recall. Model B achieved the highest F1-score of 0.81, indicating that this model's overall performance is better than the other two models. Model A had the highest precision score of 0.85, indicating that this model had the highest proportion of true positive classifications among all positive predictions. Model B had the highest recall score of 0.84, indicating that this model had the highest proportion of true positives among real positives in the data. The table illustrates that different models have various strengths and weaknesses based on the selected evaluation metrics."
372,"caption: Comparison of the performance of different models using different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score,AUC-ROC,PR-AUC, Logistic Regression,0.895,0.902,0.799,0.848,0.920,0.886, Random Forest,0.905,0.907,0.823,0.864,0.934,0.899, Decision Tree,0.869,0.854,0.728,0.786,0.871,0.812, KNN,0.890,0.868,0.801,0.833,0.912,0.880, SVM,0.891,0.868,0.805,0.837,0.914,0.876","This table presents a comparison of the performance of different models using different evaluation metrics, such as Accuracy, Precision, Recall, F1-Score, AUC-ROC, and PR-AUC. The table includes five different models, namely Logistic Regression, Random Forest, Decision Tree, KNN, and SVM. According to the table, the Random Forest model shows the best performance as it has the highest accuracy score of 0.905 and AUC-ROC of 0.934. Additionally, the Random Forest model has the highest precision score of 0.907, which means it provides fewer False Positive results. On the other hand, the Decision Tree model has the lowest F1-Score of 0.786 and PR-AUC of 0.812, indicating the model suffers from an imbalance between Precision and Recall."
373,"caption: Model performance based on different evaluation metricstable: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.85,0.84,0.88,0.81, KNN,0.77,0.75,0.74,0.76, Naive Bayes,0.72,0.73,0.68,0.78, Random Forest,0.89,0.89,0.88,0.90, XGBoost,0.92,0.92,0.91,0.94","Table shows model performances based on different evaluation metrics, including accuracy, F1-Score, precision, and recall. The table contains SVM, KNN, Naive Bayes, Random Forest, and XGBoost models' performances. The Random Forest model results in the best overall performance with an accuracy score of 0.89, F1-Score of 0.89, precision of 0.88, and recall of 0.90. Notably, the XGBoost model shows the best performance in all evaluation metrics when compared to other models. The model achieves the highest accuracy of 0.92, F1-Score of 0.92, precision of 0.91 and recall of 0.94. The results suggest that the XGBoost model outperforms other models in all evaluation metrics when used to classify the same dataset."
374,"caption: Model performance based on different evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score, Random Forest,0.82,0.76,0.80,0.78, Logistic Regression,0.75,0.68,0.73,0.70, Support Vector Machine,0.79,0.72,0.79,0.75, Multilayer Perceptron,0.85,0.81,0.83,0.82, K-Nearest Neighbor,0.76,0.69,0.75,0.72","Table 4 presents the performance of five models: Random Forest, Logistic Regression, Support Vector Machine, Multilayer Perceptron, and K-Nearest Neighbor based on different evaluation metrics. The table reports the accuracy, precision, recall, and F1-score of each model. Among all models, Multilayer Perceptron outperformed with the highest accuracy of 0.85. Furthermore, the model yielded the highest precision of 0.81, recall of 0.83, and F1-score of 0.82. In contrast, Logistic Regression had the lowest performance, with an accuracy score of 0.75 and an F1-score of 0.70."
375,"caption: Model performances based on evaluation metricstable: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.895,0.896,0.907,0.900, Decision Tree,0.925,0.920,0.942,0.930, Gradient Boosting,0.940,0.936,0.948,0.940, Random Forest,0.946,0.947,0.951,**0.948**, Support Vector Machine,0.912,0.909,0.915,0.912","The table presents the performances of different models based on multiple evaluation metrics such as Accuracy, Precision, Recall, and F1 Score. The models included in the table are Logistic Regression, Decision Tree, Gradient Boosting, Random Forest, and Support Vector Machine. Interestingly, the Random Forest model shows the highest F1 Score of **0.948**, which is closely followed by the Gradient Boosting model that achieved an F1 Score of 0.940. The table illustrates that the Random Forest model provides the highest overall model performance compared to the other models, based on the evaluation metrics presented."
376,"caption: Performance comparison of different classification models on the test dataset using various metrics.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.82,0.85,0.77,0.80, KNN,0.76,0.78,0.66,0.70, Naive Bayes,0.81,0.86,0.75,0.80, Decision Tree,0.77,0.79,0.70,0.73, Random Forest,0.89,0.90,0.84,0.86, XGBoost,0.91,0.91,0.87,0.89","The table presents the performance comparison of six classification models on the test dataset using different evaluation matrices, including accuracy, precision, recall, and F1-score. The Random Forest model attained the highest accuracy among all with 0.89. The XGBoost model showed the best results in terms of Precision (0.91) and Recall (0.87), with an F1-score of 0.89. Interestingly, the SVM model achieved high precision (0.85) and better recall (0.77), with an F1-score of 0.80. Nonetheless, all models performed remarkably well in classifying the test dataset into the desired classes."
377,"caption: Performance comparison of five different models using multiple evaluation metrics.table: Model,Accuracy,F1-score,AUC-ROC,PR-AUC, Model 1,0.85,0.84,0.96,0.82, Model 2,0.80,0.78,0.91,0.73, Model 3,0.87,0.84,0.94,0.79, Model 4,0.92,0.90,0.98,0.87, Model 5,0.82,0.81,0.93,0.76","The table displays the performance comparison of five different models using multiple evaluation metrics, namely Accuracy, F1-score, AUC-ROC, and PR-AUC. Model 4 shows the highest performance results across all the evaluation metrics, with the highest scores of Accuracy (0.92), F1-score (0.90), AUC-ROC (0.98), and PR-AUC (0.87). In contrast, Model 2 exhibits the lowest scores across all the evaluation metrics, where the scores of Accuracy, F1-score, AUC-ROC, and PR-AUC are 0.80, 0.78, 0.91, and 0.73, respectively. From the table, it seems Model 1, Model 3, and Model 5 perform moderately well compared to the other models, each having their strengths and weaknesses depending on the evaluation metric."
378,"caption: Table 4: Performance measures for various models using different evaluation metrics.table: Model Name,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.83,0.89,0.81,0.84, K-Nearest Neighbor,0.79,0.74,0.82,0.78, Decision Tree,0.82,0.84,0.80,0.82, Support Vector Machine,0.85,0.88,0.83,0.85, Naive Bayes,0.75,0.92,0.64,0.73","Table 4 presents a comparison of various models' performance using different evaluation metrics, such as Accuracy, Precision, Recall, and F1-score. Five different models, including Logistic Regression, K-Nearest Neighbor, Decision Tree, Support Vector Machine, and Naive Bayes, were evaluated based on their classification accuracy on a given dataset. Notably, the Support Vector Machine model was found to have the highest accuracy (0.85) of all the models. However, the Naive Bayes model performed well in Precision (0.92), while K-Nearest Neighbor performed excellent in Recall (0.82). This analysis demonstrates that different models can show superiority in different evaluation metrics and highlights the importance of carefully choosing the appropriate evaluation metric based on the application requirements."
379,"caption: Comparison of different models' performance based on multiple evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.82,0.82,0.83,0.81, Random Forest,0.85,0.85,0.86,0.84, Support Vector Machine,0.81,0.80,0.82,0.79, K-Nearest Neighbors,0.80,0.80,0.80,0.80, Decision Tree,0.77,0.77,0.78,0.76","The table compares the performance of different machine learning models. The models' performance is evaluated using multiple evaluation metrics, such as accuracy, F1-Score, Precision, and Recall. The table shows Logistic Regression, Random Forest, Support Vector Machine, K-Nearest Neighbors, and Decision Tree models' performance on the given dataset. Overall, the Random Forest model shows the best performance on all the evaluation metrics with an accuracy of 0.85, F1-Score of 0.85, Precision of 0.86, and Recall of 0.84. The Logistic Regression model shows a close performance with an accuracy of 0.82, F1-Score of 0.82, Precision of 0.83, and Recall of 0.81. Furthermore, the table highlights that the Decision Tree model has a relatively lower performance as compared to other models."
380,"caption: Comparison of multiple models based on different evaluation metricstable: Metric,MLP,RNN,CNN,ResNet, :-:,:-:,:-:,:-:,:-:, Accuracy,0.80,0.77,0.85,0.92, Precision,0.79,0.72,0.87,0.91, Recall,0.82,0.75,0.84,0.93, F1-score,0.80,0.73,0.85,0.92","The table presents a comparison of multiple models' performance based on different evaluation metrics: accuracy, precision, recall, and F1-score. Four models, MLP, RNN, CNN, and ResNet, were evaluated on a specific task, and their performance is shown in the table. Interestingly, ResNet achieved the best performance in all the metrics with the highest accuracy of 0.92, precision of 0.91, recall of 0.93, and F1-score of 0.92. The MLP model achieved the lowest precision (0.79), while RNN achieved the lowest recall (0.75). Overall, the table highlights the variations in model performance on different metrics and the importance of selecting the right model for a specific task."
381,"caption: Table 4: Model performance based on accuracy, precision, and recall using different machine learning models.table: Model,Accuracy,Precision,Recall, Logistic regression,0.85,0.88,0.82, SVM,0.88,0.90,0.84, Decision tree,0.78,0.72,0.81, Random forest,0.91,0.94,0.89, XGBoost,0.89,0.92,0.86","Table 4 displays the performance of five different machine learning models based on three evaluation metrics: accuracy, precision, and recall. The models included in this table are logistic regression, SVM, decision tree, random forest, and XGBoost. Among all models, the random forest shows the highest accuracy and recall of 0.91 and 0.89, respectively. Additionally, the random forest also shows the highest precision of 0.94. Meanwhile, the SVM model had the second-highest performance in all three evaluation metrics with accuracy, precision, and recall scores of 0.88, 0.90, and 0.84, respectively. Conversely, the decision tree model appears to have the lowest performance with the lowest accuracy and precision scores of 0.78 and 0.72."
382,"caption: Table 4: Evaluation metrics of different modelstable: Model,Accuracy,F1-Score,Precision,Recall,ROC-AUC,Log loss, LR,0.94,0.93,0.92,0.95,0.91,0.16, SVM,0.93,0.92,0.91,0.93,0.90,0.18, GB,0.95,0.95,0.94,0.96,0.93,0.13, RF,0.96,0.96,0.95,0.97,0.94,0.12, NN,0.94,0.93,0.93,0.94,0.93,0.15","Table 4 presents a comparison of five different models based on multiple evaluation metrics. The models include Logistic Regression (LR), Support Vector Machine (SVM), Gradient Boosting (GB), Random Forest (RF), and Neural Network (NN). The evaluation metrics used to compare the models are Accuracy, F1-Score, Precision, Recall, ROC-AUC, and Log loss. From the table, it is observed that the Random Forest model performed the best overall, obtaining the highest scores for accuracy (0.96), F1-Score (0.96), Precision (0.95), Recall (0.97), and ROC-AUC (0.94). The Neural Network model achieved the highest score for Log loss (0.15), while the Gradient Boosting model also performed well across all evaluation metrics."
383,"caption: Table 4. Comparison of different models based on multiple evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Model A,0.87,0.88,0.86,0.90, Model B,0.83,0.87,0.85,0.89, Model C,0.88,0.89,0.87,0.89, Model D,0.82,0.83,0.84,0.81, Model E,0.89,0.90,0.91,0.88, Model F,0.84,0.85,0.83,0.87","Table 4 compares six different models based on their accuracy, F1 score, precision, and recall. Model E achieves the highest accuracy, F1 score, precision, and recall with values of 0.89, 0.90, 0.91, and 0.88, respectively. The other models' performance metrics are relatively close to each other, with minor differences in each evaluation metric. However, Model D shows the lowest accuracy and recall with values of 0.82 and 0.81, respectively. Finally, despite being the second-lowest in ranking, Model B scores better in F1-score, precision, and recall than Models A and F, with an accuracy score of 0.83."
384,"caption: Table 4: Model Comparison Based on Different Evaluation Metrics.table: Model Name,Accuracy,F1 Score,Precision Score,Recall Score, SVM,0.875,0.844,0.874,0.818, KNN,0.779,0.724,0.688,0.764, Logistic Regression,0.822,0.783,0.837,0.743, Random Forest,0.902,0.897,0.923,0.873, Gradient Boosting,0.899,0.895,0.917,0.874","Table 4 illustrates the performance evaluation of different machine learning models based on their accuracy, F1-score, precision score, and recall score. The models included in the table are SVM, KNN, Logistic Regression, Random Forest, and Gradient Boosting. The table shows that Random Forest achieved the highest accuracy rate of 0.902, and its F1-score of 0.897 and recall score of 0.873 are among the highest as well. Gradient Boosting had a similar performance with a slightly lower accuracy rate of 0.899. SVM had the highest precision score of 0.874, while KNN had the lowest accuracy rate of 0.779 and the lowest recall score of 0.764. Logistic Regression performed relatively well with an accuracy rate of 0.822 and an F1-score of 0.783."
385,"caption: Performance comparison of various models based on different evaluation metrics.table: Model,Precision,Recall,F1-Score,ROC-AUC, Model 1,0.80,0.75,0.77,0.82, Model 2,0.78,0.81,0.79,0.84, Model 3,0.79,0.88,0.83,0.77, Model 4,0.75,0.72,0.73,0.66","The table presents the performance comparison of four different models based on multiple evaluation metrics. The evaluation metrics used in this table are precision, recall, F1-score, and ROC-AUC. Model 2 shows the best ROC-AUC result of 0.84, while Model 1 has the highest precision score of 0.80. Model 3 achieved the highest recall score of 0.88, and it also has the best F1-score, which is 0.83. Interestingly, model 4 shows the lowest performance results for all evaluation metrics. Overall, the table demonstrates that model performance differs based on the evaluation metric used."
386,"caption: Model performance comparison based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score,ROC AUC, Decision Tree,0.92,0.93,0.96,0.90,0.92, Logistic Regression,0.88,0.85,0.95,0.89,0.90, SVM,0.93,0.94,0.93,0.93,0.91, Random Forest,0.95,0.96,0.94,0.95,0.98, Naive Bayes,0.85,0.86,0.89,0.85,0.83","Table presents the accuracy, precision, recall, F1 score, and ROC AUC values for the five different models, including Decision Tree, Logistic Regression, SVM, Random Forest, and Naive Bayes. Notably, the Random Forest model outperformed all the models in all evaluation metrics, recording the highest accuracy, precision, recall, F1 score, and ROC AUC with 0.95, 0.96, 0.94, 0.95, and 0.98, respectively. Interestingly, the SVM model demonstrates the best precision score of 0.94, while the Naive Bayes model has the lowest performance in all evaluation metrics. These results recommend Random Forest as the best performing model, while users should avoid employing Naive Bayes for such data."
387,"caption: Comparison of different classifiers based on accuracy, F1 score, precision, and recall metrics applied to a text classification task.table: Model,Accuracy,F1 score,Precision,Recall, SVM-Linear,0.917,0.92,0.92,0.92, Decision Tree,0.865,0.86,0.84,0.87, Random Forest,0.921,0.93,0.92,0.94, Naïve Bayes,0.884,0.90,0.88,0.92, k-NN (k=3),0.848,0.85,0.81,0.89, XGBoost (learning rate=0.1),0.906,0.92,0.91,0.92, AdaBoost,0.898,0.90,0.87,0.93","Table presents a comparison of different classifiers' performance metrics based on accuracy, F1 score, precision, and recall for a text classification task. The models tested were SVM-Linear, Decision Tree, Random Forest, Naïve Bayes, K-NN (k=3), XGBoost (learning rate=0.1), and AdaBoost. The results show that Random Forest had the highest accuracy score of 0.921, followed closely by SVM-Linear with 0.917 accuracy, while k-NN (k=3) had the lowest accuracy of 0.848. For the F1 score metric, Random Forest had the highest score of 0.93, while Decision Tree had the lowest score of 0.86. Additionally, Random Forest, SVM-Linear, XGBoost, and AdaBoost models performed similarly well across different metrics. In contrast, the Naïve Bayes model had a relatively lower recall score compared to others, while k-NN (k=3) had significantly lower precision."
388,"caption: Model evaluation results based on different classification models.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.83,0.88,0.76,0.81, RF,0.85,0.87,0.81,0.84, LR,0.78,0.83,0.67,0.74, kNN,0.68,0.79,0.52,0.63","The table above summarizes the performance evaluation of four different classification models, including SVM, RF, LR, and kNN, measured based on four evaluation metrics, accuracy, precision, recall, and F1-score. The highest accuracy was achieved by RF with a score of 0.85, while SVM and LR scored 0.83 and 0.78, respectively, and kNN was the lowest with 0.68. Similarly, RF produced the highest precision score of 0.87, while LR achieved the highest recall score of 0.67. More interestingly, RF also yielded the highest F1-score of 0.84, while LR and SVM achieved F1-scores of 0.74 and 0.81, respectively. Meanwhile, kNN has the lowest scores for all performance measures. The results demonstrate that RF performs the best among the tested models based on the given dataset and evaluation metrics."
389,"caption: Table 4: Model Performance based on Multiple Evaluation Metricstable: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.90,0.87,0.84,0.91, Random Forest,0.92,0.90,0.89,0.92, SVM,0.89,0.85,0.83,0.88, Naive Bayes,0.87,0.83,0.81,0.85, Neural Network,0.93,0.91,0.91,0.91","Table 4 above shows a performance comparison of different models based on multiple evaluation metrics, including accuracy, F1-score, precision, and recall. The table includes Logistic Regression, Random Forest, SVM, Naive Bayes, and Neural Network models. The best performing model across all evaluation metrics is the Neural Network model, achieving 0.93 accuracy, 0.91 F1-score, 0.91 precision, and 0.91 recall. However, the Logistic Regression model follows closely, having an accuracy of 0.90 and F1-score of 0.87. The Random Forest model also performs quite well, achieving an accuracy of 0.92."
390,"caption: The performance of five different models based on multiple evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Model 1,0.95,0.96,0.93,0.99, Model 2,0.91,0.93,0.87,0.99, Model 3,0.96,0.97,0.93,1.00, Model 4,0.87,0.89,0.80,0.99, Model 5,0.93,0.95,0.90,0.99","Table 4 presents the performance of five different models based on multiple evaluation metrics, including Accuracy, F1 Score, Precision, and Recall. The highest Accuracy score of 0.96 was achieved by Model 3, followed closely by Model 1, with an accuracy score of 0.95. However, Model 2 had the lowest accuracy score of 0.91. Regarding F1 score, Model 3 had the highest score of 0.97, followed by Models 1, 5, and 2, respectively. Additionally, Model 4 showed the lowest F1 score, with a score of 0.89. For Precision, Model 1 scored the highest with a score of 0.93, while Model 4 had the lowest score with a score of 0.80. Finally, for Recall, all models scored above 0.99, except for Model 5, which scored 0.99. Overall, Model 3 had the best performance based on all the evaluation metrics."
391,"caption: Performance comparison of different machine learning models using evaluation metrics.table: Model,Accuracy,Sensitivity,Specificity,F1 Score, Logistic Regression,0.85,0.76,0.92,0.80, Support Vector Machine,0.79,0.70,0.84,0.66, Random Forest,0.92,0.86,0.95,0.88, Gradient Boosting,0.91,0.82,0.98,0.85, K-Nearest Neighbour,0.80,0.61,0.90,0.58","The above table compares the performance of various machine learning models using different evaluation metrics, namely Accuracy, Sensitivity, Specificity, and F1 Score. The models considered are Logistic Regression, Support Vector Machine, Random Forest, Gradient Boosting, and K-Nearest Neighbour. The Random Forest model shows superior accuracy, achieving the highest score of 0.92, with high sensitivity of 0.86 and specificity of 0.95; it also demonstrates the highest F1 Score of 0.88. However, Gradient Boosting model shows the highest specificity of 0.98, while Logistic Regression demonstrates the highest sensitivity of 0.76. The K-Nearest Neighbour model shows the lowest scores in almost all metrics, except specificity."
392,"caption: Classification performance of different models on the test dataset.table: Model,Precision,Recall,F1-score,Accuracy, SVM,0.80,0.68,0.73,0.78, KNN,0.72,0.65,0.67,0.73, RF,0.88,0.80,0.83,0.87, MLP,0.83,0.74,0.76,0.81, XGBoost,0.90,0.85,0.87,0.89","The table above shows the classification performances of five models, SVM, KNN, RF, MLP, and XGBoost, on the test dataset. The models' performances are evaluated using four different metrics: Precision, Recall, F1-score, and Accuracy. The XGBoost model achieved the highest overall performance score with an accuracy of 0.89. RF model shows the best precision and recall scores of 0.88 and 0.80, respectively. Surprisingly, the KNN model achieved a better F1-score of 0.67 compared to MLP and SVM models, despite having lower precision and recall scores."
393,"caption: Table 4: Comparison of different models' classification performance based on accuracy, F1-Score, precision, and recall.table: Model,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.87,0.78,0.84,0.73, Decision Tree,0.89,0.79,0.81,0.78, Random Forest,0.91,0.82,0.87,0.77, XGBoost,0.92,0.84,0.85,0.83, SVM,0.86,0.76,0.82,0.71",
394,"caption: Model performances based on multiple evaluation metricstable: Model,F1-score,Accuracy (%),Precision,Recall, SVM,0.82,85.0,0.84,0.8, MLP,0.81,84.0,0.85,0.77, KNN,0.78,80.0,0.79,0.77, Naive Bayes,0.77,79.0,0.72,0.82, Decision tree,0.74,75.0,0.85,0.65","The table compares different models' performances based on multiple evaluation metrics, including F1-score, accuracy, precision, and recall. The models include SVM, MLP, KNN, Naive Bayes, and Decision tree. The SVM model showed the highest F1-score of 0.82 and accuracy of 85.0%, indicating that it has the best overall performance in the set. However, it was not the most precise model, as the Decision tree outperformed all other models in terms of precision. Interestingly, the Naive Bayes model achieved the highest recall score compared to the other models, indicating that it performed well in identifying true positives."
395,"caption: Table 4: Model performances based on multiple evaluation metrics.table: Model,F1-score,ROC-AUC,PR-AUC, Logistic reg.,0.89,0.95,0.91, Random forest,0.90,0.91,0.93, Decision tree,0.84,0.89,0.87, SVM (linear),0.88,0.92,0.90, KNN,0.79,0.85,0.81","Table 4 presents the F1-score, ROC-AUC, and PR-AUC performances of different models. The table includes Logistic Regression, Random Forest, Decision Tree, SVM (linear), and KNN models. Notably, all models were evaluated using the same dataset. The Random Forest model achieved the highest PR-AUC score of 0.93, while the Decision tree model obtained the lowest score of 0.87. However, SVM (linear) and Logistic regression models obtained approximatively the same scores in all metrics. Additionally, the KNN model had the lowest F1-score of 0.79, whereas the Random Forest model had the highest F1-score of 0.90. Overall, the table indicates that different models can perform differently based on the evaluation metric used."
396,"caption: Model performances of different classifiers based on evaluation metrics.table: Model,Accuracy,F1 score,Precision,Recall, SVM,0.82,0.84,0.87,0.82, MLP,0.79,0.81,0.85,0.79, GNB,0.61,0.66,0.75,0.61, KNN,0.75,0.77,0.89,0.75, RFC,0.85,0.86,0.89,0.85","Table presents five different classifiers' performances in terms of accuracy, F1 score, precision, and recall. The SVM model obtained the highest accuracy (0.82), followed by RFC (0.85), KNN (0.75), MLP (0.79), and GNB (0.61). The RFC model produced the best F1 score (0.86), followed by SVM (0.84), MLP (0.81), KNN (0.77), and GNB (0.66) models. The precision value ranges from 0.75 to 0.89, where GNB had the lowest and RFC had the highest value. Regarding recall, all models exhibit their highest recall value at a similar level to the accuracy metric, except for GNB model, which had the lowest recall value of 0.61."
397,"caption: Model Comparison for Different Metrics.table: Approach,Metric 1,Metric 2,Metric 3, Model 1,0.841,0.736,0.912, Model 2,0.820,0.675,0.900, Model 3,0.854,0.742,0.919, Model 4,0.811,0.609,0.888, Model 5,0.865,0.778,0.925, Model 6,0.849,0.706,0.910","Table presents the performance of six different models based on three evaluation metrics. The metrics include Metric 1, Metric 2, and Metric 3. The approach column demonstrates the name of the model. Interesting observations include Model 5 obtaining top scores for all metrics: 0.865 for Metric 1, 0.778 for Metric 2, and 0.925 for Metric 3. Nevertheless, Model 4 performed the worst in all metrics, obtaining 0.811, 0.609, and 0.888 for Metric 1, Metric 2, and Metric 3, respectively. This variation in the performance of different models can be helpful for researchers in choosing the appropriate model for their needs."
398,"caption: Performance Metrics of Different Model Approachestable: Model Name,Accuracy Score,F1 Score,Precision Score,Recall Score, Model 1,0.91,0.89,0.92,0.87, Model 2,0.93,0.92,0.91,0.94, Model 3,0.86,0.83,0.87,0.79, Model 4,0.89,0.87,0.85,0.89, Model 5,0.92,0.91,0.93,0.89","The table above displays five different models, each evaluated on four distinct performance metrics; Accuracy Score, F1 Score, Precision Score, and Recall Score. Among the models, Model 2 achieved the highest Accuracy Score (0.93) and F1 Score (0.92) while Model 5 had the highest Precision Score of 0.93. On the other hand, Model 3 had the lowest Accuracy Score of 0.86, while Model 5 had the highest Recall Score of 0.89."
399,"caption: Model performance comparison with different evaluation metricstable: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.78,0.76,0.79,0.77, Decision Tree,0.72,0.68,0.78,0.73, Random Forest,0.81,0.80,0.80,0.79, XGBoost,0.82,0.81,0.81,0.80, Multilayer Perceptron,0.75,0.75,0.75,0.74","The presented table shows the performance of five different models using the accuracy, precision, recall, and F1 score metrics. The models are Logistic Regression, Decision Tree, Random Forest, XGBoost, and Multilayer Perceptron. The table depicts that XGBoost and Random Forest models have the highest accuracy score with 0.82 and 0.81, respectively. However, the Random Forest model has the highest precision and recall scores of 0.80. Additionally, the table shows that the logistic regression model has the highest F1 score of 0.77. Overall, the table provides a comparison of the strengths and weaknesses of different models and evaluation metrics used in this study."
400,"caption: Table 1: Comparison of Different Machine Learning Models' Performance Evaluation on the Test Set.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.902,0.892,0.934,0.853, KNN,0.849,0.825,0.854,0.800, Naive Bayes,0.810,0.793,0.759,0.831, Decision Trees,0.867,0.850,0.824,0.878, Random Forests,0.919,0.916,0.927,0.906","Table 1 shows a comparison of different machine learning models: SVM, KNN, Naive Bayes, Decision Trees, and Random Forests, based on their performance evaluation on the test set. The models were evaluated using multiple metrics like accuracy, F1-Score, precision, and recall. Interestingly, the Random Forests model outperformed other models with the highest accuracy of 0.919, the highest F1-Score of 0.916, the highest precision of 0.927, the second-highest recall of 0.906. The SVM model achieved the highest recall (0.853), whereas the Naive Bayes model had the lowest accuracy (0.810) and F1-Score (0.793)."
401,"caption: Table 4: Performance evaluation of different models using various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score,AUC, Model A,0.85,0.82,0.78,0.79,0.91, Model B,0.78,0.75,0.64,0.68,0.83, Model C,0.92,0.90,0.85,0.87,0.94, Model D,0.86,0.83,0.81,0.80,0.90","Table 4 presents a performance evaluation of four models using different evaluation metrics, namely accuracy, precision, recall, F1-score, and AUC. The four models are Model A, Model B, Model C, and Model D. The table shows that Model C achieved the highest overall performance with an accuracy of 0.92, precision of 0.90, recall of 0.85, F1-score of 0.87, and AUC of 0.94. Model B achieved the lowest performance with an accuracy of 0.78, precision of 0.75, recall of 0.64, F1-score of 0.68, and AUC of 0.83. Model A and Model D performed moderately with an accuracy of 0.85 and 0.86, respectively."
402,"caption: Table 4: Model performance based on different evaluation metrics.table: Model Name,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.88,0.88,0.90,0.86, Decision Tree,0.84,0.83,0.86,0.81, Random Forest,0.92,0.92,0.93,0.91, Support Vector Machine,0.85,0.85,0.87,0.82, Multilayer Perceptron,0.90,0.90,0.92,0.88","Table 4 compares the performances of five different models - Logistic Regression, Decision Tree, Random Forest, Support Vector Machine, and Multilayer Perceptron. The evaluation metrics used in the table are Accuracy, F1 Score, Precision, and Recall. The Random Forest model demonstrated the highest accuracy of 0.92, and F1 score of 0.92. Furthermore, the Multilayer Perceptron showed the highest precision of 0.92, whereas the Logistic Regression model had the highest recall of 0.86. The table demonstrates that Random Forest is the best performing model across all metrics, while Decision Tree shows the worst performance amongst the models."
403,"caption: Comparison of Different Models' Performance Using Multiple Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1-Score,AUC, Model A,0.89,0.88,0.91,0.89,0.96, Model B,0.76,0.67,0.87,0.76,0.85, Model C,0.92,0.92,0.92,0.92,0.98, Model D,0.85,0.82,0.87,0.85,0.90, Model E,0.81,0.75,0.86,0.80,0.89","The table above shows a comparison of different models' performance using multiple evaluation metrics, including Accuracy, Precision, Recall, F1-Score, and AUC. Five different models (Model A, Model B, Model C, Model D, and Model E) were trained and evaluated using the same dataset. Model C achieved the highest scores in all evaluation criteria, including Accuracy (0.92), Precision (0.92), Recall (0.92), F1-Score (0.92), and AUC (0.98). Model A also showed great performance with Accuracy (0.89), F1-Score (0.89), and AUC (0.96) scores close to Model C. Model B had the lowest performance with Accuracy (0.76), Precision (0.67), F1-Score (0.76), and AUC (0.85) scores significantly lower than the other models."
404,"caption: Model performance using multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, LR,0.72,0.71,0.74,0.72, SVM,0.68,0.67,0.69,0.68, RF,0.77,0.76,0.80,0.78, XGB,0.79,0.78,0.81,0.79, LSTM,0.82,0.81,0.84,0.82","The table showcases the performance of five models (LR, SVM, RF, XGB, LSTM) based on multiple evaluation metrics such as Accuracy, Precision, Recall, and F1-Score. The LSTM shows the best overall performance with 0.82 Accuracy, 0.81 Precision, 0.84 Recall, and 0.82 F1-Score. The RF and XGB models show similar levels of performance, with the highest Recall score, indicating the most accurate positive prediction out of the total positive samples. However, the RF model outperforms XGB in terms of Precision, which measures how many positive predictions were correct. The LR and SVM models show the lowest performance across all evaluation metrics."
405,"caption: Comparison of classification models using precision, recall, and F1 score.table: Model,Precision,Recall,F1 Score, Random Forest,0.89,0.87,0.88, XGBoost,0.91,0.89,0.90, SVM,0.83,0.92,0.87, Logistic Regression,0.91,0.88,0.89, KNN,0.85,0.85,0.85",
406,"caption: Table 4: Model performance based on different evaluation metricstable: Model,Accuracy,F1-score,Precision,Recall,AUC, SVM,0.95,0.93,0.93,0.92,0.98, KNN,0.85,0.81,0.84,0.77,0.89, Logistic Regression,0.91,0.88,0.88,0.87,0.94, Decision Tree,0.79,0.76,0.78,0.74,0.83, Random Forest,0.93,0.91,0.92,0.90,0.95","Table 4 presents the performance results of SVM, KNN, Logistic Regression, Decision Tree, and Random Forest models based on different evaluation metrics, including Accuracy, F1-score, Precision, Recall, and AUC. Notably, the table shows the SVM model's best performance with the highest AUC score of 0.98 and Accuracy score of 0.95. On the other hand, the Decision Tree model had the lowest performance overall, with an Accuracy score of 0.79, F1-score of 0.76, Precision score of 0.78, Recall score of 0.74, and an AUC score of 0.83. Overall, the table provides valuable insights for selecting the most appropriate model based on the desired evaluation metrics."
407,"caption: Table 4: Performance results of different models based on various evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, Model A,0.85,0.80,0.82,0.78, Model B,0.86,0.82,0.85,0.80, Model C,0.87,0.83,0.86,0.81, Model D,0.84,0.79,0.80,0.78","Table 4 displays the performance results of four different models based on various evaluation metrics, including accuracy, F1-score, precision, and recall. Model A shows the lowest performance, with an accuracy of 0.85, F1-score of 0.80, precision of 0.82, and recall of 0.78. Model B shows slightly better performance with an accuracy of 0.86, F1-score of 0.82, precision of 0.85, and recall of 0.80. Model C has the highest performance results with an accuracy of 0.87, F1-score of 0.83, precision of 0.86, and recall of 0.81. Interestingly, Model D shows similar performance to Model A, with an accuracy of 0.84, F1-score of 0.79, precision of 0.80, and recall of 0.78."
408,"caption: Performance evaluation results of different modelstable: Model,Accuracy,F1-score,Sensitivity,Specificity, Model A,0.85,0.87,0.89,0.81, Model B,0.73,0.76,0.80,0.66, Model C,0.90,0.92,0.91,0.90, Model D,0.78,0.81,0.87,0.70, Model E,0.92,0.93,0.93,0.92","Table records the performance evaluation results of five different models: Model A, Model B, Model C, Model D, and Model E based on multiple evaluation metrics, including Accuracy, F1-score, Sensitivity, and Specificity. Model A shows the highest Accuracy of 0.85, whereas Model E has the highest F1-score, Sensitivity, and Specificity of 0.93, 0.93, and 0.92, respectively. Model C also shows comparable performance on all metrics with Accuracy, F1-score, Sensitivity, and Specificity of 0.90, 0.92, 0.91, and 0.90. On the other hand, Model B shows relatively lower performance across all metrics. The table suggests Model E may be the best-performing model as it achieves consistently robust results on multiple metrics."
409,"caption: Model Performances using different evaluation metrics.table: Model,Accuracy,F1-Score,G-score,Precision,Recall, Decision Tree,0.76,0.75,0.66,0.77,0.74, Random Forest,0.80,0.77,0.75,0.74,0.81, Logistic Regression,0.77,0.76,0.68,0.80,0.74, Naive Bayes,0.71,0.68,0.62,0.73,0.65","The table displays the performance of multiple classification models using different evaluation metrics. The models used are Decision Tree, Random Forest, Logistic Regression, and Naive Bayes, and the evaluation metrics are Accuracy, F1-Score, G-score, Precision, and Recall. The Random Forest model performs the best with an accuracy of 0.80, F1-Score of 0.77, G-Score of 0.75, Precision of 0.74, and Recall of 0.81. The Decision Tree model achieved an accuracy of 0.76 and F1-Score of 0.75. On the other hand, Naive Bayes model produced the lowest accuracy, F1-Score, G-score, and Recall with 0.71, 0.68, 0.62, and 0.65, respectively. Logistic Regression achieved 0.77 accuracy, the highest precision of 0.80, and Recall of 0.74."
410,"caption: Performance comparison of different models on different evaluation metrics.table: Model,F1 Score,Accuracy,Precision,Recall, Model 1,0.80,0.85,0.85,0.75, Model 2,0.82,0.87,0.80,0.85, Model 3,0.78,0.83,0.82,0.75, Model 4,0.84,0.89,0.86,0.82, Model 5,0.81,0.86,0.84,0.78","The table presents a comparison of multiple models based on four different evaluation metrics such as F1 score, accuracy, precision, and recall. Each model shows varying performance in different evaluation metrics. Notably, Model 4 shows the best F1 score of 0.84, accuracy of 0.89, precision of 0.86, and recall of 0.82. Whereas Model 3 shows the least performance on all evaluation metrics, scoring only 0.78 F1 score, 0.83 accuracy, 0.82 precision, and 0.75 recall. Overall, the table helps evaluate different models' performances based on distinct evaluation metrics for better comparison and selection of the best possible model."
411,"caption: The evaluation metrics and performance results from four different models.table: Metric,Model 1,Model 2,Model 3,Model 4, Accuracy,0.85,0.84,0.89,0.81, F1-Score,0.80,0.82,0.88,0.77, Precision,0.90,0.80,0.92,0.76, Recall,0.75,0.90,0.84,0.81","The table displays the performance of four different models evaluated using various metrics. The models are identified as Model 1, Model 2, Model 3, and Model 4. The metrics used to evaluate the models in the table include Accuracy, F1-Score, Precision, and Recall. The highest performing model varies for each metric; Model 3 shows the highest accuracy score of 0.89, Model 3 performs the best in terms of F1-Score with a score of 0.88, Model 3 has the highest precision score of 0.92, and Model 2 and Model 3 have the same highest recall score of 0.90. Overall, Model 3 appears to be the best performer across the different metrics."
412,"caption: Table 4. Model performances based on different evaluation metricstable: Model,Accuracy,F1-Score,Sensitivity,Specificity, Logistic Regression,0.72,0.71,0.70,0.74, SVM,0.65,0.64,0.67,0.63, Decision Tree,0.67,0.66,0.63,0.70, Random Forest,0.82,0.80,0.81,0.83","Table 4 presents the results of four different models' performance metrics, including logistic regression, support vector machine (SVM), decision tree, and random forest. The evaluation metrics include accuracy, F1-score, sensitivity, and specificity. The logistic regression model performed the best in terms of accuracy and the F1-score, with a score of 0.72 and 0.71, respectively. The random forest model exhibited the highest score in all four metrics, at 0.82 for accuracy, 0.80 for F1-score, 0.81 for sensitivity, and 0.83 for specificity. Overall, these results showed that the random forest model outperformed other models in this study in all the evaluation metrics."
413,"caption: Performance comparison of various classification models with evaluation metrics (F1-Score, Accuracy, Precision, and Recall).table: Model,F1-Score,Accuracy,Precision,Recall, Random Forest,0.87,0.88,0.88,0.87, XGBoost,0.85,0.87,0.87,0.86, Logistic Regression,0.84,0.85,0.85,0.85, SVM (Linear),0.83,0.89,0.88,0.80, Decision Tree,0.75,0.76,0.76,0.75","The table compares the performance of various popular classification models based on F1-Score, Accuracy, Precision, and Recall metrics. The results demonstrate that Random Forest has the highest F1-Score, Accuracy, Precision, and Recall score of 0.87, 0.88, 0.88, and 0.87 respectively. Whereas, the Decision Tree model had the lowest score for all metrics among all models. Additionally, while SVM (Linear) achieved a high accuracy score (0.89), it had lower F1-Score and Recall scores. On the other hand, Logistic Regression and XGBoost have shown consistent performance across all evaluation metrics."
414,"caption: Performance of different classification models on class imbalanced datatable: Model,F1 score (class 0),F1 score (class 1),Accuracy,Precision,Recall, Support Vector Machine,0.75,0.83,0.80,0.76,0.83, Random Forest,0.84,0.90,0.87,0.85,0.90, Gradient Boosting,0.82,0.91,0.86,0.83,0.91, Logistic Regression,0.69,0.78,0.75,0.70,0.78","The table presents the performance comparison of four models: Support Vector Machine, Random Forest, Gradient Boosting, and Logistic Regression on class imbalanced data. The table includes evaluation metrics such as F1 score for both classes, Accuracy, Precision, and Recall. The Random Forest and Gradient Boosting models show comparable best results with the highest F1 scores of 0.84 and 0.91 for class 0 and the highest F1 scores of 0.90 and 0.91 for class 1, respectively, revealing better performance in handling the class imbalance problem. The Support Vector Machine has the lowest F1 score in both classes, whereas the Logistic Regression model performs moderately. Overall, the table demonstrates that RF and GB classifiers might be feasible models for class imbalanced problems."
415,"caption: Model performance based on different evaluation metricstable: Model,Train Accuracy,Test Accuracy,Precision,Recall,F1-score, Logistic Regression,0.67,0.65,0.63,0.65,0.62, Decision Tree,0.95,0.90,0.89,0.90,0.87, Random Forest,0.94,0.91,0.91,0.92,0.89, K-Nearest Neighbors,0.69,0.64,0.62,0.64,0.61, Support Vector Machine,0.81,0.79,0.78,0.80,0.77",
416,"caption: Table 1: Performance Metrics of Various Machine Learning Modelstable: Model,Accuracy,F1-Score,Precision,Recall, Random Forest,0.90,0.89,0.88,0.91, SVM,0.91,0.91,0.92,0.90, Logistic Reg.,0.89,0.87,0.90,0.84, XGBoost,0.93,0.93,0.93,0.93, Decision Tree,0.85,0.83,0.80,0.86, kNN,0.88,0.87,0.87,0.87",
417,"caption: Table 4: Performance comparison of different classification models using multiple evaluation metrics.table: Model,Precision,Recall,F1-Score,ROC-AUC, SVM,0.92,0.89,0.91,0.88, Naive Bayes,0.83,0.92,0.86,0.74, Random Forest,0.97,0.95,0.96,0.94, K-NN,0.85,0.88,0.86,0.78, Decision Tree,0.89,0.82,0.85,0.86, Logistic Regression,0.95,0.93,0.94,0.90","Table 4 compares various classification models' performance using different evaluation metrics. The table reveals SVM, Naive Bayes, Random Forest, K-NN, Decision Tree, and Logistic Regression models' Precision, Recall, F1-Score, and ROC-AUC. Notably, the Random Forest model achieved the highest Precision, Recall, and F1-Score, with scores of 0.97, 0.95, and 0.96, respectively. However, the Logistic Regression model outperformed the other models with the highest ROC-AUC score of 0.90. The Naive Bayes model yielded the lowest ROC-AUC score of 0.74, indicating it would perform poorly for a binary classification problem."
418,"caption: Comparison of multiple models based on accuracy, F1-score, precision, and recall.table: Model,Accuracy,F1-score,Precision,Recall, Model 1,0.92,0.89,0.91,0.88, Model 2,0.89,0.85,0.83,0.88, Model 3,0.95,0.91,0.94,0.88, Model 4,0.88,0.82,0.84,0.8, Model 5,0.96,0.92,0.95,0.91","The presented table shows the performance comparison of five different models based on evaluation metrics like accuracy, F1-score, precision, and recall. Model 3 has the highest accuracy of 0.95, whereas Model 5 has the highest F1-score of 0.92 and recall of 0.91 among all the models. On the other hand, Model 1 has obtained the highest precision score of 0.91. These results suggest that each model has different strengths and could prove useful in different scenarios. Therefore, choosing the most appropriate model would depend on the specific use case and evaluation metric requirements."
419,"caption: Table 4: Performance of Different Models on Evaluation Metrics.table: Model,Precision,Recall,F1-Score,Accuracy, Logistic Regression,0.78,0.65,0.71,0.80, Random Forest,0.85,0.82,0.83,0.87, Decision Tree,0.72,0.82,0.76,0.75, SVM,0.89,0.71,0.78,0.83","Table 4 presents the performance of different models on various evaluation metrics. The evaluation metrics include Precision, Recall, F1-Score, and Accuracy. The table compares the performance of four models, Logistic Regression, Random Forest, Decision Tree, and SVM. Based on the results presented in the table, SVM has achieved the highest Precision of 0.89, while Random Forest has the highest Recall of 0.82, followed by Decision Tree with 0.82. The F1 score was highest for Random Forest with 0.83. The highest accuracy was observed for Random Forest with 0.87. These results indicate that Random Forest performed the best across all evaluation metrics."
420,"caption: The performance of different classification models on the test data.table: Model,F1-score,Precision,Recall,Accuracy, Logistic Regression,0.89,0.91,0.87,0.91, Decision Tree,0.83,0.88,0.79,0.86, Random Forest,0.94,0.92,0.96,0.93, AdaBoost,0.91,0.89,0.93,0.90, Gradient Boosting,0.92,0.88,0.97,0.91","Table 1 demonstrates the performance of five classification models, namely Logistic Regression, Decision Tree, Random Forest, AdaBoost, and Gradient Boosting. The table shows F1-score, precision, recall, and accuracy metrics for each model. Based on the F1-score, Random Forest achieved the highest performance result of 0.94, followed by Gradient Boosting with a score of 0.92. However, Decision Tree showed the lowest F1-score of 0.83. When it comes to precision, Random Forest again showed the highest result of 0.92. In contrast, Logistic Regression demonstrated the highest recall score of 0.87. Overall, the findings could help researchers to choose the right model for the problem where F1-score, precision, recall, and accuracy are important."
421,"caption: Evaluation Metrics of Different Modelstable: Model,F1-score,Accuracy,Precision,Recall, Model_1,0.85,0.91,0.78,0.94, Model_2,0.72,0.82,0.57,0.94, Model_3,0.92,0.95,0.88,0.97, Model_4,0.65,0.83,0.52,0.87, Model_5,0.88,0.94,0.8,0.98","The table above presents the evaluation metrics of different models, including F1-score, accuracy, precision and recall. Model_1 shows the best performance for F1-score with a result of 0.85, while Model_3 had the best accuracy of 0.95. Model_5 had the highest precision of 0.8 and recall of 0.98. Notably, Model_2 had the lowest F1-score of 0.72 and Model_4 had the lowest precision of 0.52. These results highlight the importance of evaluating multiple metrics to understand the models' performance comprehensively."
422,"caption: Table 4: Model performances based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.85,0.87,0.83,0.85, KNN,0.80,0.76,0.81,0.78, Naive Bayes,0.78,0.79,0.81,0.79, Decision Tree,0.81,0.83,0.79,0.81","Table 4 presents the performances of four different models based on different evaluation metrics, including accuracy, precision, recall, and F1-score. The SVM model achieved the highest accuracy of 0.85, while the KNN had the lowest accuracy of 0.80. The Decision Tree model achieved the highest precision of 0.83, while the SVM had an accuracy of 0.87. On the other hand, the KNN model achieved the highest recall of 0.81, while the Naive Bayes scored 0.79. Lastly, the F1-score shows a close performance among the models with the Decision tree having the highest score of 0.81 and the KNN having the lowest score of 0.78."
423,"caption: Table 4: Performance Metrics comparison for different classification models.table: Model,F1 Score,Precision,Recall,Accuracy, Logistic Regression,0.76,0.79,0.74,0.82, Decision Trees,0.69,0.73,0.66,0.75, Random Forests,0.84,0.82,0.87,0.86, Gradient Boosting,0.86,0.83,0.90,0.88, SVM,0.78,0.84,0.73,0.83","Table 4 represents the comparison of different classification models' performance using different evaluation metrics. The models considered are Logistic Regression, Decision Trees, Random Forests, Gradient Boosting, and SVM. The evaluation metrics measured are F1-Score, Precision, Recall, and Accuracy. It is observed that Random Forests achieved the highest F1-Score (0.84), while Gradient Boosting achieved the best Precision (0.83), Recall (0.90), and Accuracy (0.88) out of all the models. However, SVM had the second-best Precision (0.84) and accuracy (0.83) scores, followed by Logistic Regression scoring 0.79 Precision and 0.82 accuracy. Decision Trees model has the lowest performance scores on all the metrics."
424,"caption: Comparison of different models' performances based on Pearson's R, Spearman's R, and MAE evaluation metrics.table: Models,Pearson's R,Spearman's R,MAE, Model A,0.75,0.64,24.2, Model B,0.63,0.51,29.8, Model C,0.87,0.79,18.9, Model D,0.68,0.58,27.1, Model E,0.91,0.84,15.5","The presented table contains a comparison among different models based on three evaluation metrics, Pearson's R, Spearman's R and MAE. The models, Model A, Model B, Model C, Model D, and Model E, exhibit their corresponding scores achieved by the above-mentioned metrics. The higher values of Pearson's R and Spearman's R indicate a strong positive correlation, while a smaller value of MAE indicates better performance. Interestingly, as per the evaluation metrics of Pearson's R and Spearman's R, Model E shows the highest performance with scores of 0.91 and 0.84, respectively. However, Model C exhibits the lowest MAE score of 18.9, leading us to believe that its predictions are more aligned with actual values."
425,"caption: Table 4: Comparison of different models' performance based on multiple evaluation metrics.table: Model,Precision,Recall,F1-score,Accuracy, Model A,0.84,0.85,0.84,0.85, Model B,0.76,0.77,0.75,0.78, Model C,0.80,0.65,0.72,0.79, Model D,0.92,0.88,0.90,0.91, Model E,0.70,0.82,0.76,0.72","Table 4 presents a comparison of multiple models based on four different evaluation metrics; precision, recall, F1-score, and accuracy. The table shows that Model D outperforms all others in terms of precision with a score of 0.92. Model A is the overall best-performing model in terms of recall, F1-score, and accuracy, with scores of 0.85, 0.84, and 0.85, respectively. In contrast, Model E shows the lowest performance scores with a precision of 0.70, recall of 0.82, F1-score of 0.76, and accuracy of 0.72. Overall, the table highlights the importance of using multiple evaluation metrics to evaluate a model's performance since a model that performs well in one metric may not perform as well in another."
426,"caption: Performance metrics of various machine learning models.table: Model,Precision,Recall,F1-Score,Accuracy, SVM,0.91,0.87,0.89,0.88, LR,0.88,0.91,0.89,0.87, RF,0.90,0.88,0.89,0.89, DT,0.87,0.84,0.85,0.87, NB,0.84,0.82,0.83,0.84, KNN,0.85,0.88,0.86,0.85, MLP,0.92,0.93,0.92,0.91","The table above summarizes the performance of seven machine learning models on the evaluation metrics of precision, recall, F1-score, and accuracy. The models include Support Vector Machine (SVM), Logistic Regression (LR), Random Forest (RF), Decision Tree (DT), Naive Bayes (NB), K-Nearest Neighbors (KNN), and Multi Layer Perceptron (MLP). Interestingly, MLP achieved the highest scores across all evaluation metrics with a precision of 0.92, recall of 0.93, F1-score of 0.92, and accuracy of 0.91. The SVM model had the highest precision score of 0.91, while RF had the highest recall score of 0.88. The LR model had the highest F1-score of 0.89. These results demonstrate significant performance differences among the evaluated models."
427,"caption: Table 4: Model performance comparison using different evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.85,0.83,0.80,0.87, Random Forest,0.90,0.88,0.85,0.91, Support Vector Machine,0.81,0.79,0.76,0.82, XGBoost,0.89,0.87,0.84,0.90","Table 4 presents the comparison of model performances using four different evaluation metrics: Accuracy, F1-score, Precision, and Recall. The table includes four different models: Logistic Regression, Random Forest, Support Vector Machine, and XGBoost, with their respective scores for each evaluation metric. The results show that the Random Forest model performed the best overall, achieving the highest scores in Accuracy (0.90), F1-score (0.88), Precision (0.85), and Recall (0.91). Meanwhile, the Support Vector Machine model achieved the lowest scores in all metrics. The table highlights the importance of considering multiple evaluation metrics in assessing model performance."
428,"caption: Model performance based on different evaluation metricstable: Model,Precision,Recall,F1-score,AUC,Accuracy, Random forest,0.89,0.87,0.88,0.92,0.87, Decision tree,0.80,0.81,0.79,0.85,0.78, SVM,0.86,0.88,0.86,0.92,0.86, Neural network,0.91,0.92,0.91,0.94,0.90","The table illustrates the model performances based on different evaluation metrics, including Precision, Recall, F1-score, AUC, and Accuracy. Various models were trained and tested on the same dataset, including Random Forest, Decision Tree, SVM, and Neural Network. The Neural Network model achieved the highest Precision, Recall, F1-score and AUC score of 0.91, 0.92, 0.91, and 0.94, respectively. The Random Forest model comes second with a corresponding score of 0.89, 0.87, 0.88 and 0.92, respectively, and outperformed the other two models. Interestingly, The Decision Tree model achieved the lowest performance result against all metrics."
429,"caption: The performance of different machine learning models on the binary classification task.table: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.785,0.812,0.774,0.853, Random Forest,0.814,0.817,0.805,0.830, Gradient Boosting,0.824,0.824,0.820,0.834, Extreme Gradient Boosting,0.831,0.837,0.824,0.852, Support Vector Machines,0.798,0.802,0.793,0.810","Table presents the performance of various machine learning models on binary classification tasks using accuracy, F1 score, precision, and recall metrics. The models include Logistic Regression, Random Forest, Gradient Boosting, Extreme Gradient Boosting, and Support Vector Machines. Extreme Gradient Boosting shows the best results with an accuracy score of 0.831, F1 score of 0.837, precision score of 0.824, and recall score of 0.852. Notably, Gradient Boosting and Random Forest also displayed competitive performances with accuracy and F1 score above 0.814. Logistic Regression and Support Vector Machines fall behind with the accuracy score below 0.798."
430,"caption: Table 4. Model comparison for different evaluation metricstable: Model Name,Precision,Recall,F1-score,Accuracy, Random Forest,0.96,0.89,0.92,0.91, Decision Tree,0.91,0.91,0.89,0.87, KNN,0.87,0.89,0.85,0.83, SVM,0.95,0.84,0.89,0.90, Naive Bayes,0.82,0.94,0.84,0.80","This table shows the performance metrics of different models in terms of precision, recall, F1-score, and accuracy. The models include Random Forest, Decision Tree, KNN, SVM, and Naive Bayes. Clearly, the Random Forest model has the best precision of 0.96 and the highest accuracy of 0.91. The Naive Bayes model has the best recall of 0.94 but the lowest accuracy of 0.80. Interestingly, the SVM model had the second-highest precision of 0.95 and overall performed well in other metrics. Overall, the table indicates that the Random Forest model is the best one for the problem at hand based on the chosen evaluation metrics."
431,"caption: Table 4: Model Performance across Different Evaluation Metricstable: Model,Accuracy (%),F1 Score,Precision,Recall,Specificity, Model 1,87.5,0.89,0.91,0.89,0.87, Model 2,84.6,0.84,0.86,0.84,0.83, Model 3,91.2,0.92,0.93,0.92,0.90, Model 4,82.3,0.80,0.83,0.80,0.81, Model 5,86.1,0.87,0.89,0.87,0.85","Table 4 compares five different models' evaluation metrics, including accuracy (%), F1 score, precision, recall, and specificity. Model 3 shows the highest accuracy of 91.2%, outperforming the other models. Model 3 also achieves the highest F1 score of 0.92, precision of 0.93, and recall of 0.92. In contrast, Model 4 has the lowest accuracy, F1 score, and recall of 82.3%, 0.80, and 0.80, respectively. Interestingly, Model 2 has the lowest accuracy and F1 score, but the second-best precision, recall, and specificity among all models. Overall, the findings indicate that Model 3 performs the best, while Model 4 has the weakest performance among the five models."
432,"caption: Table 4: Comparison of classification models using different evaluation metrics.table: Model,Accuracy,Recall,F1-Score,Precision, Logistic Regression,0.75,0.65,0.70,0.78, Random Forest,0.82,0.73,0.77,0.84, Decision Tree,0.73,0.70,0.68,0.68, K-Nearest Neighbors,0.79,0.72,0.75,0.80, Gradient Boosted Tree,0.85,0.77,0.80,0.87","Table 4 compares five different classification models' performance, that is, Logistic Regression, Random Forest, Decision Tree, K-Nearest Neighbors, and Gradient Boosted Tree. The table presents the evaluation metrics such as accuracy, recall, F1-score, and precision. Out of all models, Gradient Boosted Tree shows the best accuracy (0.85), recall (0.77), F1-score (0.80), and precision (0.87). On the other hand, Decision Tree shows the worst performance with the lowest scores on all metrics. Overall, the table demonstrates the importance of model selection and evaluation using multiple metrics."
433,"caption: Model performance based on different evaluation metrics.table: Model,Accuracy,F1-score,AUC-ROC,Precision,Recall, SVM,0.845,0.87,0.91,0.87,0.867, KNN,0.767,0.72,0.81,0.75,0.675, Random Forest,0.902,0.90,0.94,0.90,0.91, XGBoost,0.89,0.89,0.95,0.89,0.88, Naive Bayes,0.753,0.71,0.81,0.77,0.655","The table compares different models' evaluation metrics - accuracy, F1-score, AUC-ROC, precision, and recall. The SVM model demonstrated the highest AUC-ROC at 0.91. The random forest model demonstrated the highest accuracy at 0.902, F1-score at 0.9, and recall at 0.91. XGBoost achieved an impressive AUC-ROC score of 0.95. Naive Bayes exhibited the lowest accuracy, F1-score, and recall. Overall, the results suggest that the random forest model exhibits the best performance among the considered models."
434,"caption: Accuracy, F1-Score, Recall, and Precision of different models.table: Model,Accuracy,F1-Score,Recall,Precision, Logistic Regression,0.82,0.81,0.81,0.82, Random Forest,0.85,0.85,0.85,0.85, Support Vector Machine,0.83,0.82,0.82,0.82, Decision Tree,0.78,0.77,0.78,0.78, Multilayer Perceptron,0.80,0.79,0.79,0.80","Table above depicts the accuracy, F1-Score, Recall, and Precision of different models, including Logistic Regression, Random Forest, Support Vector Machine, Decision Tree, and Multilayer Perceptron. The performance metrics were evaluated using the same data set. The Random Forest model appears to be the best-performing model with an accuracy of 0.85 and F1-Score, Recall, and Precision scores of 0.85. The Decision Tree model, however, achieved the lowest scores across the metrics, with an accuracy of 0.78 and F1-Score, Recall, and Precision scores of 0.77. Interestingly, the Logistic Regression model performed slightly better than the SVM model, with an accuracy score of 0.82 and F1-Score, Recall, and Precision scores of 0.81. Finally, the Multilayer Perceptron model attained an accuracy of 0.80 and an F1-Score of 0.79, Recall of 0.79, and Precision of 0.80."
435,"caption: Comparison of different classifiers' performance metricstable: Model,Accuracy,F1 Score,Recall,Specificity, Random Forest,0.98,0.98,0.98,0.98, Support Vector Machines,0.85,0.86,0.88,0.77, Gradient Boosting,0.91,0.92,0.93,0.88, Decision Tree,0.82,0.83,0.81,0.83, Logistic Regression,0.87,0.88,0.87,0.86","The table presents the accuracy, F1 Score, recall, and specificity of the Random Forest, Support Vector Machines, Gradient Boosting, Decision Tree, and Logistic Regression classifiers. All classifiers' performance metrics were evaluated on the same dataset. The Random Forest classifier shows the best accuracy score of 0.98, which is the highest performance measure achieved in all classifiers. The Gradient Boosting classifier achieves the highest F1 Score, recall, and specificity of 0.92, 0.93, and 0.88, respectively. The Decision Tree classifier achieved the lowest accuracy score of 0.82. Overall, the table provides a valuable comparison of the different classifiers' performance metrics."
436,"caption: Comparison of model performance using different evaluation metrics.table: Model,Accuracy,F1 Score,AUC Score,Precision,Recall, SVM,0.91,0.87,0.94,0.84,0.92, Random Forest,0.89,0.85,0.92,0.82,0.88, KNN,0.88,0.84,0.91,0.81,0.85, Naive Bayes,0.82,0.76,0.89,0.75,0.78, Neural Net,0.93,0.90,0.96,0.88,0.93","The table compares the performance of five different models: SVM, Random Forest, KNN, Naive Bayes, and Neural Net. The models' performance is evaluated using multiple metrics such as accuracy, F1 score, AUC score, precision, and recall. The Neural Net model achieved the highest accuracy of 0.93, whereas the SVM model achieved the highest AUC score of 0.94. The Random Forest model is observed to be consistent in performance, with good scores across all evaluation metrics. The Naive Bayes model has the lowest performance scores across all the evaluation metrics."
437,"caption: Table 4: Model performance based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score,AUC, SVM,0.897,0.905,0.897,0.899,0.932, KNN,0.888,0.891,0.888,0.889,0.923, LR,0.905,0.906,0.905,0.906,0.930, RF,0.912,0.914,0.912,0.913,0.942","Table 4 presents model performances of four different machine learning models evaluated based on five different metrics, including Accuracy, Precision, Recall, F1-score, and AUC. The table includes Support Vector Machine (SVM), K-Nearest Neighbor (KNN), Logistic Regression (LR), and Random Forest (RF) models; it indicates Random Forest has the best performance with an accuracy score of 0.912, precision score of 0.914, recall score of 0.912, F1-score of 0.913, and AUC score of 0.942. Therefore, it is an indication that the Random Forest model could be used as the best approach for this task."
438,"caption: Table 4. Model performances based on multiple evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.91,0.91,0.92,0.91, KNN,0.85,0.84,0.89,0.81, MLP,0.93,0.93,0.92,0.94, Logistic Regression,0.88,0.87,0.88,0.87, Random Forest,0.95,0.95,0.94,0.96","Table 4 presents a comparison of different models' performances based on multiple evaluation metrics. The table shows the accuracy, F1 score, precision, and recall of SVM, KNN, MLP, Logistic Regression, and Random Forest models. The Random Forest model shows the best performance across all the evaluation metrics with the highest accuracy, F1 score, precision, and recall of 0.95, 0.95, 0.94, and 0.96, respectively. Notably, the MLP model achieved the second-best performance overall with a high accuracy, F1 score, and recall of 0.93, while the SVM model came third with a balanced precision, recall, and F1 score of 0.92 and 0.91."
439,"caption: Model Comparisons on Classification Task Metricstable: Model,Accuracy,F1-score,Precision,Recall, LogReg,0.850,0.750,0.900,0.650, Random Forest,0.870,0.760,0.890,0.690, SVM,0.840,0.730,0.880,0.670, MLP,0.880,0.770,0.850,0.710, XGBoost,0.890,0.780,0.860,0.730","The table presents the evaluation metrics (Accuracy, F1-score, Precision, Recall) of multiple machine learning models (LogReg, Random Forest, SVM, MLP, XGBoost) on a classification task. The accuracy metric measures the overall accuracy of the model, while the F1-score measures the model's balance between precision and recall. Interestingly, the MLP model outperforms all other models in terms of accuracy, F1-score, precision, and recall. The Random Forest and XGBoost models produced competitive results in all metrics, while SVM had the lowest accuracy, F-1 score, and recall. The table provides vital information for selecting a suitable model for the classification task considering the evaluation metrics."
440,"caption: The performance of different classifiers assessed using five evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score,AUC, SVM,.90,.92,.87,.89,.88, LR,.86,.88,.83,.85,.82, RF,.88,.91,.85,.86,.85, KNN,.82,.87,.75,.78,.73","The presented table  demonstrates the performance assessment of four different classifiers using five evaluation metrics. The table indicates the accuracy, precision, recall, F1-score, and AUC of support vector machine (SVM), logistic regression (LR), random forest (RF), and k-nearest neighbors (KNN). Interestingly, the table shows that SVM and RF achieved the highest accuracy with the same score of 0.88. In contrast, LR and KNN got lower accuracy with 0.86 and 0.82, respectively. Moreover, all classifiers have differences in their performance regarding precision, recall, F1-score, and AUC, which could affect the selection of the best classifier for a particular task."
441,"caption: Table 4: Model performances based on different evaluation metrics.table: Model,Accuracy,F1-Score,ROC-AUC,PR-AUC, Logistic Regression,0.88,0.89,0.92,0.87, Random Forest,0.85,0.87,0.90,0.81, Support Vector Machine,0.91,0.92,0.95,0.91, XGBoost,0.87,0.88,0.92,0.86","Table 4 illustrates the performance of four different models based on multiple evaluation metrics. The accuracy, F1-Score, ROC-AUC, and PR-AUC metrics were used to compare the performance of Logistic Regression, Random Forest, Support Vector Machine, and XGBoost. The Support Vector Machine model achieved the highest accuracy and F1-Score with values of 0.91 and 0.92, respectively. The Logistic Regression model showed the highest ROC-AUC with a value of 0.92, and finally, the Random Forest model had the lowest PR-AUC score of 0.81. Overall, the performance results vary widely across the different evaluation metrics, indicating the importance of choosing the appropriate metric based on the research question."
442,"caption: Model performance based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.84,0.79,0.88,0.83, Random Forest,0.89,0.83,0.93,0.87, Support Vector Machine,0.85,0.77,0.91,0.83, Neural Network,0.91,0.86,0.94,0.90","The table compares the performance of multiple models in a classification task based on a set of evaluation metrics. The evaluated metrics include Accuracy, Precision, Recall, and F1 score. The table shows that the best model performance varies depending on the evaluation metric; however, overall, the Neural Network model offers the best performance with an Accuracy of 0.91 and F1 Score of 0.90. The Random Forest model exhibits high Precision and Recall scores of 0.83 and 0.93, respectively. The Logistic Regression model offers the highest Precision score of 0.79, while the Support Vector Machine model had the highest Recall score of 0.91."
443,"caption: Model performances based on multiple metricstable: Models,Accuracy,F1 Score,Precision,Recall, Model A,0.85,0.78,0.79,0.77, Model B,0.83,0.79,0.85,0.74, Model C,0.88,0.81,0.85,0.78, Model D,0.89,0.79,0.88,0.72","The table presents the evaluation results for four different models, Model A, Model B, Model C, and Model D. Each model's accuracy, F1 score, precision, and recall metric scores are shown in the table. Model C recorded the highest accuracy and F1 score of 0.88 and 0.81, respectively. Model A had the highest precision score of 0.79, while Model D had the lowest recall score of 0.72. Overall, Model C demonstrated the best performance across all the metrics observed."
444,"caption: Model performance based on different evaluation metricstable: Model,F1-Score,Accuracy,AUC-ROC,Precision,Recall, Random Forest,0.89,0.88,0.91,0.88,0.9, XGBoost,0.87,0.89,0.9,0.87,0.87, Support Vector Machine,0.91,0.85,0.89,0.89,0.93, Multilayer Perceptron,0.84,0.87,0.8,0.87,0.81","Table  shows the comparison of four different machine learning models based on the varied evaluation metrics. The evaluation metrics used are F1-Score, accuracy, AUC-ROC, precision, and recall. The table exhibits that the Support Vector Machine (SVM) model has the highest F1-Score with a value of 0.91. Random Forest model exhibits the highest accuracy and AUC-ROC, with values of 0.88 and 0.91, respectively. The SVM model also shows the highest precision and recall with values of 0.89 and 0.93, respectively. Multilayer Perceptron (MLP) model performed least well with the lowest F1-score, precision, and recall among the four models."
445,"caption: Model performances based on multiple evaluation metricstable: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.75,0.71,0.68,0.77, LR,0.80,0.75,0.74,0.76, RF,0.85,0.81,0.84,0.78, KNN,0.70,0.66,0.63,0.70, DT,0.75,0.70,0.65,0.76","The table presents the performance of five different models. The models were assessed based on four different evaluation metrics, including accuracy, F1-Score, precision, and recall. SVM achieved an accuracy of 0.75 with a recall of 0.77. LR performed slightly better with an accuracy of 0.80 and a precision of 0.74. However, RF outperformed the other models by achieving an accuracy of 0.85 and a precision of 0.84. In terms of F1-Score and recall, DT performed relatively poorly compared to the other models. On the other hand, KNN had a lower accuracy of 0.70, though showed better recall than SVM at 0.70."
446,"caption: Performance comparison of different models based on multiple evaluation metrics.table: Model,Accuracy,F1-score,AUC,Precision,Recall, Logistic Reg.,0.84,0.85,0.90,0.79,0.93, SVM,0.81,0.83,0.88,0.77,0.89, KNN,0.77,0.79,0.81,0.74,0.85, Decision Tree,0.74,0.75,0.73,0.71,0.79, Random Forest,0.89,0.91,0.94,0.87,0.95","The table presents a performance comparison of different machine learning models. Multiple evaluation metrics including Accuracy, F1-Score, AUC, Precision, and Recall are shown in the table. The Logistic Regression model achieved the highest Accuracy rate of 0.84, and the highest AUC of 0.90. However, the Random Forest model outperformed all other models, achieving the highest scores in all metrics except for Accuracy, which was second highest. The SVM model also performed well, with an AUC of 0.88, higher than Decision Tree and KNN models."
447,"caption: Table 4: Performance evaluation of different models based on different metrics.table: Model,Accuracy,Precision,Recall,F1-score, logistic regression,0.89,0.91,0.85,0.87, decision tree,0.84,0.76,0.82,0.79, random forest,0.92,0.94,0.89,0.91, support vector machine,0.87,0.87,0.87,0.87, artificial neural network,0.91,0.92,0.87,0.89","Table 4 compares the performance of five different models based on multiple metrics. The models - logistic regression, decision tree, random forest, support vector machine, and artificial neural network - were evaluated using accuracy, precision, recall, and F1-score. Random Forest outperformed all other models in all evaluation metrics with the highest accuracy of 0.92, precision of 0.94, recall of 0.89, and F1-score of 0.91. Interestingly, the artificial neural network model and logistic regression model produced very similar results across all metrics, with slightly better results for the former. The decision tree model was the least accurate, with an accuracy of 0.84."
448,"caption: Comparison of model performances based on evaluation metricstable: Metric,Model_1,Model_2,Model_3,Model_4, RMSE,0.93,0.88,1.50,1.01, R-squared,0.78,0.84,0.52,0.88, MAE,0.63,0.68,1.12,0.72","The table presents a comparison of four different models' performances based on three evaluation metrics: Root Mean Square Error (RMSE), R-squared, and Mean Absolute Error (MAE). Model_2 outperformed the other models in terms of RMSE with a score of 0.88, whereas Model_3 showed the least desirable performance with an RMSE of 1.50. Conversely, Model_1 had the lowest RMSE of 0.93. In terms of R-squared, Model_2 performed the best with a score of 0.84 while Model_3 achieved the lowest R-squared of 0.52. Lastly, Model_3 demonstrated the highest MAE of 1.12, while Model_1 displayed the lowest MAE of 0.63. The table provides a comprehensive comparison of different models' performances based on different evaluation metrics."
449,"caption: Evaluation metrics of different classification modelstable: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.89,0.90,0.87,0.88, Naive Bayes,0.80,0.84,0.75,0.77, Random Forest,0.93,0.94,0.92,0.93, XGBoost,0.92,0.93,0.91,0.92","The table presents the accuracy, precision, recall, and F1-score evaluation metrics of four classification models: logistic regression, naive Bayes, random forest, and XGBoost. Notably, all models were evaluated on the same dataset. The table highlights that the random forest model achieved a high level of accuracy (0.93) indicating that it correctly classified the majority of the data. The logistic regression model obtained the best precision score (0.90), indicating that it correctly identified most of the positive classes compared to the other models. However, the XGBoost model achieved the best recall (0.91) and F1-score (0.92), demonstrating that it has the highest true positive rate and is an accurate overall predictor."
450,"caption: Table 4: Evaluation of different models based on accuracy, precision, recall, F1 score, and AUC.table: Model Name,Accuracy,Precision,Recall,F1 Score,AUC, Logistic Regression,0.81,0.82,0.68,0.74,0.893, Decision Tree,0.78,0.73,0.72,0.72,0.836, KNN,0.81,0.78,0.75,0.76,0.872, SVM,0.79,0.77,0.71,0.73,0.850, Random Forest,0.83,0.80,0.78,0.78,0.897","Table 4 presents an evaluation of different models based on accuracy, precision, recall, F1 score, and AUC metrics. The table exhibits Logistic Regression, Decision Tree, KNN, SVM, and Random Forest models' performances. The Random Forest model scored the highest accuracy of 0.83, followed closely by KNN and Logistic Regression with 0.81 accuracy. Random Forest and Logistic Regression models also achieved the highest precision of 0.80 and 0.82, respectively. The highest recall score of 0.75 was achieved by KNN. The F1-score was highest for Logistic Regression with a score of 0.74. Finally, the Random Forest model obtained the highest AUC score of 0.897."
451,"caption: Table 4. Performance comparison of different models on various evaluation metrics.table: Model,F1-score,Precision,Recall,ROC-AUC,PR-AUC, Model A,0.85,0.80,0.93,0.92,0.85, Model B,0.83,0.82,0.88,0.88,0.77, Model C,0.89,0.86,0.93,0.90,0.80, Model D,0.82,0.80,0.86,0.79,0.76, Model E,0.88,0.90,0.87,0.91,0.84","Table 4 shows the performance comparison of five different models on various evaluation metrics. The models were evaluated based on their F1-score, Precision, Recall, ROC-AUC, and PR-AUC scores. Notably, Model C achieved the highest F1-score of 0.89, with high Precision of 0.86 and Recall of 0.93. Additionally, Model E performed remarkably well in terms of Precision with a score of 0.90. On the other hand, Model D showed weaker performance in comparison to the other models, with the lowest PR-AUC score of 0.76 and ROC-AUC score of 0.79. Overall, the table provides insights into the relative performance of the different models and can guide the selection of suitable models for the specific task."
452,"caption: Performance comparison of different classification models on the given evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.845,0.930,0.814,0.868, Decision Tree,0.776,0.787,0.784,0.783, Random Forest,0.901,0.931,0.890,0.910, Support Vector Machines,0.856,0.927,0.853,0.888, XGBoost,0.915,0.948,0.905,0.926","This table presents a performance comparison of five different models with multiple evaluation metrics, including Accuracy, Precision, Recall, and F1 Score, for a classification problem. Notably, the Random Forest model demonstrated the highest accuracy of 0.901, while XGBoost achieved the highest accuracy score of 0.915. Similarly, XGBoost also exhibited the highest precision and F1 Score scores of 0.948 and 0.926, respectively, while Logistic Regression demonstrated the highest recall score of 0.814. Overall, this table provides useful insights into the various models' strengths and weaknesses in the classification of the given problem."
453,"caption: Table 4: Model Performance Based on Various Metricstable: **Model**,**F1-score**,**Precision**,**Recall**,**Accuracy**, Decision Tree,0.65,0.62,0.68,0.73, k-NN,0.72,0.69,0.76,0.78, Naive Bayes,0.68,0.71,0.66,0.81, SVM,0.80,0.83,0.77,0.85, Random Forest,0.86,0.89,0.83,0.89","Table 4 presents the F1-score, precision, recall, and accuracy of five popular classification models. The classification models include Decision Tree, k-NN, Naive Bayes, SVM, and Random Forest trained and tested with the same dataset. It can be observed that the Random Forest model provides the best results in terms of F1-score, precision, recall, and accuracy with values of 0.86, 0.89, 0.83, and 0.89, respectively. The SVM model also shows strong performance with an F1-score of 0.80, precision of 0.83, recall of 0.77, and accuracy of 0.85. Conversely, Decision Tree has the lowest performance among the models, achieving an F1-score of 0.65, precision of 0.62, recall of 0.68, and accuracy of 0.73. Overall, the results highlight the promising performance of Random Forest and SVM models for classification tasks."
454,"caption: Comparison of Model Performance Based on Various Metricstable: Model,Accuracy,Balanced Accuracy,F1 Score,Precision,Recall, Model A,0.82,0.75,0.81,0.85,0.78, Model B,0.78,0.77,0.79,0.71,0.89, Model C,0.89,0.80,0.88,0.92,0.85, Model D,0.86,0.76,0.84,0.82,0.87, Model E,0.92,0.79,0.91,0.94,0.88","Table 4 exhibits a comprehensive comparison of five different models based on several evaluation metrics, including Accuracy, Balanced Accuracy, F1 Score, Precision, and Recall. Notably, all models' performance results varied across different metrics. Model E achieved the highest score in all metrics with Accuracy of 0.92, Balanced Accuracy of 0.79, F1 Score of 0.91, Precision of 0.94, and Recall of 0.88. In contrast, Model B had moderate Accuracy of 0.78 and the lowest Precision of 0.71. Meanwhile, Model A had the highest Precision of 0.85 and Model D had the highest Recall of 0.87."
455,"caption: Table 4: Model performance on various metricstable: Models,F1 score,Recall,Precision,Accuracy, SVM,0.85,0.80,0.90,0.86, Logistic Regression,0.87,0.82,0.93,0.88, Decision Tree,0.78,0.72,0.85,0.81, Random Forest,0.90,0.87,0.93,0.91","Table 4 displays a comparison of multiple models' performances concerning different evaluation metrics. Focusing on the F1 score shows that the Random Forest model achieved the highest score of 0.90, followed by Logistic Regression with a score of 0.87, while the Decision Tree model had the lowest F1 score of 0.78. In terms of recall, the performance follows a similar pattern to the F1 score: the highest score is observed in the Random Forest model with 0.87 and followed by Logistic Regression with 0.82. However, the Decision Tree model still has the lowest score with 0.72. Precision scores show that Logistic Regression outperforms the other models, obtaining a score of 0.93. Finally, the accuracy results suggest that Random Forest has the highest accuracy of 0.91, while Decision Tree has the lowest accuracy of 0.81."
456,"caption: Model Performance Evaluation Metricstable: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.875,0.856,0.867,0.877, Support Vector Machines,0.904,0.902,0.899,0.906, Random Forest Classifier,0.911,0.905,0.908,0.902, Gradient Boosting Classifier,0.907,0.903,0.898,0.908, Multilayer Perceptron,0.893,0.890,0.893,0.888, Naive Bayes,0.827,0.812,0.822,0.804, K Nearest Neighbors,0.879,0.872,0.872,0.873","Table presents model performances of various models according to different evaluation metrics. Specifically, the table shows the models' accuracy, F1 score, precision, and recall. Each model's performance is evaluated based on a dataset with a binary classification problem. Overall, the table reveals that the Random Forest Classifier and Gradient Boosting Classifier models have the highest accuracy score of 0.911 and 0.907, respectively. Moreover, the Table also shows that Support Vector Machines have the best F1 score, Precision and Recall compared to the other models. Interestingly, Naive Bayes and Multilayer Perceptron have lower accuracy scores despite having a relatively good F1 score and precision."
457,"caption: Model performance based on different evaluation metrics.table: Model name,Accuracy,F1-score,Precision,AUC-ROC,Recall, Logistic Regression,0.85,0.87,0.85,0.92,0.90, Decision Tree,0.80,0.76,0.78,0.85,0.74, Random Forest,0.91,0.92,0.94,0.97,0.89, Support Vector,0.87,0.88,0.87,0.93,0.88","The table illustrates the accuracy, F1-score, precision, AUC-ROC, and recall of different models, including Logistic Regression, Decision Tree, Random Forest, and Support Vector. The highest accuracy of 0.91 is obtained by the Random Forest model, while Support Vector attains the highest precision of 0.87. F1-score highest score is obtained by Random Forest with a score of 0.92, while Decision Tree attains the lowest score of 0.76. Notably, the Random Forest model performs significantly well in terms of all evaluation metrics."
458,"caption: Performance comparison of various models on the classification task.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.92,0.91,0.90,0.90, SVM,0.89,0.88,0.93,0.90, Decision Tree,0.85,0.83,0.87,0.84, Random Forest,0.93,0.95,0.91,0.93, Neural Network,0.91,0.92,0.88,0.89","The table above reports the performance comparison of various models on the classification task employing accuracy, precision, recall, and F1 score as evaluation metrics. Results show that Random Forest outperforms all other models, achieving the highest accuracy of 0.93. Random Forest also demonstrates the best precision and F1 score of 0.95 and 0.93, respectively, followed by Neural Network with 0.92 precision and Logistic Regression with 0.90 F1 score. SVM has the highest recall score of 0.93, while Decision Tree has the lowest accuracy, precision, recall, and F1 score of 0.85, 0.83, 0.87, and 0.84, respectively."
459,"caption: Table 4: Model performance using multiple evaluation metricstable: Model,Precision,Recall,F1,AUC, SVM,0.92,0.75,0.83,0.87, RF,0.86,0.80,0.83,0.90, LR,0.80,0.84,0.82,0.86, MLP,0.72,0.89,0.79,0.84, KNN,0.76,0.70,0.73,0.82","Table 4 displays the performances of five different models, including SVM, RF, LR, MLP, and KNN, based on multiple evaluation metrics, including Precision, Recall, F1, and AUC. Each model's performance was evaluated using the same dataset with the same split. The RF model exhibited the best overall performance based on the highest F1 score of 0.83 and AUC of 0.90. Interestingly, SVM had the highest precision result of 0.92, while MLP had the highest recall of 0.89. It is worth noting that while SVM had the highest precision, it had a lower F1 score compared to LR and RF models, implying the model is not well suited for the dataset used in the study."
460,"caption: Table 4: Model performance based on different evaluation metrics for a binary classification problem.table: Model,Accuracy,Precision,Recall,F1-score,MCC, SVM,0.92,0.91,0.88,0.89,0.81, KNN,0.90,0.89,0.84,0.84,0.78, RF,0.95,0.98,0.93,0.95,0.91, NB,0.88,0.92,0.83,0.87,0.75, LR,0.91,0.89,0.88,0.88,0.79","Table 4 presents the model performance for a binary classification problem using different evaluation metrics. The table features five models, including Support Vector Machine (SVM), K-Nearest Neighbors (KNN), Random Forest (RF), Naive Bayes (NB), and Logistic Regression (LR). The evaluation metrics used in the table are Accuracy, Precision, Recall, F1-score, and MCC. It is noteworthy that the Random Forest model achieved the highest accuracy score of 0.95, precision score of 0.98, recall score of 0.93, F1-score of 0.95, and MCC score of 0.91. On the other hand, the Naive Bayes model obtained the lowest accuracy score of 0.88, precision score of 0.92, recall score of 0.83, F1-score of 0.87, and MCC score of 0.75. This table demonstrates that different models perform differently on different evaluation metrics, highlighting the importance of choosing the right metric for the task at hand."
461,"caption: Performance metrics of different models on the datasettable: Model,Accuracy (%),F1-Score,Precision,Recall, CNN,0.85,0.85,0.86,0.84, LSTM,0.89,0.89,0.89,0.89, RF,0.92,0.92,0.93,0.91, SVM,0.88,0.88,0.88,0.88, KNN,0.81,0.81,0.83,0.80","The table presents the performance of five different machine learning models on a given dataset in terms of Accuracy, F1-Score, Precision, and Recall. The models include CNN, LSTM, RF, SVM, and KNN. Notably, the RF model attained the highest accuracy of 0.92, followed by the LSTM model with 0.89, while KNN had the lowest accuracy of 0.81. Regarding F1-score, the RF and LSTM models achieved the highest score of 0.92, followed by the SVM and KNN models with 0.88 and 0.81, respectively. Additionally, all models have the same precision and recall scores, ranging between 0.86 and 0.88. Overall, the RF model shows the best performance across all metrics."
462,"caption: Table 4: Model performance comparison based on different evaluation metrics.table: Models,Accuracy,Precision,Recall,F1 score, Logistic Regression,0.78,0.80,0.75,0.77, Random Forest,0.86,0.87,0.85,0.86, Decision Trees,0.73,0.77,0.70,0.73, SVM,0.81,0.83,0.80,0.81, Naive Bayes,0.69,0.70,0.67,0.68","The table presents a comparison of five different classification models' performances based on four evaluation metrics. The models include Logistic Regression, Random Forest, Decision Trees, SVM, and Naive Bayes. The evaluation metrics entail accuracy, precision, recall, and F1 score. Notably, Random Forest outperforms other models in all the metrics, scoring the highest accuracy of 0.86 and the highest F1 score of 0.86. Meanwhile, Decision Trees give the lowest accuracy of 0.73, and Naive Bayes has the lowest F1 score of 0.68. Overall, the Random Forest model appears to be the most suitable model for the given classification problem."
463,"caption: Table 4: Evaluation results of various models on a classification tasktable: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.78,0.54,0.82,0.64, Random Forest,0.84,0.64,0.86,0.74, Decision Tree,0.77,0.49,0.90,0.63, KNN,0.80,0.58,0.77,0.66, Naive Bayes,0.73,0.40,0.91,0.56","Table 4 summarizes the evaluation results of different models on a classification task. The table displays the accuracy, precision, recall, and F1-Score performance metrics for SVM, Random Forest, Decision Tree, KNN, and Naive Bayes models. Notably, the Random Forest model outperforms the other models' accuracy, achieving a score of 0.84, while the Naive Bayes model achieved the lowest accuracy score of 0.73. The Naive Bayes model achieved the highest recall score of 0.91 while the Decision Tree model achieved the highest precision score of 0.90. Overall, the table provides a comparison of different machine learning models for a particular classification task."
464,"caption: Performance comparison of different Machine learning algorithms on the test dataset.table: Model,Accuracy,Precision,Recall,F1-score, Random Forest,0.97,0.94,0.87,0.91, Naive Bayes,0.89,0.75,0.92,0.82, Support Vector,0.93,0.84,0.74,0.78, Decision Tree,0.95,0.91,0.87,0.89, K-Nearest Neighbor,0.88,0.71,0.63,0.66","The table presents the performance comparison results of Random Forest, Naive Bayes, Support Vector, Decision Tree, and K-Nearest Neighbor algorithms on the test dataset. The evaluation metrics include Accuracy, Precision, Recall, and F1-score. Random Forest obtained the best performance results for all evaluation metrics with an Accuracy of 0.97, Precision of 0.94, Recall of 0.87, and F1-score of 0.91. On the other hand, Naive Bayes produced the lowest Precision but with the highest Recall of 0.92. The Support Vector algorithm obtained a Precision of 0.84 and Recall of 0.74. Lastly, K-Nearest Neighbor produced the lowest performance results among all models, with an Accuracy of 0.88 and poor Precision, Recall, and F1-scores."
465,"caption: Performance of five different models for the classification tasktable: Model Name,Accuracy,F1 Score,Precision,Recall, Model 1,0.92,0.91,0.94,0.89, Model 2,0.89,0.87,0.92,0.83, Model 3,0.94,0.93,0.95,0.92, Model 4,0.85,0.81,0.87,0.76, Model 5,0.90,0.89,0.92,0.87","Table 1 presents a comparison of the performance of five different models in a classification task based on multiple evaluation metrics, including Accuracy, F1 Score, Precision, and Recall. The table shows that Model 3 has the highest accuracy among all models with a score of 0.94, while Model 4 has the lowest accuracy of 0.85. Similarly, Model 3 outperforms all other models in terms of F1 Score, Precision, and Recall while Model 4 has the lowest scores in all three categories. Overall, the table findings suggest that Model 3 is the best-performing model out of all five models tested."
466,"caption: Performance comparison of different models using multiple evaluation metrics.table: Model,Accuracy,Precision,F1-score,Recall,AUC, Model A,0.85,0.87,0.80,0.75,0.90, Model B,0.91,0.92,0.88,0.86,0.94, Model C,0.80,0.78,0.81,0.85,0.88, Model D,0.93,0.95,0.93,0.92,0.96","Table presents the performance comparison of four different models based on five different evaluation metrics - Accuracy, Precision, F1-Score, Recall, and AUC. The table shows Model A, B, C, and D's Accuracy, Precision, F1-score, Recall, and AUC score. Of all four models, Model D achieved the highest accuracy of 0.93, while Model C had the lowest accuracy of 0.80. Model D also achieved the highest Precision, F1-score, Recall, and AUC of 0.95, 0.93, 0.92, and 0.96 consecutively. On the other hand, Model A had the highest Recall of 0.75, which is relatively lower compared to Model D."
467,"caption: Table 1: Model Performance on Different Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1 Score, SVM,0.92,0.90,0.89,0.89, KNN,0.85,0.84,0.71,0.76, Random Forest,0.94,0.92,0.93,0.93, Naive Bayes,0.78,0.71,0.75,0.73, XGBoost,0.91,0.87,0.91,0.89","The table above shows the performance of different models on multiple evaluation metrics. SVM, Random Forest, and XGBoost performed well with accuracies of 0.92, 0.94, and 0.91, respectively. Furthermore, Random Forest and XGBoost models demonstrate higher precision, recall, and F1 scores than SVM. Naive Bayes model's performance is relatively poorer in comparison to the other models. Notably, KNN had the lowest accuracy among the models but also had the highest precision value. Overall, the table provides significant insights into the models' relative performances based on different evaluation metrics."
468,"caption: Model performances using different evaluation metrics.table: Model,Accuracy (std.),Precision (std.),Recall (std.),F1 (std.), Logistic regression (L1 regularization),0.88 (0.01),0.90 (0.02),0.86 (0.03),0.88 (0.02), Logistic regression (L2 regularization),0.89 (0.01),0.92 (0.02),0.85 (0.04),0.88 (0.02), Decision tree,0.85 (0.02),0.87 (0.03),0.83 (0.03),0.85 (0.02), Random forest,0.92 (0.01),0.94 (0.01),0.90 (0.02),0.92 (0.01), Gradient boosted decision tree,0.93 (0.01),0.94 (0.01),0.92 (0.01),0.93 (0.01)","The table compares the performance of five different models using four different evaluation metrics: accuracy, precision, recall, and F1. The models evaluated include logistic regression with L1 and L2 regularization, decision tree, random forest, and gradient boosted decision tree. The table clearly shows that the gradient boosted decision tree model has the best overall performance, achieving the highest accuracy, precision, recall and F1 scores with an accuracy of 0.93 (0.01), precision of 0.94 (0.01), recall of 0.92 (0.01) and F1 score of 0.93 (0.01). Interestingly, the random forest model has overall slightly better precision, recall and F1 scores than the logistic regression models but has a slightly lower accuracy score. The decision tree model performed the poorest in all the metrics compared to other models in the table."
469,"caption: Table 4: Model performances evaluated using multiple metrics.table: Model 1,Model 2,Model 3, Metric 1,0.78,0.91,0.77, Metric 2,0.67,0.83,0.71, Metric 3,0.52,0.62,0.51, Metric 4,0.91,0.96,0.92, Metric 5,0.35,0.42,0.38","Table 4 presents the performance of Model 1, Model 2, and Model 3 evaluated using different metrics. Metrics 1 to 5 are provided, revealing varying levels of performance for each model. Model 2 shows the highest performance across all metrics, whereas Model 1 has the lowest scores. One interesting observation is that while Model 3 has low outcomes with Metrics 1, 3, and 5, it performs almost as well as Model 2 with Metrics 2 and 4. Overall, this table highlights the importance of evaluating models using various metrics to assess their performance comprehensively."
470,"caption: Performance metrics of multiple models.table: Model,Precision,Recall,F1-Score,Accuracy,AUC, Model A,0.82,0.79,0.80,0.75,0.85, Model B,0.79,0.83,0.81,0.72,0.88, Model C,0.81,0.81,0.81,0.74,0.87, Model D,0.87,0.76,0.81,0.76,0.89, Model E,0.84,0.84,0.84,0.72,0.86","The table presents a performance comparison of five different models based on precision, recall, F1-Score, accuracy, and AUC. Model A scored the highest precision of 0.82, while Model D had the highest precision of 0.87. Model B demonstrated the highest recall value of 0.83. Model E had the highest F1-Score of 0.84, and all the models showed quite similar accuracy values. However, Model D showed the highest accuracy score of 0.76. The AUC scores range from 0.85 for Model A to 0.89 for Model D, indicating that Model D performed best in terms of overall classification performance."
471,"caption: Table 4: F1-Score, Precision, and Recall comparison of different models.table: Model,F1-Score,Precision,Recall, Random forest,0.92,0.93,0.92, SVM,0.84,0.83,0.84, Logistic Regression,0.85,0.83,0.85, K-Nearest Neighbor (KNN),0.78,0.80,0.78","Table 4 displays the F1-score, precision, and recall evaluation metrics of four models: Random forest, SVM, Logistic Regression, and K-Nearest Neighbor (KNN). All models are evaluated on the same dataset, and the results indicate that Random forest outperforms the other models with an F1-score of 0.92, precision of 0.93, and recall of 0.92. SVM, Logistic Regression, and KNN have F1-scores of 0.84, 0.85, and 0.78, respectively. Notably, Random forest model demonstrates a more balanced performance with equally impressive precision and recall scores."
472,"caption: Table 4: Performance of different algorithms using multiple evaluation metricstable: Algorithm,F1 Score,AUC Score,Accuracy Score, SVM,0.75±0.02,0.70±0.03,83.24±0.46, Naive Bayes,0.55±0.08,0.61±0.06,71.32±1.33, Logistic Regression,0.80±0.03,0.74±0.05,85.45±0.52, Random Forest,0.90±0.02,0.86±0.03,92.12±0.27, Gradient Boosting,0.92±0.01,0.89±0.02,93.67±0.32","Table 4 shows the performance of different algorithms on a common dataset evaluated for multiple evaluation metrics, including F1-Score, AUC-Score, and Accuracy Score. The models compared in the table are SVM, Naive Bayes, Logistic Regression, Random Forest, and Gradient Boosting. From the results, it can be observed that Gradient Boosting achieved the best performance for all three evaluation metrics. It recorded the highest F1-Score of 0.92±0.01, AUC Score of 0.89±0.02, and Accuracy Score of 93.67±0.32. Additionally, Random Forest provided the second-best results, obtaining F1-Score of 0.90±0.02, AUC Score of 0.86±0.03, and Accuracy Score of 92.12±0.27."
473,"caption: Model performances based on multiple evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.893,0.899,0.889,0.911, Logistic Regression,0.868,0.882,0.859,0.906, Random Forest,0.902,0.904,0.897,0.912, XGBoost,0.908,0.906,0.917,0.896, K-Nearest Neighbor,0.882,0.883,0.877,0.900","The table shows the model performances of SVM, Logistic Regression, Random Forest, XGBoost, and K-Nearest Neighbor based on multiple evaluation metrics. The metrics used include Accuracy, F1-score, Precision, and Recall. Notably, the XGBoost model obtained the highest Accuracy score of 0.908, and the highest Precision score of 0.917. However, the highest F1-score of 0.906 was obtained by the Random Forest model. The SVM model achieved the highest Recall score of 0.911, while the Logistic Regression model performed relatively lower in all metrics compared to the other models. The K-Nearest Neighbor model achieved moderate performance scores in all evaluation metrics."
474,"caption: Table 4: Comparison of different models' performances using multiple evaluation metrics on the test set.table: Model,Accuracy (%),F1-score,Precision,Recall, SVM,86.5,0.850,0.830,0.870, RF,90.1,0.904,0.889,0.919, GBM,89.8,0.896,0.884,0.909, MLP,88.3,0.878,0.862,0.895","Table 4 compares multiple classification models' performance on a test dataset using various evaluation metrics. The table includes models such as SVM, RF, GBM, and MLP, each with accuracy, F1-score, precision, and recall results. The RF model outperformed the other models, achieving an accuracy score of 90.1%, an F1-score of 0.904, precision of 0.889, and recall of 0.919. The MLP model achieved the lowest performance among the models, with an accuracy score of 88.3%, an F1-score of 0.878, precision of 0.862, and recall of 0.895. Overall, the RF model exhibits the best performance among the tested models."
475,"caption: Model performance comparison of multiple models on different evaluation metrics.table: Metric,Model 1,Model 2,Model 3,Model 4,Model 5, Accuracy,0.86,0.76,0.81,0.72,0.78, Precision,0.92,0.55,0.73,0.8,0.62, Recall,0.85,0.92,0.72,0.62,0.67, F1-score,0.88,0.68,0.73,0.7,0.63","The table presents the performance comparison of multiple models on different evaluation metrics such as Accuracy, Precision, Recall, and F1-Score. The table consists of five different models, and it is observed that Model 1 has the highest accuracy score with a score of 0.86. On the other hand, Model 2 has the lowest accuracy score with a score of 0.76. Furthermore, Model 1 and Model 2 have the highest and the lowest precision scores with values of 0.92 and 0.55, respectively. Model 2 and Model 4 have the highest and lowest recall scores with values of 0.92 and 0.62, respectively. Lastly, the highest and lowest F1-score values are seen in Model 1 and Model 5 with scores of 0.88 and 0.63, respectively. This table provides valuable insights into the performance of different models on various evaluation metrics, allowing for a more informed decision when choosing a model."
476,"caption: Performance comparison of different models on various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score,AUC, Logistic Regression,0.84,0.85,0.78,0.81,0.88, Random Forest,0.87,0.86,0.81,0.83,0.91, Naive Bayes,0.79,0.77,0.85,0.80,0.87, Support Vector Machine,0.78,0.74,0.81,0.77,0.83, Multi-layer Perceptron,0.82,0.80,0.82,0.81,0.85","This table presents the performance comparison of different classification models based on various evaluation metrics. The models evaluated in this table are Logistic Regression, Random Forest, Naive Bayes, Support Vector Machine (SVM), and Multi-layer Perceptron (MLP). The evaluation metrics used in this table are Accuracy, Precision, Recall, F1-Score, and AUC. It can be observed that the Random Forest model has the highest accuracy of 0.87, while the Logistic Regression model has the highest AUC score of 0.88. The Naive Bayes model has the highest Precision of 0.77, while the SVM model has the highest Recall of 0.81. The F1-Score column shows that most models have similar performance except for the Naive Bayes model that trails the others. Overall, the Random Forest model seems to perform the best across most evaluation metrics."
477,"caption: The performance of different models using multiple evaluation metrics.table: Model,Accuracy,F1-Score,Sensitivity,Specificity, SVM,0.954,0.945,0.961,0.944, KNN,0.955,0.944,0.965,0.936, DNN,0.959,0.953,0.955,0.963, LR,0.957,0.949,0.959,0.956, RF,0.961,0.958,0.956,0.965","This table presents the performances of five different models based on four evaluation metrics: accuracy, F1-score, sensitivity, and specificity. The models include Support Vector Machine (SVM), K-Nearest Neighbor (KNN), Deep Neural Network (DNN), Logistic Regression (LR), and Random Forest (RF). Notably, the Random Forest model performs the best with an accuracy of 0.961 and an F1-score of 0.958, followed closely by DNN with an accuracy of 0.959 and F1-score of 0.953. Furthermore, all models achieved high sensitivity scores, indicating their ability to correctly identify positive cases, with KNN achieving the highest sensitivity of 0.965. However, all models struggled to maintain high specificity scores, with Random Forest being the only model to achieve a specificity score greater than 0.95."
478,"caption: Model evaluation metrics for different modelstable: Model,Accuracy,Recall,Precision,F1-score,AUC, Model A,0.81,0.78,0.83,0.81,0.87, Model B,0.79,0.81,0.77,0.79,0.85, Model C,0.76,0.74,0.78,0.75,0.83, Model D,0.85,0.85,0.83,0.84,0.91, Model E,0.83,0.84,0.80,0.81,0.89","The table showcases the model evaluation metrics of five models. The table presents accuracy, recall, precision, F1-score, and AUC evaluation metrics for every model. Model A performs the best in terms of accuracy with a score of 0.81. Model D has the highest AUC score of 0.91. Out of the five models, Model D is the top-performing model in terms of recall, precision, and F1-score. Model E follows Model D closely in terms of performance, while Model B also shows acceptable performance in all the evaluation metrics. By comparing the metrics, it is evident that Model A has high accuracy, while Model D and E have high recall, precision, and F1-score with high AUC values, making these models the best for prediction tasks."
479,"caption: Table 4: Model performances across different evaluation metrics.table: Model Name,Accuracy,F1 Score,Recall,Precision, Model A,0.85,0.80,0.70,0.95, Model B,0.81,0.78,0.68,0.90, Model C,0.87,0.75,0.80,0.70, Model D,0.84,0.82,0.72,0.94","The table above presents a comparison of various models based on different evaluation metrics. The models presented are Model A, Model B, Model C, and Model D. The evaluation metrics are Accuracy, F1 Score, Recall, and Precision. Among the models, Model C has the highest accuracy of 0.87, while Model B had the lowest accuracy score of 0.81. For F1 Score, Model D had the highest score of 0.82, while Model C had the lowest score of 0.75. Regarding Recall and Precision metrics, the results are a bit different, with a more significant disparity in scores among the models. Model A had the highest Recall score of 0.70, while Model C had the highest Precision score of 0.70. Conversely, Model B had the lowest Recall score of 0.68, while Model A had the lowest Precision score of 0.95."
480,"caption: Performance comparison of various classification models based on different evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.89,0.88,0.86,0.91, Decision Tree,0.84,0.81,0.80,0.82, Random Forest,0.91,0.90,0.89,0.90, SVM,0.87,0.85,0.84,0.85, Naive Bayes,0.82,0.79,0.76,0.81","The table represents the comparison of five different classification models, including Logistic Regression, Decision Tree, Random Forest, SVM, and Naive Bayes based on different evaluation metrics such as Accuracy, F1-Score, Precision, and Recall. The highest accuracy of 0.91 was achieved by the Random Forest model followed by Logistic Regression with an accuracy of 0.89. Moreover, the Random Forest and Logistic Regression models perform consistently well across all evaluation metrics compared to other models. The Naive Bayes model shows the lowest performance with an accuracy of 0.82, demonstrating that the model may not be suitable for this specific classification task."
481,"caption: Performance of different models using multiple evaluation metrics on the dataset.table: Models,Accuracy,F1 Score,Precision,Recall,AUC Score, Logistic Regression,0.85,0.82,0.81,0.84,0.95, Random Forest,0.87,0.83,0.85,0.82,0.94, Support Vector Machines,0.86,0.84,0.84,0.84,0.95, Multilayer Perceptron,0.83,0.81,0.81,0.82,0.93","Table presents the comparison of four classification models, Logistic Regression, Random Forest, Support Vector Machines, and Multilayer Perceptron, using multiple evaluation metrics on a given dataset. The metrics evaluated include Accuracy, F1-Score, Precision, Recall, and AUC Score. According to the results, the Random Forest model achieved the highest accuracy (0.87) and F1-Score (0.83), while the Support Vector Machines achieved the best Precision score (0.84) and AUC score (0.95). Surprisingly, Logistic Regression showed a little better Recall than Random Forest (0.84 vs. 0.82). The Multilayer Perceptron demonstrates the minimum performance in comparison to the other models in the table. Overall, the table provides a comprehensive overview of the models' performance in classification tasks."
482,"caption: Table 4: Model performance based on accuracy, F1 score, precision, and recall.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.972,0.976,0.987,0.965, Random Forest,0.969,0.972,0.983,0.962, Naive Bayes,0.910,0.855,0.979,0.753, Logistic Regression,0.928,0.937,0.984,0.893, K-Nearest Neighbor,0.932,0.941,0.970,0.914","Table 4 compares the model performance of SVM, Random Forest, Naive Bayes, Logistic Regression, and K-Nearest Neighbor. Four evaluation metrics such as accuracy, F1 Score, Precision, and Recall have been presented to measure model performance. The results showed that SVM had the highest accuracy, F1 Score, and precision, and Naive Bayes had the lowest performance compared to the other models. However, random forest model showed the highest recall result. The table suggests that SVM and Random Forest could be the best-suited models based on the evaluation metrics presented."
483,"caption: Table 4: Classification performance comparison of different models based on multiple evaluation metricstable: Model,Acc,F1-score,Precision,Recall,AUC, SVM,0.876,0.865,0.869,0.898,0.934, Random Forest,0.874,0.864,0.867,0.921,0.925, Logistic Regression,0.843,0.834,0.834,0.874,0.908, XGBoost,0.897,0.890,0.897,0.925,0.943","Table 4 demonstrates a performance comparison of various models based on multiple evaluation metrics, including Accuracy, F1-Score, Precision, Recall, and AUC. The table shows that the SVM and Random Forest models achieved similar accuracy scores, 0.876 and 0.874, respectively. Interestingly, the Random Forest model outperformed the other models in terms of recall, with a score of 0.921. The best performing model overall is XGBoost, with an accuracy score of 0.897 and the highest F1-Score, Precision, Recall, and AUC scores among all the models. The Logistic Regression model obtainable exhibited a decent AUC score of 0.908. These results imply that machine learning models can be used effectively in classification tasks."
484,"caption: Table 4: Performance of Different Models on Multiple Evaluations on the Datasettable: Model,F1-score,Accuracy,AUC, LogReg,0.85,0.80,0.87, Decision Tree,0.80,0.75,0.81, Random Forest,0.89,0.83,0.91, SVM,0.87,0.81,0.90, XGBoost,0.91,0.85,0.93","Table 4 presents the performance of five different models - LogReg, Decision Tree, Random Forest, SVM, and XGBoost based on three different evaluation metrics- F1-score, Accuracy, and AUC. The model performances are evaluated on a given dataset. The Random Forest model performed the best with an F1-score of 0.89, accuracy of 0.83, and AUC of 0.91. The XGBoost model is the only model that achieved scores above 0.90 across all three evaluation metrics. Interestingly, the Decision Tree model obtained the lowest performance scores with an F1-score of 0.80, accuracy of 0.75, and AUC of 0.81. Overall, the table provides insights into the comparative performance of various models on multiple evaluation metrics."
485,"caption: Table 4: Model performance comparison using different evaluation metrics.table: Model name,Accuracy,Precision,Recall,F1-Score, Model 1,0.890,0.891,0.878,0.884, Model 2,0.899,0.907,0.896,0.901, Model 3,0.902,0.904,0.900,0.902, Model 4,0.893,0.901,0.886,0.894, Model 5,0.905,0.904,0.911,0.906","Table 4 illustrates the performance evaluation of five different models concerning Accuracy, Precision, Recall, and F1-Score. The table displays that Model 5 demonstrates the best performance results for Accuracy with a score of 0.905, and Recall with a score of 0.911. Model 3 shows the second-best performance across all the evaluation metrics. Interestingly, Model 2 exhibits better Precision than any other models, with a significant score of 0.907. However, Model 5 received the best F1-Score score with a score of 0.906."
486,"caption: Results of Different Models used for Binary Classification of Text Datatable: Model,Precision,Recall,F1-Score,PR-AUC,ROC-AUC, Naive Bayes,0.92,0.86,0.88,0.88,0.89, Decision tree,0.82,0.87,0.84,0.72,0.69, Random Forest,0.96,0.94,0.93,0.93,0.94, Logistic regression,0.94,0.97,0.94,0.91,0.93","The table displays the performance results of various models used for binary classification of text data. The models used in this table include Naive Bayes, Decision tree, Random Forest, and Logistic Regression. Evaluation metrics like precision, recall, F1-score, PR-AUC, and ROC-AUC are used to assess the models. Interestingly, Random Forest shows the highest values in most evaluation metrics. The model also performs well in terms of both precision and recall, proving to be reliable in binary classification tasks. Logistic Regression shows a close second in performance measures. Decision tree, on the other hand, fails to perform well in PR-AUC and ROC-AUC compared to other models, while Naive Bayes provides reasonable performance in most of the evaluation metrics."
487,"caption: Performance Metrics of Various Machine Learning Modelstable: Model,Accuracy,F1 Score,Recall,Precision, SVM with RBF,0.850,0.835,0.859,0.812, Random Forest,0.860,0.840,0.868,0.814, K-Nearest Neighbors,0.770,0.757,0.766,0.748, Logistic Regression,0.840,0.825,0.847,0.805, Decision Tree,0.820,0.801,0.823,0.781","The table above compares the performance of multiple machine learning models in terms of accuracy, f1 score, recall, and precision. Five models, namely SVM with RBF, Random Forest, K-Nearest Neighbors, Logistic Regression, and Decision Tree, are assessed using the same dataset and evaluation metrics. Random Forest boasts the highest accuracy rate (0.860), while SVM with RBF achieves the highest F1-score (0.835) and recall rate (0.859). On the other hand, K-Nearest Neighbors and Logistic Regression have lower accuracy and F1-scores than the other models. This table provides an overview of the strengths and weaknesses of each model and can aid in selecting the best model for a specific task."
488,"caption: Performance of Different Models on Evaluation Metricstable: Model,F1-score,Precision,Recall,Accuracy, Logistic Regression,0.75,0.68,0.85,0.70, Decision Tree,0.70,0.65,0.77,0.62, Random Forest,0.79,0.74,0.86,0.74, XGBoost,0.82,0.78,0.89,0.79, Support Vector Machine,0.69,0.61,0.81,0.65","The table above reports the performance of different machine learning models on multiple evaluation metrics, namely F1-score, Precision, Recall, and Accuracy. The models compared include Logistic Regression, Decision Tree, Random Forest, XGBoost, and Support Vector Machine. The results show that XGBoost outperforms other models in all evaluation metrics, reporting the highest F1-score of 0.82, Precision of 0.78, Recall of 0.89, and Accuracy of 0.79. Random Forest follows closely behind, with the second-highest score in all evaluation metrics. The Support Vector Machine reports the lowest score in all evaluation metrics, indicating under-performance compared to other models."
489,"caption: Comparison of different models based on various evaluation metrics.table: Model Name,Accuracy,F1-Score,Precision,Recall,AUC, Model 1,0.90,0.91,0.89,0.92,0.94, Model 2,0.92,0.93,0.90,0.97,0.91, Model 3,0.89,0.90,0.87,0.92,0.93, Model 4,0.95,0.94,0.95,0.93,0.97","Table shows a comparison of four different models based on their accuracy, F1-Score, Precision, Recall, and AUC. Model 4 shows the best performance in all metrics with an accuracy score of 0.95, F1-Score 0.94, Precision 0.95, Recall 93, and AUC 0.97 closely followed by Model 2, which has an accuracy score of 0.92, F1-Score 0.93, Precision 0.90, Recall 0.97, and AUC score of 0.91. Interestingly, Model 3 has the lowest performance among all the models in all metrics. Further analysis can be made to understand the reasons behind Model 3's lower performance."
490,"caption: Evaluation of different models in terms of various metrics.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.856,0.834,0.847,0.821, Random Forest,0.865,0.849,0.852,0.846, KNN,0.823,0.792,0.780,0.807, Decision Tree,0.812,0.781,0.776,0.787, Naive Bayes,0.789,0.763,0.740,0.789","The table represents the evaluation of five different models in terms of their accuracy, F1-score, precision, and recall. The models evaluated include Support Vector Machine (SVM), Random Forest, K-Nearest Neighbors (KNN), Decision Tree, and Naive Bayes. Among all the models, Random Forest shows the highest accuracy at 0.865, while SVM has the highest F1-score with 0.834, and KNN had the lowest accuracy of 0.823. In terms of precision, SVM has the best performance with 0.847, while Naive Bayes has the worst performance with 0.740. Additionally, SVM has the best recall, while Naive Bayes has the worst recall. Overall, the Random Forest model appears to be the most reliable, considering the multiple evaluation metrics performed."
491,"caption: Table 4: Model performance based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.89,0.80,0.91,0.85, KNN,0.84,0.78,0.83,0.77, Decision Tree,0.79,0.71,0.72,0.69, Naive Bayes,0.88,0.87,0.81,0.83, Random Forest,0.94,0.97,0.91,0.94","Table 4 presents a comparison of multiple models' performances based on various evaluation metrics, including Accuracy, Precision, Recall, and F1-Score. The results reveal that the Random Forest model shows the best overall performance with an accuracy of 0.94, Precision of 0.97, Recall of 0.91, and F1-Score of 0.94. SVM and Naive Bayes models also perform well with high Precision scores of 0.80 and 0.87, respectively. Interestingly, the KNN model had the lowest performance across all metrics, indicating it may not be the best model choice for this particular dataset."
492,"caption: Table 4: Performance Results of Different Models Using Various Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.859,0.846,0.876,0.860, Naive Bayes,0.764,0.752,0.829,0.774, Random Forest,0.948,0.945,0.950,0.947, Gradient Boosting,0.935,0.927,0.942,0.935, SVM,0.861,0.840,0.883,0.861","Table 4 presents the performances of five models measured using multiple evaluation metrics. The models tested include Logistic Regression, Naive Bayes, Random Forest, Gradient Boosting, and SVM. The evaluation metrics used to compare the models' performance include accuracy, precision, recall, and F1 score. Interestingly, the Random Forest model offers the best overall performance with an accuracy of 0.948, precision of 0.945, recall of 0.950, and F1 score of 0.947 compared to the other models. On the other hand, Naive Bayes has the lowest overall performance score with an accuracy of 0.764, precision of 0.752, recall of 0.829, and F1 score of 0.774. Moreover, SVM shows the highest recall score and the top third overall performer."
493,"caption: Model performance comparison using different evaluation metrics.table: Model name,Accuracy,Precision,Recall,F1-score, SVM,0.86,0.90,0.83,0.86, Random Forest,0.87,0.91,0.86,0.88, XGBoost,0.88,0.91,0.87,0.89, MLP,0.90,0.93,0.89,0.91, CNN,0.91,0.94,0.90,0.92","Table 1 presents a comparison of different machine learning models' performance using the Accuracy, Precision, Recall, and F1-score evaluation metrics. The table exhibits SVM, Random Forest, XGBoost, MLP, and CNN models' performance results. The MLP obtained the highest accuracy (0.90) compared to other models. The CNN achieved the highest Precision, Recall, and F1-score with scores of 0.94, 0.90, and 0.92, respectively. Notably, the Random Forest model performs better than other models in all evaluation metrics except for Precision and Recall."
494,"caption: Model performances based on different evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.832,0.820,0.777,0.867, Log. Regression,0.825,0.810,0.750,0.881, Random Forest,0.872,0.856,0.812,0.905, KNN,0.784,0.720,0.662,0.783, Naïve Bayes,0.750,0.700,0.646,0.755","The table shows the model performances based on different evaluation metrics, such as accuracy, F1-Score, precision, and recall. The table consists of five different models - SVM, Log. Regression, Random Forest, KNN, and Naïve Bayes. The Random Forest model shows the best performance in terms of accuracy, F1-Score, and recall with scores of 0.872, 0.856, and 0.905, respectively. The logistic regression model showed a slightly higher precision rate of 0.750 than Random Forest's 0.812. KNN and Naïve Bayes models have the lowest performance rates in all evaluation metrics. In conclusion, based on the table, the Random Forest model performed the best, followed closely by SVM and Logistic Regression models."
495,"caption: Table 4: Comparison of different models based on RMSE, R2 and MAE evaluation metrics.table: Model,RMSE,R2,MAE, Linear Regression,4.56,0.76,3.82, Decision Tree,5.23,0.67,4.01, Random Forest,4.31,0.79,3.57, XGBoost,4.12,0.82,3.44","Table 4 compares different models based on three evaluation metrics: RMSE, R2, and MAE. The table presents the performance results of Linear Regression, Decision Tree, Random Forest, and XGBoost models. The results show that XGBoost outperforms the other models with an RMSE of 4.12, R2 score of 0.82, and MAE value of 3.44. Random Forest and Linear Regression models follow closely with a close score on RMSE and MAE. However, XGBoost has a higher R2 score, indicating better goodness of fit than other models. The Decision Tree model exhibits the lowest R2 value and comparatively higher RMSE and MAE values, indicating poorer model performance than other models."
496,"caption: Table 4: Model performances on different evaluation metrics.table: Model,F1 Score,Accuracy,Precision,Recall,AUC, Logistic Regression,0.87,0.92,0.86,0.88,0.91, Decision Tree,0.78,0.81,0.76,0.81,0.67, Random Forest,0.90,0.91,0.89,0.91,0.92, KNN,0.73,0.79,0.71,0.75,0.75, SVM,0.84,0.88,0.83,0.86,0.89","Table 4 is a comparison of different models' performances based on various evaluation metrics. The models in the table include Logistic Regression, Decision Tree, Random Forest, KNN, and SVM. These models were evaluated using different evaluation metrics such as F1 score, Accuracy, Precision, Recall, and AUC. Interestingly, the Random Forest model achieved the highest scores for all the evaluation metrics, including F1 score, Accuracy, Precision, Recall, and AUC, making it the best-performing model in this comparison. The results show the importance of evaluating models based on multiple different evaluation metrics, as it can lead to a more comprehensive understanding of their performance."
497,"caption: Table 4: Model performance evaluation using precision, recall, and f1-scoretable: Model,Precision,Recall,F1-Score, Logistic Regression,0.76,0.82,0.78, Random Forest,0.81,0.78,0.80, Support Vector Classifier,0.79,0.81,0.80, Naive Bayes,0.64,0.75,0.69, Gradient Boosting,0.86,0.81,0.83","Table 4 compares the performance of multiple models using precision, recall, and f1-score evaluation metrics. The table shows the performance scores for Logistic Regression, Random Forest, Support Vector Classifier, Naive Bayes, and Gradient Boosting models in predicting the accuracy of the dataset. Among the models, Gradient Boosting model exhibits the highest performance results in terms of precision (0.86), recall (0.81), and f1-score (0.83). The other models show relatively good performance results as well, but the Gradient Boosting model shows the most promising results, making it an excellent choice for predicting the dataset's accuracy."
498,"caption: Evaluation metrics comparison of four different models.table: Metric,Model 1,Model 2,Model 3,Model 4, Accuracy,75.2%,86.8%,71.5%,54.3%, Precision,0.69,0.79,0.55,0.32, Recall,0.83,0.92,0.71,0.48, F1-Score,0.70,0.84,0.50,0.36","The table above compares multiple evaluation metrics for four different models. The metrics used for comparison were Accuracy, Precision, Recall, and F1-Score. Model 2 achieved the highest Accuracy (86.8%) and Precision (0.79) scores. Model 1 also showed decent accuracy with 75.2% and precision with 0.69. On the other hand, Model 4 shows the lowest performance results, with an accuracy of 54.3%, precision of 0.32, recall of 0.48, and an f1-score of 0.36. Overall, model 2 was the best performer based on the available evaluation metrics."
499,"caption: Model performance metrics for different classifierstable: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.85,0.84,0.87,0.85, Random Forest,0.90,0.89,0.91,0.90, SVM,0.83,0.82,0.84,0.83, Neural Network,0.92,0.91,0.93,0.92","Table above shows a comparison of different models' performance metrics in terms of accuracy, precision, recall, and F1-Score. The table exhibits Logistic Regression, Random Forest, SVM, and Neural Network classifiers. Notably, all models were trained and tested using the same dataset. The Neural Network model achieved the highest accuracy score of 0.92, while the Random Forest model achieved the best performance in precision, recall, and F1-Score with scores of 0.91, 0.91, and 0.90, respectively. It is interesting to note that SVM had the lowest performance scores in all four metrics, illustrating the importance of selecting the appropriate classifier for different tasks."
500,"caption: Table 4: Model evaluation metrics comparisontable: Model,Accuracy,Precision,Recall,F1_score, Logistic Regression,0.95,0.95,0.95,0.95, Random Forest,0.94,0.94,0.94,0.94, XGBoost,0.96,0.96,0.96,0.96, Decision Tree,0.91,0.91,0.91,0.91, SVM,0.89,0.89,0.89,0.89","Table 4 presents a comparison of different machine learning models' evaluation metrics. The table includes accuracy, precision, recall, and F1-score scores for different models, including Logistic Regression, Random Forest, XGBoost, Decision Tree, and SVM models."
501,"caption: Table 4: Performance comparison of five different models based on different evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, Random Forest,0.907,0.906,0.914,0.899, SVM,0.899,0.889,0.882,0.897, Logistic Regression,0.895,0.884,0.887,0.882, KNN,0.882,0.862,0.870,0.855, Naive Bayes,0.844,0.838,0.830,0.859","Table 4 presents a comparison of five different models' performances based on different evaluation metrics. The table exhibits the models' accuracy, F1-score, precision, and recall. The Random Forest model shows the best accuracy of 0.907, while SVM has the highest F1-score of 0.889. On the other hand, Logistic Regression model achieved the highest precision of 0.887, while KNN model has the highest recall of 0.855. Interestingly, the Naive Bayes model shows the lowest performance results in all evaluation metrics. Overall, the table highlights the need to evaluate models based on multiple metrics rather than relying on a single metric to evaluate model performance."
502,"caption: Table 1: Evaluation metrics for different modelstable: Model Name,Metrics,Result 1,Result 2,Result 3,Result 4, Model 1,F1-Score,0.9,0.86,0.93,0.91, AUC,0.69,0.81,0.78,0.75, Model 2,F1-Score,0.87,0.92,0.89,0.91, AUC,0.82,0.9,0.85,0.8, Model 3,F1-Score,0.93,0.95,0.91,0.92, AUC,0.87,0.93,0.88,0.85, Model 4,F1-Score,0.92,0.94,0.89,0.93, AUC,0.88,0.92,0.89,0.83","Table 1 presents the evaluation metrics for four different models, namely Model 1, Model 2, Model 3, and Model 4. The table displays the F1-Score and AUC metrics for each model. Model performances are shown through four different results for each metric. Interestingly, Model 3 shows the best F1-Score performance with scores ranging from 0.91 to 0.95, while Model 2 has the highest AUC results with scores between 0.82 and 0.9. Overall, the table highlights the varied model performances and the importance of selecting the most suitable evaluation metric for the intended application."
503,"caption: Performance comparison of different models based on multiple evaluation metrics.table: Model,F1-Score,Recall,Precision, SVM,0.787,0.788,0.786, Logistic Regression,0.803,0.808,0.798, Decision Tree,0.742,0.739,0.746, Random Forest,0.831,0.830,0.833, XGBoost,0.825,0.826,0.824","The above table illustrates a comparison of various machine learning models' performances based on multiple evaluation metrics. The models include SVM, Logistic Regression, Decision Tree, Random Forest and XGBoost. The evaluation metrics include F1-Score, Recall, and precision, each score indicating different performance parameters. Random Forest and XGBoost models show the highest F1-Score of 0.831 and 0.825, respectively, while the Decision Tree model has the lowest F1-Score of 0.742. Interestingly, all models perform nearly identically for recall and precision."
504,"caption: Table 4: Model performances using different evaluation metrics.table: Model,Accuracy,F1-score,AUROC,PR-AUC, Logistic Regression,0.90,0.85,0.91,0.72, Random Forest,0.92,0.87,0.92,0.79, Naive Bayes,0.82,0.76,0.91,0.63, Support Vector Machine,0.89,0.83,0.87,0.71","Table 4 exhibits the performance of four different models, including Logistic Regression, Random Forest, Naive Bayes, and Support Vector Machine, based on multiple evaluation metrics, including Accuracy, F1-Score, AUROC, and PR-AUC. The table shows that Random Forest achieved the highest accuracy of 0.92, whereas Naive Bayes reported the lowest accuracy of 0.82. In terms of F1-Score, Random Forest performed the best with a score of 0.87, and Naive Bayes had the lowest F1-Score of 0.76. The AUROC metric illustrates that Random Forest model has the best performance with a score of 0.92, while Support Vector Machine had the lowest score of 0.87. Notably, the Random Forest model reported the highest value for the PR-AUC of 0.79, while Naive Bayes reported the lowest value of 0.63."
505,"caption: Table 4: Model performance using different metrics.table: Model,Accuracy,F1 Score,Precision,Recall,Specificity, Logistic Regression,0.82,0.80,0.83,0.79,0.85, Decision Tree,0.73,0.71,0.72,0.70,0.76, Random Forest,0.87,0.85,0.87,0.84,0.90, Gradient Boosting,0.89,0.87,0.89,0.86,0.91, Support Vector Machine,0.80,0.77,0.81,0.75,0.85","Table 4 shows the comparison of different models' performances in a binary classification problem using different evaluation metrics, including accuracy, F1 score, precision, recall, and specificity. The models evaluated in the table include Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Support Vector Machine. The Gradient Boosting model outperformed the others in terms of accuracy, F1 score, precision, and recall, achieving values of 0.89, 0.87, 0.89, and 0.86, respectively. However, the Random Forest model had the best specificity at 0.90, highlighting its ability to predict the negative class correctly. Additionally, Logistic Regression had a good balance between precision and recall, achieving scores of 0.83 and 0.79, respectively."
506,"caption: Comparison of model performance using different evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score,AUC-ROC, SVM,0.86,0.87,0.84,0.86,0.92, k-NN,0.81,0.83,0.80,0.81,0.87, Naive Bayes,0.72,0.68,0.78,0.72,0.76, Decision Tree,0.78,0.77,0.76,0.76,0.83, Random Forest,0.84,0.85,0.83,0.84,0.91","Table above presents a comparison of different models based on multiple evaluation metrics. The models examined include SVM, k-NN, Naive Bayes, Decision Tree, and Random Forest. These models were evaluated based on the accuracy, precision, recall, F1-score, and AUC-ROC. Notably, the Random Forest and SVM models achieved the highest AUC-ROC scores of 0.91 and 0.92, respectively. Conversely, the Naive Bayes model performed poorly in comparison with the other models, obtaining the lowest AUC-ROC score of 0.76. Furthermore, the k-NN model had the lowest accuracy score of 0.81, while the Random Forest model displayed the highest accuracy of 0.84."
507,"caption: Results of different classification models on Test Datatable: Model,Precision,Recall,F1-Score,Accuracy, Model 1,0.80,0.75,0.77,0.85, Model 2,0.85,0.75,0.80,0.86, Model 3,0.90,0.80,0.85,0.88, Model 4,0.88,0.85,0.86,0.87","The table above presents an overview of multiple models' performances based on different evaluation metrics on a Test dataset. The models were evaluated using Precision, Recall, F1-Score and Accuracy metrics. The results show that Model 3 outperforms all the other models with a Precision score of 0.90, Recall of 0.80, F1-Score of 0.85, and Accuracy of 0.88. Interestingly, Model 2 has the highest precision value of 0.85, and Model 4 has the highest recall value of 0.85. Model 1, even though it has the lowest overall scores, still performs reasonably well with a Precision score of 0.8 and an Accuracy score of 0.85."
508,"caption: Table 4. Model evaluation results based on accuracy, F1-score, precision, recall, and AUC.table: Model,Accuracy (%),F1-Score,Precision,Recall,AUC, Model 1,80.5,0.71,0.65,0.80,0.85, Model 2,83.2,0.75,0.69,0.85,0.88, Model 3,88.2,0.80,0.75,0.85,0.92, Model 4,85.7,0.78,0.71,0.87,0.89, Model 5,89.5,0.82,0.79,0.85,0.94","Table 4 shows the model evaluation results using different evaluation metrics: accuracy, F1-score, precision, recall, and AUC. The table displays 5 different models with their respective performance scores. Model 5 performed the best in all evaluation metrics, achieving an accuracy of 89.5%, F1-score of 0.82, precision of 0.79, recall of 0.85, and AUC of 0.94. Interestingly, Model 1 had a relatively low F1-score of 0.71, whereas Model 3 had the highest AUC of 0.92. Among the models, Model 2 had the highest accuracy score of 83.2%, while Model 1 had the lowest accuracy of 80.5%."
509,"caption: Model Performance on a Binary Classification Tasktable: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.87,0.88,0.85,0.91, KNN,0.81,0.82,0.80,0.83, Decision Tree,0.66,0.60,0.64,0.57, Random Forest,0.90,0.91,0.87,0.94, Naive Bayes,0.75,0.70,0.77,0.64","Table 1 reveals a comparison of different machine learning classifiers' performance on a binary classification task based on multiple evaluation metrics, including accuracy, F1-score, Precision, and Recall. The classifiers include SVM, KNN, Decision Tree, Random Forest, and Naive Bayes, which were trained and tested on the same dataset. The Random Forest model outperforms all other models in all metrics, with the highest accuracy of 0.90, F1-score of 0.91, precision of 0.87, and recall of 0.94. The SVM model produces the second-best result, with a balanced combination of accuracy, F1-score, precision, and recall. The Decision Tree and Naive Bayes result indicates the lowest accuracy and F1-score, indicating their limited usefulness in this classification task."
510,"caption: Model Evaluation Metrics for Classification Tasktable: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.86,0.84,0.78,0.81, Random Forest,0.88,0.86,0.84,0.85, SVM,0.91,0.90,0.88,0.89, Multi-layer Perceptron,0.85,0.82,0.81,0.81","The table presents model evaluation metrics for a classification task. Accuracy, Precision, Recall, and F1 Score were used to evaluate the performance of the Logistic Regression, Random Forest, SVM, and Multi-layer Perceptron models. The SVM model achieved the highest accuracy with a score of 0.91, while the Logistic Regression model had the lowest accuracy of 0.86. On the other hand, the Random Forest model produces the highest Precision score of 0.86 and Recall score 0.84. Notably, the SVM model also produced an excellent Precision score of 0.90 and Recall score of 0.88. Therefore, the Random Forrest and SVM models demonstrate the best trade-off between Precision, and Recall for the task."
511,"caption: Model performances using different metrics.table: Model,F1-Score,Accuracy,Precision,Recall, SVM with RBF kernel,0.80,0.74,0.77,0.84, Naïve Bayes,0.73,0.68,0.71,0.75, Random Forest,0.85,0.80,0.83,0.88, XGBoost,0.87,0.83,0.85,0.89, LightGBM,0.88,0.82,0.84,0.93","Table 4 shows the F1-score, accuracy, precision, and recall performance of different models namely Support Vector Machines (SVM) with a Radial Basis Function (RBF) kernel, Naïve Bayes, Random Forest, XGBoost, and LightGBM. The models were evaluated using the same dataset, and each model's performance was computed for each evaluation metric. From the table, LightGBM has the highest F1-score of 0.88, and a high recall value of 0.93, despite a slight decrease in accuracy compared to some models. On the other hand, XGBoost performed well in F1-score (0.87), accuracy (0.83), precision (0.85), and recall (0.89). Overall, the models demonstrate different strengths in the various evaluation metrics highlighting the importance of selecting evaluation metric(s) that match the task at hand to choose the best-performing model."
512,"caption: Model performance of logistic regression, decision tree, random forest, and XGBoost based on accuracy, F1-score, precision, recall, and AUC-ROC.table: Model,Accuracy,F1-score,Precision,Recall,AUC-ROC, Logistic Regression,0.75,0.70,0.78,0.66,0.82, Decision Tree,0.69,0.65,0.68,0.62,0.74, Random Forest,0.81,0.77,0.85,0.71,0.88, XGBoost,0.82,0.79,0.87,0.73,0.90","Table presented above summarises the performances of four models: logistic regression, decision tree, random forest, and XGBoost. The table presents evaluation metrics for classification models,including accuracy, F1-score, precision, recall, and AUC-ROC. Notably, the XGBoost model obtained the best results in accuracy, F1-score, precision, recall, and AUC-ROC. The results for Random forest are close with the AUC-ROC of 0.88. Meanwhile, the logistic regression model had the lowest accuracy at 0.75, while the decision tree model had the lowest AUC-ROC at 0.74. Overall, the table illustrates different models and metrics that are useful for comparing classification models' performance."
513,"caption: Table 4: Model performance based on different evaluation metrics on the test datatable: Model,Accuracy (%),F1 Score,Precision,Recall, SVM,88.2,0.812,0.791,0.834, Logistic Regression,89.7,0.821,0.805,0.837, Random Forest,91.5,0.844,0.847,0.842, K-Nearest Neighbors,87.1,0.803,0.779,0.828","Table 4 presents model performance based on different evaluation metrics on the test data. The table displays the accuracy, F1 score, precision, and recall of the SVM, Logistic Regression, Random Forest, and K-Nearest Neighbors models. Notably, all models were trained and tested on the same dataset. The Random Forest model demonstrates the best accuracy, F1 score, and Recall, with scores of 91.5%, 0.844 and 0.842 correspondingly. Interestingly, the Logistic Regression model had the highest precision score of 0.805. The SVM model shows a good overall performance with an accuracy score of 88.2%. On the other hand, the K-Nearest Neighbors model shows the lowest overall performance, with an accuracy score of 87.1%."
514,"caption: Table 4: Comparative performance metrics of different models.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.78,0.72,0.67,0.78, Naive Bayes,0.64,0.44,0.78,0.32, Logistic Regression,0.81,0.74,0.72,0.76, Decision Tree,0.73,0.68,0.57,0.84, Random Forest,0.85,0.83,0.80,0.87","Table 4 compares the performance metrics (Accuracy, F1 Score, Precision and Recall) of different models, including SVM, Naive Bayes, Logistic Regression, Decision Tree, and Random Forest. The table shows that the Random Forest model performs best, achieving an accuracy score of 0.85, F1 Score of 0.83, Precision of 0.80, and Recall of 0.87. On the other hand, Naive Bayes has the lowest Accuracy score of 0.64, while Decision Tree has the lowest Precision score of 0.57. Additionally, Logistic Regression has the best Precision score of 0.72. Therefore, it can be concluded that the Random Forest model is the best-performing model based on these performance metrics."
515,"caption: Table 4: Model Performance Comparison based on Accuracy, F1 Score, and Precision metricstable: Model,Accuracy,F1 Score,Precision, A,0.85,0.84,0.88, B,0.86,0.87,0.83, C,0.84,0.83,0.87, D,0.87,0.88,0.88","Table 4 showcases a comparison of the performance of different models based on Accuracy, F1 Score, and Precision metrics. Model A shows the highest Precision score of 0.88 and Accuracy score of 0.85, while Model D achieved the highest F1 Score of 0.88 and an Accuracy score of 0.87. Model B outperforms all other models with a high F1 Score of 0.87, while Model C shows the lowest performance in all three metrics. Overall, the table suggests that Model B and D are the most well-performing models based on the given metrics."
516,"caption: Table 4: Model evaluation metrics on the test set with different classifiers.table: Model,Precision,Recall,F1-score,Accuracy, LR,0.85,0.56,0.67,0.82, SVM,0.89,0.62,0.72,0.83, KNN,0.92,0.79,0.85,0.88, RF,0.94,0.82,0.87,0.90, XGB,0.93,0.84,0.88,0.91","Table 4 provides the evaluation metrics on the test set with five distinct classifiers including Logistic Regression (LR), Support Vector Machines (SVM), K-Nearest Neighbors (KNN), Random Forest (RF), and Extreme Gradient Boosting (XGB). The evaluation metrics presented include Precision, Recall, F1-score, and Accuracy. Every model was trained and evaluated on the same dataset. The Random Forest classifier outperformed other algorithms with the highest precision score of 0.94, recall of 0.82, F1-score of 0.87, and accuracy of 0.90. The KNN classifier also demonstrated good performance, achieving high precision, recall, F1-score, and accuracy. The SVM and XGB classifiers achieved comparable results with decent precision, recall, F1-score, and accuracy in contrast to LR's performance across all metrics."
517,"caption: Performances of different models on multiple evaluation metrics.table: Model Name,Precision (P),Recall (R),F1-score,AUC, Model 1,0.7,0.6,0.65,0.75, Model 2,0.8,0.75,0.77,0.81, Model 3,0.92,0.87,0.89,0.93, Model 4,0.82,0.91,0.86,0.88, Model 5,0.94,0.92,0.93,0.96","The table above shows the performance of different models on multiple evaluation metrics, including Precision (P), Recall (R), F1-score, and AUC. Model 1 achieved a moderate F1-score and AUC of 0.65 and 0.75, respectively. Model 2 performed slightly better than Model 1 with a significantly better AUC of 0.81. Model 3 shows a superior performance compared to other models with the highest precision, recall, F1-score, and AUC of 0.92, 0.87, 0.89, and 0.93, respectively. Model 4 achieved a lower recall but higher precision and F1-score compared to Model 2. Lastly, Model 5 performed well in all metrics, and it shows the highest precision, recall, and F1-score of 0.94, 0.92, and 0.93, respectively, with the highest AUC of 0.96."
518,"caption: Table 4: Model comparison based on various evaluation metrics.table: Model Name,Accuracy,F1 Score (macro),Precision (positive class),Recall (positive class),AUC-ROC, Model 1,0.85,0.82,0.87,0.79,0.92, Model 2,0.86,0.85,0.88,0.82,0.93, Model 3,0.84,0.80,0.85,0.76,0.91, Model 4,0.87,0.86,0.89,0.83,0.94, Model 5,0.85,0.83,0.87,0.80,0.92","Table 4 compares the performance of five different models based on multiple evaluation metrics. The models are evaluated using Accuracy, F1 Score(macro), Precision(positive class), Recall(positive class), and AUC-ROC performance metrics. It can be observed that Model 4 obtained the highest performance over all metrics except for Accuracy where Model 2 performed slightly better. On the other hand, Model 3 scored the lowest performance on all metrics, indicating the need to revisit the model architecture. Overall, the results suggest that Model 4 has the highest potential to be used as the final model for this task."
519,"caption: Performance Metrics for Different Modelstable: Model,Accuracy,F1 Score,Precision,Recall,AUC Score, Model 1,0.85,0.81,0.84,0.88,0.90, Model 2,0.86,0.79,0.78,0.86,0.89, Model 3,0.87,0.82,0.85,0.87,0.91, Model 4,0.83,0.80,0.82,0.85,0.87, Model 5,0.89,0.84,0.87,0.91,0.92","The table presents a comparison of different models' evaluation metrics. The models are evaluated based on Accuracy, F1 Score, Precision, Recall, and AUC Score. Model 5 shows the most optimal results for all evaluation metrics, achieving the highest values of Accuracy (0.89), F1 score (0.84), Precision (0.87), Recall (0.91), and AUC Score (0.92). On the other hand, Model 2 had a relatively lower F1 score and Precision value, while Model 4 had a lower AUC Score and Accuracy. Therefore, Model 5 can be considered the best performing model among the presented models based on the evaluated metrics."
520,"caption: Table 4: Model performances based on different evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall,AUC, Logistic Regression,0.86,0.83,0.83,0.84,0.92, Random Forest,0.88,0.85,0.87,0.84,0.91, SVM,0.89,0.87,0.88,0.87,0.92, Decision Tree,0.81,0.78,0.77,0.79,0.85, XGBoost,0.90,0.88,0.89,0.87,0.93","Table 4 summarizes the performances of various models, such as Logistic Regression, Random Forest, SVM, Decision Tree, and XGBoost, using multiple evaluation metrics, including Accuracy, F1 Score, Precision, Recall, and AUC. The models were tested on the same dataset, and SVM recorded the highest Accuracy rate of 0.89 among all the models, followed by XGBoost with an Accuracy of 0.90. On the other hand, Decision Tree performed poorest in terms of the evaluation metrics with the lowest Accuracy of 0.81 and the AUC score of 0.85. The Random Forest model also showed compelling performances conforming to the other well-known models in the ensemble of classifiers."
521,"caption: Model evaluation metrics for classification task.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.82,0.80,0.82,0.78, KNN,0.73,0.67,0.68,0.69, Decision Tree,0.85,0.84,0.86,0.82, Random Forest,0.87,0.85,0.89,0.82, Gradient Boosting,0.86,0.85,0.86,0.85","The table presents different models' performances using multiple evaluation metrics. The models considered in the table are SVM, KNN, Decision Tree, Random Forest, and Gradient Boosting. The evaluation metrics used are Accuracy, F1 Score, Precision, and Recall. All models were trained and tested on the same dataset, and their corresponding accuracy scores range from 0.73 to 0.87. Furthermore, F1 scores range from 0.67 to 0.85, and Precision scores range from 0.68 to 0.89. The Decision Tree model had the highest accuracy and precision score, 0.85, and 0.86, respectively. Conversely, the Random Forest model had the highest F1 score of 0.85."
522,"caption: Table 4: Model performance based on different evaluation metricstable: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.89,0.88,0.90,0.86, Naive Bayes,0.82,0.81,0.86,0.77, Random Forest,0.95,0.95,0.96,0.94, XGBoost,0.96,0.96,0.97,0.95","Table 4 reports the performance of four models based on different evaluation metrics: Accuracy, F1 Score, Precision, and Recall. The models used in the experiment are Logistic Regression, Naive Bayes, Random Forest, and XGBoost. The highest F1 Score and Accuracy were achieved by the XGBoost model with a score of 0.96. The Random Forest and XGBoost models outperformed the Logistic Regression and Naive Bayes across all evaluation metrics. The Random Forest model achieved the highest Precision with a score of 0.96, while the XGBoost achieved the highest Recall score with a value of 0.95."
523,"caption: Model Performance Comparison using various metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Random Forest,0.98,0.98,0.98,0.98, SVM,0.95,0.95,0.92,0.93, KNN,0.87,0.87,0.83,0.84, Decision Tree,0.92,0.92,0.91,0.91, Naive Bayes,0.76,0.81,0.62,0.63, Neural Network,0.99,0.99,0.99,0.99","The table depicts the performance comparison of six different classification models concerning various evaluation metrics. The metrics used are Accuracy, Precision, Recall, and F1-Score. The best-performing model overall is the Neural Network model with the highest Accuracy, Precision, Recall, and F1-Score of 0.99. The Random Forest model also exhibits excellent performance with an overall Accuracy, Precision, Recall, and F1-Score of 0.98. The Naive Bayes model, on the other hand, has the weakest performance overall, with an F1-Score of only 0.63. Overall, the table provides a useful comparison of model performances using various metrics."
524,"caption: Comparison of different models' performance based on multiple evaluation metricstable: Model,Accuracy,F1 Score,Precision,Recall, LR,0.92,0.95,0.89,1.00, KNN,0.85,0.90,0.85,0.98, SVM,0.90,0.94,0.88,1.00, RF,0.96,0.97,0.96,0.98, XGB,0.95,0.97,0.96,0.97","Table above compares different models based on their accuracy, F1 score, precision, and recall metrics. The table includes Logistic Regression (LR), K-Nearest Neighbor (KNN), Support Vector Machine (SVM), Random Forest (RF), and Extreme Gradient Boosting (XGB) models. Notably, the Random Forest model achieved the highest accuracy of 0.96, while all models achieved high accuracy scores ranging from 0.85 to 0.96. However, the LR, SVM, and XGB models demonstrated the same precision scores of 0.96, indicating that these models made fewer false-positive predictions. The SVM and LR models achieved a perfect recall score of 1.00, indicating that these models could predict all actual positive cases correctly. The F1 score shows how well the model balances precision and recall. The KNN model obtained a lower F1 score of 0.90, while all other models achieved F1 scores ranging from 0.94 to 0.97, indicating their effectiveness in balancing precision and recall."
525,"caption: Model performances based on different evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.87,0.81,0.87,0.89, Decision Tree,0.78,0.74,0.81,0.69, Random Forest,0.91,0.87,0.91,0.94, Support Vector Machine,0.84,0.77,0.84,0.81, K-Nearest Neighbor,0.76,0.72,0.76,0.70","The table presents an evaluation of multiple models based on various metrics like accuracy, F1 score, precision, and recall. The models evaluated were Logistic Regression, Decision Tree, Random Forest, Support Vector Machine, and K-Nearest Neighbor. The Random Forest model achieved the highest accuracy of 0.91, followed closely by Logistic Regression's accuracy of 0.87. Similarly, the Random Forest model had the highest F1 score of 0.87 and Recall score of 0.94. The Decision Tree model had the lowest scores for all metrics, with an accuracy of 0.78 and F1 score of 0.74. Overall, the Random Forest model outperformed the other models in most metrics."
526,"caption: Table 1: Model performances based on different evaluation metrics.table: Model,F1 Score,Precision,Recall,Specificity, Logistic Regression,0.82,0.83,0.81,0.86, Random Forest,0.84,0.87,0.81,0.89, Support Vector Machine,0.80,0.84,0.77,0.84, Gradient Boosting,0.83,0.87,0.80,0.88","Table 1 compares different models' performances based on various evaluation metrics, including F1 Score, Precision, Recall, and Specificity. The table shows that the Random Forest model performs the best in terms of F1 Score, achieving a score of 0.84. On the other hand, the Support Vector Machine model has the lowest F1 Score of 0.80. The Precision score is highest for the Random Forest model (0.87), while it is lowest in the Logistic Regression model (0.83). The Recall score is highest for the Random Forest model (0.81) and lowest in the Support Vector Machine model (0.77). Finally, the Specificity score is the highest for the Random Forest model (0.89), while it is lowest in the Support Vector Machine model (0.84). Overall, the Random Forest model seems to have the best performance across various evaluation metrics."
527,"caption: Comparison of different models based on multiple evaluation metrics.table: Model,F1-score,Precision,Recall,Accuracy, Model 1,0.85,0.80,0.90,0.90, Model 2,0.87,0.84,0.91,0.88, Model 3,0.92,0.87,0.98,0.85, Model 4,0.83,0.81,0.85,0.84, Model 5,0.91,0.88,0.94,0.87","Table above shows the performance of five different models on multiple evaluation metrics. These evaluation metrics are F1-score, Precision, Recall, and Accuracy. Model 3 has the highest F1-score among all models with a score of 0.92. Meanwhile, Model 2 has the second-highest F1-score of 0.87, followed by Model 5 with a score of 0.91. Model 3 has the highest Recall score of 0.98, while Model 1 has the lowest Recall score of 0.90. Model 5 has the highest Precision score of 0.88, whereas Model 3 has the lowest Precision score of 0.87. Further, Model 1 has the highest Accuracy score of 0.90, while Model 3 has the lowest Accuracy score of 0.85. Therefore, it can be concluded that different models perform differently on various evaluation metrics."
528,"caption: Comparison of Machine Learning Modelstable: Model,Accuracy,Precision,Recall,F1-Score, Logistic Reg.,0.75,0.77,0.71,0.74, Decision Tree,0.61,0.55,0.62,0.58, Random Forest,0.81,0.82,0.78,0.80, K-NN,0.69,0.68,0.74,0.71, Naive Bayes,0.72,0.79,0.61,0.68","Table one shows a comparison between five different machine learning models. The models' accuracy, precision, recall, and F1-Score metrics are recorded, and comparisons are made based on these results. A logistic regression model achieved the highest accuracy with a score of 0.75. However, the Random Forest model achieved the best result in precision, recall, and F1-Score metrics, with scores of 0.82, 0.78, and 0.80, respectively. In contrast, the Decision Tree model generated the lowest scores in all metrics, while the Naive Bayes model had a relatively low recall score. Overall, the Random Forest model can be considered the best performer."
529,"caption: Table 4: Model performance comparison on the classification task for a binary dataset using different algorithms based on Precision, Recall, F1-Score, Accuracy, AUC-ROC, and PR-AUC evaluation metrics.table: Model Name,Precision,Recall,F1-Score,Accuracy,AUC-ROC,PR-AUC, Logistic Regression,0.78,0.82,0.80,0.75,0.82,0.74, Decision Tree,0.75,0.76,0.75,0.71,0.76,0.69, Random Forest,0.81,0.84,0.83,0.79,0.85,0.78, Gradient Boosting,0.82,0.83,0.82,0.78,0.84,0.76, Support Vector Machine,0.84,0.87,0.85,0.81,0.87,0.80","Table 4 exhibits the model performance comparison results amongst several algorithms used for a binary classification task. The performance measures considered here are Precision, Recall, F1-Score, Accuracy, AUC-ROC, and PR-AUC. The classification algorithms considered in this table are Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Support Vector Machine. Notably, Support Vector Machine (SVM) demonstrated the highest Precision and Recall results of 0.84 and 0.87, respectively, while the highest F1-Score and AUC-ROC were achieved by the Random Forest with 0.83 and 0.85, respectively. Interestingly, Logistic Regression showed the highest accuracy with 0.75."
530,"caption: Performance of Various Models on the Test Settable: Models,Precision,Recall,F1 Score,Accuracy, Logistic Regression,0.85,0.78,0.80,0.89, Decision Tree,0.78,0.72,0.73,0.82, Random Forest,0.92,0.88,0.89,0.93, Support Vector Machine,0.89,0.83,0.85,0.90","The table reports the performance of four models on a test dataset. The evaluation metrics presented are precision, recall, F1 score, and accuracy. The highest precision score is achieved by Random Forest model (0.92). The Logistic regression model achieved a competitive precision score of 0.85. The Decision Tree model achieved the lowest precision score. The Random Forest model also produces the highest recall score (0.88) and F1 score (0.89). Support Vector Machine model produces an F1 score of 0.85. However, Random Forest model achieved the highest accuracy score (0.93)."
531,"caption: Comparison of model performances using multiple metrics.table: Model 1,Model 2,Model 3, Metric 1,0.78,0.84,0.91, Metric 2,0.64,0.71,0.89, Metric 3,0.82,0.83,0.87, Metric 4,0.52,0.76,0.91","Table presents the performance scores of three different models on four evaluation metrics. Model 1 has the lowest scores across all metrics, while Model 2 exhibits the highest Metric 4 score of 0.76. Interestingly, Model 3 outperforms the other models in Metric 1, Metric 2, and Metric 4, with scores of 0.91, 0.89, and 0.91, respectively. The highest score in Metric 3 is achieved by Model 2 with a score of 0.83. The table's results suggest that Model 3 is the best overall performer, while Model 2 has a particular skill in Metric 3."
532,"caption: Table 4: Performance results of different models based on multiple evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall,AUC, Model A,0.82,0.78,0.75,0.81,0.89, Model B,0.77,0.70,0.66,0.73,0.84, Model C,0.84,0.79,0.76,0.82,0.91, Model D,0.80,0.75,0.71,0.77,0.88, Model E,0.89,0.85,0.82,0.88,0.94","Table 4 displays the performance results of five different models in terms of accuracy, F1 score, precision, recall, and AUC. The models were tested using the same dataset, and the evaluation metrics were calculated based on the model's prediction results. Notably, Model E has the highest performance metric scores in all the evaluation metrics, including accuracy (0.89), F1 score (0.85), precision (0.82), recall (0.88), and AUC (0.94). However, Model C and Model A also display promising results with accuracy scores of 0.84 and 0.82 and AUC scores of 0.91 and 0.89, respectively."
533,"caption: Table 4. Model performances on different metricstable: Models,Accuracy,Precision,F1-Score,Recall, Random Forest,0.925,0.902,0.921,0.904, SVM (RBF),0.908,0.815,0.828,0.848, MLP,0.941,0.932,0.937,0.926, Logistic Regression (balanced),0.886,0.705,0.758,0.847, Logistic Regression,0.932,0.912,0.925,0.918","Table 4 presents the performances of different models on various evaluation metrics. The models include Random Forest, SVM (RBF), MLP, Logistic Regression (balanced), and Logistic Regression. The evaluation metrics comprise Accuracy, Precision, F1-score, and Recall. Interestingly, MLP performed the best with an accuracy of 0.941, precision of 0.932, F1-score of 0.937, and recall of 0.926. While Logistic Regression achieved the highest precision at 0.912 and Random Forest had the highest recall at 0.904. The Logistic Regression (balanced) model had a lower accuracy of 0.886 but had the highest recall at 0.847, indicating a valuable model in specific applications."
534,"caption: Table 4. Performance of Different Models on Evaluation Metricstable: Model name,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.92,0.88,0.91,0.86, Random Forest Classifier,0.95,0.93,0.94,0.92, Support Vector Machine,0.89,0.84,0.87,0.81, Multi-Layer Perceptron,0.93,0.90,0.92,0.88","Table 4 presents the performance of different models on evaluation metrics, including Accuracy, F1-Score, Precision, and Recall. The table includes Logistic Regression, Random Forest Classifier, Support Vector Machine, and Multi-Layer Perceptron models. The Random Forest Classifier has achieved the highest Accuracy with a score of 0.95, while the Support Vector Machine has the lowest Accuracy of 0.89. The Random Forest Classifier has also shown the highest precision and recall scores with 0.94 and 0.92, respectively. Overall, the Random Forest Classifier seems to perform better than other models followed by the Multi-Layer Perceptron model."
535,"caption: Comparison of Model Performances Based on Precision, Recall, and F1 Scoretable: Model Name,Precision,Recall,F1 Score, Model A,0.75,0.86,0.80, Model B,0.81,0.78,0.79, Model C,0.70,0.92,0.79, Model D,0.82,0.81,0.81, Model E,0.73,0.11,0.19","The table above compares the performances of five different models based on their Precision, Recall, and F1 scores. From the five models compared in the table, Model D shows the best F1 score of 0.81, indicating higher precision and recall ratios. However, in terms of Precision, Model B had the highest score of 0.81, performing reasonably well compared to other models. Surprisingly, Model E performed poorly with the lowest precision and recall scores, implying that it is not the best choice for the evaluations."
536,"caption: Table 4: Model performance comparison based on multiple evaluation metricstable: Model,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.89,0.88,0.90,0.85, Random Forest,0.92,0.90,0.91,0.90, AdaBoost Classifier,0.90,0.88,0.92,0.85, Gradient Boosting Classifier,0.91,0.89,0.92,0.87, XGBoost Classifier,0.92,0.90,0.91,0.90","Table 4 showcases the comparison of five different machine learning models' performances based on multiple evaluation metrics, including Accuracy, F1-Score, Precision, and Recall. The table demonstrates that all models achieved high accuracy, with Random Forest and XGBoost Classifier recording the highest of 0.92 and all models scoring above 0.88 F1-Score. Notably, Random Forest performed the best on precision with a score of 0.91, while the AdaBoost Classifier achieved the lowest Recall score of 0.85. Overall, the table highlights the differences in model performances based on different evaluation metrics, with Random Forest and XGBoost Classifier being the two best performing models across all metrics."
537,"caption: Comparison of different models' classification performancestable: Model,Acc,F1,Precision,Recall, SVM,0.85,0.83,0.90,0.78, Random Forest,0.84,0.82,0.89,0.77, Decision Tree,0.81,0.78,0.86,0.71, Neural Network,0.86,0.85,0.89,0.81, KNN,0.73,0.71,0.89,0.59","The performance of five different classification models (SVM, Random Forest, Decision Tree, Neural Network, and KNN) was evaluated using the evaluation metrics: Accuracy, F1 score, Precision, and Recall. The table reveals that the highest classification accuracy is attained by Neural Network with an accuracy of 0.86. By contrast, KNN model had the lowest accuracy of 0.73. In F1 score, Neural Network also performs relatively better with a score of 0.85, compared to KNN, which had the lowest score of 0.71. Interestingly, the KNN model exhibit the highest Precision of 0.89, whereas its lowest Recall of 0.59 shows that it recognizes fewer actual positive cases. In comparison, the SVM and Random Forest models have similar performance with moderate Precision and Recall. The Decision Tree model depicts the poorest performance overall from all the models."
538,"caption: Comparison of performance metrics for different models.table: Model,F1-score (class 0),Precision (class 1),Recall (class 2),Accuracy, SVM,0.84,0.67,0.78,0.85, KNN,0.79,0.45,0.91,0.81, Logistic Regression,0.82,0.55,0.77,0.83, Decision Tree,0.69,0.59,0.74,0.72, Gradient Boosting,0.87,0.78,0.89,0.88","The table compares the F1-score, Precision, Recall, and Accuracy of different models, including SVM, KNN, Logistic Regression, Decision Tree, and Gradient Boosting. The SVM model shows the highest F1-score of 0.84 in class 0, while the Gradient Boosting model demonstrates the highest F1-score of 0.87 overall. Moreover, the Gradient Boosting model achieves the highest accuracy score of 0.88. However, the KNN model attained the highest precision score of 0.45 in class 1. Interestingly, the KNN model also had the highest Recall score of 0.91 in class 2. The Decision Tree model had the lowest performance metrics compared to other models. Overall, the table highlights the varied performance and effectiveness of machine learning models in different situations."
539,"caption: Model performances for different classifiers based on multiple evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.89,0.91,0.90,0.92, KNN,0.82,0.83,0.81,0.85, Random forest,0.92,0.93,0.92,0.93, XGBoost,0.91,0.92,0.91,0.93, MLP,0.86,0.87,0.86,0.88, Naive Bayes,0.75,0.66,0.76,0.57","Table 1 lists different classifiers' performance based on multiple evaluation metrics such as accuracy, F1-Score, Precision, and Recall. The table displays the model performances of SVM, KNN, Random forest, XGBoost, MLP, and Naive Bayes for a specific dataset. Random forest achieved the highest accuracy score of 0.92, followed by XGBoost and SVM with an accuracy of 0.91 and 0.89, respectively. The Naive Bayes model achieved the lowest performance. Notably, Random forest and XGBoost models have higher F1-Scores, Precision, and Recall than other classifiers, which indicates that these models' overall performance is better. However, SVM achieved the highest Precision score of 0.90, while Random forest and XGBoost have relatively high Recall scores."
540,"caption: Classification model performance comparison using multiple evaluation metrics.table: Model,Accuracy,Recall,Precision,F1-score, Support Vector Machine,0.87,0.89,0.85,0.87, Multilayer Perceptron,0.85,0.88,0.78,0.83, Decision Tree,0.73,0.51,0.45,0.48, Naïve Bayes,0.82,0.77,0.91,0.83, Logistic Regression,0.88,0.90,0.89,0.89","This table compares different classification models' performance in binary classification tasks using multiple evaluation metrics, including Accuracy, Recall, Precision, and F1-score. The models evaluated are Support Vector Machine, Multilayer Perceptron, Decision Tree, Naïve Bayes, and Logistic Regression. The Support Vector Machine and Logistic Regression models outperformed the other models in all the evaluation metrics. The Decision Tree model's accuracy, recall, and precision scores were considerably lower than the other models, while the Naïve Bayes model had the best precision score. In conclusion, the Support Vector Machine and the Logistic Regression models display the best performance across all metrics for this experiment's binary classification task."
541,"caption: Performance comparison of different models based on Accuracy, F1 Score, and AUC.table: Model,Accuracy,F1 Score,AUC, SVM,0.78,0.75,0.83, KNN,0.72,0.70,0.77, LR,0.82,0.79,0.85, DT,0.70,0.72,0.63, RF,0.83,0.82,0.88, XGBoost,0.84,0.82,0.87","The table presents a comparison of different models' performances based on Accuracy, F1 Score, and AUC. The table shows the results for Support Vector Machine (SVM), K-Nearest Neighbors (KNN), Logistic Regression (LR), Decision Tree (DT), Random Forests (RF), and XGBoost models. Notably, the Random Forests model has the highest accuracy of 0.83, followed closely by the XGBoost model at 0.84. In contrast, the KNN model has the lowest accuracy of 0.72. The F1 score shows that the Random Forests and XGBoost models have the best performance with a score of 0.82. However, the SVM, LR, and DT models have low F1 scores. The AUC indicates that the RF model has the highest performance of 0.88, while the DT model has the lowest with 0.63. The results suggest that the RF and XGBoost models could be the best performing models for the given dataset, considering the different evaluation metrics."
542,"caption: Performance of different models using multiple evaluation metricstable: Model,Accuracy (±std),F1 (±std),AUC (±std), Logistic Regression,0.84±0.01,0.85±0.02,0.81±0.03, Support Vector Machine,0.87±0.02,0.88±0.01,0.84±0.02, Random Forest,0.91±0.01,0.90±0.01,0.89±0.02, XGBoost,0.92±0.01,0.91±0.01,0.90±0.02","The table presents the accuracy, F1 score, and AUC of four different models: Logistic Regression, Support Vector Machine, Random Forest, and XGBoost. All the models were trained and tested on the same dataset, and the table shows their mean scores with standard deviations. Notably, Random Forest and XGBoost outperform the other models in accuracy, F1 score, and AUC. The Support Vector Machine has the second-best scores among all models. These results indicate that ensemble models such as Random Forest and XGBoost are effective in achieving better model performance compared to simpler models such as Logistic Regression and Support Vector Machine."
543,"caption: Comparison of different models based on multiple evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, A,0.85,0.85,0.83,0.87, B,0.91,0.89,0.88,0.90, C,0.79,0.80,0.75,0.85, D,0.87,0.88,0.84,0.92, E,0.93,0.92,0.91,0.93","Table presents the models' accuracy, F1-score, precision, and recall evaluation metrics. Model A has the second-lowest performance in accuracy, F1-score, and precision metrics, with an accuracy of 0.85, F1-score of 0.85, and precision of 0.83. Model B shows the highest metrics in accuracy, F1-score, and precision, with a score of 0.91, 0.89, and 0.88, respectively. However, the recall metric for model B is the second-lowest with a value of 0.90. Model C demonstrates the lowest metrics in accuracy, F1-score, precision, and recall, with a score of 0.79, 0.80, 0.75, and 0.85, respectively. Model D has an accuracy of 0.87, F1-score of 0.88, precision of 0.84, and recall of 0.92. Lastly, Model E shows the best performance in all evaluation metrics with a score of 0.93 for accuracy, 0.92 for F1-score, 0.91 for precision, and 0.93 for recall."
544,"caption: Table 4: Performance comparison of different modelstable: Models,Precision,Recall,F1-Score,Accuracy, Model A,0.85,0.72,0.78,0.82, Model B,0.81,0.78,0.79,0.86, Model C,0.78,0.85,0.74,0.81, Model D,0.87,0.69,0.77,0.83, Model E,0.75,0.81,0.78,0.76","Table 4 presents the performance analysis of various models based on different evaluation metrics, such as precision, recall, F1-Score, and overall accuracy. The table includes Model A, B, C, D, and E. Notably, Model B shows the best F1-score (0.79) with 0.81 and 0.78 precision and recall scores, respectively. Model A has the highest precision score of 0.85, while Model D has the highest recall score of 0.69. Accuracy scores of the models range between 0.76 to 0.86. Based on the evaluation metrics, Model B appears to perform better than the other models."
545,"caption: Model performance on different evaluation metricstable: Model,Accuracy,Kappa,F1-score, SVM,0.89,0.76,0.81, Naive Bayes,0.86,0.73,0.76, Decision Tree,0.76,0.55,0.66, MLP,0.92,0.81,0.87","The table shows the comparative evaluation metrics of multiple models: SVM, Naive Bayes, Decision Tree, and MLP. The models are assessed based on their accuracy, kappa, and F1-score. Notably, the MLP model shows the highest accuracy of 0.92, kappa of 0.81, and F1-score of 0.87. On the other hand, the Decision Tree model performed the worst, with the lowest accuracy of 0.76, kappa of 0.55, and F1-score of 0.66. Overall, the table highlights notable differences in the model's evaluation metrics based on the chosen algorithm, indicating that some models may perform better based on the evaluation metric of interest."
546,"caption: Comparison of models using different evaluation metricstable: Model,F1-score (class 0),F1-score (class 1),Precision (class 0),Precision (class 1),Recall (class 0),Recall (class 1), Model A,0.75,0.60,0.80,0.55,0.70,0.70, Model B,0.65,0.72,0.70,0.80,0.90,0.55, Model C,0.80,0.65,0.90,0.50,0.70,0.80, Model D,0.70,0.70,0.60,0.75,0.80,0.65","Table presents a comparison of four different models based on their performance on diverse evaluation metrics, including F1-score, precision, and recall. The models were tested on a two-class classification problem. Model A achieved the highest F1-score (class 0) of 0.75 and Recall (class 0) of 0.70. Interestingly, Model C had the highest precision (class 0) of 0.90 and Recall (class 1) of 0.80. The performance of Model B lies between the other models. The table showcases the performance of the tested models across multiple evaluation metrics, providing insights for selecting the appropriate model depending on the specific requirements of the task."
547,"caption: Model performances for the classification task.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.84,0.77,0.74,0.82, Logistic Regression,0.78,0.70,0.66,0.74, Random Forest,0.88,0.83,0.80,0.86, XGBoost,0.90,0.85,0.82,0.88","The table presents the performance results of four different models, SVM, Logistic Regression, Random Forest, and XGBoost, for the classification task. The evaluation metrics used in this table are Accuracy, F1-Score, Precision, and Recall. Overall, all four models performed relatively well, with XGBoost model showing the highest accuracy score of 0.90. The Random Forest had the best F1-Score of 0.83 and precision score of 0.80, while SVM had the highest recall score of 0.82. Logistic Regression model had the lowest performance results compared to the other models."
548,"caption: Performance of different models using various evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall,AUC, Logistic Regression,0.81,0.78,0.82,0.74,0.88, Decision Tree,0.76,0.72,0.70,0.75,0.72, Random Forest,0.86,0.84,0.80,0.88,0.92, SVM,0.82,0.79,0.85,0.73,0.89, XGBoost,0.90,0.89,0.86,0.92,0.94","The presented table demonstrates the comparison of five models; Logistic Regression, Decision Tree, Random Forest, SVM, and XGBoost. For each model, the table shows their performance based on different evaluation metrics, such as Accuracy, F1-Score, Precision, Recall, and AUC. The XGBoost model performs the best among all the models, achieving a remarkably high Accuracy of 0.90, and an F1-score of 0.89, Precision of 0.86, Recall of 0.92, and 0.94 AUC score. The Random Forest and the Logistic regression models also performed well with an AUC score of 0.92 and 0.88, respectively, while Decision tree and SVM models performed poorly when compared to other models."
549,"caption: Table 4: Model comparison based on accuracy, F1, and AUC metricstable: Model,Accuracy,F1,AUC, Model A,0.85,0.83,0.87, Model B,0.82,0.79,0.84, Model C,0.87,0.86,0.86, Model D,0.81,0.77,0.83, Model E,0.90,0.89,0.88","Table 4 presents a comparison of the performance of five different models. The evaluation metrics used are accuracy, F1 score, and AUC score. Model E attains the best accuracy score of 0.90, followed by Model C and Model A with 0.87 and 0.85, respectively. For the F1 score metric, Model E also achieves the highest score of 0.89, followed by Model C with 0.86. Interestingly, Model A, which had the second-best accuracy score of 0.85, had the lowest F1 score of 0.83. For the AUC metric, Model A ranks the best with a score of 0.87, followed closely by Model E with 0.88. In contrast, Models B and D achieved the lowest scores across all three metrics."
550,"caption: Table 4: Model Performance based on Multiple Evaluation Metricstable: Model,Accuracy,F1-score,Precision,Recall, XGBoost,0.89,0.88,0.87,0.91, Random forest,0.87,0.86,0.84,0.89, Neural network,0.90,0.89,0.88,0.91, SVM,0.85,0.84,0.82,0.87, KNN,0.86,0.85,0.83,0.88","Table 4 showcases a comparison of multiple machine learning models' performances based on different evaluation metrics. The table includes the XGBoost, Random forest, Neural network, SVM, and KNN models. The metrics used to evaluate their performances are Accuracy, F1-score, Precision, and Recall. Notably, the Neural network model shows the best performance in all the metrics compared to the other models. However, the XGBoost model performs well in terms of Accuracy and Recall, while the Random forest and KNN models perform relatively better in terms of F1-score and Precision. Overall, the table helps to compare the models' performances objectively and select the most efficient model based on the evaluation metric in consideration."
551,"caption: Comparison of four different models' performance based on different metrics.table: Model,Precision,Recall,F1-score,Accuracy, Model A,0.85,0.81,0.83,0.88, Model B,0.80,0.85,0.82,0.86, Model C,0.88,0.75,0.81,0.87, Model D,0.74,0.92,0.82,0.83","Table X compares four different models based on multiple metrics, including Precision, Recall, F1-score, and Accuracy. Model A achieved the highest Precision score of 0.85, while Model C had the highest Recall score of 0.75. The F1-score presents an overall performance evaluation by balancing Precision and Recall scores, and Model A obtained the highest F1-score of 0.83. Interestingly, Model D showed the highest Accuracy score of 0.83, despite having the lowest scores in other metrics. The table's results demonstrate the importance of considering multiple metrics to evaluate models' performance for particular tasks, where achieving the highest score in one metric does not necessarily represent the best overall performance."
552,"caption: Comparison of Model Performance across Multiple Metrics.table: Model,Accuracy,F1-Score,Precision,Recall, Logistic Regress,0.89,0.86,0.88,0.88, SVM,0.91,0.89,0.93,0.87, Random Forest,0.93,0.90,0.92,0.90, XGBoost,0.94,0.93,0.94,0.92, Neural Network,0.92,0.90,0.91,0.96","Table above shows the performance results (Accuracy, F1-Score, Precision, and Recall) for different classification models (Logistic Regression, SVM, Random Forest, XGBoost, and Neural Network). XGBoost had the highest accuracy of 0.94. The F1-score for Random Forest and XGBoost were the highest with 0.90. Precision and Recall values are ranging between 0.87-0.96 and 0.88-0.96 respectively. Overall, all models performed well, but XGBoost had the highest accuracy, and Random Forest and XGBoost had the highest F1-Score. It is worth investigating the Neural Network's higher recall values further."
553,"caption: Table 4: Comparison of different models using multiple evaluation metricstable: Model,F1 Score,Precision,Recall,AUC, Logistic Regression,0.85,0.87,0.83,0.93, Random Forest,0.88,0.89,0.87,0.92, K-Nearest Neighbor,0.70,0.77,0.70,0.82, SVM,0.84,0.86,0.82,0.90, Naive Bayes,0.78,0.85,0.77,0.89","Table 4 depicts a comparison of different machine learning models based on multiple evaluation metrics, including F1 score, precision, recall, and AUC. The table shows the performance results for the Logistic Regression, Random Forest, K-Nearest Neighbor, SVM, and Naive Bayes models. The Random Forest model performed the best across all metrics, achieving a high F1 score of 0.88, precision of 0.89, recall of 0.87, and AUC of 0.92. The K-nearest neighbor model had lower scores in all metrics but still achieved an AUC of 0.82, indicating its usability in specific applications. The SVM and Logistic Regression models had similar scores, but SVM yielded a slightly higher AUC of 0.90."
554,"caption: Performance results of different models based on multiple evaluation metrics.table: Model,Precision,Recall,F1-Score,AUC, Model 1,0.81,0.68,0.74,0.92, Model 2,0.85,0.75,0.80,0.94, Model 3,0.77,0.82,0.79,0.88, Model 4,0.89,0.79,0.84,0.95, Model 5,0.91,0.86,0.88,0.96","The table presents the performance results of five different models based on four evaluation metrics - Precision, Recall, F1-Score, and AUC. The table shows that Model 5 achieved the best overall performance across all evaluation metrics, with the highest precision of 0.91 and AUC of 0.96. Interestingly, Model 4 had the highest precision score of 0.89, while Model 2 had the highest recall score of 0.75. On the other hand, Model 3 had the lowest precision score of 0.77 and the lowest AUC of 0.88, indicating that it performed the worst. Overall, the table provides useful information on the relative performances of different models on multiple evaluation metrics, which can help in selecting the best-performing model for the given task."
555,"caption: Table 1: Model evaluation metrics comparison.table: Model,Precision (Avg),Recall (Avg),F1-Score (Avg),Precision (Ham),Recall (Ham),F1-Score (Ham), SVM,0.93,0.91,0.92,0.94,0.97,0.95, Naive Bayes,0.92,0.93,0.92,0.95,0.93,0.94, Random Forest,0.96,0.98,0.96,0.99,0.96,0.97, Decision Tree,0.91,0.92,0.91,0.96,0.93,0.94","Table 1 presents the results of four different models' performance using various evaluation metrics. The performance evaluation metrics applied in this table include Precision, Recall, and F1-Score. Interestingly, it is clear from the table that the Random Forest model performed the best in terms of Precision (Avg), Recall (Avg), and F1-Score (Avg), where it attained a score of 0.96, 0.98, and 0.96, respectively. However, it is worth noting that the Decision Tree Model achieved the best Precision (Ham) score of 0.96, while the Random Forest model attained the best Recall (Ham) and F1-Score (Ham) with 0.96 and 0.97, respectively."
556,"caption: Model Performance on Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1-Score,AUC-ROC, Model A,0.92,0.91,0.93,0.92,0.90, Model B,0.89,0.87,0.91,0.89,0.86, Model C,0.91,0.88,0.94,0.91,0.89, Model D,0.87,0.85,0.89,0.87,0.83, Model E,0.93,0.92,0.94,0.93,0.91","The table displays the evaluation metrics for five different models (Model A to E). The evaluation metrics include Accuracy, Precision, Recall, F1-Score, and AUC-ROC. Model E exhibits the best performance, achieving the highest score for all the evaluation metrics. However, Model D had the least performance with the lowest score on all metrics compared to the other four models. Interestingly, Model A and Model C both have a high recall score of around 0.93 while Model B slightly lacks in this parameter, with a recall score of 0.91. The F1-score is consistent among all models, ranging from 0.87 to 0.93."
557,"caption: Model performance on the evaluation metrics.table: Model,Accuracy,Precision (positive),Precision (negative),Recall (positive),Recall (negative),F1-Score, A,0.85,0.80,0.90,0.75,0.90,0.77, B,0.82,0.75,0.88,0.70,0.87,0.71, C,0.88,0.85,0.90,0.80,0.91,0.82, D,0.84,0.78,0.88,0.83,0.85,0.80, E,0.87,0.83,0.90,0.80,0.91,0.81",
558,"caption: Model performances measured by various evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.87,0.85,0.89,0.82, Decision Tree,0.81,0.80,0.85,0.75, Random Forest,0.91,0.90,0.93,0.87, Naive Bayes,0.74,0.73,0.76,0.69, Support Vector Machine,0.89,0.88,0.91,0.85","The table captures the performance of five machine learning models trained on a given dataset. The models are Logistic Regression, Decision Trees, Random Forest, Naive Bayes, and Support Vector Machines, and their performance has been measured by four different evaluation metrics: Accuracy, F1 Score, Precision, and Recall. The Random Forest model outperforms all other models with an Accuracy of 0.91, F1 Score of 0.90, Precision of 0.93, and Recall of 0.87. The Logistic Regression is the second-best performer with an Accuracy of 0.87 and Precision of 0.89. Naive Bayes model shows the lowest scores in all evaluation metrics, whereas Decision Tree and SVM are performing moderately well."
559,"caption: Comparison of model performances based on various evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score,AUC,PR AUC, Model 1,0.92,0.91,0.93,0.92,0.87,0.88, Model 2,0.88,0.89,0.84,0.86,0.74,0.75, Model 3,0.85,0.81,0.89,0.84,0.63,0.66, Model 4,0.93,0.92,0.95,0.93,0.91,0.92, Model 5,0.91,0.89,0.93,0.91,0.89,0.90","The table presents the model performances of five different models based on six evaluation metrics - accuracy, precision, recall, F1-score, AUC, and PR AUC. Model 1 achieved the highest overall performance with an accuracy of 0.92 and PR AUC of 0.88. However, Model 4 scored the highest in precision, recall, and F1-score with 0.92, 0.95, and 0.93, respectively. It also showed the highest score in AUC which is 0.91. Interestingly, Model 2 had the lowest AUC and PR AUC scores, while Model 3 had the lowest accuracy score. Overall, the table highlights the performance of these models and identifies apparent differences in their performance across multiple evaluation metrics."
560,"caption: Table 4: Model performance based on different evaluation metricstable: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.72,0.73,0.67,0.69, Decision Tree,0.80,0.77,0.87,0.81, Naive Bayes,0.69,0.70,0.62,0.64, Support Vector Machines,0.76,0.77,0.70,0.72, Random Forest,0.85,0.86,0.81,0.83","Table 4 presents the evaluation metrics of different models namely Logistic Regression, Decision Tree, Naive Bayes, Support Vector Machines, and Random Forest. The models have been trained and tested using the same dataset. The table shows the accuracy, precision, recall, and F1 score of each model. Notably, the Random Forest model shows the highest accuracy with a score of 0.85, while Decision Tree exhibits the highest precision of 0.77. Additionally, the Decision Tree model achieves the highest recall with a score of 0.87 and the highest F1 score with a score of 0.81. The results indicate that the Random Forest and Decision Tree models demonstrate the best overall performance in terms of accuracy, precision, recall, and F1 score."
561,"caption: Model Performance Comparison Using Multiple Evaluation Metricstable: Model,Precision,Recall,F1-Score,Accuracy, Support Vector Machine,0.90,0.88,0.88,0.89, Random Forest,0.85,0.91,0.88,0.88, Gaussian Naive Bayes,0.76,0.93,0.84,0.84, AdaBoost,0.83,0.89,0.86,0.85","The table displays the evaluation metrics of Precision, Recall, F1-Score, and Accuracy for four classification models, namely Support Vector Machine (SVM), Random Forest, Gaussian Naive Bayes (GNB), and AdaBoost. SVM exhibits the highest precision score of 0.90, while GNB shows the highest recall score of 0.93. The Random Forest outperformed the other models in F1-Score (0.88), and AdaBoost had the highest accuracy score of 0.85. These findings suggest that each model may have unique strengths depending on the evaluation metrics' importance."
562,"caption: Model performances based on different evaluation metricstable: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.89,0.87,0.88,0.85, RF,0.85,0.84,0.87,0.80, KNN,0.80,0.76,0.78,0.75, LR,0.88,0.85,0.88,0.82, NB,0.70,0.63,0.65,0.62","The table presents a comparison between SVM, RF, KNN, LR, and NB models' performances based on five evaluation metrics: Accuracy, F1-Score, Precision, Recall. The highest accuracy was achieved by SVM with a score of 0.89, while the lowest accuracy was NB with a score of 0.70. On the other hand, the lowest F1-Score, Precision, and Recall were recorded by NB with scores of 0.63, 0.65, and 0.62, respectively. Interestingly, although LR achieved a similar accuracy score with SVM, it had lower scores on all other evaluation metrics, indicating SVM's better performance. Finally, the RF model scored the highest Precision with 0.87."
563,"caption: Comparison of different regressors' performance in predicting house prices.table: Model,Mean Absolute Error (MAE),Root Mean Squared Error (RMSE),R-squared (R²), Linear Regression,0.23,0.38,0.70, Random Forest Regressor,0.19,0.32,0.80, Gradient Boosting Regressor,0.18,0.30,0.82, Support Vector Regressor,0.27,0.42,0.63, Multi-layer Perceptron Regressor,0.20,0.36,0.75","Table presents the model performance of multiple regression models in predicting house prices. The evaluation metrics include mean absolute error (MAE), root mean squared error (RMSE), and R-squared (R²). The models included in the table are Linear Regression, Random Forest Regressor, Gradient Boosting Regressor, Support Vector Regressor, and Multi-layer Perceptron Regressor. The results show that Gradient Boosting Regressor yielded the best performance results for all the three metrics: MAE of 0.18, RMSE of 0.30, and R² of 0.82. Notably, Random Forest Regressor and Multilayer Perceptron Regressor also showed strong performance, with R² scores of 0.80 and 0.75, respectively. Meanwhile, the Support Vector Regressor and Linear Regression models performed least effectively and yielded the highest error values."
564,"caption: Comparison of different models based on multiple evaluation metrics.table: Models,Metric 1,Metric 2,Metric 3, Model A,0.90,0.87,0.80, Model B,0.82,0.91,0.84, Model C,0.95,0.80,0.92, Model D,0.88,0.85,0.78, Model E,0.91,0.93,0.86","Table 4 presents a comparison of different models based on multiple evaluation metrics. The table exhibits five models, each with three metrics: Metric 1, Metric 2, and Metric 3. The models were evaluated using the same dataset, and the results showed variations among the metrics. Model C shows the highest result in Metric 1 (0.95), while Model B performed best in Metric 2 (0.91). Model C also achieved the highest result in Metric 3 (0.92), with Model E achieving the second-best result (0.86). These variations suggest that different models perform differently across the range of evaluation metrics, and as such, researchers should consider these metrics when selecting the best model for their specific use case."
565,"caption: Model performance using various evaluation metricstable: Model,Accuracy,Precision,Recall,F1 Score, Decision Tree,0.767,0.730,0.771,0.743, Random Forest,0.846,0.851,0.804,0.827, K-Nearest Neighbors,0.790,0.744,0.705,0.723, Support Vector,0.860,0.842,0.839,0.837","This table shows the performance of four different classification models in predicting a binary outcome. The models' accuracy, precision, recall, and F1 Score metric values are presented in the table. The Random Forest model performed the best in terms of accuracy, achieving a score of 0.846, while the Decision Tree model had the lowest accuracy score of 0.767. Despite the lower accuracy score of the K-Nearest Neighbors model at 0.790, it shows the highest precision of 0.744. Meanwhile, the Support Vector model had the highest scores in precision and recall, with a score of 0.842 and 0.839, respectively."
566,"caption: Performance results of different models using various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, Random forest (RF),0.85,0.87,0.80,0.83, Support vector machine (SVM),0.79,0.73,0.82,0.76, Multilayer Perceptron (MLP),0.82,0.85,0.77,0.81, Naive Bayes (NB),0.76,0.81,0.69,0.75, Convolutional Neural Network (CNN),0.87,0.89,0.87,0.88","The table compares the performance of different models using various evaluation metrics. The models include Random forest (RF), Support vector machine (SVM), Multilayer Perceptron (MLP), Naive Bayes (NB), and Convolutional Neural Network (CNN). The evaluation metrics used to measure the models include Accuracy, Precision, Recall, and F1-score. Notably, CNN has the highest accuracy of 0.87, whereas RF has the highest precision of 0.87 and Recall of 0.80. MLP has the highest F1-score of 0.81. SVM has the lowest accuracy and F1-score, while NB has the lowest Precision and Recall. Interestingly, CNN's precision is slightly better than all other models, while its recall is equal to its accuracy."
567,"caption: Table 4: Model performance comparison based on multiple evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall,AUC, Model 1,0.89,0.90,0.91,0.88,0.95, Model 2,0.85,0.82,0.84,0.81,0.90, Model 3,0.92,0.94,0.91,0.97,0.94, Model 4,0.81,0.79,0.83,0.76,0.87, Model 5,0.88,0.86,0.90,0.83,0.92","Table 4 presents a performance comparison of five different models based on various evaluation metrics, including Accuracy, F1-score, Precision, Recall, and AUC. Model 3 exhibits the highest accuracy and F1-score of 0.92 and 0.94, respectively. Model 1 has achieved the highest precision of 0.91, while the recall value assigned to Model 3 is the highest with a score of 0.97. Interestingly, Model 5 has the highest AUC value of 0.92. However, different models perform differently in various evaluation metrics, indicating that there is no single 'best' model."
568,"caption: Performance comparison of various models using different evaluation metrics.table: Model,F1-score,AUC-ROC,Sensitivity,Specificity, Random Forest,0.80,0.86,0.76,0.78, Logistic Regression,0.65,0.73,0.61,0.62, Support Vector Machine,0.73,0.79,0.74,0.69, Gradient Boosting,0.77,0.81,0.76,0.68, Neural Network,0.82,0.88,0.81,0.76","The table presents the performance comparison of various models using different evaluation metrics: F1-score, AUC-ROC, sensitivity, and specificity. The Random Forest model achieved the highest F1-score of 0.80 and AUC-ROC of 0.86. The Neural Network model achieved the highest AUC-ROC score of 0.88 and the highest sensitivity of 0.81 while keeping specificity at 0.76. The Logistic Regression model had the lowest scores in all evaluation metrics, while the Support Vector Machine and Gradient Boosting models have competitive performance scores. This table can provide valuable insights into choosing the most appropriate model based on the objective at hand and particular evaluation metrics."
569,"caption: Comparison of Different Machine Learning Models Based on Various Evaluation Metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.785,0.742,0.847,0.781, Naive Bayes,0.713,0.652,0.585,0.614, Decision Tree,0.825,0.787,0.845,0.803, Random Forest,0.869,0.857,0.871,0.862, K-Nearest Neighbor,0.801,0.806,0.720,0.762","The table provides a comparison of different machine learning models based on various evaluation metrics such as accuracy, precision, recall, and F1 score. The model performances were evaluated using the same dataset, and each model had its optimized hyperparameters. Random Forest exhibits the best overall performance with an accuracy of 0.869 and an F1-score of 0.862. Surprisingly, K-Nearest Neighbor achieved an excellent precision score of 0.806 with reasonable accuracy and recall scores. Logistic Regression and Decision Tree models perform similarly in terms of accuracy, with around 0.785 and 0.825, respectively. Naive Bayes, although having a quick training time, lacks behind other models in terms of effectiveness."
570,"caption: Performance metrics of different models on the test dataset.table: Model,Accuracy,F1 score,Precision,Recall, Model 1,0.87,0.91,0.87,0.95, Model 2,0.89,0.93,0.88,0.98, Model 3,0.82,0.86,0.85,0.89, Model 4,0.86,0.92,0.89,0.94","The table compares the model performances using different evaluation metrics- accuracy, F1 score, precision, and recall on the test dataset. Model 2 has the highest accuracy (0.89) and F1 score (0.93), while Model 3 has the lowest accuracy (0.82) and F1 score (0.86). Notably, Model 2 has the highest precision of 0.88, while Model 4 has the highest recall of 0.94. The table's observation highlights that the different metrics give a different perspective on the model performance, and choosing the appropriate evaluation metric is critical for a particular application."
571,"caption: Table 4: Evaluation metrics of different models on the test dataset.table: Model,Accuracy,F1-score,Precision,Recall, Model 1,0.85,0.83,0.86,0.80, Model 2,0.88,0.84,0.89,0.80, Model 3,0.82,0.80,0.84,0.77, Model 4,0.84,0.82,0.85,0.79, Model 5,0.86,0.84,0.87,0.81",
572,"caption: Accuracy, F1-Score, Precision, and Recall of different models.table: Model,Accuracy,F1-Score,Precision,Recall, Model A,0.89,0.78,0.87,0.72, Model B,0.82,0.69,0.78,0.61, Model C,0.73,0.52,0.63,0.44, Model D,0.91,0.84,0.91,0.79","The table presents the evaluation metrics' performance results of four models, A, B, C, and D, for a particular classification task. The metrics include Accuracy, F1-Score, Precision, and Recall, which are all necessary for assessing model performance. Interestingly, Model D exhibited an outstanding performance across all the metrics, with Accuracy of 0.91, F1-Score of 0.84, Precision of 0.91, and Recall of 0.79. However, Model A reported a high score of Precision, while Model B has the lowest scores on all metrics compared to other models, indicating a poor performance. Furthermore, Model C has the lowest Accuracy score, which requires further analysis to understand the reason behind the performance."
573,"caption: table 4: Model performance comparison using different evaluation metricstable: Model,Precision,Recall,F1-score,Accuracy, SVM,0.85,0.87,0.86,0.83, KNN,0.78,0.84,0.80,0.76, Random Forest,0.90,0.92,0.91,0.89, Naive Bayes,0.72,0.85,0.78,0.71, LSTM,0.92,0.93,0.92,0.91","Table 4 presents the model performances of SVM, KNN, Random Forest, Naive Bayes, and LSTM based on different evaluation metrics, including Precision, Recall, F1-score, and Accuracy. The table indicates that the LSTM model demonstrated the best performance in all metrics, achieving the highest Precision of 0.92, Recall of 0.93, F1-score of 0.92, and Accuracy of 0.91. Interestingly, Random Forest comes in second, achieving Precision of 0.90, Recall of 0.92, F1-score of 0.91, and Accuracy of 0.89. However, Naive Bayes performed much worse than the other models across all evaluation metrics."
574,"caption: Comparison of five different models based on precision, recall, F1-score, and AUC performance metrics.table: Model Name,Precision,Recall,F1-Score,AUC, Logistic Regression,0.85,0.80,0.82,0.91, Decision Trees,0.79,0.81,0.78,0.84, Random Forests,0.91,0.86,0.88,0.94, Support Vector Machines,0.84,0.87,0.85,0.92, Artificial Neural Networks,0.87,0.91,0.85,0.93","The table above provides a comprehensive comparison of five machine learning models based on four performance metrics; precision, recall, F1-score, and Area Under the ROC Curve (AUC). As shown, the Random Forests model outperforms other models concerning precision, recall, F1-score, and AUC, with scores of 0.91, 0.86, 0.88, and 0.94, respectively. However, the Artificial Neural Networks model has the best recall of 0.91. In contrast, Logistic Regression has the best precision of 0.85, and Support Vector Machines model has the best F1-score of 0.85. The Decision Trees model has the lowest score in all performance metrics."
575,"caption: Comparison of model performances based on various evaluation metrics.table: Model Name,F1-Score,Accuracy,Precision,Recall, Model A,0.85,0.89,0.90,0.83, Model B,0.82,0.86,0.84,0.81, Model C,0.87,0.88,0.89,0.86, Model D,0.80,0.79,0.77,0.84, Model E,0.89,0.92,0.90,0.89","Table exhibits the results of different models based on various evaluation metrics, including F1-score, Accuracy, Precision, and Recall. Model A shows the highest F1-Score of 0.85, while Model E yields the highest F1-Score of 0.89. Model E also gives good Accuracy, Precision, and Recall scores of 0.92, 0.90, and 0.89, respectively. However, Model D shows the lowest F1-Score among all models, having a score of 0.80. Interestingly, Model C has a Precision score of 0.89, which is slightly higher than all other models. Finally, the performances of models across different evaluation metrics suggest that Model E performs the best."
576,"caption: Performance of multiple models on a binary classification task.table: Model,Accuracy,F1-Score,AUC-ROC, SVM,0.876,0.813,0.927, KNN,0.817,0.728,0.879, Naive Bayes,0.912,0.845,0.942, Logistic Regression,0.891,0.821,0.929, Decision Tree,0.851,0.782,0.899","The above table displays the performance of multiple models on a binary classification task. The models evaluated include SVM, KNN, Naive Bayes, Logistic Regression, and Decision Tree. The table shows the accuracy, F1-Score, and AUC-ROC of each model after performing the classification task on a common dataset. Interestingly, Naive Bayes obtained the highest accuracy and F1-Score of 0.912 and 0.845, respectively. SVM performed slightly lower with an accuracy of 0.876, but the highest AUC-ROC of 0.927. The Decision Tree performed the lowest with3 performance metrics below the 0.9 threshold. Overall, the table provides an informative comparison of different models that could aid in model selection."
577,"caption: Table 4: Model performances based on Precision, F1-score, Accuracy, and AUC metrics for Models A, B, C, D, and E.table: Model,Precision,F1-score,Accuracy,AUC, Model A,0.86,0.89,0.90,0.78, Model B,0.82,0.85,0.91,0.80, Model C,0.90,0.92,0.93,0.85, Model D,0.75,0.80,0.88,0.73, Model E,0.83,0.87,0.92,0.79","The presented Table 4 compares the performance results for Models A, B, C, D, and E based on Precision, F1-score, Accuracy, and AUC metrics. Notably, Model C had the highest Precision score of 0.90, followed by Models A and E with 0.86 and 0.83, respectively. Model C also had the highest F1-score of 0.92, while the lowest F1-score belonged to Model D with 0.80. In terms of Accuracy, Model C outperformed other models, having a score of 0.93 and followed closely by Model E with 0.92. However, the AUC scores demonstrate that Model C was inferior to Models A and B, which received 0.78 and 0.80 scores, respectively. Overall, the results suggest that Model C demonstrates superior results across various evaluation metrics."
578,"caption: Performance comparison of different models using various evaluation metrics.table: Models,Accuracy,F1_score,Precision,Recall, Logistic regression,0.90,0.91,0.88,0.95, Decision tree,0.92,0.92,0.93,0.90, Support Vector Machine,0.87,0.88,0.91,0.85, Random forest,0.95,0.95,0.96,0.94, Naive Bayes,0.82,0.86,0.80,0.94","Table 4 above presents a comparison of five different models' performance on a given dataset using various evaluation metrics. The models' performances were evaluated using Accuracy, F1_score, Precision, and Recall metrics. As shown in the table, the Random forest model achieves the highest performance across all metrics with an accuracy of 0.95, F1_score of 0.95, Precision of 0.96, and Recall of 0.94. Interestingly, the Logistic regression model performed second-best, achieving an accuracy of 0.90, F1_score of 0.91, Precision of 0.88, and Recall of 0.95. The Naive Bayes model, on the other hand, showed the least performance across all metrics."
579,"caption: Evaluation metrics for various classification models.table: Models,F1-score,Precision,Recall,AUC, Logistic Regression,0.92,0.95,0.89,0.99, SVM,0.91,0.94,0.89,0.98, Random Forest,0.93,0.96,0.91,0.99, XGBoost,0.94,0.97,0.91,0.99, Decision Tree,0.89,0.93,0.87,0.97","Table shows the evaluation metrics such as F1-score, precision, recall, and AUC, for different models: Logistic Regression, SVM, Random Forest, XGBoost, and Decision Tree. The table indicates that XGBoost had the best F1-score of 0.94, precision of 0.97, recall of 0.91, and AUC of 0.99. Random Forest closely follows XGBoost with an F1-score of 0.93, precision of 0.96, recall of 0.91, and AUC of 0.99. On the other hand, Decision tree had the lowest F1-score of 0.89, precision of 0.93, recall of 0.87, and AUC of 0.97."
580,"caption: Model performance summary of different evaluation metrics.table: Model,Accuracy,F1 Score,Recall,Precision, A,0.82,0.74,0.69,0.81, B,0.83,0.76,0.72,0.81, C,0.85,0.78,0.74,0.82, D,0.81,0.72,0.67,0.80","The table above summarises the performance of four different models based on multiple evaluation metrics. The evaluation metrics of Accuracy, F1 Score, Recall, and Precision were used to assess the performance of models A, B, C, and D. Model C achieved the best accuracy score of 0.85 while model B obtained the highest F1 Score of 0.76. Model A achieved the highest recall score of 0.69, and model C achieved the highest precision score of 0.82. Overall, model C is the best-performing model based on the highest accuracy and precision scores."
581,"caption: Table 4: Comparison of model performances on two datasets using accuracy, F1-Score, precision and recalltable: Dataset,Model,Accuracy,F1-Score,Precision,Recall, A,Random Forest,0.91,0.91,0.93,0.89, A,SVM,0.83,0.82,0.84,0.81, A,KNN,0.78,0.77,0.76,0.78, B,Random Forest,0.85,0.84,0.87,0.81, B,SVM,0.77,0.76,0.81,0.72, B,KNN,0.73,0.72,0.69,0.75","Table 4 shows a comparison of models based on their performances on two different datasets (A and B) using various evaluation metrics - Accuracy, F1-Score, Precision, and Recall. Random Forest outperforms other models on both datasets, achieving the highest accuracy score for Dataset A (0.91) and the second-highest for Dataset B (0.85). Conversely, KNN has the lowest accuracy on both datasets - 0.78 for dataset A and 0.73 for dataset B. Notably, while random forest has the highest accuracy score, SVM has the best precision scores for both datasets (0.84 and 0.81). Finally, the Recall metrics show KNN models performing better on both datasets compared to other models."
582,"caption: Evaluation metrics of five different modelstable: Model,Precision,Recall,F1 Score,AUC, :-,:-:,:-:,:-:,:-:, Logistic Regression,0.84,0.65,0.72,0.89, Random Forest,0.88,0.70,0.76,0.91, Decision Tree,0.75,0.85,0.79,0.84, Gradient Boosting,0.90,0.78,0.83,0.92, Support Vector Machine,0.82,0.73,0.77,0.85","The table displays the evaluation metrics of five different models, namely Logistic Regression, Random Forest, Decision Tree, Gradient Boosting and Support Vector Machine. The metrics include Precision, Recall, F1 Score, and AUC. The table showcases that of all the models, the Gradient Boosting has the highest F1 score (0.83), while Random Forest has the highest Precision (0.88) and AUC (0.91). Decision Tree, on the other hand, has the highest Recall value (0.85). In summary, the table provides insights into the performance of various models on the given dataset."
583,"caption: Table 4: Comparison of multiple models' accuracy, F1-score, and AUC.table: Model,Accuracy,F1-score,AUC, Logistic Regression,0.75,0.77,0.82, Random Forest,0.83,0.84,0.87, Gradient Boosting,0.81,0.82,0.84, MLP (Neural Network),0.80,0.81,0.85",
584,"caption: Performance of different models based on various evaluation metrics.table: Model Name,Accuracy,Precision,Recall,F1-Score,Specificity, Logistic Reg,0.85,0.86,0.91,0.88,0.82, Naive Bayes,0.80,0.77,0.88,0.82,0.72, SVM,0.90,0.89,0.95,0.92,0.86, Decision Tree,0.82,0.80,0.86,0.83,0.77, Random Forest,0.92,0.91,0.96,0.93,0.88","The table compares the performances of five different models based on multiple evaluation metrics, including Accuracy, Precision, Recall, F1-score, and Specificity. The Logistic Regression model showed the second-best overall performance in terms of accuracy, with a score of 0.85. The SVM model performed the best among all models with an accuracy score of 0.90 and was the top-performing model in terms of Precision, Recall, and F1-Score. The decision tree model scored the lowest accuracy score of all models at 0.82, followed by the Naive Bayes model, which recorded an accuracy score of 0.80. Interestingly, the Random Forest model achieved the highest accuracy score of 0.92, and it was the second-best model based on evaluation metrics Precision, Recall, and F1-Score. Overall, the SVM model demonstrated superior performance compared to the other models based on multiple evaluation metrics."
585,"caption: Table 4: Performance comparison of different classification models on the dataset.table: Model,Accuracy,F1-Score,Precision,Recall, KNN,0.80,0.78,0.82,0.72, Random Forest,0.89,0.87,0.88,0.86, Logistic Regression,0.85,0.83,0.86,0.80, SVM (linear),0.86,0.85,0.84,0.87, SVM (RBF),0.84,0.82,0.87,0.77","Table 4 presents the comparison of multiple classification models based on the accuracy, F1-Score, precision, and recall metrics. The table includes KNN, Random Forest, Logistic Regression, and SVM models with linear and RBF kernels. The Random Forest model shows the highest accuracy of 0.89, followed closely with the SVM (linear) model accuracy of 0.86. However, the Random Forest model achieved the highest F1-score, precision, and recall compared to other models. The KNN model shows a lower accuracy comparatively but has the best recall among the models. Moreover, the SVM model with the RBF kernel had the highest precision among all the models but a significantly lower recall score. These results could provide valuable insights for selecting appropriate models based on different evaluation criteria."
586,"caption: Table 4: Model Performance comparison on Accuracy, F1 score, and AUC.table: Model,Accuracy,F1 Score,AUC, Random Forest,0.92,0.87,0.93, Gradient Boosting,0.88,0.83,0.90, Logistic Regression,0.85,0.77,0.87, SVM,0.89,0.85,0.92, KNN,0.80,0.72,0.83","Table 4 highlights the performance comparison on Accuracy, F1 Score, and AUC of 5 different models- Random Forest, Gradient Boosting, Logistic Regression, SVM, and KNN. All models were trained and evaluated using the same dataset. The Random Forest model achieved the highest Accuracy of 0.92 and AUC of 0.93, followed by SVM with accuracy of 0.89 and AUC 0.92. Random Forest also achieved the highest F1 score of 0.87, followed by Gradient Boosting with F1 score of 0.83. KNN, on the other hand, shows the lowest performance in all the three evaluation metrics."
587,"caption: Performance Metrics of Different Models.table: Metric,Model 1,Model 2,Model 3,Model 4,Model 5, Accuracy,0.85,0.80,0.82,0.87,0.84, AUC,0.92,0.89,0.88,0.91,0.90, Precision,0.87,0.79,0.84,0.91,0.86, Recall,0.82,0.87,0.80,0.88,0.84, F1 Score,0.84,0.82,0.79,0.89,0.85","Table presents the performance metrics of Model 1, Model 2, Model 3, Model 4, and Model 5, measured through Accuracy, AUC, Precision, Recall, and F1 Score. Model 4 performs the best across all metrics with a high accuracy of 0.87, AUC of 0.91, precision of 0.91, recall of 0.88, and F1 score of 0.89. Model 2 also had a relatively high accuracy of 0.80 but with lower performance in AUC, Precision, Recall, and F1 score. It's interesting to note that Model 1 and Model 5 had the same accuracy of 0.85, but Model 1 outperformed Model 5 in all other metrics except Recall. Finally, model 3 performed the worst among all models, with an accuracy, AUC, Precision, Recall, and F1 score of 0.82, 0.88, 0.84, 0.80, and 0.79, respectively."
588,"caption: Performance comparison of different models based on multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.82,0.83,0.77,0.80, Naive Bayes,0.78,0.79,0.70,0.73, Random Forest,0.89,0.91,0.84,0.87, KNN,0.80,0.81,0.74,0.77, Decision Tree,0.85,0.87,0.80,0.83","The above table presents the performance comparison of SVM, Naive Bayes, Random Forest, KNN, and Decision Tree models based on multiple evaluation metrics. The table presents the models' accuracy, precision, recall, and F1-Score as evaluation metrics. Among all the presented models, Random Forest shows the highest accuracy of 0.89, precision of 0.91, and F1-score of 0.87, indicating that it produces more accurate and robust results compared to other models. SVM also performed well, producing 0.83 precision and 0.77 recall, while the Naive Bayes model had the lowest scores for all metrics."
589,"caption: Performance metrics of various models.table: Model,Accuracy,F1 Score,Precision,Recall, Model A,0.85,0.81,0.87,0.76, Model B,0.82,0.79,0.84,0.75, Model C,0.87,0.84,0.86,0.81, Model D,0.80,0.71,0.83,0.63, Model E,0.90,0.86,0.89,0.84","Table 4 presents a comparison of different models' performance metrics based on accuracy, F1 score, precision, and recall. The table shows Model A, Model B, Model C, Model D, and Model E, along with their corresponding accuracy, F1 score, precision, and recall results. Notably, Model E showed the highest overall performance, with an accuracy of 0.90, F1 score of 0.86, precision of 0.89, and recall of 0.84, while Model D showed the lowest overall performance, with an accuracy of 0.80, F1 score of 0.71, precision of 0.83, and recall of 0.63. The other models displayed moderate results in different performance metrics."
590,"caption: Performance comparison of various models using different evaluation metrics.table: Model,Precision,Recall,F1-Score,ROC-AUC,PR-AUC, Model 1,0.80,0.70,0.74,0.85,0.65, Model 2,0.88,0.92,0.90,0.81,0.70, Model 3,0.68,0.84,0.75,0.77,0.60, Model 4,0.92,0.82,0.86,0.91,0.75, Model 5,0.76,0.94,0.84,0.84,0.50, Model 6,0.94,0.88,0.90,0.88,0.80","The table provides a performance comparison of six different models based on various evaluation metrics, including precision, recall, F1-score, ROC-AUC, and PR-AUC. The models were trained and tested on the same dataset. Model 4 performed the best with the highest precision of 0.92, the highest ROC-AUC of 0.91, and the second-highest PR-AUC of 0.75. Model 6 had the highest precision of 0.94 and the highest PR-AUC of 0.80. Model 2 scored the highest F1-score of 0.90, but with relatively low PR-AUC of 0.70. Interestingly, Model 5 achieved the highest recall of 0.94 while having the lowest PR-AUC of 0.50."
591,"caption: Table 4: Model performances assessed by multiple different evaluation metricstable: Model,F1 score,Precision,Recall,Accuracy,AUC, Logistic Regression,0.83,0.82,0.85,0.81,0.89, Decision Tree,0.78,0.80,0.76,0.75,0.81, Random Forest,0.87,0.84,0.89,0.86,0.93, Gradient Boosting,0.89,0.87,0.93,0.85,0.91, Support Vector Machine,0.81,0.75,0.89,0.79,0.88","Table 4 shows the different model performances' evaluation metrics, including F1 score, precision, recall, accuracy, and AUC. The models evaluated against these metrics are Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Support Vector Machine (SVM). The Random Forest model outperformed all other models with the highest F1 score of 0.87, Precision 0.84, Recall 0.89, Accuracy 0.86, and the highest AUC 0.93. The Gradient Boosting model also performed well, producing the second-highest F1 score of 0.89 and recall of 0.93. In contrast, Support Vector Machine had comparatively lower precision of 0.75. Overall, Random Forest and Gradient Boosting are the two most promising models based on the evaluation metrics."
592,"caption: Table 4: Comparison of different models using three different evaluation metrics.table: Model,Accuracy,F1-Score,AUC-ROC, LogReg,0.79,0.75,0.83, SVM,0.82,0.80,0.85, KNN,0.77,0.74,0.80, RF,0.84,0.81,0.89, XGB,0.85,0.82,0.90","Table 4 presents a comparison of five different models on three different evaluation metrics, namely, Accuracy, F1-Score, and AUC-ROC. The models included in the table are LogReg, SVM, KNN, RF, and XGB. All the models were evaluated on the same dataset. From the table, it can be observed that the Random Forest (RF) model has the highest Accuracy (0.84) and AUC-ROC (0.89), while the XGBoost (XGB) model has the highest F1-Score (0.82). SVM has the second-highest Accuracy and AUC-ROC, whereas K-NN has the lowest score on all the evaluation metrics."
593,"caption: Model performance comparison using different evaluation metricstable: Models,Accuracy,F1-score,Precision,Recall,AUC-ROC,PR-AUC, Logistic Regression,0.85,0.84,0.86,0.83,0.89,0.91, Random Forest,0.84,0.82,0.86,0.79,0.87,0.90, SVM,0.83,0.81,0.85,0.77,0.86,0.87, KNN,0.75,0.72,0.79,0.66,0.73,0.75, Gradient Boosting,0.87,0.87,0.86,0.88,0.91,0.92","Table 1 presents a comparison of the model performances using multiple evaluation metrics, including Accuracy, F1-score, Precision, Recall, AUC-ROC, and PR-AUC. The models applied in this study include Logistic Regression, Random Forest, SVM, KNN, and Gradient Boosting. The Random Forest model has the highest AUC-ROC and PR-AUC scores of 0.87 and 0.90, respectively. Gradient Boosting has the highest accuracy and F1-score of 0.87. Additionally, Logistic Regression with an accuracy score of 0.85 has the best performance when compared with the other two linear models, SVM and KNN."
594,"caption: Evaluation metrics for multiple models.table: Model,Precision Score,Recall Score,F1-Score,Accuracy, Decision Tree,0.84,0.85,0.84,0.85, Random Forest,0.87,0.87,0.87,0.88, Support Vector Machine,0.52,0.65,0.58,0.57, Logistic Regression,0.72,0.69,0.71,0.73, XGBoost,0.81,0.82,0.81,0.82",
595,"caption: Table 4. Model performances based on different evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.95,0.94,0.96,0.93, Logistic Regression,0.88,0.84,0.76,0.93, Random Forest,0.91,0.89,0.87,0.92, Gradient Boosting,0.93,0.92,0.91,0.93, Naive Bayes,0.81,0.76,0.69,0.86","Table 4 presents a comparison of machine learning models' performances based on different evaluation metrics, including accuracy, F1 Score, Precision, and Recall. The table showcases five different models, such as SVM, Logistic Regression, Random Forest, Gradient Boosting, and Naive Bayes. Notably, the SVM model shows the best accuracy with a score of 0.95, followed closely by Gradient Boosting with a score of 0.93. On the other hand, Naive Bayes had the lowest scores in all the evaluation metrics. Interestingly, Logistic Regression shows a high recall score but sacrifices precision, showcasing a trade-off between the two metrics."
596,"caption: Model performance on different evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.94,0.94,0.95,0.94, Random Forest,0.92,0.92,0.93,0.92, Decision Tree,0.86,0.86,0.88,0.86, Support Vector Machine,0.91,0.91,0.92,0.91, Neural Network,0.96,0.96,0.96,0.96","The table compares the performances of different models based on multiple evaluation metrics: Accuracy, F1-score, Precision, and Recall. The dataset was split into training and testing sets, and the models were trained using the training data before testing against the testing data. The Neural Network model shows the highest performance with the highest accuracy, F1-score, precision, and recall (0.96 each). Logistic Regression and Support Vector Machine models exhibit precise results in all evaluation metrics. On the other hand, Decision Tree models show weaker performance with lower accuracy, F1-score, precision, and recall, respectively. The Random Forest model has moderate results in all metrics with significant relative difference compared to the Neural Network model."
597,"caption: Table 4: The performance of different models using multiple different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.91,0.93,0.90,0.92, KNN,0.89,0.91,0.89,0.90, Naive Bayes,0.86,0.85,0.87,0.86, Random Forest,0.94,0.95,0.94,0.94, ANN,0.92,0.94,0.92,0.93","Table 4 presents the performance of five different models using multiple evaluation metrics, including Accuracy, Precision, Recall, and F1-Score. The table shows SVM, KNN, Naive Bayes, Random Forest, and ANN models' performances. Interestingly, the Random Forest model outperforms all other models, with a higher accuracy score of 0.94 and precision, recall, and F1-Score of 0.95, 0.94, and 0.94, respectively. SVM also shows good performance, achieving the highest accuracy score of 0.91 and precision of 0.93. KNN and Naive Bayes models slightly underperfomed compared to other models. ANN shows a slightly lower accuracy score of 0.92 compared to the Random Forest model but still shows impressive performance with precision, recall, and F1-Score values of 0.94, 0.92, and 0.93, respectively."
598,"caption: Table 4: Model performance based on different evaluation metricstable: Model,F1-score,Precision,Recall,AUC, Logistic Regression,0.89,0.91,0.87,0.91, Random Forest,0.91,0.93,0.89,0.94, XGBoost,0.93,0.91,0.95,0.93, SVM,0.87,0.85,0.89,0.89","Table 4 shows the model performance based on different evaluation metrics, including F1-score, Precision, Recall, and AUC. It compares the performance of four different models, namely Logistic Regression, Random Forest, XGBoost, and SVM. The highest-performing model for each evaluation metric is as follows: XGBoost for F1-score (0.93), Random forest for Precision (0.93) and Recall (0.89), and Logistic Regression for AUC (0.91). Interestingly, the XGBoost model achieved the highest F1-score at 0.93, while Random forest model attained the highest Precision and Recall. These observations indicate that different models perform differently based on different evaluation metrics, therefore warranting careful consideration before selecting a model."
599,"caption: Table 4: Model Performance Based on Different Evaluation Metrics.table: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.8,0.81,0.79,0.80, Decision Tree,0.75,0.77,0.69,0.73, SVM,0.78,0.82,0.75,0.78, Naive Bayes,0.63,0.66,0.54,0.60, KNN,0.70,0.60,0.48,0.53","Table 4 presents the performance assessment of five different models: Logistic Regression, Decision Tree, SVM, Naive Bayes, and KNN based on different evaluation metrics, including Accuracy, Precision, Recall, and F1-score. Among the mentioned models, Logistic Regression achieved the highest accuracy of 0.8. In terms of precision, SVM showed the best result with 0.82, while Logistic Regression had the highest recall of 0.79. Moreover, Logistic Regression obtained the best F1-score of 0.8. Interestingly, even though Decision Tree had the lowest accuracy, it exhibited good precision and recall values with 0.77 and 0.69, respectively. In brief, Table 4 provides a comparison of the models for this dataset based on the chosen evaluation metrics."
600,"caption: Table 4: Model performances based on multiple evaluation metrics for a binary classification problem.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.92,0.89,0.91,0.87, RF,0.91,0.88,0.87,0.90, MLP,0.89,0.87,0.86,0.89, kNN,0.85,0.81,0.76,0.87","Table 4 represents a comparison of different models' performances based on multiple evaluation metrics, namely Accuracy, F1-score, Precision, and Recall. The table showcases SVM, RF, MLP, and kNN models' evaluation metrics. From the table, SVM and RF models show the best accuracy with 0.92 and 0.91, respectively. Moreover, SVM also shows the best F1-score of 0.89, followed closely by RF with 0.88. Interestingly, kNN achieved the highest Recall of 0.87, while SVM achieved the highest precision of 0.91. Overall, the table provides a comprehensive overview of the different models' performances based on multiple metrics, making it easy for the reader to compare and contrast the models' strengths and weaknesses."
601,"caption: Table 4: Performance Results of Different Models on the Datasettable: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.85,0.82,0.70,0.76, Random Forest,0.80,0.78,0.68,0.71, Logistic Regression,0.83,0.81,0.73,0.76, XGBoost,0.85,0.83,0.71,0.76","Table 4 presents the performance results of four different models, namely SVM, Random Forest, Logistic Regression, and XGBoost, on the dataset. The evaluation metrics considered for the models are Accuracy, Precision, Recall, and F1-Score. The SVM model achieved the highest accuracy of 0.85, while XGBoost attained the highest Precision score of 0.83. On the other hand, Logistic Regression obtained the highest Recall score of 0.73, and SVM attained the best F1-Score of 0.76. The Random Forest model had an Accuracy score of 0.80 and performed lowest among all models."
602,"caption: Evaluation metrics of multiple models on the test dataset.table: Model,F1-score,Precision,Recall,ROC-AUC, Model A,0.83,0.85,0.82,0.90, Model B,0.79,0.78,0.80,0.82, Model C,0.71,0.74,0.68,0.72, Model D,0.85,0.87,0.82,0.91, Model E,0.88,0.90,0.86,0.95","Table presents the F1-score, Precision, Recall, and ROC-AUC evaluation metrics of multiple models on the test dataset. Model A has the highest ROC-AUC of 0.90 while Model E has the highest precision and recall of 0.90 and 0.86, respectively. On the other hand, Model C has the lowest score for all the evaluation metrics. Interestingly, the F1-score of Model E is the highest score with 0.88 followed by Model D with 0.85. The results showcase that the models' performance varies based on the evaluation metric used, and users should choose a suitable model based on the performance measure of interest."
603,"caption: Performance metrics of different models.table: Model,F1-score,Accuracy,Precision,Recall, SVM,0.91,0.92,0.93,0.89, KNN,0.86,0.88,0.87,0.85, LR,0.89,0.91,0.91,0.88, RF,0.94,0.95,0.95,0.93, NB,0.80,0.85,0.83,0.78","The table presents the F1-score, accuracy, precision, and recall of five models: SVM, KNN, LR, RF, and NB. The performance outcomes were calculated using a dataset of the same size and provided an indication of how each model performed with the given task. The Random Forest model achieved the highest F1-score of 0.94 with an accuracy of 0.95 and a precision score of 0.95. The SVM model stood out for the highest precision and recall scores of 0.93 and 0.89, respectively, while the KNN model had the lowest performance across all categories. The NB model had the lowest F1-score with a value of 0.80; however, it achieved an accuracy score of 0.85 and a precision score of 0.83. Therefore, amongst the different models, the RF model and the SVM model appear to have performed the best in this case."
604,"caption: Comparison of different models' performances based on multiple evaluation metrics.table: Model,Accuracy,Recall,Precision,F1-Score,AUC, Model 1,0.87,0.92,0.84,0.88,0.90, Model 2,0.84,0.90,0.78,0.83,0.87, Model 3,0.91,0.95,0.89,0.92,0.93, Model 4,0.79,0.80,0.72,0.75,0.83, Model 5,0.92,0.94,0.91,0.92,0.95","Table depicts the performances of different models using different evaluation metrics, including Accuracy, Recall, Precision, F1-score, and AUC. Model 1 showed the highest Accuracy at 0.87, while Model 5 had the highest AUC of 0.95. The Recall score demonstrates Model 5 achieved the highest score of 0.94, followed closely by Model 3 at 0.95. Model 1 had the highest Precision of 0.84, while Model 5 scored the highest on F1-Score, with a value of 0.92. In summary, Model 5 performed the best, followed by Model 3, whereas Model 4 exhibited the poorest performance results."
605,"caption: Performance measures of different classification models.table: Model,Accuracy,Precision,Recall,F1-score,AUROC, Logistic Regression,0.95,0.95,0.96,0.95,0.98, SVM,0.91,0.92,0.89,0.90,0.96, Decision Tree,0.89,0.91,0.85,0.87,0.90, Naive Bayes,0.82,0.85,0.78,0.80,0.87","The table presents the performance measures (Accuracy, Precision, Recall, F1-Score, and AUROC) of four different classification models: Logistic Regression, SVM, Decision Tree, and Naive Bayes. The results are based on the evaluation metrics of a binary classification problem. Notably, the Logistic Regression model has the highest accuracy score of 0.95. Additionally, this model also achieved the highest precision, recall, and F1-Score of 0.95, 0.96, and 0.95, respectively. However, the highest AUROC score was achieved by the SVM classifier with a score of 0.96. It is also interesting to note that the Naive Bayes model achieved the lowest scores for all the evaluation metrics, with an accuracy score of 0.82."
606,"caption: Table 4: Model performance based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score,AUC, LR,0.85,0.81,0.70,0.75,0.86, SVM,0.78,0.77,0.63,0.68,0.75, RF,0.89,0.85,0.82,0.82,0.90, ANN,0.91,0.87,0.85,0.85,0.92","Table 4 provides a comparison of four different models' (LR, SVM, RF, and ANN) performance based on accuracy, precision, recall, F1-score, and AUC evaluation metrics. The highest accuracy score is obtained by the ANN model with 0.91. The highest precision value of 0.87 is attained by the ANN model as well. The RF model produces the highest recall score of 0.82, while the ANN model has the highest F1-score of 0.85. Interestingly, the RF model performs better than the other models regarding the area under the curve (AUC), of 0.90."
607,"caption: Table 4: Model performance based on different evaluation metricstable: Model,Accuracy,F1-Score,Recall,Precision, SVM,0.89,0.89,0.78,0.98, RF,0.85,0.86,0.71,0.97, KNN,0.82,0.83,0.69,0.98, MLP,0.88,0.88,0.77,0.99","Table 4 displays the performance results of different models based on evaluation metrics such as accuracy, F1-Score, recall, and precision. The table includes the SVM, Random forest (RF), k-Nearest Neighbor (KNN), and Multi-Layer Perceptron (MLP) models. Notably, the SVM model achieved the highest accuracy of 0.89, while the KNN model obtained the lowest accuracy of 0.82. The RF model achieved the highest F1-Score of 0.86, with the KNN model obtaining the lowest F1-Score of 0.83. The MLP model achieved the highest Precision value of 0.99, while the KNN model had the lowest value of 0.98."
608,"caption: Table 4: Model performance on evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.89,0.82,0.87,0.79, Decision Tree,0.84,0.76,0.82,0.72, Random Forest,0.91,0.84,0.89,0.80, XGBoost,0.93,0.89,0.91,0.86, SVM,0.92,0.87,0.84,0.91","Table 4 illustrates the performance of various models, namely Logistic Regression, Decision Tree, Random Forest, XGBoost, and Support Vector Machine (SVM), based on different evaluation metrics. These models were trained and tested using the same dataset. The evaluation metrics primarily used are Accuracy, F1 Score, Precision, and Recall. It is interesting to note that the XGBoost model outperforms every other model based on every evaluation metric with a maximum accuracy score of 0.93, F1 score 0.89, Precision 0.91, and Recall 0.86, making it the most effective model among all five. The results show that XGBoost is the most suitable model for predicting future test data based on the given dataset."
609,"caption: Table 4: Comparative evaluation of different models using multiple metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.895,0.897,0.900,0.905, Decision Tree,0.880,0.877,0.881,0.884, Random Forest,0.925,0.927,0.932,0.920, XGBoost,0.935,0.938,0.942,0.934","Table 4 depicts the comparative evaluation of four different models' performances using multiple evaluation metrics. The models evaluated in the table are Logistic Regression, Decision Tree, Random Forest, and XGBoost, and the evaluation metrics assessed are Accuracy, F1 Score, Precision, and Recall. Notably, Random Forest and XGBoost models achieved the highest Accuracy (0.925 and 0.935, respectively), while XGBoost had the best performance for all metrics evaluated, including F1 Score (0.938), Precision (0.942), and Recall (0.934). The Logistic Regression model also demonstrated a commendable performance in all metrics evaluated. However, the Decision Tree model exhibited the lowest performance compared to the other models assessed."
610,"caption: Model performance of different classifiers using accuracy, precision, recall, and F1 score metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.85,0.64,0.85,0.73, Decision Tree,0.80,0.56,0.78,0.65, Random Forest,0.91,0.78,0.91,0.84, SVM,0.82,0.62,0.82,0.70, KNN,0.87,0.71,0.87,0.78","The table shows the comparative performance of various classifiers, such as logistic regression, decision tree, random forest, SVM, and KNN, using the accuracy, precision, recall, and F1 score metrics. Notably, the random forest classifier achieved the best results with an accuracy score of 0.91, followed by KNN, which had an accuracy score of 0.87. In terms of precision, the random forest classifier again had the highest score of 0.78, whereas KNN resulted in the second-highest score of 0.71. The recall and F1 score for both classifiers followed the same trend. Therefore, the table highlights that the Random Forest classifier is the best model for the given dataset and evaluation metrics."
611,"caption: Table 4: Evaluation metrics of different modelstable: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,94.7%,0.92,0.89,0.945, Decision Tree,92.5%,0.87,0.87,0.869, Random Forest,96.1%,0.95,0.92,0.989, Gradient Boosting,95.3%,0.94,0.91,0.987, Support Vector Machine,92.4%,0.89,0.88,0.894","Table 4 highlights the performances of five different models based on various evaluation metrics. The evaluation metrics include accuracy, F1 score, precision, and recall. The table shows that the Random Forest model has achieved the highest accuracy (96.1%) and F1 score (0.95). However, the Logistic Regression model has the highest precision (0.89), and the Gradient Boosting model has the highest recall (0.987). The Support Vector Machine model has the lowest accuracy (92.4%) and F1 score (0.89) but is relatively balanced in precision and recall. The overall performance of each model can thus be compared using different metrics."
612,"caption: Performance of multiple classifiers on the binary classification task.table: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.80,0.82,0.72,0.76, Decision Tree,0.72,0.69,0.75,0.67, Random Forest,0.85,0.87,0.80,0.82, SVM,0.75,0.78,0.68,0.72","The table shows the performance of several classifiers, including Logistic Regression, Decision Tree, Random Forest, and SVM, on a binary classification task. Multiple evaluation metrics, including Accuracy, Precision, Recall, and F1-score, were used to evaluate the model's performance. The Random Forest classifier yielded the highest accuracy of 0.85 and highest Precision of 0.87. In contrast, the Logistic Regression classifier performed the best in terms of recall with a score of 0.72. Lastly, the Random Forest classifier achieved the highest F1-score of 0.82, indicating its balanced performance between precision and recall."
613,"caption: Model Performance using Various Machine Learning Algorithmstable: Model,Accuracy,Precision,Recall,F1 Score, Support Vector Machine,0.904,0.918,0.845,0.872, K-Nearest Neighbors,0.885,0.905,0.782,0.819, Logistic Regression,0.890,0.899,0.825,0.846, Decision Tree,0.836,0.852,0.736,0.769, Naive Bayes,0.872,0.897,0.790,0.829","The table presents the performance results of different machine learning models. Five models were evaluated based on their accuracy, precision, recall, and F1 score. Notably, the support vector machine shows the highest accuracy score of 0.904, while the K-nearest neighbors model has the lowest accuracy score of 0.885. Interestingly, the Naive Bayes model shows the highest precision score of 0.897, while the Decision Tree model has the lowest precision score of 0.852. Furthermore, the Support Vector Machine model outperforms other models in Recall and F1 Score. Overall, the table highlights the necessity of choosing an appropriate model based on the desired evaluation metrics."
614,"caption: Table 4: Model Performance based on Multiple Evaluation Metricstable: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.90,0.88,0.82,0.95, KNN,0.89,0.87,0.80,0.93, RF,0.92,0.91,0.88,0.94, XGB,0.93,0.92,0.90,0.95, ANN,0.91,0.90,0.86,0.94","Table 4 depicts five different models' evaluation metrics, including Accuracy, F1-Score, Precision, and Recall. SVM, KNN, RF, XGB, and ANN are the presented models. The XGB model showed the highest accuracy of 0.93 with the best F1-Score, Precision, and Recall of 0.92, 0.90, and 0.95, respectively. Meanwhile, the least performing model was KNN, with an accuracy of 0.89. Interestingly, the RF model's Precision and Recall scores were very close to each other, with values of 0.88 and 0.94, respectively. Overall, the table shows that the XGB model outperforms the others in all the evaluation metrics."
615,"caption: Table 4: Comparison of different models based on multiple evaluation metrics.table: Model,F1 score,Accuracy,Precision,Recall, Model 1,0.85,0.91,0.84,0.86, Model 2,0.75,0.82,0.65,0.89, Model 3,0.81,0.89,0.79,0.83, Model 4,0.92,0.95,0.94,0.9, Model 5,0.79,0.86,0.73,0.87","Table 4 presents a comparison of different models based on various evaluation metrics such as F1 score, accuracy, precision, and recall. Model 4 shows the best F1 score, precision, and recall, with scores of 0.92, 0.94, and 0.9, respectively. Model 1 records the best accuracy result of 0.91. Model 2 demonstrates the lowest F1 score, precision, and accuracy, but a high recall of 0.89. Overall, the table implies that Model 4 outperforms the other models in almost all evaluation metrics except accuracy."
616,"caption: Performance comparison of different models based on multiple evaluation metricstable: Model,Accuracy,F1 Score,Precision,Recall, Model A,0.846,0.645,0.734,0.679, Model B,0.862,0.687,0.696,0.679, Model C,0.814,0.578,0.653,0.536, Model D,0.888,0.756,0.788,0.753, Model E,0.906,0.789,0.821,0.789","The table presents a comparison of five different models' performance based on multiple evaluation metrics, namely Accuracy, F1 Score, Precision, and Recall. Notably, all models were trained and tested using the same dataset. The results show that Model E achieved the highest Accuracy, F1 Score, Precision, and Recall, with a score of 0.906, 0.789, 0.821, and 0.789, respectively. Model D also showed good performance with an Accuracy of 0.888 and an F1 Score of 0.756. Model A, B, and C showed moderate to low performance, with Model C achieving the lowest Accuracy, F1 Score, Precision, and Recall among all the models."
617,"caption: Table 4: Model performance comparison based on different classification metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.81,0.79,0.82,0.77, Random Forest,0.86,0.85,0.88,0.82, SVM (Linear),0.84,0.82,0.87,0.77, XGBoost,0.88,0.88,0.90,0.87","Table 4 shows a comparison of different models based on multiple classification metrics, including accuracy, F1 score, precision, and recall. The table includes Logistic Regression, Random Forest, SVM (Linear), and XGBoost models. The Random Forest model achieved the highest accuracy score of 0.86, while the XGBoost model scored the highest in F1 Score, precision and recall with scores of 0.88, 0.90, and 0.87, respectively. The Logistic Regression model shows a fair accuracy score of 0.81 but lower precision and recall scores than the other models. It is worth noting that the SVM (Linear) model achieved a high precision score of 0.87, but its recall score was lower than other models."
618,"caption: Table 4: Comparison of various models based on different evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall,AUC-ROC, Model 1,0.85,0.84,0.86,0.82,0.92, Model 2,0.87,0.86,0.88,0.85,0.93, Model 3,0.81,0.79,0.82,0.76,0.89, Model 4,0.90,0.90,0.91,0.89,0.95","Table 4 presents a comparison of various models' performance based on different evaluation metrics such as Accuracy, F1-score, Precision, Recall, and AUC-ROC. The table includes four different models, each of which has been evaluated with these metrics for a particular task. Notably, Model 4 stands out as the best performer compared to other models, achieving the highest Accuracy score of 0.90, F1-score of 0.90, Precision and Recall scores of 0.91 and 0.89, respectively, and the highest AUC-ROC score of 0.95. Therefore, Model 4 can be considered as the best-performing model among others based on these evaluation metrics."
619,"caption: Models' performance comparison based on different evaluation metrics.table: Model,Metric,Result, Linear regression,R-squared,0.75, MAE (kcal/mol),1.45, RMSE (kcal/mol),2.01, LASSO regression,R-squared,0.69, MAE (kcal/mol),1.62, RMSE (kcal/mol),2.32, MLP,R-squared,0.82, MAE (kcal/mol),1.30, RMSE (kcal/mol),1.92, Random Forest,R-squared,0.81, MAE (kcal/mol),1.32, RMSE (kcal/mol),1.98","The presented table shows a performance comparison of different regression models based on three evalutation metrics: R-squared, mean absolute error (MAE), and root mean squared error (RMSE). The models include linear regression, LASSO regression, MLP, and Random Forest models. Interestingly, MLP achieved the highest R-squared score of 0.82 while LASSO regression performed the poorest among the four models, with an R-squared of 0.69. However, LASSO regression had the smallest MAE (1.62 kcal/mol), indicating its relatively higher accuracy. Linear regression had a respectable MAE result of 1.45 kcal/mol, and Random Forest had the closest RMSE score of 1.98 kcal/mol to MLP's RMSE score of 1.92 kcal/mol. Consequently, researchers might consider selecting MLP or Random Forest models to achieve an optimal trade-off between R-squared, MAE, and RMSE performance metrics."
620,"caption: Table 4: Comparison of different models using multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.886,0.692,0.595,0.639, SVM (poly kernel),0.902,0.738,0.605,0.661, SVM (rbf kernel),0.899,0.722,0.603,0.647, Random Forest,0.921,0.839,0.643,0.718, XGBoost,0.924,0.860,0.636,0.727","The table presents a comparison of five different models' performance based on multiple evaluation metrics. The models include Logistic Regression, SVM with poly kernel, SVM with rbf kernel, Random Forest, and XGBoost. The evaluation metrics include Accuracy, Precision, Recall, and F1-Score. Random Forest and XGBoost models outperform other models, with Random forest achieving the highest Accuracy with a score of 0.921 and Precision with a score of 0.839. The XGBoost model obtained the highest Precision with a score of 0.860 and F1-Score with a score of 0.727, whereas the SVM models yielded the highest Recall scores."
621,"caption: Comparison of different classification models' performance results based on evaluation metrics.table: Model,F1-score,Accuracy,Cohen's Kappa, SVM,0.78,0.85,0.67, LR,0.75,0.82,0.52, RF,0.82,0.81,0.71, KNN,0.68,0.76,0.54","The provided table above presents the comparison of different classification models based on three evaluation metrics: F1-score, Accuracy, and Cohen's Kappa. The table includes four models: SVM, LR, RF, and KNN. The table shows RF as the best-performing model in terms of F1-score (0.82). However, the SVM model stands out with the highest accuracy score (0.85) and the highest Cohen's Kappa score at 0.67. In contrast, KNN and LR models underperformed compared to other models. The results suggest that the RF and SVM models are potentially effective machine learning techniques for classification tasks, and professionals should use these models for similar data projects."
622,"caption: Table 4: Comparative evaluation of different models based on multiple metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.85,0.89,0.78,0.83, Random Forest,0.92,0.92,0.89,0.90, Gradient Boosting,0.91,0.90,0.90,0.90, Decision Tree,0.87,0.85,0.87,0.86, SVM,0.89,0.91,0.82,0.86","Table 4 presents the comparative evaluation of different models based on multiple metrics, including Accuracy, Precision, Recall, and F1 Score. The table includes Logistic Regression, Random Forest, Gradient Boosting, Decision Tree, and SVM models. The models were evaluated using the same dataset, and each model achieved different performances across various metrics. The strongest model is Random Forest with the highest accuracy of 0.92 and precision of 0.92. On the other hand, Logistic Regression performed well in all metrics except recall, with a recall score of only 0.78. Interestingly, SVM achieved the highest precision score of 0.91, while Gradient Boosting achieved equal precision and recall scores of 0.90. Overall, the table demonstrates that the selected models achieved different performances in various metrics and may be suitable for different practical applications."
623,"caption: Table 4: Model performance comparison using multiple evaluation metrics.table: Model Name,Evaluation Metric 1,Evaluation Metric 2,Evaluation Metric 3,Evaluation Metric 4, Model A,0.59,0.86,0.79,0.90, Model B,0.66,0.75,0.68,0.92, Model C,0.72,0.80,0.70,0.88, Model D,0.82,0.61,0.63,0.81, Model E,0.79,0.73,0.64,0.85, Model F,0.68,0.88,0.72,0.89","Table 4 compares the performance of six different models using four different evaluation metrics. The metrics include Evaluation Metric 1, Evaluation Metric 2, Evaluation Metric 3, and Evaluation Metric 4. Model D has the highest value of Evaluation Metric 1 at 0.82, but the lowest value for Evaluation Metric 2 at 0.61. Model F has the highest value for Evaluation Metric 2 at 0.88, whereas Model A has the lowest value of 0.59 for Evaluation Metric 1. Moreover, Model A and Model D have the highest and lowest values, respectively, for Evaluation Metric 4. Overall, Model C has the best average performance across all metrics, while Model D has the worst average performance."
624,"caption: Comparison of multiple models' performances on different evaluation metrics.table: Models,Accuracy,Precision,Recall,F1 Score,AUC, Model A,0.78,0.73,0.81,0.77,0.82, Model B,0.83,0.80,0.87,0.83,0.85, Model C,0.81,0.83,0.78,0.80,0.81, Model D,0.79,0.72,0.88,0.79,0.84, Model E,0.84,0.87,0.82,0.84,0.88","Table shows the performance comparison of five different models A, B, C, D and E based on their accuracy, precision, recall, F1 score, and AUC. Many observations can be drawn from the results in the table. For instance, Model B has the highest accuracy of 0.83 and AUC of 0.85, whereas Model E has the highest precision of 0.87 and the highest F1 score of 0.84. Contrarily, Model D has the highest recall of 0.88 but has the lowest precision of 0.72. This table can help readers to compare multiple models' performance on different evaluation metrics simultaneously."
625,"caption: Performance comparison of multiple different models in terms of precision, recall, F1 Score, and accuracy.table: Model,Precision,Recall,F1 Score,Accuracy, Model A,0.85,0.89,0.87,0.91, Model B,0.78,0.97,0.86,0.89, Model C,0.94,0.82,0.88,0.93, Model D,0.67,0.73,0.70,0.82, Model E,0.91,0.91,0.91,0.94","The table highlights the comparison of five different models based on different evaluation metrics, including precision, recall, F1 score, and accuracy. Model A outperformed all other models contained in the table in terms of precision with a value of 0.85. Alternatively, Model C demonstrated the highest precision score of 0.94. Despite Model B and Model E having a relatively low precision score compared to Model A and Model C, they showed the highest recall with scores of 0.97 and 0.91, respectively. Model E showed the highest F1 Score of 0.91 out of all models and demonstrated high accuracy with a score of 0.94. Meanwhile, Model D only performed reasonably well, particularly in terms of precision, where it scored the least among all models."
626,"caption: Performance comparison of different models on binary classification task.table: Model,Precision,Recall,F1-score,AUC,Accuracy, LogReg,0.85,0.90,0.87,0.72,0.85, Naive Bayes,0.78,0.72,0.75,0.65,0.79, Random Forest,0.92,0.97,0.94,0.84,0.93, Gradient Boosting,0.88,0.95,0.91,0.81,0.89, Support Vector Machine,0.84,0.91,0.87,0.77,0.84","The table summarizes the performances of five different models on a binary classification task. The evaluation metrics used were precision, recall, F1-score, AUC, and accuracy. Notably, the Random Forest model achieved the highest precision of 0.92 and recall of 0.97, resulting in the highest F1-score of 0.94. The Gradient Boosting model outperformed other models in terms of accuracy, achieving 0.89. Interestingly, the Naive Bayes model achieved a higher AUC score than Support Vector Machine, while LogReg showed the highest accuracy balance among the metrics. Overall, the table shows the strength and weaknesses of each model while highlighting the importance of considering multiple evaluation metrics."
627,"caption: Table 4: Comparison of different models based on multiple evaluation metrics (F1-Score, Precision, Recall, and Accuracy)table: Model,F1-Score,Precision,Recall,Accuracy, SVM,0.84,0.83,0.86,0.82, KNN,0.78,0.75,0.87,0.72, MLP,0.87,0.82,0.93,0.83, LR,0.82,0.83,0.80,0.82, RF,0.88,0.90,0.86,0.87","Table 4 compares multiple models based on their F1-Score, Precision, Recall, and Accuracy evaluation metrics. The models include SVM, KNN, MLP, LR, and RF. The table reveals that the MLP model achieves the highest F1-Score of 0.87, Precision of 0.82, Recall of 0.93, and Accuracy of 0.83. The RF model also performs well with an F1-Score of 0.88, Precision of 0.90, Recall of 0.86, and Accuracy of 0.87. However, the KNN model has the lowest performance across all the evaluation metrics with an F1-Score of 0.78, Precision of 0.75, Recall of 0.87, and Accuracy of 0.72."
628,"caption: Comparison of different models’ performance on the test data based on various evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, Decision tree,0.91,0.91,0.92,0.90, Random forest,0.95,0.95,0.96,0.94, AdaBoost,0.93,0.93,0.94,0.92, Gradient Boosting,0.96,0.96,0.97,0.95, Logistic regression,0.93,0.93,0.93,0.93, Support Vector Machine,0.93,0.93,0.94,0.93","Table 4 presents a comparative performance of different models using multiple evaluation metrics. The table compares the accuracy, F1-score, precision, and recall of six models, including Decision tree, Random forest, AdaBoost, Gradient Boosting, Logistic regression, and Support Vector Machine (SVM). It is observed that Gradient Boosting achieved the best performance on all metrics with the accuracy, F1-score, precision, and recall values of 0.96, 0.96, 0.97, and 0.95, respectively. Unexpectedly, Random forest achieved the second-best score with the accuracy, F1-score, precision, and recall of 0.95, 0.95, 0.96, and 0.94, respectively. SVM, Logistic regression, and AdaBoost showed a close performance with roughly similar scores. Meanwhile, Decision tree achieved a relatively lower score than other models but still performed well."
629,"caption: Model performance evaluation resultstable: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.87,0.90,0.85,0.87, Random Forest,0.85,0.87,0.89,0.88, Naive Bayes,0.82,0.83,0.79,0.81, Neural Net,0.88,0.91,0.84,0.87","The table presents the evaluation results using different performance metrics of four models, namely SVM, Random Forest, Naive Bayes, and Neural Net. The metrics chosen to evaluate the results are Accuracy, Precision, Recall, and F1-Score. Interestingly, the SVM model achieved the highest accuracy score of 0.87, while the Neural Net model obtained the highest precision score of 0.91. The Random Forest model had the best F1-Score of 0.88, while Naive Bayes had the least F1-Score of 0.81. These results provide insights for selecting the best-performing model based on specific evaluation metrics."
630,"caption: Comparison of model performance based on different evaluation metricstable: Model Name,Accuracy,F1-Score,Recall,Precision,Specificity, Logistic Regression,0.84 ± 0.01,0.85 ± 0.02,0.80 ± 0.03,0.91 ± 0.02,0.85 ± 0.02, Decision Tree,0.80 ± 0.05,0.80 ± 0.03,0.76 ± 0.05,0.85 ± 0.03,0.76 ± 0.05, Random Forest,0.91 ± 0.02,0.92 ± 0.01,0.89 ± 0.03,0.96 ± 0.02,0.89 ± 0.03, Support Vector Machine,0.82 ± 0.03,0.82 ± 0.02,0.77 ± 0.05,0.89 ± 0.04,0.77 ± 0.05, Neural Network,0.92 ± 0.01,0.93 ± 0.02,0.92 ± 0.02,0.95 ± 0.03,0.87 ± 0.04","Table 1 presents the performance of different models on various evaluation metrics. The table compares accuracy, F1-score, recall, precision, and specificity measures. The evaluation metrics were obtained by testing the models on the same dataset. Interestingly, the table demonstrates that the Neural Network model achieved the highest accuracy with 0.92±0.01. Similarly, the Random Forest model achieved the highest F1-score - 0.92±0.01 and Precision - 0.96±0.02 values. However, the Neural Network model obtained the highest Recall - 0.92±0.02 and the Logistic Regression achieved the highest Specificity - 0.85±0.02. The Decision tree model achieved the lowest performance for all the evaluation metrics, recording the lowest accuracy among other models with 0.80± 0.05."
631,"caption: A comparison of different classification models' performances based on multiple evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.87,0.86,0.89,0.83, KNN,0.85,0.82,0.87,0.78, Decision Tree,0.81,0.77,0.80,0.74, Random Forest,0.89,0.88,0.90,0.86, XGBoost,0.91,0.90,0.93,0.87","The table presents a comparison of different classification models based on the evaluation metrics of accuracy, F1-score, precision, and recall. The SVM, KNN, Decision Tree, Random Forest, and XGBoost models are evaluated using the same dataset. The XGBoost model achieved the highest accuracy and F1-score of 0.91 and 0.90, respectively. The Random Forest model outperformed other models in precision and recall with scores of 0.90 and 0.86. Furthermore, the SVM model had a high precision value of 0.89, but its recall score of 0.83 was the lowest among all models. Overall, the Random Forest and XGBoost models demonstrate superior performance based on this comparison."
632,"caption: Table 4. Model performance based on different evaluation metricstable: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.87,0.80,0.89,0.73, Naive Bayes,0.78,0.68,0.77,0.60, Logistic Regression,0.91,0.86,0.92,0.80, Random Forest,0.93,0.89,0.94,0.85","Table 4 reports the classification performance of four different models based on multiple evaluation metrics, including Accuracy, F1-Score, Precision, and Recall. The SVM model shows the highest Accuracy of 0.87, while the Random Forest model demonstrates the best overall performance in terms of F1-Score, Precision, and Recall with scores of 0.89, 0.94, and 0.85, respectively. Logistic Regression shows good performance across all evaluation metrics, achieving an Accuracy of 0.91, an F1-Score of 0.86, a Precision of 0.92, and Recall of 0.80. Naive Bayes has the lowest Accuracies, Precisions, and F1-Scores among the models, recording scores of 0.78, 0.77, and 0.68, respectively."
633,"caption: Table 4: Model performances based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Decision Tree,0.74,0.75,0.79,0.76, Logistic Regression,0.84,0.82,0.87,0.84, k-NN,0.83,0.81,0.89,0.84, SVM,0.86,0.84,0.91,0.87, Random Forest,0.88,0.87,0.92,0.89, XGBoost,0.89,0.91,0.89,0.90","Table 4 presents the performances of different models based on different evaluation metrics, including Accuracy, Precision, Recall, and F1-Score. The table exhibits six models that have been trained and tested on the same dataset. Notably, the XGBoost model shows the highest accuracy score of 0.89. The model with the highest precision score is observed to be XGBoost, with a score of 0.91. Conversely, the Decision tree model recorded the lowest precision score of 0.75. The SVM model achieved the highest recall score of 0.91, while Decision Tree had the lowest recall score of 0.79. When observing the F1-Score, Random Forest and XGBoost achieved the highest scores of 0.89 and 0.90, respectively, while the Decision tree achieved the lowest F1-Score of 0.76."
634,"caption: Table 4: Model evaluation results based on different metrics for different models.table: Model,Accuracy,Precision,Recall,F1-score, Model 1,0.89,0.91,0.85,0.88, Model 2,0.88,0.90,0.84,0.87, Model 3,0.87,0.88,0.87,0.87, Model 4,0.91,0.94,0.88,0.91","Table 4 presents the performance evaluation results for multiple models based on various metrics, including Accuracy, Precision, Recall, and F1-score. Model 1 achieved the highest accuracy score of 0.89, while Model 4 produced the highest precision score of 0.94. Interestingly, Model 3 achieved the highest recall score of 0.87, which indicates that it was the most effective model in identifying the actual positive cases. Overall, Model 4 showed the highest F1-score of 0.91, which suggests that it has the best balance between precision and recall among all the models."
635,"caption: Table 4: Model performance based on various evaluation metricstable: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.83,0.89,0.76,0.82, Decision Tree,0.72,0.75,0.7,0.72, Random Forest,0.87,0.89,0.84,0.86, Gradient Boosting,0.85,0.87,0.81,0.84, Support Vector Machine,0.84,0.85,0.8,0.83","Table 4 compares the performance of various machine learning models for a classification task in terms of accuracy, precision, recall, and F1 Score. The models assessed in the table include Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Support Vector Machine. The best-performing model for each metric is determined by the highest score for that particular metric. The Random Forest model is the best-performing model in terms of accuracy with a score of 0.87. The Logistic Regression model has the highest precision of 0.89 while the Random Forest model achieved the highest Recall of 0.84. Furthermore, the Gradient Boosting model has the most balanced F1 Score of 0.84. Overall, the Random Forest model outperforms other models regarding accuracy, precision, and recall."
636,"caption: Comparison of model performance based on accuracy, precision, recall, and F1 score.table: Model_name,Accuracy,Precision,Recall,F1 Score, Random Forest,0.83,0.85,0.80,0.82, Logistic Regression,0.76,0.70,0.82,0.76, Decision Tree,0.78,0.79,0.74,0.76, SVM,0.82,0.83,0.78,0.80, KNN,0.75,0.74,0.70,0.71","Table presents the comparison of the performance of five different classification models based on their accuracy, precision, recall, and F1 score. The models are Random Forest, Logistic Regression, Decision Tree, SVM, and KNN. The evaluation metrics are presented in a tabulated format, clearly showing how each model performed based on its accuracy, precision, recall, and F1 score. The Random Forest and SVM models show the highest accuracy of 0.83 and 0.82, respectively, while the Logistic Regression model performed the lowest with an accuracy of 0.76. The same pattern is observed for precision and recall, while Decision Tree model performs the best for F1 score with a score of 0.76."
637,"caption: Evaluation metrics of different machine learning models.table: Model,Accuracy,Recall,Precision,F1-Score, LR,0.874,0.896,0.864,0.879, KNN,0.824,0.835,0.821,0.827, SVM,0.901,0.916,0.897,0.907, RF,0.921,0.926,0.919,0.922, XGB,0.908,0.916,0.905,0.908","The table above describes the accuracy, recall, precision, and F1-Score results of five different machine learning models, namely Logistic Regression (LR), K-Nearest Neighbors (KNN), Support Vector Machine (SVM), Random Forest (RF), and XGBoost (XGB). The table shows that RF obtained the highest accuracy score of 0.921 followed closely by SVM with 0.901. Additionally, RF and SVM have similar recall, precision, and F1-Score results. Notably, KNN performs poorly compared to the other models, with an accuracy score of 0.824 and recall score of 0.835. In contrast, all other models have recall scores greater than 0.896."
638,"caption: Comparison of model performances based on different evaluation metricstable: Model,Accuracy,F1-score,Precision,Recall, Model 1,0.85,0.82,0.87,0.78, Model 2,0.79,0.74,0.81,0.68, Model 3,0.91,0.89,0.92,0.86, Model 4,0.83,0.79,0.82,0.76, Model 5,0.88,0.86,0.89,0.83","Table presents a comparison between five different models' performance based on their accuracy, F1-score, precision, and recall. Notably, Model 3 achieved the highest accuracy score of 0.91, which is 6% higher than the lowest accuracy score achieved by Model 2. Similarly, Model 3 also achieved the highest precision and recall score of 0.92 and 0.86, respectively. However, Model 1 performed the best based on F1-score, with the score of 0.82, which is 8% higher than the lowest score achieved by Model 2. Overall, this table highlights the varying performances of different models based on different evaluation metrics and reveals that no single model performs best in all metrics."
639,"caption: Performance comparison of different models in classification tasktable: Model,Accuracy,Precision,Recall,F1 Score, SVM,0.85,0.86,0.88,0.87, Naive Bayes,0.78,0.80,0.82,0.81, Random Forest,0.88,0.90,0.90,0.90, Gradient Boosting,0.89,0.91,0.92,0.92, Multi-layer Perceptron,0.86,0.87,0.89,0.88","The table compares multiple models for a classification task based on different evaluation metrics. The models evaluated include SVM, Naive Bayes, Random Forest, Gradient Boosting, and Multi-layer Perceptron. The evaluation metrics include Accuracy, Precision, Recall, and F1 Score. Interesting observations from the table show that Naive Bayes had the lowest accuracy of 0.78, while Gradient Boosting had the highest of 0.89. The Random Forest and Gradient Boosting models demonstrated a high precision, recall, and F1 score of 0.90 and 0.92, respectively, indicating that these models are highly reliable for classification tasks."
640,"caption: Model Comparison using Different Evaluation Metrics.table: Model Name,Accuracy,Precision,Recall,F1 Score,AUC, Logistic Regression,0.93,0.89,0.94,0.91,0.97, Random Forest,0.95,0.94,0.94,0.94,0.98, Support Vector Machine,0.90,0.88,0.89,0.88,0.94, Neural Network,0.91,0.92,0.88,0.90,0.96","The table titled 'Model Comparison using Different Evaluation Metrics' presents the performance comparison of four different models based on multiple evaluation metrics, including Accuracy, Precision, Recall, F1 Score, and AUC. The models are Logistic Regression, Random Forest, Support Vector Machine, and Neural Network. The Random Forest model achieved the highest accuracy score of 0.95, while the Logistic Regression and Neural Network models performed well in terms of Precision. The table also demonstrates the tradeoffs among the different models regarding the Recall and F1 Score metrics. For instance, the Support Vector Machine and Neural Network models exhibited higher Recall rates, whereas the Logistic Regression model had relatively higher F1 Scores. Finally, the AUC metric revealed that all models had high discrimination capabilities."
641,"caption: Model performance comparison based on different evaluation metricstable: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.94,0.93,0.95,0.91, KNN,0.86,0.85,0.88,0.83, Random Forest,0.95,0.94,0.96,0.92, Logistic Regression,0.92,0.90,0.93,0.87, XGBoost,0.96,0.95,0.97,0.93","The above table shows the performance comparison of five machine learning models based on four evaluation metrics: Accuracy, F1 Score, Precision, and Recall. The models are Support Vector Machine (SVM), K-Nearest Neighbors (KNN), Random Forest, Logistic Regression, and XGBoost. The Random Forest model performs the best with the highest accuracy of 0.95, F1 score of 0.94, precision of 0.96, and recall of 0.92. The XGBoost model also performs impressively with accuracy of 0.96, F1 score of 0.95, precision of 0.97, and recall of 0.93. Moreover, the SVM model has the highest precision score of 0.95. The KNN model relatively underperforms while all the other models perform similarly."
642,"caption: Model performance from different models based on multiple evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, Model 1,0.82,0.81,0.84,0.78, Model 2,0.76,0.81,0.70,0.94, Model 3,0.89,0.88,0.92,0.84, Model 4,0.72,0.71,0.80,0.63, Model 5,0.95,0.94,0.96,0.92","Table presents the comparison of different machine learning models' performances based on multiple evaluation metrics. The evaluation criteria include accuracy, F1-score, precision, and recall. Model 1 had the highest accuracy out of all the models, achieving a score of 0.82. Model 5, on the other hand, presented the best result for F1-score (0.94), precision (0.96), and recall (0.92), indicating it being the best performing model overall. Interestingly, Model 2 achieved a high recall score of 0.94, but with a relatively low accuracy result of 0.76. Lastly, Model 4 obtained the lowest score for all criterion, showing its lack of performance."
643,"caption: Model comparison based on different metrics.table: Model Name,Accuracy,Precision,Recall,F1-Score, Random Forest,0.92,0.93,0.91,0.91, Decision Tree,0.86,0.87,0.84,0.84, Logistic Regression,0.88,0.89,0.88,0.87, Naive Bayes,0.84,0.85,0.83,0.83, Support Vector Machines,0.90,0.91,0.89,0.89","The table above presents a comparison of different models based on multiple evaluation metrics -Accuracy, Precision, Recall, and F1-score. The table includes the Random Forest, Decision Tree, Logistic Regression, Naive Bayes, and Support Vector Machines models. The models were evaluated on the same dataset, and the highest score for each metric is highlighted. Notably, the Random Forest model exhibited the highest performance for all metrics, except for Precision, where Support Vector Machines demonstrated slightly better performance. Decision tree and Naive Bayes had average performance results, while Logistic Regression and Support Vector Machines showed similar results with very minimal differences. Overall, the Random Forest model emerges as the best-performing model, given its higher performance in various metrics."
644,"caption: Table 4: Evaluation metrics of different models.table: Models,Accuracy,Precision,F1-Score,AUC, Logistic Regression,0.78,0.72,0.74,0.76, K-Nearest Neighbor,0.75,0.68,0.71,0.73, Decision Tree,0.82,0.76,0.78,0.80, Random Forest,0.85,0.82,0.83,0.84, XGBoost,0.87,0.85,0.86,0.86","Table 4 showcases the accuracy, precision, F1-Score, and AUC of different models, namely, Logistic Regression, K-Nearest Neighbor, Decision Tree, Random Forest, and XGBoost. The table implies that all models have achieved a good accuracy score, where XGBoost stands out with the highest accuracy of 0.87. In terms of precision, Random Forest outperformed other models with 0.82. Random Forest also exhibits the highest F1-Score of 0.83, followed closely by XGBoost with a score of 0.86. Interestingly, XGBoost and Random Forest have the same AUC notation of 0.86. Decision Tree demonstrated a good overall balance between all metrics with an accuracy score of 0.82, precision of 0.76, F1-Score of 0.78, and AUC of 0.8."
645,"caption: Model evaluation results for different classification algorithms.table: Model,Accuracy,F1 Score,Precision,Recall, Random Forest,0.89,0.81,0.85,0.78, XGBoost,0.91,0.83,0.87,0.81, Logistic Regression,0.84,0.74,0.77,0.72, Decision Tree,0.88,0.78,0.81,0.75, Naive Bayes,0.80,0.70,0.75,0.66","The table presents evaluation results for different classification models using different evaluation metrics like Accuracy, F1 Score, Precision, and Recall. The table shows that the XGBoost model has the best performance with an accuracy score of 0.91. The Random Forest model has the second-best performance with an accuracy score of 0.89. The Logistic Regression model has the lowest accuracy score of 0.84. When we consider the F1 Score metric, the XGBoost model has the highest score of 0.83. The Naive Bayes model has the lowest scores for all metrics. The table helps us to compare the different models' performances and choose the best model for our classification task based on evaluation metrics' importance."
646,"caption: Table 4: Performance comparison of five different models based on different evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, Logistic regression,0.72,0.68,0.65,0.72, Random Forest,0.79,0.76,0.77,0.76, SVM,0.65,0.59,0.62,0.65, Multilayer Perceptron,0.75,0.72,0.71,0.76, K-Nearest Neighbors,0.66,0.61,0.63,0.66","Table 4 presents a comparison of five different models based on different evaluation metrics. The models are evaluated using accuracy, F1-score, precision, and recall, which are presented in the table. The models are Logistic regression, Random Forest, SVM, Multilayer Perceptron, and K-Nearest Neighbors. The Random Forest model exhibits the highest accuracy of 0.79, while the Logistic Regression model exhibits the highest F1-score of 0.68. Interestingly, the SVM model shows the lowest performance results in all metrics compared to the other models."
647,"caption: Model performance evaluation using various metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.80,0.74,0.72,0.77, Decision Tree,0.79,0.71,0.73,0.68, Random Forest,0.84,0.80,0.79,0.81, XGBoost,0.86,0.82,0.83,0.81","Table presents the performance results of four different machine learning models - Logistic Regression, Decision Tree, Random Forest, and XGBoost on a binary classification problem. The performance of each model was evaluated based on four performance metrics -- Accuracy, F1 Score, Precision, and Recall. The best model in terms of all four metrics is XGBoost, followed by Random Forest, Logistic Regression, and Decision Tree. XGBoost achieved the highest accuracy, F1 Score, precision, and recall of 0.86, 0.82, 0.83, and 0.81, respectively. Thus, XGBoost can be considered as the best performing model among the four models for the given problem."
648,"caption: Model performance on different metricstable: Model Name,F1-Score,Precision,Recall,Accuracy, Model A,0.925,0.921,0.930,0.922, Model B,0.920,0.918,0.921,0.919, Model C,0.930,0.929,0.935,0.927, Model D,0.912,0.914,0.908,0.913","Table illustrates the model performance of Model A, Model B, Model C, and Model D on four different evaluation metrics. Here, the metrics are F1-Score, Precision, Recall, and Accuracy, representing different aspects of the classification task. Model C shows the best performance on all metrics with an F1-Score of 0.930, Precision of 0.929, Recall of 0.935, and Accuracy of 0.927. Model A has the second best performance with a slightly lower F1-Score of 0.925, Precision of 0.921, Recall of 0.930, and Accuracy of 0.922. Model B has a moderate performance with a lower score on all metrics than Model A and Model C. Model D has the lowest performance on all metrics, albeit with a negligible difference in scores from Model B."
649,"caption: Model comparison using multiple evaluation metrics.table: LSTM,BERT,Random Forest,XGBoost, F1-score,0.755,0.512,0.782,0.721, Precision,0.743,0.568,0.805,0.717, Recall,0.780,0.484,0.765,0.727, Accuracy,0.807,0.587,0.841,0.786, Specificity,0.810,0.621,0.847,0.772","Table presents a comparison of multiple models based on F1-score, Precision, Recall, Accuracy, and Specificity evaluation metrics. The LSTM, BERT, Random Forest, and XGBoost models show different performance results for each evaluation criteria. Notably, the Random Forest model exhibits the highest F1-score and Precision of 0.782 and 0.805, respectively. Moreover, the Random Forest model and LSTM model show the highest accuracy and specificity results, respectively. However, BERT model depicts the lowest results for all evaluation criteria. The table provides researchers with a way to compare models for better decision-making."
650,"caption: Evaluation metrics scores of different classification modelstable: Model,Accuracy,F1 Score,AUC, Logistic Regression,0.92,0.91,0.96, Support Vector Machines,0.94,0.92,0.97, Random Forest,0.95,0.94,0.97, Extreme Gradient Boosting,0.94,0.93,0.97, Artificial Neural Networks,0.93,0.92,0.96","Table presents the performance evaluation of Logistic Regression, Support Vector Machines, Random Forest, Extreme Gradient Boosting, and Artificial Neural Networks models in terms of accuracy, F1 score, and AUC. All models were trained and tested using the same dataset. Random forest shows superior performance with an accuracy score of 0.95 and F1 score of 0.94. However, the AUC score was the same for Support Vector Machines, Random Forest, and Extreme Gradient Boosting models, achieving an accuracy score of 0.97. Interestingly, Support Vector Machines and Extreme Gradient Boosting models show better performance in terms of accuracy and F1 score, respectively, while all models have comparable results for the other two metrics."
651,"caption: Performance comparison of different classifiers on the test dataset.table: Model,F1-score,Accuracy,Precision,Recall, Logistic Regression,0.85,0.82,0.87,0.84, SVM,0.84,0.80,0.85,0.84, Random Forest,0.89,0.87,0.88,0.90, XGBoost,0.91,0.88,0.90,0.92, Naive Bayes,0.75,0.75,0.77,0.75","The table compares the performances of different classifiers on the test dataset, based on several evaluation metrics such as F1-score, accuracy, precision, and recall. The models included in the table are Logistic Regression, SVM, Random Forest, XGBoost, and Naive Bayes."
652,"caption: Table 4: Performance metrics comparison of different models using the same dataset.table: Model name,PR-AUC,ROC-AUC,F1-score,Accuracy, SVM,0.827,0.759,0.841,0.719, Logistic regression,0.858,0.782,0.846,0.733, KNN,0.836,0.751,0.829,0.703, Naive Bayes,0.792,0.710,0.770,0.657, Decision tree,0.815,0.731,0.830,0.687, Random forest,0.897,0.815,0.887,0.789","Table 4 presents a comparison of multiple models' performances using the same dataset. The table shows SVM, Logistic regression, KNN, Naive Bayes, Decision tree, and Random forest's PR-AUC, ROC-AUC, F1-score, and accuracy. The Random forest model achieved the best PR-AUC, ROC-AUC, F1-score, and accuracy scores of 0.897, 0.815, 0.887, and 0.789, respectively, outperforming all other models. Also, the Logistic regression achieved the second-best results, with a PR-AUC, ROC-AUC, F1-Score, and accuracy of 0.858, 0.782, 0.846, and 0.733, respectively. Although SVM scored the lowest among all models for F1-Score and accuracy, it performed better than other models, such as Naive Bayes and Decision tree, regarding ROC-AUC and PR-AUC."
653,"caption: Table 1: Model performances on the evaluation metricstable: Model,Precision,Recall,F1 Score,Accuracy,AUC, SVM,0.76,0.66,0.70,0.81,0.87, RF,0.84,0.70,0.75,0.83,0.91, KNN,0.72,0.62,0.64,0.75,0.82, LR,0.79,0.71,0.73,0.80,0.85","Table 1 presents the performance evaluation of four classification models - SVM, RF, KNN, and LR. The evaluation metrics include precision, recall, F1 score, accuracy, and AUC. The table shows that RF had the highest precision (0.84), while SVM had the highest AUC (0.87). However, LR model showed competitive results on all metrics, including precision (0.79), recall (0.71), F1 score (0.73), accuracy (0.80), and AUC (0.85). The KNN model had the lowest performance metrics scores. Overall, the table suggests that the RF and SVM models have better accuracy with a slightly lower F1 score and recall while LR models have slightly lower accuracy with competitive F1 score and recall."
654,"caption: Table 1: Performance evaluation of different machine learning modelstable: Model Name,F1 Score,Accuracy,Precision,Recall, Logistic Regression,0.70,0.73,0.78,0.64, Decision Tree,0.68,0.70,0.72,0.65, Random Forest,0.71,0.74,0.76,0.67, Support Vector Machine,0.71,0.71,0.75,0.68, Naive Bayes,0.62,0.63,0.58,0.68","Table 1 demonstrates the performance evaluation of five different machine learning models based on multiple evaluation metrics. These evaluation metrics include F1-score, accuracy, precision, and recall. It is essential to note that the models were trained and tested on the same dataset. The table shows that the Random Forest model had the highest F1-score, accuracy, and precision at 0.71, 0.74, and 0.76, respectively. However, the Support Vector Machine model had the highest recall score of 0.68. The Logistic Regression model had a better F1 score than the Decision Tree and Naive Bayes models. In summary, the results show that the Random Forest model performed better than the other models in most evaluation metrics."
655,"caption: Performance measures for different models.table: Model,Accuracy,Precision,Recall,F1-Score, Model A,0.80,0.75,0.82,0.78, Model B,0.82,0.78,0.73,0.75, Model C,0.84,0.83,0.85,0.83, Model D,0.72,0.70,0.74,0.70, Model E,0.86,0.87,0.89,0.88","The table illustrates the accuracy, precision, recall, and F1-Score achieved by Model A, Model B, Model C, Model D, and Model E on the task performed. Interestingly, Model C demonstrated the highest accuracy (0.84) and F1-Score (0.83), indicating a better overall performance than the other models. Additionally, Model E exhibited an impressive precision score (0.87) and recall score (0.89), indicating Model E has a high level of relevance between the retrieved and relevant documents. Model D, on the other hand, produced the lowest accuracy (0.72) and F1-Score (0.70) among the models analyzed."
656,"caption: Model Performance in Different Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1 Score, SVM,0.89,0.90,0.79,0.84, Logistic Regression,0.91,0.92,0.86,0.89, Random Forest,0.93,0.95,0.89,0.92, XGBoost,0.94,0.96,0.91,0.93","Table presents the evaluation of multiple models' performance based on different classic evaluation metrics: Accuracy, Precision, Recall, and F1 Score. The models include SVM, Logistic Regression, Random Forest, and XGBoost. The Random Forest model outperforms other models with the highest Accuracy, Precision, and F1 Score of 0.93, 0.95, and 0.92, respectively. Additionally, XGBoost surpasses other models with the highest Recall of 0.91. The overall results indicate that all models perform reasonably well in classification tasks, proving their effectiveness in various real-world applications."
657,"caption: Table 4: Model performances by accuracy, F1 score, precision, and recall scores for different classification models.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.87,0.86,0.88,0.84, SVM (linear kernel),0.81,0.78,0.85,0.72, SVM (rbf kernel),0.92,0.91,0.90,0.93, Random Forest,0.94,0.93,0.94,0.92, XGBoost,0.93,0.92,0.93,0.91, Feedforward Neural Net,0.89,0.87,0.88,0.86","Table 4 presents the performance results of various classification models by accuracy, F1 score, precision, and recall metrics. The table consists of six models - Logistic Regression, SVM with linear and rbf kernels, Random Forest, XGBoost, and Feedforward Neural Net. The Random Forest model achieved the highest accuracy (0.94), F1 score (0.93), and precision (0.94) scores, while SVM with rbf kernel achieved the highest recall score (0.93). Interestingly, Logistic Regression performed well in all metrics, with accuracy (0.87), F1 score (0.86), precision (0.88), and recall (0.84) scores falling in the top 3 scores of all models. The table provides an overview of model performances suitable for selecting the most appropriate model for classification tasks based on specific evaluation metrics."
658,"caption: Table 4: Comparison of Multiple Models Based on Accuracy, Recall, and F1-Score.table: Model,Accuracy,Recall,F1-Score, Logistic Regression,0.85,0.89,0.87, Naive Bayes,0.81,0.78,0.73, SVM,0.88,0.90,0.89, Random Forest,0.90,0.90,0.88, XGBoost,0.91,0.91,0.90","Table 4 presents the performance comparison of five different models, namely Logistic Regression, Naive Bayes, SVM, Random Forest, and XGBoost, based on three different metrics, Accuracy, Recall, and F1-Score. The table indicates that XGBoost is the best performing model with an Accuracy of 0.91, Recall of 0.91, and F1-Score of 0.90. The Random Forest model also shows excellent performance with an Accuracy of 0.90 and Recall of 0.90. Both models outperformed Logistic Regression, Naive Bayes, and SVM. Interestingly, Naive Bayes yielded the lowest F1-Score of 0.73 with an Accuracy of 0.81 while SVM achieved an Accuracy of 0.88, Recall of 0.90, and F1-Score of 0.89."
659,"caption: Table 4: Model performance based on multiple evaluation metricstable: Model,Accuracy,Precision,Recall,F1-score,AUC, Logistic Regression,0.93,0.89,0.81,0.85,0.971, Support Vector Classifier,0.88,0.79,0.85,0.72,0.942, XGBoost,0.95,0.91,0.87,0.89,0.983, LightGBM,0.94,0.93,0.86,0.88,0.973, Random Forest (n_estimators),0.94,0.90,0.88,0.89,0.979, Decision Tree (max_depth),0.80,0.75,0.70,0.72,0.846","Table 4 compares the performance of multiple models on multiple evaluation metrics. The models included in the table are Logistic Regression, Support Vector Classifier, XGBoost, LightGBM, Random Forest (n_estimators), and Decision Tree (max_depth). The evaluation metrics measured are Accuracy, Precision, Recall, F1-score, and AUC. Notably, XGBoost achieved the best performance across all metrics with an accuracy of 0.95, Precision of 0.91, Recall of 0.87, F1-score of 0.89, and AUC of 0.983. The Logistic Regression model produced the second-best performance, scoring 0.971 in AUC. The Decision Tree model had the lowest overall performance among all models, achieving an accuracy score of 0.80."
660,"caption: Model performances on different evaluation metricstable: Model,Metric,Result, Logistic Regression,Accuracy,0.87, F1-score,0.79, Precision,0.84, Recall,0.75, Decision Tree,Accuracy,0.81, F1-score,0.73, Precision,0.69, Recall,0.78, Random Forest,Accuracy,0.90, F1-score,0.85, Precision,0.89, Recall,0.81, Support Vector Machine,Accuracy,0.83, F1-score,0.75, Precision,0.80, Recall,0.71","This table summarizes the results for four different models: Logistic Regression, Decision Tree, Random Forest, and Support Vector Machine, based on multiple evaluation metrics, including accuracy, F1-score, precision, and recall. The highest accuracy score of 0.90 was achieved by the Random Forest model, while the Logistic Regression model achieved the best precision score of 0.84. The Random Forest model also achieved the highest F1-score of 0.85, while Decision Tree had the lowest F1-score of 0.73. Furthermore, the Support Vector Machine model had the lowest accuracy and F1-scores; however, it had the highest recall score of 0.71. This table helps to compare different models' performances based on specific evaluation metrics."
661,"caption: Table 4: Model performances based on various evaluation metrics.table: Model,F1 Score,Precision,Recall,Accuracy, Logistic Regression,0.856,0.891,0.824,0.879, Random Forest,0.880,0.901,0.858,0.894, SVM,0.853,0.886,0.823,0.876, MLP,0.897,0.912,0.883,0.912","Table 4 presents the performances of four models, namely, Logistic Regression, Random Forest, SVM, and MLP. The models are evaluated based on various metrics: F1-score, Precision, Recall, and Accuracy. The table exhibits the F1-score, Precision, Recall, and Accuracy of each model, indicating how well the models performed relative to each other. Interestingly, The MLP model performed best on all the metrics, achieving the best F1-Score (0.897), Precision (0.912), Recall (0.883), and Accuracy (0.912). The Random Forest model also performed relatively well, showing high precision (0.901) and recall (0.858) scores, while Logistic Regression and SVM exhibited moderate performances overall."
662,"caption: Table 4: Model performance comparison based on accuracy, sensitivity, specificity, and AUC.table: Model,Accuracy,Sensitivity,Specificity,AUC, SVM,0.85,0.72,0.91,0.84, KNN,0.80,0.62,0.85,0.73, RF,0.89,0.80,0.92,0.90, XGB,0.91,0.84,0.93,0.94, MLP,0.87,0.76,0.91,0.86","Table 4 presents a comparison of five different models based on four evaluation metrics: accuracy, sensitivity, specificity, and AUC. The Support Vector Machine (SVM) model achieved the highest accuracy score of 0.85, while Random Forest (RF) model produced the highest sensitivity score with a value of 0.80. The XGBoost (XGB) model's specificity score (0.93) was higher than all other models, indicating its capacity to accurately classify negative samples. Additionally, the XGB model produced the highest AUC score of 0.94, signifying its ability to differentiate between classes better. The MLP model, on the other hand, achieved relatively lower scores across all evaluation metrics."
663,"caption: Performance of different models on a binary classification tasktable: Model,F1-Score,Accuracy,Precision,Recall, Logistic Regression,0.87,0.90,0.84,0.92, Decision Trees,0.82,0.86,0.80,0.84, Random Forests,0.89,0.91,0.88,0.91, Gradient Boosting,0.91,0.92,0.90,0.93, Support Vector Machines (Linear),0.87,0.89,0.86,0.88, Support Vector Machines (RBF),0.84,0.87,0.81,0.88","The table above presents the comparison of multiple models' performance on a binary classification task, with each model's F1-score, accuracy, precision, and recall presented. The table exhibits Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, Support Vector Machines (Linear), and Support Vector Machines (RBF) models. Notably, Gradient Boosting appears to have the highest F1-score with a score of 0.91, followed by Random Forest with a score of 0.89. Additionally, Gradient Boosting and Random Forest models have the highest accuracy scores of 0.92 and 0.91, respectively. It is also worth noting that the Support Vector Machines (RBF) model achieved the lowest F1-score and accuracy score compared to the other models, with the F1-score of 0.84 and accuracy of 0.87."
664,"caption: Model performance of different classifiers based on F1 score, recall, precision, and specificity on a binary classification task.table: Model,F1 score,Recall,Precision,Specificity, SVM,0.87,0.85,0.89,0.93, KNN,0.82,0.78,0.87,0.91, Naive Bayes,0.68,0.62,0.76,0.88, Random Forest,0.91,0.88,0.94,0.96, XGBoost,0.92,0.90,0.94,0.97","The presented table shows the performance of five different classifiers in terms of F1 score, recall, precision, and specificity. SVM (Support Vector Machine), KNN (K-Nearest Neighbours), Naive Bayes, Random Forest, and XGBoost were used to classify a binary dataset. Among all the models, Random Forest and XGBoost outperform the others across all evaluation metrics, achieving high F1 score, recall, precision, and specificity. In particular, XGBoost obtained the highest F1 score, recall, precision, and specificity values, indicating its robustness and stability in this classification task. Meanwhile, SVM achieved the highest specificity, which reflects its ability to classify negative cases accurately."
665,"caption: Table 4. Model performance on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Model A,0.85,0.86,0.84,0.85, Model B,0.83,0.85,0.80,0.82, Model C,0.87,0.89,0.85,0.87, Model D,0.81,0.82,0.78,0.80","Table 4 shows the performance of four different models (Model A, Model B, Model C, and Model D) based on four evaluation metrics: Accuracy, Precision, Recall, and F1 Score. Model C demonstrated the highest performance with an accuracy of 0.87, precision of 0.89, recall of 0.85, and an F1 score of 0.87. Model A and Model B also showed good performance with an accuracy of 0.85 and 0.83, respectively. On the other hand, Model D had the least performance overall with an accuracy of 0.81 and relatively low scores on other metrics as well. Overall, Model C performed the best across all metrics, depicting its suitability for the respective problem."
666,"caption: Performance of different models on a classification task using multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.897,0.905,0.879,0.890, KNN,0.876,0.895,0.831,0.861, MLP,0.905,0.912,0.892,0.900, RF,0.921,0.931,0.909,0.919, XGB,0.917,0.927,0.903,0.914","The table above summarizes the performance of various models concerning Accuracy, Precision, Recall, and F1-score metrics. The table shows that RF achieved the highest accuracy of 0.921, followed closely by XGB, which recorded an accuracy of 0.917. RF also has the highest Precision of 0.931 and Recall of 0.909. SVM obtained the highest precision (0.905), while MLP achieved the highest recall score of 0.892. Overall, these results provide insights into the different strengths and weaknesses of the evaluated classification models."
667,"caption: Model comparison based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score,Time (s), Logistic Regression,0.89,0.88,0.91,0.89,5, Support Vector Machine,0.91,0.91,0.90,0.91,25, Random Forest,0.93,0.95,0.92,0.93,10, XGBoost,0.94,0.93,0.96,0.94,15, Multilayer Perceptron,0.85,0.86,0.83,0.84,20",
668,"caption: Model Evaluation Metrics.table: Model,F1 Score,Accuracy,Precision,Recall, SVM,0.85,0.92,0.87,0.83, Random Forest,0.92,0.95,0.91,0.93, K-Nearest Neigh.,0.82,0.89,0.83,0.81, Decision Trees,0.84,0.90,0.86,0.82, Naive Bayes,0.78,0.83,0.80,0.76","Table 1 presents the evaluation metrics for different models to analyze their performance. The models used are SVM, Random Forest, K-Nearest-Neighbor, Decision Tree, and Naive Bayes. The evaluation metrics table includes F1 score, Accuracy, Precision, and Recall. The Random Forest model has the highest F1 score of 0.92, which indicates the model's better overall performance. SVM has the highest accuracy score of 0.92, while K-nearest-neighbors obtained the lowest accuracy score of 0.89. The Naive Bayes model achieved the lowest F1 score but had the highest precision score of 0.8. The table's results indicate that Random Forest can be considered the best model in terms of overall performance based on these metrics."
669,"caption: Table 4: Multiple model performance based on multiple evaluations.table: Model,Accuracy,F1 Score (Class 0),F1 Score (Class 1),Precision (Class 0),Precision (Class 1),Recall (Class 0),Recall (Class 1), SVM,0.89,0.85,0.92,0.87,0.89,0.84,0.93, Random Forest,0.95,0.94,0.95,0.93,0.96,0.97,0.93, KNN (k=5),0.88,0.81,0.91,0.87,0.89,0.79,0.92, Logistic Regression,0.91,0.88,0.92,0.84,0.94,0.94,0.9, Naïve Bayes,0.86,0.81,0.89,0.82,0.85,0.79,0.91, XGBoost,0.94,0.92,0.94,0.92,0.94,0.93,0.95","Table 4 depicts six different models and their performances using various evaluation metrics. The models' accuracy, F1 score for class 0 and class 1, precision for class 0 and 1, recall for class 0 and 1 are presented. The Random Forest model shows the highest accuracy score of 0.95, and it also performed the best in all other evaluation metrics, except for recall in class 1, where XGBoost attained the best score of 0.95. Interestingly, the Naïve Bayes model delivered the lowest accuracy score of 0.86 but still maintained a decent F1 score in class 1. Overall, the model performances vary depending on the evaluation metric, and the Random Forest model seems to be the best option."
670,"caption: Table 4: Model performance comparison based on different evaluation metricstable: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.83,0.82,0.85,0.80, Decision Trees,0.77,0.75,0.82,0.70, Random Forests,0.89,0.88,0.91,0.84, Support Vector Machines,0.84,0.83,0.83,0.84","Table 4 compares the model performance of four different models on different evaluation metrics. The models assessed include Logistic Regression, Decision Trees, Random Forests, and Support Vector Machines. The models' performance is evaluated on the basis of accuracy, F1 score, precision, and recall. The Random Forest model exhibits the highest accuracy and F1 score with 0.89 and 0.88, respectively, while the Decision Trees model shows the lowest performance on all evaluation metrics. The SVM model achieves the highest recall score with 0.84, and the Logistic Regression model demonstrates the best precision score among all models with 0.85."
671,"caption: Comparison of model performances based on different evaluation metrics.table: Models,Accuracy,F1 Score,AUC Score, Model A,0.96,0.95,0.88, Model B,0.93,0.91,0.85, Model C,0.94,0.92,0.86, Model D,0.92,0.90,0.83, Model E,0.97,0.96,0.89","The table presents a comparison of model performances in terms of accuracy, F1 score, and AUC score. The table lists five models, Model A, B, C, D and E, and their corresponding scores obtained through evaluation metrics. Notably, Model E had the highest scores across all evaluation metrics, with an accuracy of 0.97, F1 score of 0.96, and AUC score of 0.89. On the other hand, Model D had the lowest scores, with an accuracy of 0.92, F1 score of 0.90, and AUC score of 0.83. The table provides a comprehensive comparison of all models' performance, highlighting Model E as the best-performing model."
672,"caption: Table 4: Model Performance Comparison based on Multiple Evaluation Metrics.table: Model,RMSE,MAE,R-Squared, Random Forest,2.347,1.862,0.798, XGBoost,2.299,1.862,0.802, SVR (linear),3.373,2.657,0.582, SVR (rbf),2.882,2.182,0.690, MLP,2.468,1.865,0.777","Table 4 compares five different models—Random Forest, XGBoost, SVR (linear), SVR (rbf), and MLP—based on various evaluation metrics. These metrics include Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), and R-squared. Random Forest and XGBoost exhibit the best RMSE scores of 2.347 and 2.299, respectively, while MLP and Random Forest show the lowest MAE scores of 1.865 and 1.862, respectively. When it comes to R-Squared, all models perform relatively well, but XGBoost and Random Forest stand out with 0.802 and 0.798 scores, respectively. Interestingly, SVR (linear) yielded the highest RMSE and MAE scores of 3.373 and 2.657, respectively, implying its inferior performance."
673,"caption: Comparison of different machine learning models using different evaluation metricstable: Model,Accuracy,Precision (0),Precision (1),Recall (0),Recall (1),AUC, Logistic Regression,0.88,0.85,0.92,0.89,0.87,0.92, SVM RBF,0.89,0.86,0.93,0.91,0.87,0.93, Random Forest,0.91,0.88,0.94,0.92,0.90,0.94, Gradient Boosting,0.90,0.87,0.94,0.91,0.89,0.93",
674,"caption: Model evaluation metrics for classification tasks.table: **Model**,**Accuracy**,**Precision**,**Recall**,**F1-Score**, Logistic Regression,0.82,0.80,0.85,0.82, Random Forest,0.87,0.85,0.89,0.87, K-Nearest Neighbors,0.78,0.77,0.79,0.78, Gradient Boosting,0.89,0.87,0.91,0.89","Table highlights classification model evaluation metrics, such as accuracy, precision, recall, and F1-score for four classification models - Logistic Regression, Random Forest, K-Nearest Neighbors, and Gradient Boosting. The results show that Gradient Boosting has the highest performance in terms of accuracy, precision, recall, and F1-score, with values of 0.89, 0.87, 0.91, and 0.89, respectively. On the other hand, the K-Nearest Neighbors model has the lowest performance among the models, with an accuracy of 0.78, precision of 0.77, recall of 0.79, and an F1-score of 0.78. These results suggest the Gradient Boosting model can be the most suitable model for the classification tasks presented in the analysis."
675,"caption: Table 4: Model performances based on evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score, Model 1,0.92,0.89,0.87,0.88, Model 2,0.91,0.87,0.89,0.88, Model 3,0.93,0.90,0.91,0.91, Model 4,0.91,0.88,0.84,0.86, Model 5,0.94,0.92,0.92,0.92","Table 4 shows the accuracy, precision, recall, and F1-score of five different models used in the experiment. The models' performance is variable, with Model 1 having the highest accuracy score of 0.92, Model 5 having the highest precision score of 0.92, and Models 3 and 5 achieving the highest recall score of 0.91. Notably, each model's F1-score is relatively close, with Model 3 obtaining the highest F1-score of 0.91. These evaluation metrics are crucial in determining the model's overall performance in classification tasks, with Model 5 emerging as the most robust model in this experiment."
676,"caption: Model evaluation metrics for different classification algorithms.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.8655,0.8626,0.797,0.8285, Decision Tree,0.8622,0.8467,0.817,0.8316, Random Forest,0.8911,0.8902,0.821,0.8542, Gradient Boosting,0.8938,0.8969,0.810,0.8513, XGBoost,0.8983,0.9093,0.802,0.8523","The table shows the accuracy, precision, recall, and F1 score calculated for various classification algorithms, such as Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and XGBoost models. The results were obtained by running the models on a similar dataset. Interestingly, XGBoost performed the best in terms of accuracy (0.8983), while Random Forest had the highest precision (0.8902). Notably, Gradient Boosting achieved the highest precision (0.8969) and F1 score (0.8513). Overall, the results show that XGBoost and Gradient Boosting are suitable for this classification problem."
677,"caption: Table 4: Comparison of Different Classifierstable: Models,Accuracy,f1-score,Precision,Recall, Model A,0.95,0.94,0.93,0.95, Model B,0.87,0.81,0.83,0.81, Model C,0.91,0.88,0.87,0.89, Model D,0.93,0.89,0.91,0.88, Model E,0.84,0.75,0.77,0.74","Table 4 presents a comparison of different classifiers' performances based on various metrics, including accuracy, f1-score, precision, and recall. Model A has the highest accuracy score of 0.95, followed by Model D with a score of 0.93. Model B has the lowest accuracy score of 0.87, indicating poor performance. In terms of f1-score, Model A has the highest score of 0.94, while Model E has the lowest of 0.75. For precision, Model D has the highest score of 0.91, while Model E has the lowest of 0.77. For recall, Model A has the highest score of 0.95, while Model E has the lowest of 0.74. Overall, Model A and Model D outperform the others in most of the evaluation metrics. On the other hand, Model E seems to struggle and requires significant improvement."
678,"caption: Table 4: Model performance comparison based on multiple evaluation metricstable: Model,Accuracy,F1-Score,Precision,Recall, Model A,0.95,0.93,0.92,0.94, Model B,0.89,0.91,0.85,0.97, Model C,0.92,0.94,0.91,0.98, Model D,0.84,0.86,0.80,0.94, Model E,0.88,0.87,0.91,0.84",
679,"caption: Performance comparison of different classification modelstable: Model,Accuracy,F1 Score,Recall,Precision, Decision Tree,0.80,0.70,0.65,0.85, Random Forest,0.85,0.75,0.80,0.70, Naive Bayes,0.75,0.65,0.60,0.70, Support Vector Machine,0.90,0.85,0.80,0.90, Logistic Regression,0.86,0.75,0.70,0.80","The table compares the performance of five different classification models, including Decision Tree, Random Forest, Naive Bayes, Support Vector Machine, and Logistic Regression, based on four evaluation metrics: accuracy, F1 score, recall, and precision. The Support Vector Machine model achieved the highest accuracy of 0.90, followed by Logistic Regression with 0.86. The Naive Bayes model obtained the lowest accuracy of 0.75. The Support Vector Machine also outperformed the other models with the best F1 score of 0.85. The Decision Tree model had a higher precision of 0.85, while the Logistic regression model had a better recall of 0.70. Overall, the Support Vector Machine model tended to perform better than the other models in most evaluation metrics."
680,"caption: A table comparing the performances of Model A, B, C, D, and E based on three different evaluation metrics.table: Model Name,Metric 1,Metric 2,Metric 3, Model A,0.67,0.45,0.87, Model B,0.53,0.69,0.78, Model C,0.72,0.44,0.89, Model D,0.66,0.56,0.75, Model E,0.82,0.77,0.91","The table presents the performance results of Model A, B, C, D, and E based on three different evaluation metrics. The metrics used were not explicitly mentioned providing flexibility in the study's evaluation approach. Interestingly, Model E has shown the best performance in all three metrics, with the highest scores of 0.82, 0.77, and 0.91 respectively. Model E's performance scores are notably higher than the other models, suggesting that it may be the best model among those tested. In contrast, Model B has the worst performance in all three metrics, with the lowest scores of 0.53, 0.69, and 0.78."
681,"caption: Performance comparison of different models based on multiple evaluation metrics.table: Model,F1-Score,Accuracy,Precision,Recall, SVM,0.85,0.92,0.90,0.80, RF,0.89,0.93,0.91,0.87, k-NN,0.84,0.91,0.88,0.81, MLP,0.86,0.93,0.88,0.84, NB,0.71,0.89,0.75,0.65",
682,"caption: Table 4: Model performance based on accuracy, F1-Score, AUC, and precision.table: Model,Accuracy,F1-Score,AUC,Precision, Logistic Regression,0.87,0.83,0.92,0.85, Decision Tree,0.84,0.81,0.89,0.82, Random Forest,0.91,0.87,0.94,0.88, XGBoost,0.92,0.88,0.95,0.89, Support Vector Machine,0.86,0.83,0.90,0.84","Table 4 compares the performance of five different classification models based on their accuracy, F1-Score, AUC, and precision. The models include Logistic Regression, Decision Tree, Random Forest, XGBoost, and Support Vector Machine. Notably, Random Forest and XGBoost models perform relatively better than other models based on all four evaluation metrics, achieving an accuracy of 0.91 and 0.92, an F1-Score of 0.87 and 0.88, an AUC of 0.94 and 0.95, and a precision of 0.88 and 0.89, respectively. In contrast, Decision Tree performs the worst among evaluated models, achieving an accuracy of 0.84, an F1-Score of 0.81, an AUC of 0.89, and a precision of 0.82."
683,"caption: Model performance based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.75,0.79,0.71,0.74, RF,0.81,0.84,0.81,0.82, KNN,0.67,0.71,0.64,0.65, NB,0.62,0.65,0.56,0.58","The table above showcases the accuracy, precision, recall, and F1-score performance of different models. The SVM model shows an accuracy of 0.75 and a precision score of 0.79, indicating a 71% recall rate and an F1-score of 0.74. The Random Forest (RF) model demonstrates a better accuracy score (0.81) than the SVM model. RF also exhibits the best precision score of 0.84, a recall rate of 81%, and has an F1-score of 0.82. Comparatively, the K-nearest neighbors (KNN) model records an accuracy of 0.67, the lowest among all models. Similarly, the naive Bayes (NB) model's accuracy score is 0.62, with the lowest precision and recall rates among all models."
684,"caption: Table 4: Performance comparison of various models using different evaluation metrics.table: Model,Accuracy,F1,Precision,Recall, Logistic Regression,0.85,0.85,0.87,0.83, SVM,0.81,0.79,0.76,0.82, Naive Bayes,0.76,0.74,0.77,0.72, Random Forest,0.89,0.89,0.91,0.87, XGBoost,0.88,0.87,0.89,0.85","Table 4 provides a performance comparison of five different models using different evaluation metrics, namely Accuracy, F1 Score, Precision, and Recall. The models examined in the study include Logistic Regression, Support Vector Machine (SVM), Naive Bayes, Random Forest, and XGBoost. The table shows that the Random Forest model achieved the highest Accuracy score of 0.89, F1 Score of 0.89, Precision score of 0.91, and Recall score of 0.87. The Logistic Regression model performed the second best with an Accuracy score of 0.85, F1 Score of 0.85, Precision score of 0.87, and Recall score of 0.83. Overall, the table demonstrates that Random Forest is the best-performing model in this comparative study."
685,"caption: Performance metric comparison of different modelstable: Model,Accuracy,Precision,Recall,F1 Score,AUC Score, SVM,0.87,0.89,0.85,0.87,0.92, AdaBoost,0.84,0.82,0.87,0.84,0.89, KNN,0.81,0.77,0.85,0.81,0.88, Naive Baye,0.75,0.70,0.81,0.75,0.81, Random Forest,0.92,0.93,0.90,0.92,0.97","The table above shows the performance metric comparison of multiple different models, including SVM, AdaBoost, KNN, Naive Baye, and Random Forest. Each model's performance was evaluated using different metrics such as Accuracy, Precision, Recall, F1 Score, and AUC Score, where higher scores indicate better performance. Notably, the Random Forest model performed the best among the models for all the metrics, with an accuracy of 0.92, precision of 0.93, recall of 0.90, F1 score of 0.92, and AUC score of 0.97. This suggests that the Random Forest model might be a suitable choice for the given task. On the other hand, Naive Baye performed the poorest among the models for all the metrics."
686,"caption: Comparison of different models based on multiple evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, Log Regression,0.829,0.738,0.716,0.761, Decision Tree,0.766,0.702,0.632,0.784, Naive Bayes,0.814,0.665,0.584,0.785, Random Forest,0.922,0.915,0.899,0.932","The table above presents the performance comparison of four different models based on accuracy, F1-score, Precision, and Recall metrics. The models compared are Log Regression, Decision Tree, Naive Bayes, and Random Forest. The Random Forest model appears to have the best overall performance, including the highest accuracy of 0.922 and F1-Score of 0.915, as well as the highest precision of 0.899 and recall of 0.932. However, the Decision Tree model has the lowest accuracy of 0.766 and the lowest F1-Score of 0.702. The Naive Bayes model has the lowest precision of 0.584. Overall, the Random Forest model outperformed the other three models across all evaluation metrics."
687,"caption: Performance Comparison of Different Modelstable: Model Name,Precision,Recall,F1 Score,Accuracy,AUC, SVM,0.91,0.93,0.92,0.93,0.882, Random Forest,0.92,0.91,0.91,0.92,0.887, Neural Network,0.90,0.89,0.89,0.89,0.875, Naive Bayes,0.89,0.90,0.89,0.90,0.842, Decision Tree,0.87,0.88,0.87,0.87,0.823","This table presents the performance comparison of five different models using five evaluation metrics, including Precision, Recall, F1 Score, Accuracy, and AUC. The models compared are SVM, Random Forest, Neural Network, Naive Bayes, and Decision Tree. The table reveals that SVM has the highest precision of 0.91 and recall of 0.93. On the other hand, Random Forest has the highest accuracy and AUC with 0.92 and 0.887, respectively. It is noticed that Naive Bayes has the lowest AUC of 0.842, and Decision Tree has the lowest Precision of 0.87. Overall the table highlights the different performances of different models for the same dataset, and each model has its strengths and weaknesses depending on the evaluation metric."
688,"caption: Performance of different models based on multiple evaluation metricstable: Model Name,Accuracy,Precision,Recall,F1-score, Model A,0.85,0.79,0.63,0.70, Model B,0.89,0.83,0.75,0.78, Model C,0.90,0.85,0.76,0.80, Model D,0.92,0.87,0.81,0.83, Model E,0.91,0.89,0.78,0.83","The table compares the performance of five different models (Model A, Model B, Model C, Model D, and Model E) based on four different evaluation metrics, namely Accuracy, Precision, Recall, and F1-score. The table shows that Model D outperforms all other models in terms of Accuracy, Precision, and F1-score with values of 0.92, 0.87, and 0.83, respectively. However, Model E has the highest Recall score of 0.78 and a high F1-score of 0.83, despite being lower than Model D. Model C has the highest Precision score of 0.85 and a high F1-score of 0.80. The results suggest that Model D is the best-performing model overall, but Model E and Model C are also competitive alternatives with their high scores in Recall and Precision, respectively."
689,"caption: Performance comparison of models on evaluation metricstable: Model,F1-Score,Accuracy,Precision,Recall, Model A,0.85,0.92,0.87,0.82, Model B,0.81,0.88,0.84,0.78, Model C,0.87,0.91,0.89,0.85, Model D,0.79,0.86,0.80,0.78, Model E,0.89,0.94,0.91,0.87","The table presents performance comparison of five different models based on multiple evaluation metrics - F1-Score, Accuracy, Precision, and Recall. Model A achieved the highest F1-Score and Accuracy score of 0.85 and 0.92, respectively, while Model E presented the highest Precision score of 0.91. Interestingly, Model C scored the highest Recall score of 0.85, a close score to Model A's F1-Score. Model B and Model D showed inferior performances in comparison to other models. Overall, Model A and Model E performed best in terms of F1-Score and Precision score, respectively."
690,"caption: Model comparison based on multiple evaluation metrics.table: Model,Precision,Recall,F1 Score,Accuracy, LogReg,0.87,0.78,0.80,0.85, KNN,0.78,0.68,0.69,0.76, DecisionTree,0.70,0.73,0.68,0.70, MLP,0.90,0.80,0.84,0.88, SVM,0.83,0.77,0.78,0.81","The table presents a comparison of five different models- Logistic Regression, K-Nearest Neighbors (KNN), Decision Tree, Multi-layer Perceptron (MLP), and Support Vector Machines (SVM) based on multiple evaluation metrics, including Precision, Recall, F1 Score, and Accuracy. Notably, the MLP model has the highest precision of 0.90, indicating that it has the lowest false-positive rate among all models. On the other hand, the Decision Tree model has the highest Recall of 0.73, signifying that it has the lowest false-negative rate among all models. The MLP model also exhibited the highest F1 Score of 0.84 and accuracy of 0.88. Overall, the MLP model showed the best performance based on the combination of multiple evaluation metrics."
691,"caption: Comparison of model performances using different evaluation metricstable: Model,F1-score,Precision,Recall,Accuracy, Logistic Regression,0.86,0.90,0.82,0.89, Decision Tree,0.82,0.86,0.79,0.85, Random Forest,0.89,0.91,0.87,0.90, XGBoost,0.92,0.93,0.91,0.92","The above table provides a comparison between four classification models: Logistic Regression, Decision Tree, Random Forest, and XGBoost, utilizing various evaluation metrics: F1-score, Precision, Recall, and Accuracy. The models' performance was computed based on the same dataset and tested with the same parameters. Interestingly, the XGBoost model attained the highest F1-score result of 0.92, followed by Random Forest with an F1-score of 0.89. In addition, the Precision and Recall assessments are closely related to F1-score, showing XGBoost's exemplary performance in all metrics. However, Logistic Regression and Random Forest show slightly higher accuracy levels of 0.89 and 0.90, respectively, compared to the other models."
692,"caption: Model performance metrics for different classification modelstable: Model,Accuracy,Precision,Recall, Random forest,78.5,0.746,0.812, XGBoost,80.2,0.768,0.834, SVM,78.0,0.761,0.811, Neural network,81.3,0.794,0.843","The table shows the performance metrics for different classification models, including Random forest, XGBoost, SVM, and Neural network. The models were evaluated on the accuracy, precision, and recall metrics. The Neural network model achieves the highest accuracy with a score of 81.3%, while Random forest has the lowest accuracy of 78.5%. However, the Random forest model shows the highest recall of 0.812, which is higher than that of SVM and Neural network. Meanwhile, XGBoost has the highest precision of 0.768 followed by Neural network with 0.794, while SVM and Random forest have lower precision values of 0.761 and 0.746, respectively. Overall, the Neural network model performs best across all three metrics, but Random forest still shows strong performance in recall."
693,"caption: Table 4: Model evaluation metrics comparisontable: Model,F1 Score,Accuracy,Precision,Recall, Logistic Regression,0.75,0.82,0.78,0.73, Random Forest,0.83,0.86,0.81,0.86, Support Vector Machine,0.76,0.81,0.75,0.78, Multi-Layer Perceptron,0.78,0.84,0.82,0.75","Table 4 presents the comparison of the performance of different models on various evaluation metrics. The metrics include F1 score, accuracy, precision, and recall. The table includes four models: Logistic Regression, Random Forest, Support Vector Machine, and Multi-Layer Perceptron. The best-performing models for each metric are highlighted. The Random Forest model showed the best F1 score of 0.83, while the Multi-Layer Perceptron model had the highest accuracy of 0.84. The Precision metric was dominated by the Multi-Layer Perceptron, which achieved a score of 0.82. The Random Forest and Support Vector Machine models had the highest recall score of 0.86 and 0.78, respectively."
694,"caption: Table 4. Comparison of multiple models' performance based on precision, recall, F1-Score, and AUC.table: Model,Precision,Recall,F1-Score,AUC, Model A,0.86,0.89,0.87,0.92, Model B,0.83,0.87,0.85,0.88, Model C,0.91,0.84,0.87,0.90","Table 4 presents a comparison of multiple models based on precision, recall, F1-Score, and AUC. The table includes Model A, Model B, and Model C. Model A has the highest Precision value of 0.86, while Model C has the highest Precision value of 0.91. Model B has the lowest Precision value of 0.83. Model A has the highest Recall value of 0.89; however, Model C has the highest F1-Score value of 0.87. Additionally, Model A has the highest AUC value of 0.92, while Model B has the lowest AUC value of 0.88. Overall, the table shows the variability that exists when evaluating different models against multiple metrics."
695,"caption: Model performance comparison based on different evaluation metricstable: Model,Accuracy,F1 Score,AUC Score, Random Forest 1,0.84,0.85,0.88, Random Forest 2,0.82,0.83,0.85, SVM,0.78,0.80,0.83, Neural Network,0.80,0.81,0.86, Logistic Regression,0.77,0.79,0.82","The table presents a comparison of multiple models' performance based on different evaluation metrics, including Accuracy, F1 Score, and AUC Score. The table exhibits Random Forest 1, Random Forest 2, SVM, Neural Network, and Logistic Regression models. Interestingly, Random Forest 1 achieved the highest AUC score with 0.88, indicating the best class separation ability, while Neural Network had the highest F1 score of 0.81. The overall model with the highest Accuracy is Random Forest 1 with 0.84 followed closely by Neural Network with 0.80, indicating good overall predictive performance. The table provides valuable information for model selection based on specific evaluation metrics."
696,"caption: Model performances based on various metricstable: Model,F1-score,Precision,Recall,Accuracy, SVM,0.756,0.837,0.689,0.836, Naïve Bayes,0.634,0.735,0.558,0.747, Random Forest,0.886,0.917,0.858,0.914, Gradient Boosting,0.906,0.927,0.887,0.925","Table presents different machine learning models' performance based on multiple evaluation metrics. The models considered in the table are SVM, Naïve Bayes, Random Forest, and Gradient Boosting. The metrics used to measure the models' performance are F1-score, Precision, Recall, and Accuracy. Notably, the Random Forest model outperforms the other models in all the metrics considered, achieving the best F1-score, Precision, Recall, and Accuracy. Interestingly, the Gradient Boosting model had a slightly higher F1-score and Precision score than the SVM model. However, the SVM model had a higher Recall score than the Gradient Boosting model, and all other models had a higher Accuracy score than the Naïve Bayes model."
697,"caption: Comparison of different models' performances based on various evaluation metrics.table: Model,Accuracy (mean +- std),Precision (mean +- std),Recall (mean +- std),F1-score (mean +- std), Logistic Regression,0.85 +- 0.02,0.91 +- 0.04,0.82 +- 0.03,0.86 +- 0.02, Random Forest,0.93 +- 0.01,0.94 +- 0.02,0.92 +- 0.01,0.93 +- 0.01, KNN,0.80 +- 0.03,0.84 +- 0.03,0.79 +- 0.03,0.80 +- 0.02, SVM,0.86 +- 0.02,0.89 +- 0.03,0.85 +- 0.02,0.87 +- 0.02, XGBoost,0.94 +- 0.01,0.95 +- 0.02,0.94 +- 0.01,0.94 +- 0.01","The above table presents the mean and standard deviation of the accuracy, precision, recall, and F1-score for five different models: Logistic Regression, Random Forest, KNN, SVM, and XGBoost. The performance results were obtained based on an equal amount of training and testing data. Interestingly, XGBoost outperformed all other models with the highest accuracy of 0.94 +- 0.01, precision of 0.95 +- 0.02, recall of 0.94 +- 0.01, and F1-score of 0.94 +- 0.01. Random Forest achieved the second-highest performance scores for all the evaluation metrics, excelling ahead of all other models. However, KNN performed the worst of all models, with the lowest accuracy, precision, recall, and F1-score, indicating KNN is not a suitable model for the available dataset."
698,"caption: Model performance based on different approaches using multiple evaluation metrics.table: Models,Precision,Recall,F1-score,AUC, Logistic Regression,0.85,0.83,0.84,0.78, Support Vector Machine,0.87,0.89,0.88,0.81, Random Forest,0.91,0.92,0.92,0.86, Gradient Boosting Decision Tree (GBDT),0.92,0.93,0.92,0.87, Convolutional NN,0.91,0.94,0.93,0.88","Table 4 presents the performance of five different models' evaluation metrics, including precision, recall, F1-score, and AUC. The table shows that all models' precision, recall, and F1-score values are above 0.8, demonstrating good model performance. Random Forest has the highest precision, recall, and F1-score values of 0.91, 0.92, and 0.92, respectively. The Convolutional NN achieved the highest AUC of 0.88 among all the models, closely followed by GBDT with an AUC of 0.87. Consequently, this indicates that different models perform differently depending on the evaluation metrics employed. It is essential to choose a suitable model based on the evaluation metrics' significance in the research question."
699,"caption: Comparison of model performances using different evaluation metrics.table: Model,F1-score,Precision,Recall, Logistic Regression,0.823,0.764,0.893, Random Forest,0.859,0.821,0.902, SVM,0.814,0.741,0.903, Gradient Boosting,0.876,0.850,0.903","Table shows a comparison of different models' performance results using three key evaluation metrics: F1-score, precision, and recall. The Logistic Regression model achieved an F1-score of 0.823, precision of 0.764, and recall of 0.893, while the Random Forest model had an F1-score of 0.859, precision of 0.821, and recall of 0.902. Surprisingly, SVM achieved the poorest F1-score of 0.814, precision of 0.741, and recall of 0.903 amongst the models considered. The Gradient Boosting model performed the best amongst all models with an F1-score of 0.876, precision of 0.85, and recall of 0.903. Notably, all models were trained and tested using the same dataset."
700,"caption: Model performances based on different evaluation metrics.table: Model Name,Accuracy,Precision,Recall,F1-Score,AUC-ROC, Model 1,0.87,0.85,0.82,0.83,0.90, Model 2,0.88,0.87,0.80,0.83,0.91, Model 3,0.89,0.85,0.83,0.84,0.87, Model 4,0.91,0.90,0.88,0.88,0.94, Model 5,0.93,0.91,0.89,0.90,0.95","Table 1 shows the performance of five different models based on five evaluation metrics: Accuracy, Precision, Recall, F1-Score, and AUC-ROC. Model 5 shows the highest accuracy score of 0.93 out of all models, while Model 1 has the lowest score of 0.87. Moreover, Model 4 displays the top precision and recall scores of 0.90 and 0.88, respectively, while Model 3 demonstrates the best F1-Score of 0.84. Notably, Model 5 had the highest score for AUC-ROC with 0.95, followed by Model 4 with 0.94. Overall, Model 5 appears to be the best-performing model, closely followed by Model 4."
701,"caption: Performance comparison of different models using various evaluation metrics.table: Metric,Model 1,Model 2,Model 3,Model 4,Model 5, Accuracy,0.87,0.85,0.88,0.86,0.84, Precision,0.82,0.84,0.86,0.87,0.81, Recall,0.85,0.87,0.84,0.83,0.86, F1-score,0.83,0.85,0.85,0.85,0.83","The table displays the performance comparison of five different models based on various evaluation metrics. The models' performance scores were evaluated based on accuracy, precision, recall, and F1-score. Model 3 achieved the best accuracy score of 0.88, while Model 4 shows the highest precision score of 0.87. Model 2 scored the highest recall score of 0.87. Notably, Models 1, 2, and 4 have a total precision of above 0.83, indicating they have a high level of confidence in predicting the positive class. Meanwhile, Models 1, 2, and 5 have an average F1-score of 0.84, which suggests that they perform well in balancing precision and recall. Overall, Model 3 has the most top scores across the different evaluation metrics."
702,"caption: Table 4: Performance of various classification models using different evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.85,0.84,0.83,0.85, Decision Tree,0.82,0.80,0.79,0.81, Naive Bayes,0.77,0.74,0.76,0.72, KNN,0.81,0.78,0.80,0.76","Table 4 showcases the performance of Logistic Regression, Decision Tree, Naive Bayes, and K-Nearest Neighbors (KNN) classification models using different evaluation metrics. The models were evaluated using Accuracy, F1-score, Precision, and Recall metrics to measure their performance. The results reveal that Logistic Regression had the highest accuracy with a score of 0.85, while KNN scored the lowest with a score of 0.81. However, Naive Bayes had the lowest F-1 score of 0.74, while Logistic Regression had the highest score of 0.84. The results demonstrate that the performance of models can vary according to the evaluation metrics used."
703,"caption: Model performance on various evaluation metrics.table: Model,Accuracy,F1 score,Precision,Recall, A,0.85,0.80,0.75,0.87, B,0.93,0.91,0.88,0.93, C,0.71,0.60,0.56,0.64, D,0.84,0.81,0.79,0.82, E,0.94,0.92,0.89,0.95","The table above compares the accuracy, F1 score, precision, and recall performance of five different models. Model B shows the best overall performance, with an accuracy score of 0.93, an F1 score of 0.91, a precision score of 0.88, and a recall score of 0.93. Model E had the highest accuracy score of 0.94, while B had the highest F1 and precision scores of 0.91 and 0.88, respectively. Model E performed the best in recall with a score of 0.95. Model C had the lowest performance on all metrics, with an accuracy score of 0.71, the F1 score of 0.60, precision score of 0.56, and recall score of 0.64."
704,"caption: Table 4: Performance comparison of different models based on different evaluation metrics.table: Models,Accuracy,F1-Score,AUC,Precision, Model A,0.89,0.91,0.78,0.87, Model B,0.92,0.92,0.81,0.91, Model C,0.85,0.87,0.74,0.83, Model D,0.93,0.95,0.85,0.94","Table 4 compares the performance of four different models based on various evaluation metrics. The evaluation metrics used in this table are accuracy, F1-score, AUC, and precision. Models A, B, C, and D achieved different performances, with Model D showing the best results in all metrics. Notably, Model B was the second-best model, with the highest accuracy and F1-score. However, Model D showed the highest AUC and precision scores, indicating that it effectively balances the true positive rate and false positive rate and produces high-quality results. On the other hand, Model C exhibited the lowest results overall. This table highlights the importance of using multiple metrics to accurately evaluate models' performance."
705,"caption: Model performances with multiple evaluation metricstable: Model,Accuracy,F1 Score,Precision,Recall, Logistic Reg.,0.754,0.752,0.764,0.744, Decision Tree,0.692,0.691,0.705,0.678, Random Forest,0.802,0.800,0.816,0.785, Gradient Boost,0.822,0.820,0.832,0.809, SVM (linear),0.768,0.766,0.774,0.754, SVM (rbf),0.780,0.778,0.788,0.768","The table presents the model performances for six different models of Logistic Regression, Decision Tree, Random Forest, Gradient Boost, SVM (linear), and SVM (rbf). Each model's accuracy, F1 score, precision, and recall metrics are included. Notably, Gradient Boosting achieved the best results across all evaluation metrics, with an accuracy of 0.822, F1 score of 0.820, precision of 0.832, and recall of 0.809. Interestingly, among the SVM models, the linear kernel function performs better with an accuracy of 0.768, F1 score of 0.766, precision of 0.774, and recall of 0.754 compared to the rbf kernel function. The Random Forest model also performed well, with an accuracy of 0.802, F1 score of 0.800, precision of 0.816, and recall of 0.785."
706,"caption: Performance of different classification models based on precision, recall, and F1-score.table: Model,Precision (mean ±sd),Recall (mean ±sd),F1-score (mean ±sd), Logistic Regression,0.85±0.02,0.75±0.03,0.79±0.01, Decision Tree,0.75±0.03,0.71±0.02,0.73±0.01, Random Forest,0.90±0.02,0.85±0.02,0.87±0.01, Support Vector Machine,0.76±0.02,0.78±0.02,0.77±0.02, K-Nearest Neighbor,0.79±0.02,0.82±0.02,0.80±0.01",
707,"caption: Table 4: Multiple models' performance on different evaluation metrics.table: Model,Recall,F1-Score,Precision, Logistic Regression,0.85,0.76,0.94, Naive Bayes,0.89,0.79,0.92, Decision Tree,0.74,0.68,0.83, Random Forest,0.92,0.84,0.94, XGBoost,0.94,0.88,0.90","In Table 4, we display the performance of multiple models on different evaluation metrics. The models evaluated in the table include Logistic Regression, Naive Bayes, Decision Tree, Random Forest, and XGBoost. For each model, we report Recall, F1-Score and Precision as the evaluation metrics. Notably, Random Forest and XGBoost yielded the highest Recall, F1-Score, and Precision values. The Naive Bayes model also showed competitive performance, attaining Recall of 0.89, F1-Score of 0.79, and Precision of 0.92. Conversely, the Decision Tree model performed poorly with a Recall of 0.74, F1-Score of 0.68, and Precision of 0.83. Overall, the results demonstrate that the Random Forest and XGBoost models seem to outperform the other models across all metrics."
708,"caption: Table 4. Model performance based on multiple evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score,ROC-AUC, Logistic Regression,0.89,0.91,0.87,0.89,0.95, Random Forest,0.92,0.94,0.91,0.92,0.97, SVM,0.85,0.88,0.83,0.85,0.92, Neural Network,0.93,0.92,0.95,0.93,0.96",
709,"caption: Table 4: Model evaluation results on the validation set.table: Model,Precision,Recall,F1,Accuracy,Cohen Kappa, Logistic Regression,0.82,0.67,0.73,0.76,0.49, Random Forest,0.75,0.70,0.71,0.68,0.34, Support Vector Machine,0.61,0.80,0.69,0.54,0.08, K-Nearest Neighbors (KNN),0.59,0.66,0.59,0.48,0.06",
710,"caption: Comparison of performance metrics across different models.table: Model,Accuracy,F1 Score,Precision,Recall,AUC-ROC,AUC-PR, Model 1,0.86,0.89,0.90,0.88,0.90,0.88, Model 2,0.83,0.86,0.80,0.93,0.83,0.84, Model 3,0.91,0.93,0.94,0.92,0.92,0.91, Model 4,0.85,0.88,0.86,0.89,0.91,0.89, Model 5,0.92,0.94,0.93,0.95,0.94,0.93","The table highlights the comparison of multiple models based on various evaluation metrics, including Accuracy, F1 Score, Precision, Recall, AUC-ROC, and AUC-PR. Model 3 achieved the best results with the highest accuracy (0.91) and F1 score (0.93), while Model 5 achieved the highest precision (0.93) and Recall (0.95). Interestingly, while Model 1 has the highest AUC-ROC and AUC-PR (0.90 and 0.88 respectively), it comes second in Accuracy and F1 Score. The results suggest that some of the models may be suited for a specific evaluation metric."
711,"caption: Table 4: Model performance based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score,Specificity, Logistic Regression,0.92,0.93,0.91,0.92,0.93, Decision Tree,0.86,0.85,0.85,0.85,0.88, SVM,0.94,0.95,0.94,0.94,0.93, Naive Bayes,0.90,0.91,0.89,0.90,0.91","Table 4 shows the performance of different models, Logistic Regression, Decision Tree, SVM, and Naive Bayes, based on multiple evaluation metrics, namely Accuracy, Precision, Recall, F1-score, and Specificity. All models were evaluated on the same dataset. SVM achieved the highest accuracy of 0.94, while Logistic Regression and Naive Bayes models had accuracy measurements of 0.92 and 0.90, respectively. Interestingly Decision Tree had the highest specificity of 0.88, while SVM had notably high Precision, Recall, F1-score of 0.95, 0.94, and 0.94 respectively."
712,"caption: Table 4: Evaluation metrics for different models.table: Model,Accuracy,F1-score,AUC-ROC,PR-AUC, Logistic Regression,0.78,0.76,0.84,0.72, Decision Tree,0.72,0.65,0.76,0.63, Random Forest,0.84,0.82,0.91,0.80, XGBoost,0.86,0.84,0.93,0.86, Multi-layer Perceptron,0.80,0.78,0.88,0.76","Table 4 presents an evaluation of different models using multiple evaluation metrics. The models' accuracy, F1-score, AUC-ROC, and PR-AUC were calculated and presented in the table. The table exhibits Logistic Regression, Decision Tree, Random Forest, XGBoost, and Multi-layer Perceptron models. The Random Forest and XGBoost models performed well in this evaluation, achieving high scores across all metrics. The XGBoost model reached the highest accuracy of 0.86 and F1-score of 0.84. The highest AUC-ROC and PR-AUC scores were achieved by the XGBoost and Logistic Regression models, respectively."
713,"caption: Table 4: Model performance comparison based on multiple evaluation metricstable: Model,Precision,Recall,F1-score,Accuracy, Logistic Regression,0.82,0.80,0.81,0.79, Support Vector Machine,0.80,0.85,0.82,0.82, Decision Tree,0.70,0.75,0.72,0.73, Random Forest,0.78,0.82,0.80,0.81, XGBoost,0.83,0.88,0.85,0.86, Multilayer Perceptron,0.75,0.70,0.72,0.73, Convolutional Neural Network,0.87,0.88,0.87,0.88","Table 4 shows different models' performance comparison based on four different evaluation metrics. The models included are logistic regression, support vector machine (SVM), decision tree, random forest, XGBoost, multilayer perceptron (MLP), and convolutional neural network (CNN). The metrics used for the comparison are precision, recall, F1-score and accuracy. Notably, SVM achieved the highest recall score of 0.85, while CNN had the highest precision score of 0.87. Also, XGBoost showed the best accuracy score of 0.86 compared to the other models in the table. Thus, based on this table, we conclude that XGBoost and CNN are the best performers."
714,"caption: A comparison of different classification models using multiple evaluation metrics.table: Model,Precision,Recall,F1-Score,AUC, SVM,0.75,0.80,0.77,0.88, Logistic Regression,0.68,0.81,0.73,0.82, Decision Tree,0.71,0.72,0.71,0.79, Random Forest,0.85,0.75,0.80,0.92, Naive Bayes,0.62,0.88,0.64,0.76","This table compares the performance of different classification models, including SVM, Logistic Regression, Decision Tree, Random Forest, and Naive Bayes, using four evaluation metrics: Precision, Recall, F1-Score, and AUC. The best results for each metric are highlighted in bold. The Random Forest model performed best in terms of precision (0.85) and F1-Score (0.80), while Naive Bayes had the highest recall (0.88). The SVM model achieved the highest AUC score (0.88). It is interesting to note that the Logistic Regression model performed relatively poorly compared to the other models for all metrics except recall (0.81)."
715,"caption: Table 4. Model performance based on different evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, LR,0.92,0.89,0.91,0.88, SVM,0.95,0.93,0.92,0.96, RF,0.96,0.94,0.96,0.93, NN,0.94,0.92,0.93,0.93","Table 4 illustrates the performance of multiple models based on various evaluation metrics, including accuracy, F1-score, precision, and recall. The table captures the results of Logistic Regression (LR), Support Vector Machine (SVM), Random Forest (RF), and Neural network (NN) models. The highest accuracy score is achieved by the RF model with an accuracy score of 0.96. However, the LR and NN models are also competitive with an accuracy score of 0.92 and 0.94, respectively. Additionally, the RF model outperforms the other models in terms of F1-score, precision, and recall. However, SVM models are more precise than other models with a precision score of 0.92."
716,"caption: Table 4: Comparative performance of different models based on various evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, RF,0.93,0.89,0.91,0.87, SVM,0.91,0.86,0.90,0.82, LR,0.89,0.83,0.86,0.80, MLP,0.88,0.81,0.85,0.77, KNN,0.85,0.78,0.82,0.74","Table 4 presents a comparison of different machine learning models' performances based on their accuracy, F1-score, precision, and recall values. The table contains five models: Random forest (RF), support vector machine (SVM), logistic regression (LR), multi-layer perceptron (MLP), and k-nearest neighbors (KNN). The best accuracy was achieved by the RF model, with a score of 0.93, while the KNN model had the lowest accuracy result of 0.85. The RF model also shows the highest F1-score and precision of 0.89 and 0.91, respectively, while LR had the highest recall value of 0.80. These results indicate that the RF model performs better in terms of overall evaluation metrics."
717,"caption: Performance results for different models using multiple evaluation metrics on a binary classification task.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.86,0.85,0.88,0.82, Decision Tree,0.79,0.78,0.79,0.77, K-Nearest Neighbor,0.83,0.81,0.83,0.80, Random Forest,0.89,0.89,0.91,0.87, Neural Network,0.92,0.92,0.93,0.91","The table presents a comparison of five different models' performance results on a binary classification task using multiple evaluation metrics. The evaluated metrics are Accuracy, F1 Score, Precision, and Recall. The Random Forest model achieved the best overall performance, scoring the highest accuracy of 0.89, the highest F1 score of 0.89, the highest precision of 0.91, and the second-best recall score of 0.87. The Neural Network model showed the best performance for all evaluation metrics. It achieved the highest accuracy of 0.92, the highest F1 Score of 0.92, the highest precision score of 0.93, and the highest recall score of 0.91. Notably, the Logistic Regression model had the second-best performance for all the evaluation metrics with accuracy of 0.86, F1 score of 0.85, precision of 0.88, and recall of 0.82."
718,"caption: Evaluation of Different Modelstable: Model,Accuracy,F1 Score,AUC Score, Logistic Regression,0.88,0.86,0.93, Support Vector Machine,0.91,0.89,0.94, Decision Tree,0.83,0.78,0.85, Random Forest,0.93,0.92,0.96, Gradient Boosting,0.92,0.90,0.95","This table summarizes the evaluation of different models using various metrics, including accuracy, F1-score, and AUC score. The models evaluated in this table include Logistic Regression, Support Vector Machine (SVM), Decision Tree, Random Forest, and Gradient Boosting. The Random Forest model achieves the highest accuracy (0.93) and F1-score (0.92) among all models. SVM performs the best in terms of the AUC score (0.94). Interestingly, the Decision Tree model has the lowest accuracy (0.83) and F1-score (0.78) compared to other models. The table provides valuable information for choosing the best model to fit the dataset, based on different evaluation metrics."
719,"caption: Performance comparison of multiple models based on different evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.89,0.88,0.90,0.87, KNN,0.86,0.84,0.89,0.80, NB,0.88,0.85,0.91,0.81, MLP,0.91,0.90,0.93,0.88, CNN,0.93,0.92,0.94,0.91","The table above presents the performance of five classification models based on different evaluation metrics. The table exhibits the results of SVM, KNN, Naive Bayes (NB), Multi-Layer Perceptron (MLP), and Convolutional Neural Network (CNN) models. All models were evaluated based on accuracy, F1-score, precision, and recall. Interestingly, the CNN model outperformed all other models with the highest scores in all evaluation metrics. The MLP model also demonstrated great performance, while the KNN model showed the lowest performance, particularly in recall. Overall, the table highlights the importance of evaluating models using multiple metrics in determining the best model for a classification task."
720,"caption: Model performance analysis with different evaluation metricstable: Model,Accuracy,Precision,Recall,F1-score, Model 1,0.862,0.888,0.926,0.888, Model 2,0.897,0.876,0.932,0.884, Model 3,0.912,0.898,0.947,0.907, Model 4,0.853,0.825,0.917,0.867","The presented table includes the comparison of four different models' performance based on accuracy, precision, recall, and F1-score metrics. The table shows that Model 3 obtained the highest accuracy score of 0.912, while Model 4 obtained the lowest score of 0.853. However, Model 3 and Model 2 have the highest precision and recall scores, respectively, that is 0.898 and 0.932. Remarkably, Model 4 achieved the highest F1-score of 0.867, while Model 1 achieved the lowest F1-score of 0.888. Overall, the table shows a different set of strengths and weaknesses of each model based on different evaluation metrics."
721,"caption: Performance of different models using various evaluation metricstable: Model,Accuracy,F1-score,Precision,Recall, Logistic regression,0.91,0.92,0.93,0.91, Decision tree,0.82,0.83,0.85,0.81, Random forest,0.93,0.94,0.93,0.96, Support vector machines,0.89,0.89,0.91,0.88, K-nearest neighbours,0.85,0.85,0.87,0.84","The table presents the accuracy, F1-score, precision, and recall of five different models, including logistic regression, decision tree, random forest, support vector machines, and K-nearest neighbors. Overall, the random forest model demonstrates the best performance, achieving the highest accuracy of 0.93, F1-score of 0.94, precision of 0.93, and recall of 0.96, respectively. The logistic regression model shows the second-best overall performance with an accuracy of 0.91, F1-score of 0.92, precision of 0.93, and recall of 0.91, respectively. Interestingly, the decision tree model had the lowest performance overall, achieving the lowest accuracy of 0.82, F1-score of 0.83, precision of 0.85, and recall of 0.81, respectively. In summary, random forest and logistic regression models have better performance than others."
722,"caption: Model performances based on various evaluation metrics.table: Model,F1-score,Precision,Recall,Accuracy, A,0.72,0.82,0.64,0.76, B,0.79,0.85,0.74,0.82, C,0.68,0.77,0.62,0.72, D,0.84,0.90,0.79,0.87, E,0.77,0.86,0.70,0.79","Table x above presents a comparison of different models' performances based on multiple evaluation metrics. The table includes F1-score, precision, recall, and accuracy of models A through E. Notably, model D (F1-score of 0.84) demonstrates a better F1-score than the other models, while model E (precision of 0.86) has shown the best precision. Moreover, model B outperformed all the models in the recall category with a score of 0.74. Based on the accuracy metric, model D obtained the highest score of 0.87, indicating that the model can predict accurately. Finally, the findings suggest that model performances can differ based on the selected evaluation metric."
723,"caption: Table 4: Multiple model performance comparison based on various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score,AUC, Logistic Regression,0.82,0.84,0.78,0.81,0.89, Random Forest,0.85,0.87,0.81,0.84,0.92, Support Vector Machines,0.80,0.83,0.75,0.78,0.88, Multi-layer Perceptron,0.78,0.81,0.72,0.76,0.87, Convolutional Neural Network,0.86,0.88,0.82,0.85,0.93","Table 4 displays a performance comparison of multiple models based on various evaluation metrics, including Accuracy, Precision, Recall, F1 Score, and AUC. The models used for the study include Logistic Regression, Random Forest, Support Vector Machines, Multi-layer Perceptron, and a Convolutional Neural Network. Random Forest achieved the best Accuracy, Precision, and F1 Score of 0.85, 0.87, and 0.84, respectively, while the Convolutional Neural Network achieved the best AUC with a score of 0.93, followed by Random Forest with an AUC of 0.92. Overall, the table highlights the varying performances of different models based on different evaluation metrics."
724,"caption: Table 1: The performance comparison of classic classification models on the given dataset.table: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.91,0.94,0.92,0.93, SVM,0.93,0.96,0.91,0.94, Multinomial NB,0.87,0.89,0.83,0.86, KNN,0.85,0.83,0.80,0.81, Random Forest,0.94,0.95,0.94,0.94, XGBoost,0.95,0.96,0.95,0.95",
725,"caption: Performance metrics of four different machine learning models on a classification task.table: Model Name,Accuracy,Precision,Recall, Random Forest,0.82,0.85,0.76, SVM,0.80,0.83,0.71, Decision Tree,0.76,0.70,0.80, KNN,0.78,0.81,0.66","The table summarizes the performance of four different machine learning models on a classification task using three different evaluation metrics, namely accuracy, precision, and recall. The Random Forest model shows the best accuracy score of 0.82. The precision scores show that all models performed relatively well with Random Forest and SVM showing the highest precision scores of 0.85 and 0.83, respectively. The Recall scores show that the Decision tree model performed the best with a score of 0.80, whereas, the SVM model has the lowest recall score of 0.71. Overall, the table provides a comprehensive view of different models' performances using multiple evaluation metrics."
726,"caption: Table 4: Model performance from different approaches based on accuracy, F1-Score, Precision, and Recalltable: Model,Accuracy,F1-score,Precision,Recall, SVM,0.86,0.84,0.87,0.81, Random forest,0.83,0.80,0.82,0.75, KNN,0.75,0.70,0.72,0.67, Naive Bayes,0.79,0.73,0.76,0.71","Table 4 presents a comparison of different models' performances based on evaluation metrics such as accuracy, F1-score, precision, and recall. The table shows the accuracy, F1-Score, precision, and recall scores for SVM, Random Forest, KNN, and Naive Bayes models. Notably, the SVM model showed the highest accuracy with a score of 0.86. However, the Random Forest model showed the best F1-score of 0.80 followed closely by the Naive Bayes model with a score of 0.73. Additionally, the SVM model shows the highest precision with a score of 0.87, and the Naive Bayes model showed the best recall with a score of 0.71."
727,"caption: Different model performances using the validation dataset.table: Model,Accuracy,Precision,Recall,F1 Score, SVM,0.82,0.85,0.78,0.81, Random Forest,0.88,0.87,0.84,0.85, MLPClassifier,0.85,0.84,0.81,0.83, Naive Bayes,0.78,0.79,0.75,0.76, K-Nearest Neighbor,0.79,0.81,0.73,0.76","The table illustrates the accuracy, precision, recall, and F1 score for five different machine learning models, including SVM, Random Forest, MLPClassifier, Naive Bayes, and K-Nearest Neighbor, based on their evaluation using the validation dataset. The Random Forest model shows the best performance in terms of accuracy with a score of 0.88. On the other hand, out of the five models, SVM shows better precision, recall, and F1 score with 0.85, 0.78, and 0.81, respectively. Naive Bayes model achieved the lowest scores for all evaluation metrics, and K-Nearest Neighbor got the lowest recall and F1 score with 0.73 and 0.76, respectively, among all models."
728,"caption: Table 4: Comparison of different models' performance using multiple evaluation metrics.table: Model,Accuracy (%),F1 Score,Recall,Precision, Logistic Regression,93.21,0.930,0.921,0.940, Naive Bayes,88.12,0.881,0.823,0.948, Support Vector Machine,95.67,0.956,0.949,0.964, Random Forest,96.57,0.966,0.963,0.970, XGBoost,96.43,0.964,0.962,0.966","Table 4 presents a comparison of multiple models' performance using different evaluation metrics such as Accuracy, F1 Score, Recall, and Precision. The models presented in the table are Logistic Regression, Naive Bayes, Support Vector Machine, Random Forest, and XGBoost. All models were trained and tested on the same dataset. As per the table, the Random Forest model shows the highest accuracy score (96.57%), followed closely by XGBoost (96.43%). The Random Forest model also achieves the highest F1 Score (0.966), Recall (0.963), and Precision (0.970). The Support Vector Machine model also demonstrates high accuracy and F1 score with 95.67% and 0.956 respectively. Interestingly, Naive Bayes has the lowest accuracy score of 88.12%, but it exhibited high recall (0.823) and precision (0.948) score."
729,"caption: Classification model performancestable: Model,Accuracy,F1-score,Recall,Precision, Decision Tree,0.73,0.58,0.47,0.79, Logistic Regression,0.81,0.67,0.60,0.76, SVM,0.79,0.65,0.56,0.77, KNN,0.78,0.62,0.54,0.73, Multinomial Naive Bayes,0.76,0.59,0.51,0.71, Random Forest,0.85,0.71,0.65,0.78, AdaBoost,0.82,0.68,0.63,0.74, XGBoost,0.87,0.75,0.70,0.80","The presented table displays a comparison of different classification models, including Decision Tree, Logistic Regression, SVM, KNN, Multinomial Naive Bayes, Random Forest, AdaBoost, and XGBoost. The evaluation metrics include Accuracy, F1-score, Recall, and Precision. Results indicate that XGBoost has the highest Accuracy of 0.87, while Random Forest had the best F1-Score, Recall, and Precision of 0.71, 0.65, 0.78, respectively. On the other hand, Logistic Regression showed the best Recall value of 0.60, with an Accuracy of 0.81. Interestingly, Naive Bayes achieved relatively low performance results in all evaluation metrics with an Accuracy of 0.76 and F1-Score of 0.59. Overall, the Random Forest and XGBoost models demonstrated better performance than the other models."
730,"caption: Table 4: Performance Results of Different Models using Various Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.85,0.79,0.86,0.82, Decision Tree,0.77,0.71,0.73,0.72, Random Forest,0.89,0.86,0.85,0.85, Support Vector Machines,0.87,0.82,0.89,0.85, Gradient Boosting Classifier,0.90,0.88,0.88,0.87","Table 4 presents the performance results of different classification models using various evaluation metrics. The models analyzed were Logistic Regression, Decision Tree, Random Forest, Support Vector Machines, and Gradient Boosting Classifier. Multiple evaluation metrics such as Accuracy, Precision, Recall, and F1 Score were used to evaluate model performances. Interestingly, the Gradient Boosting Classifier achieved the highest accuracy score of 0.90, followed closely by the Random Forest model with a score of 0.89. Similarly, the Gradient Boosting Classifier also had the highest Precision score of 0.88, and the highest recall score of 0.88, with an F1 score of 0.87. On the other hand, the Decision Tree model achieved the lowest scores across all performance metrics, highlighting its inferior performance compared to other models."
731,"caption: Model Performance Metricstable: Model,Accuracy,F1-Score,Precision,Recall, Logreg,0.85,0.85,0.849,0.85, SVM,0.84,0.84,0.846,0.85, KNN,0.71,0.69,0.713,0.71, Naive Bayes,0.68,0.68,0.715,0.63, Decision Tree,0.82,0.79,0.80,0.78, Random Forest,0.91,0.91,0.911,0.91","Table presents comparative statistics for different models' performance, measuring accuracy, F1-score, precision, and recall. The models discussed include Logistic Regression (Logreg), Support Vector Machine (SVM), k-Nearest Neighbors (KNN), Naive Bayes, Decision Tree, and Random Forest. The data suggests that Random Forest has the highest accuracy, achieving 91% while also scoring the best F1-score, precision, and recall among the models. The next-best models were Logreg and SVM, with accuracy scores of 85 and 84%, respectively. KNN had a lower accuracy of 71%, while Naive Bayes had an accuracy score of 68%. In contrast, Decision Tree achieved 82% accuracy, which was relatively high but lower than the best performing model, Random Forest."
732,"caption: Model Performance Comparison based on multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.837,0.840,0.830,0.834, KNN,0.820,0.818,0.810,0.814, RF,0.853,0.852,0.855,0.853, GB,0.857,0.855,0.858,0.856, LR,0.833,0.838,0.828,0.833",
733,"caption: Model performances based on different evaluation metrics.table: Model,Accuracy,F1-Score,Recall,Precision, SVM,0.81,0.77,0.73,0.83, KNN,0.73,0.66,0.58,0.77, DT,0.79,0.69,0.77,0.63, RF,0.87,0.81,0.89,0.76, NB,0.65,0.43,0.71,0.31","The table illustrates the comparison of different models based on their performance for different evaluation metrics. The models include Support Vector Machine (SVM), k-Nearest Neighbors (KNN), Decision Trees (DT), Random Forest (RF), and Naive Bayes (NB). The evaluation metrics comprise accuracy, F1-score, recall, and precision. RF model showed the best overall performance for accuracy, F1-score, and recall with scores of 0.87, 0.81, and 0.89, respectively. SVM showed the best performance for precision with a score of 0.83. KNN and NB models showed significantly lower performance than the rest of the models for all evaluation metrics."
734,"caption: Model performances on various evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.87,0.87,0.86,0.91, Decision Tree,0.83,0.82,0.84,0.80, Random Forest,0.91,0.91,0.92,0.92, Support Vector Machine,0.89,0.89,0.87,0.92, Neural Network,0.88,0.88,0.87,0.89","The table presents the comparison of five different models (Logistic Regression, Decision Tree, Random Forest, Support Vector Machine, and Neural network) based on accuracy, F1 score, precision, and recall evaluation metrics. The Random Forest model outperformed other models with the highest accuracy, F1 score, and recall values of 0.91, 0.91, and 0.92, respectively. However, it had a slightly lower precision score of 0.92. The Logistic Regression model had the second-best performance with an accuracy score of 0.87 and an F1 score of 0.87. On the other hand, the Decision Tree model had the lowest accuracy and F1 score, while the Support Vector Machine model had the highest precision but its accuracy and recall values were slightly lower than the Random Forest model. The Neural Network achieved moderately better performance on all metrics compared to Logistic Regression."
735,"caption: Table 4: Performance metrics of different models in binary classification problem.table: Model,Accuracy,Precision,Recall,F1-Score, Random Forest,0.85,0.87,0.84,0.85, XGBoost,0.83,0.88,0.79,0.83, SVM,0.80,0.84,0.75,0.79, Naïve Bayes,0.78,0.81,0.73,0.77, Logistic Reg.,0.82,0.85,0.80,0.82","Table 4 compares multiple machine learning models in terms of their accuracy, precision, recall, and F1-Score metrics. The table showcases five models: Random Forest, XGBoost, SVM, Naïve Bayes, and Logistic Regression. The evaluation metrics offer interesting observations regarding the performance of these models in a binary classification problem. While Random Forest and XGBoost have the highest accuracy scores of 0.85 and 0.83, respectively, the SVM model shows the highest precision with a score of 0.84. Furthermore, the Logistic Regression has the highest F1-Score of 0.82. These observations could aid researchers in selecting the most suitable model based on their objectives."
736,"caption: Table 4: Model performances based on different evaluation metrics.table: Model,F1-Score,Recall,Precision,Accuracy, Logistic Regression,0.80,0.70,0.92,0.85, Decision Tree,0.67,0.67,0.67,0.81, Random Forest,0.82,0.71,0.96,0.87, Support Vector Machine,0.75,0.60,0.98,0.83","Table 4 presents the evaluation metrics of F1-Score, Recall, Precision, and Accuracy of several models: Logistic Regression, Decision Tree, Random Forest, and Support Vector Machines. The best model for each metric is highlighted using bold font. Based on this table, Random Forest results in the highest F1-Score with 0.82, Precision with 0.96, and Accuracy with 0.87. Logistic Regression produced the best recall result with 0.70. Interestingly, Support Vector Machine's precision score is the highest with 0.98, but it had relatively lower F1-Score, Recall, and Accuracy scores compared to others. Decision Tree produced the lowest scores for all evaluation metrics, showcasing that it is not the optimal model for this dataset."
737,"caption: Table 4. Model performances based on accuracy, precision, recall, and F1-score.table: Model,Accuracy,Precision,Recall,F1-score, Model A,0.80,0.72,0.85,0.78, Model B,0.85,0.78,0.87,0.83, Model C,0.82,0.77,0.83,0.80, Model D,0.88,0.81,0.90,0.85, Model E,0.89,0.83,0.87,0.85","Table 4 compares the performance of five different models (A to E) based on four evaluation metrics: accuracy, precision, recall, and F1-score. Model D and Model E achieved the highest accuracy, with Model E having the highest accuracy score of 0.89. Model E also achieved the highest F1-score and the highest precision score, while Model D had the highest recall score. Overall, Model E performed the best across all the evaluation metrics, followed closely by Model D. This table highlights the importance of considering multiple evaluation metrics while assessing model performance."
738,"caption: Table 4: Model Performance Evaluation Using Multiple Metricstable: Model,Accuracy,F1 Score,AUC Score, Logistic Regression,0.80,0.73,0.89, Decision Tree,0.69,0.61,0.75, Random Forest,0.82,0.78,0.89, Support Vector Machine,0.71,0.62,0.83","Table 4 presents a comparison of the performance metrics of four models namely Logistic Regression, Decision Tree, Random Forest, and Support Vector Machine. These models have been evaluated based on three different metrics: Accuracy, F1-score, and AUC-score. The presented results show that the Random Forest model outperformed all other models based on all the metrics with an Accuracy score of 0.82, F1-score of 0.78, and AUC-score of 0.89. Logistic Regression also achieved a fairly high overall performance with an Accuracy score of 0.80, F1-score of 0.73, and AUC-score of 0.89. However, both Decision Tree and Support Vector Machine are found to have lower overall performance with lower metrics scores."
739,"caption: Table 4: Performance of Machine Learning models on sentiment analysis task using evaluation metricstable: Model,Accuracy,F1-Score,Recall,Precision, SVM,0.80,0.81,0.73,0.91, Naive Bayes,0.70,0.70,0.79,0.63, Random Forest,0.85,0.85,0.85,0.84, Logistic Regression,0.75,0.75,0.80,0.70","Table 4 presents the results of four different machine learning models (SVM, Naive Bayes, Random Forest, and Logistic Regression) evaluated based on accuracy, F1-Score, recall, and precision metrics concerning a sentiment analysis task. It can be observed that Random Forest achieved the highest accuracy, F1-Score, and recall scores, with accuracy rate of 0.85, F1-Score of 0.85, and recall of 0.85. Meanwhile, SVM had the highest precision score of 0.91, though it had the lowest recall score. Naive Bayes had the lowest accuracy score of 0.70. Logistic Regression had a moderate accuracy score of 0.75, which is consistent with its F1-Score, recall, and precision scores."
740,"caption: Table 4: Model performances based on multiple evaluation metricstable: Model,Accuracy,PR-AUC,F1-score, SVM,0.85,0.78,0.75, KNN,0.81,0.67,0.67, Naive Bayes,0.75,0.59,0.53, Random Forest,0.88,0.82,0.79, XGBoost,0.89,0.83,0.81","Table 4 compares the model performances of five different models (SVM, KNN, Naive Bayes, Random Forest, and XGBoost) on multiple evaluation metrics accuracy, PR-AUC, and F1-score. The highest accuracy is reported by XGBoost with 0.89, followed by Random Forest with 0.88. Random Forest and XGBoost also exhibit the highest performance scores in terms of PR-AUC and F1-score. Interestingly, Naive Bayes shows the lowest scores for all metrics. Overall, the table displays the performance differences of different models, which can be useful for choosing the best model combination for specific use-cases."
741,"caption: Performance measures of different models based on multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score,ROC-AUC, Model1,0.876,0.901,0.854,0.877,0.931, Model2,0.899,0.892,0.914,0.887,0.889, Model3,0.846,0.834,0.891,0.847,0.894, Model4,0.891,0.921,0.837,0.878,0.892, Model5,0.895,0.905,0.892,0.896,0.932","Table presenting the performance of multiple models based on evaluation metrics including Accuracy, Precision, Recall, F1-Score, and ROC-AUC. The table includes Model1 to Model5, where each of them was evaluated using the same dataset. Notably, Model1 had the highest Accuracy (0.876), and Model4 had the highest Precision (0.921), while Model5 had the highest Recall (0.892), F1-Score (0.896), and ROC-AUC (0.932). Interestingly, Model1 and Model4 had the closest scores across all evaluation metrics, indicating their comparable performance."
742,"caption: Performance comparison of different classification models across various evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Model A,0.82,0.79,0.81,0.85, Model B,0.79,0.76,0.74,0.78, Model C,0.87,0.85,0.89,0.84, Model D,0.93,0.90,0.94,0.87, Model E,0.75,0.70,0.68,0.78","The table illustrates a thorough comparison of five different classification models, namely Model A, Model B, Model C, Model D, and Model E. The performance results from different evaluation metrics, including Accuracy, F1 Score, Precision, and Recall, are tabulated. Notably, Model D surpasses all other models in terms of Accuracy and F1 Score, with an accuracy score of 0.93 and an F1 Score of 0.90. Model C achieved the highest Precision, with a score of 0.89, while Model A had the highest Recall with a score of 0.85. Model E had the lowest performance results across all evaluation metrics, with an Accuracy score of 0.75 and F1 Score, Precision, and Recall scores at 0.70, 0.68, and 0.78, respectively. Overall, the table shows that Model D is the best performing model among the compared models."
743,"caption: Performance comparison of different models based on different evaluation metricstable: Model,Accuracy,F1 Score,Recall,Precision, Logistic Regression,0.87,0.88,0.9,0.87, Multinomial Naive Bayes,0.79,0.76,0.85,0.7, Random Forest,0.91,0.91,0.94,0.89, Gradient Boosting,0.93,0.93,0.95,0.92","The table shows a performance comparison of different models based on the evaluation metrics, including accuracy, F1 score, recall, and precision. The models include Logistic Regression, Multinomial Naive Bayes, Random Forest, and Gradient Boosting, with their corresponding performance results in each metric. Random Forest shows the highest accuracy of 0.91, while Gradient Boosting takes the lead in F1 score, recall, and precision with 0.93, 0.95, and 0.92 scores, respectively. Overall, Gradient Boosting shows the best collective performance across all metrics."
744,"caption: Comparison of classification models' performance across different evaluation metricstable: Models,Accuracy,F1 Score,Precision,Recall, SVM (rbf kernel),0.89,0.84,0.91,0.78, KNN,0.82,0.77,0.85,0.72, Random Forest,0.92,0.88,0.90,0.86, Gradient Boosting,0.93,0.90,0.91,0.89, Multi-layer Perceptron (MLP),0.91,0.87,0.88,0.86","The table presents a comparison of classification models based on multiple evaluation metrics, including Accuracy, F1 Score, Precision, and Recall. The models compared in this table include SVM (rbf kernel), KNN, Random Forest, Gradient Boosting, and Multi-layer Perceptron (MLP). Notably, Random Forest and Gradient Boosting models achieved the highest accuracy of 0.92 and 0.93, respectively, while the KNN model recorded the lowest accuracy of 0.82. The F1 Score metric also showed superior performance from Gradient Boosting and Random Forest models compared to other models. Moreover, the Precision results for the SVM and MLP models are higher than the other models. Finally, the SVM model recorded the highest value for Recall, while KNN achieved the lowest recall value."
745,"caption: Model evaluation for different models using various metrics.table: Model,Accuracy,Recall,Precision,Specificity,F1-score, Model A,0.76,0.83,0.68,0.80,0.75, Model B,0.78,0.75,0.71,0.81,0.73, Model C,0.72,0.78,0.63,0.73,0.70, Model D,0.80,0.81,0.74,0.82,0.77",
746,"caption: Table 4: Model performance based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.90,0.95,0.85,0.90, Decision Tree,0.87,0.89,0.80,0.84, Random Forest,0.91,0.94,0.87,0.90, Gradient Boosting,0.93,0.95,0.90,0.92, Support Vector Machine,0.89,0.93,0.84,0.88","Table 4 displays the model performance based on different evaluation metrics. The models used for the comparison include Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Support Vector Machine. The table displays the accuracy, precision, recall, and F1-score of each of the models. Most models demonstrate high accuracy rates, with Gradient Boosting performing the best with an accuracy rate of 0.93. Similarly, Gradient Boosting outperformed other models with high precision, recall, and F1-score values. In contrast, Decision Tree failed to achieve a higher recall value in contrast to other comparable models."
747,"caption: Table 4: Overall performance of various models based on multiple evaluation metrics.table: Model Name,Accuracy,F1-Score,Recall,Precision, Random Forest,89.11%,0.846,0.856,0.868, K-NN,86.71%,0.728,0.720,0.748, Decision Tree,80.23%,0.721,0.690,0.719, SVM,91.56%,0.904,0.914,0.909, Naive Bayes,78.98%,0.692,0.714,0.703","Table 4 compares the overall performance of different models based on different evaluation metrics. The models include Random Forest, K-NN, Decision Tree, SVM, and Naive Bayes. The evaluation metrics include Accuracy, F-1 Score, Recall, and Precision. From the table, SVM shows the best overall performance, with the highest Accuracy score of 91.56%, F1-Score of 0.904, Recall of 0.914, and Precision of 0.909. On the other hand, Naive Bayes exhibited the lowest overall performance across all evaluation metrics."
748,"caption: Performance of different models based on multiple evaluation metrics.table: Model,F1 (class 0),F1 (class 1),Precision (class 0),Precision (class 1),Recall (class 0),Recall (class 1), Logistic Reg.,0.90,0.85,0.92,0.80,0.87,0.90, K-Nearest Neigh.,0.91,0.87,0.87,0.94,0.95,0.82, Decision Tree,0.92,0.88,0.93,0.86,0.91,0.90, Random Forest,0.94,0.90,0.94,0.90,0.94,0.89, XGBoost,0.93,0.89,0.91,0.93,0.95,0.85","Table 4 showcases the performance of different models based on multiple evaluation metrics, including F1-score, precision, and recall for each class. The table comprises five different models, namely Logistic Regression, K-Nearest Neighbor, Decision Tree, Random Forest, and XGBoost. Random Forest shows the best overall performance with an F1-score of 0.94 for class 0 and 0.90 for class 1, matched by a precision score of 0.94 and recall score of 0.89. On the other hand, K-Nearest Neighbor has a precision score of 0.94 for class 1, resulting in the highest precision score for this class. Interestingly, Decision Tree has very similar performance metrics to Random Forest even though the latter has significantly higher complexity and runtime requirements. Finally, Logistic Regression and XGBoost show competitive performances, less complex, and runtime-efficient."
749,"caption: Evaluation of different modelstable: Model,Acc,PR-AUC,F1-score, Logistic Reg.,0.85,0.78,0.86, SVM,0.82,0.76,0.83, RandomForest,0.87,0.79,0.88, XGBoost,0.88,0.80,0.89","Table above shows the performance evaluation of four different models including Logistic Regression, SVM, Random Forest, and XGBoost. The table shows the results of three different evaluation metrics, including accuracy, PR-AUC, and F1-score. The Random Forest model has the highest accuracy of 0.87, while XGBoost has the highest PR-AUC of 0.80. The F1-score is used primarily when there are uneven class-distribution since the accuracy doesn't offer a reliable assessment in such cases. The highest F1-score is achieved by XGBoost with 0.89. Therefore, we can conclude that XGBoost is the best-performing model on these metrics."
750,"caption: Table 4: Various model performances based on different evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Model 1,0.89,0.88,0.91,0.86, Model 2,0.92,0.91,0.94,0.89, Model 3,0.87,0.86,0.88,0.85, Model 4,0.93,0.92,0.95,0.89, Model 5,0.94,0.93,0.96,0.90","Table 4 displays the performance results of various models based on different evaluation metrics, including Accuracy, F1 Score, Precision, and Recall. The table shows that Model 5 outperformed all other models with a 0.94 accuracy score, the highest among all models. Conversely, Model 3 had the lowest accuracy score of 0.87, proving to be the worst-performing model. In terms of F1 Score, precision, and recall, Model 5 also performed the best, followed by Model 4. However, Model 2 surpassed all other models in terms of precision and recall. Overall, the table indicates that each model has a unique area of strength and should be chosen based on the evaluation metric of interest."
751,"caption: Comparison table of different models using multiple evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Random Forest,0.91,0.89,0.93,0.87, Logistic Regression,0.89,0.85,0.88,0.82, Decision Tree,0.81,0.78,0.81,0.73, K-Nearest Neighbors,0.86,0.82,0.84,0.80, Support Vector Machine,0.88,0.85,0.87,0.83","The table presents the performances of five different models: Random Forest, Logistic Regression, Decision Tree, K-Nearest Neighbors, and Support Vector Machine. Accuracy, F1 Score, Precision, and Recall metrics were used to evaluate the models' performance. Interestingly, Random Forest shows the highest performance with an accuracy of 0.91, while Decision Tree model had the lowest performance with an accuracy of 0.81. All models were tested and trained on the same dataset."
752,"caption: Table 4: Model performance for classification task using different evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.84,0.82,0.86,0.78, KNN,0.79,0.81,0.76,0.87, RF,0.90,0.87,0.94,0.82, MLP,0.92,0.90,0.93,0.88, DT,0.78,0.74,0.79,0.69, GB,0.88,0.85,0.89,0.81","Table 4 compares the performance of six different machine learning models on a classification task using various evaluation metrics. The table shows the accuracy, F1-score, precision, and recall scores of support vector machine (SVM), K-nearest neighbors (KNN), random forest (RF), multilayer perceptron (MLP), decision tree (DT), and gradient boost (GB) models. Notably, MLP shows the highest accuracy and F1-score of 0.92 and 0.90, respectively, while RF has the highest precision of 0.94. KNN exhibits the highest recall score of 0.87. Interestingly, DT shows the lowest accuracy and F1-score, but it has the highest precision and recall among all models. The results suggest that the choice of the machine learning model depends on the evaluation metric that is most essential to the problem."
753,"caption: Table 4: Model comparison based on different performance metrics.table: Model,F1-score,Precision,Recall,Accuracy, SVM,0.85,0.89,0.82,0.87, KNN,0.81,0.84,0.79,0.85, Random Forest,0.89,0.91,0.87,0.90, Logistic Regression,0.88,0.90,0.86,0.89, Naive Bayes,0.83,0.81,0.85,0.84","Table 4 compares several models' performances based on various performance metrics. The table includes SVM, KNN, Random Forest, Logistic Regression, and Naive Bayes models' F1-score, Precision, Recall, and Accuracy. Notably, the Random Forest model outperforms the other models in terms of F1-score, Precision, and Recall, with a score of 0.89, 0.91, and 0.87, respectively. On the other hand, the Logistic Regression model achieves the highest accuracy score of 0.89, while the KNN model exhibits the lowest accuracy score of 0.85. Overall, the comparison indicates that the Random Forest and Logistic Regression models are suitable for predicting the outcome of the target variable based on the provided features, and the model selection will ultimately depend on the intended use case and the user's preferences."
754,"caption: Performance comparison of different models on evaluation metricstable: Model,Precision,Recall,F1-score,AUC,Brier Score, Logistic Regression,0.78,0.83,0.80,0.89,0.15, Decision Tree,0.74,0.73,0.73,0.76,0.21, k-NN,0.63,0.72,0.62,0.68,0.29, SVM,0.88,0.91,0.89,0.93,0.09, Random Forest,0.89,0.87,0.88,0.93,0.12","Table above provides the performance comparisons for Logistic Regression, Decision Tree, k-NN, SVM, and Random Forest models on five different evaluation metrics, namely Precision, Recall, F1-score, AUC, and Brier Score. It illustrates that the SVM method outperformed the other models in all evaluation metrics with 0.88, 0.91, 0.89, 0.93, and 0.09 as Precision, Recall, F1-score, AUC, and Brier Score, respectively. Surprisingly, the Random Forest model also performed relatively well and was ranked second in all five evaluation metrics."
755,"caption: Model performance based on different evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score,AUC, Model A,0.89,0.92,0.87,0.89,0.92, Model B,0.92,0.94,0.91,0.92,0.95, Model C,0.85,0.88,0.83,0.85,0.84, Model D,0.91,0.93,0.92,0.91,0.94","Table presents the performance of four models, Model A, Model B, Model C, and Model D, based on multiple evaluation metrics. The evaluation metrics used are Accuracy, Precision, Recall, F1-Score, and AUC. Model B performs the best overall with the highest values for Accuracy (0.92), Precision (0.94), Recall (0.91), and AUC (0.95). Model D shows the highest Recall score (0.92), while Model A has the highest Precision score (0.92). Interestingly, Model C shows the lowest performance scores across all evaluation metrics."
756,"caption: Comparison of different models' performance.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.87,0.90,0.84,0.87, Random Forest,0.91,0.94,0.89,0.91, Support Vector Machine,0.86,0.88,0.85,0.86, Multilayer Perceptron,0.88,0.91,0.87,0.88, Naive Bayes,0.83,0.84,0.80,0.82","The table presents a comparison of several classification models' performance in terms of accuracy, precision, recall, and F1 score. The models tested include Logistic Regression, Random Forest, Support Vector Machine, Multilayer Perceptron, and Naive Bayes. The best-performing model based on Accuracy was Random Forest, achieving a score of 0.91. However, the model with the best Precision was Multilayer Perceptron, with a score of 0.91. The model with the best Recall score was Logistic Regression, with a score of 0.84. Moreover, in terms of F1 score, Random Forest was the best-performing model, achieving a score of 0.91. The results indicate that different models excel in different evaluation metrics, suggesting that specific models may be more suitable depending on the task and evaluation metric."
757,"caption: Comparing Model Performances Across Multiple Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1 Score,AUC, SVM,0.89,0.91,0.84,0.87,0.93, Logistic Regression,0.84,0.83,0.75,0.79,0.88, Random Forest,0.90,0.93,0.85,0.88,0.91, KNN,0.81,0.82,0.65,0.72,0.80, Decision Tree,0.87,0.86,0.83,0.84,0.84","The table presents a comparison of five different models' performances based on multiple evaluation metrics. The models compared are SVM, Logistic Regression, Random Forest, KNN, and Decision Tree. The evaluation metrics evaluated include accuracy, precision, recall, F1 score, and AUC. Each model was trained and tested on the same dataset, and the results exhibit that Random Forest performs the best across evaluation metrics. Notably, SVM achieved the highest accuracy score of 0.89, while Logistic Regression has the lowest performance results across all evaluation metrics. Finally, although KNN achieves the lowest AUC score, it performs reasonably in other evaluation metrics with an accuracy score of 0.81 and F1 score of 0.72."
758,"caption: Table 4: Model evaluation metrics and accuracies for various classification algorithms.table: Model,Precision,Recall,F1-score,Accuracy, Logistic Regression,0.85,0.89,0.87,0.88, Decision Tree,0.78,0.75,0.76,0.79, Random Forest,0.89,0.88,0.89,0.89, Support Vector Machine,0.87,0.86,0.87,0.87, Artificial Neural Network,0.91,0.89,0.90,0.91","Table 4 shows the evaluation results of several classification algorithms, namely Logistic Regression, Decision Tree, Random Forest, Support Vector Machine, and Artificial Neural Network models. The evaluation metrics include Precision, Recall, F1-score, and accuracy. Among the various models, the Artificial Neural Network model shows the highest precision of 0.91, while the Random Forest model has the highest F1-score of 0.89. The Logistic Regression model achieves relatively reasonable precision, recall, and F1-score of 0.85, 0.89, and 0.87, respectively.  Notably, all models achieve high accuracy scores, indicating their suitability for conducting effective classifications."
759,"caption: Comparison of different models based on various evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.8591,0.7921,0.8055,0.7844, KNN,0.8198,0.7157,0.7396,0.6944, RF,0.9011,0.8642,0.8783,0.8509, XGB,0.8912,0.8459,0.8532,0.8404, MLP,0.8821,0.8264,0.8457,0.8087","The table presents a comparison of different models' performance based on multiple evaluation metrics such as Accuracy, F1-Score, Precision and Recall. The results show that the RF model performed the best with highest Accuracy, F1-Score, Precision and Recall scores of 0.9011, 0.8642, 0.8783, and 0.8509 respectively. The XGB and MLP models achieved relatively similar performance with a slight edge for the XGB model, while SVM and KNN models lag a bit behind. Nevertheless, all models in the table performed reasonably well in predicting the target variables."
760,"caption: Table 4. Performance metrics for different classification modelstable: Model,Accuracy,Precision,Recall,F1 Score, Random Forest,0.876,0.884,0.862,0.873, XGBoost,0.879,0.883,0.872,0.877, Support Vector,0.873,0.880,0.860,0.870, Decision Tree,0.842,0.847,0.836,0.842, Naive Bayes,0.812,0.825,0.800,0.812","Table 4 presents the accuracy, precision, recall, and F1 score for five different classification models: Random Forest, XGBoost, Support Vector, Decision Tree, and Naive Bayes. The results were obtained from a classification problem in a supervised learning setting. Interestingly, Random Forest and XGBoost models exhibit the highest accuracy of 0.876 and 0.879, respectively, while Decision Tree and Naive Bayes showed the lowest performance scores. Furthermore, all models displayed a higher precision score than recall, suggesting they tend to classify more non-events than events."
761,"caption: Performance Metrics of Different Models.table: Model Name,F1 Score,Precision,Recall,Accuracy, Model A,0.83,0.94,0.75,0.92, Model B,0.87,0.92,0.83,0.93, Model C,0.82,0.86,0.78,0.91, Model D,0.90,0.89,0.91,0.94, Model E,0.86,0.85,0.88,0.93","The table presents the F1 Score, Precision, Recall, and Accuracy scores of five different models (Model A to Model E). Among all models, Model D has the highest F1 Score (0.90), which suggests that it has a good balance between Precision and Recall scores. Model A has the highest Precision score (0.94) indicating that this model has a lower chance of false positives. On the other hand, Model E has the highest Recall score (0.88), indicating that this model has a lower number of false negatives. The table highlights that evaluation metrics vary among models and should be chosen based on the research question and priorities."
762,"caption: Model performance across multiple evaluation metricstable: Model,Accuracy,F1-score,Precision,Recall, Naive Bayes,0.84,0.83,0.85,0.82, Decision Tree,0.71,0.69,0.72,0.67, Random Forest,0.89,0.88,0.91,0.85, Support Vector Machine,0.75,0.74,0.76,0.72, Logistic Regression,0.79,0.78,0.81,0.76, XGBoost,0.91,0.90,0.92,0.88","The table above presents the performance of six different models, namely Naive bayes, Decision tree, Random forest, Support vector machine, Logistic regression, and XGBoost based on multiple evaluation metrics, including Accuracy, F1-score, Precision, and Recall. Notably, the XGBoost model achieved the highest Accuracy, F1-score, and Precision with scores of 0.91, 0.90 and 0.92, respectively, while Random forest achieved the highest Recall of 0.85. The Decision tree model shows the lowest performance scores among the six models across all performance metrics, with an Accuracy of 0.71, F1-score of 0.69, Precision of 0.72, and Recall of 0.67. Overall, the Random forest and XGBoost models appear to perform the best across the evaluated metrics."
763,"caption: Table 4: Evaluation of Different Models based on Accuracy, F1-score, Precision, and Recall.table: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.87,0.89,0.91,0.88, Support Vector Machines,0.89,0.91,0.92,0.90, Random Forest,0.91,0.92,0.95,0.91, Gradient Boosting,0.90,0.92,0.93,0.92, Decision Tree,0.86,0.88,0.91,0.86","Table 4 depicts the performances of five distinct models evaluated via four evaluation metrics. The accuracy, F1-score, precision, and recall metrics were applied to evaluate the model performances. The models investigated in this study are Logistic Regression, Support Vector Machines, Random Forest, Gradient Boosting, and Decision Tree. Overall, the Random Forest model exhibited the highest accuracy of 0.91, F1-score of 0.92 and precision of 0.95, while the Support Vector Machines model performed exceedingly well in the recall metric with a score of 0.90. Interestingly, the Decision Tree model had the lowest scores in the metrics."
764,"caption: Table 4: Performance evaluation of different classification models based on multiple metrics.table: Model,F1-score,Precision,Recall,Accuracy, BERT,0.84,0.90,0.79,0.87, GPT-2,0.74,0.79,0.69,0.82, Bi-LSTM,0.85,0.87,0.83,0.86, Random Forest,0.82,0.85,0.81,0.85, SVM,0.80,0.83,0.78,0.84","Table 4 presents the performance evaluation of different classification models based on multiple metrics. The table consists of five distinct models, namely BERT, GPT-2, Bi-LSTM, Random Forest, and SVM. The models' performance evaluation is based on their F1-score, Precision, Recall, and Accuracy metrics. The best performing model is Bi-LSTM with the highest F1-Score, Precision, and Recall scores of 0.85, 0.87, and 0.83, respectively. However, the BERT and SVM models show the highest Accuracy scores of 0.87 and 0.84, respectively. Overall, the table highlights the different classification models' performance based on the different metrics used."
765,"caption: Table 4: Evaluation of different models based on accuracy, F1-score, and MCC.table: Model,Accuracy,F1-Score,MCC, Model A,0.89,0.86,0.71, Model B,0.91,0.85,0.62, Model C,0.84,0.78,0.49, Model D,0.87,0.83,0.57, Model E,0.92,0.90,0.75","Table 4 presents a performance comparison of different models based on accuracy, F1-score, and MCC. The table shows five models tested, named Model A to Model E. All models achieved different accuracies ranging from 0.84 to 0.92. Interestingly, Model E had the highest accuracy of 0.92, followed by Model B with 0.91. On the other hand, Model C exhibited the lowest accuracy of 0.84. Observing the F1-score values, model E had a score of 0.90, overtaken only by Model A with 0.86. The MCC score was also calculated for each model, and Model E had the highest score of 0.75, followed by Model A with 0.71. Overall, the performance differences between the models indicate the superiority of Model E."
766,"caption: Model performances comparison based on different evaluation metricstable: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.89,0.85,0.87,0.84, Support Vector Machine,0.84,0.80,0.79,0.82, Random Forest,0.93,0.92,0.93,0.91, Gradient Boosting,0.92,0.91,0.91,0.92, Multi-Layer Perceptron,0.90,0.88,0.86,0.91","Table 1 presents an evaluation comparison of five different models based on multiple evaluation metrics. The models include logistic regression, support vector machine, random forest, gradient boosting, and multi-layer perceptron. The evaluation metrics include accuracy, F1-score, precision, and recall. The random forest model exhibits the highest accuracy result of 0.93, followed closely by gradient boosting and multi-layer perceptron models with accuracy of 0.92 and 0.90, respectively. All models show high F1-scores, precision, and recall, with random forest having the highest F1-score of 0.92 and precision and recall of 0.93 and 0.91, respectively."
767,"caption: Comparison of different models' performances on the evaluation metrics.table: Model,Accuracy,F1,Precision,Recall,AUC, Logistic Regression,0.789,0.724,0.765,0.686,0.85, Random Forest,0.847,0.815,0.829,0.801,0.92, Gradient Boosting,0.831,0.785,0.798,0.774,0.91, K-Nearest Neighbours,0.783,0.694,0.730,0.661,0.82, Support Vector Machine,0.812,0.760,0.792,0.732,0.88","The above table shows a comparison of different models' classification performance evaluation metrics, namely accuracy, F1, precision, recall, and AUC. The models are Logistic Regression, Random Forest, Gradient Boosting, K-Nearest Neighbours, and Support Vector Machine. The Random Forest model achieved the highest accuracy of 0.847, followed by Gradient Boosting 0.831 and Support Vector Machine 0.812. In terms of F1, Random Forest attained the highest of 0.815, while Logistic Regression had the lowest F1 of 0.724. The Precision metric highest score was recorded by Random Forest at 0.829, while Logistic Regression had the lowest score at 0.765. Similarly, Random forest had the highest recall score of 0.801, while Logistic Regression attained the lowest with a score of 0.686. Lastly, Random Forest had the highest AUC of 0.92, followed by Gradient Boosting's 0.91 AUC score."
768,"caption: Table 4: Model performance comparisons using different evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.84,0.85,0.80,0.82, Random Forest,0.89,0.86,0.91,0.88, Support Vector Machine,0.92,0.91,0.93,0.92, Multilayer Perceptron,0.88,0.87,0.85,0.86, K-Nearest Neighbor,0.86,0.84,0.86,0.84","Table 4 presents the model performance comparisons of five different models using different evaluation metrics. The models include Logistic Regression, Random Forest, Support Vector Machine, Multilayer Perceptron, and K-Nearest Neighbor. The evaluation metrics used are Accuracy, Precision, Recall, and F1-Score. Interestingly, the Support Vector Machine achieved the best score in all the evaluation metrics with Accuracy of 0.92, Precision of 0.91, Recall of 0.93, and F1-Score of 0.92. In contrast, Logistic Regression had the lowest Recall value of 0.80 and F1-Score of 0.82. In summary, the Support Vector Machine is the best model in terms of performance across all the evaluation metrics."
769,"caption: Comparison of different models based on multiple evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.879,0.891,0.880,0.903, Decision Tree,0.865,0.871,0.876,0.866, Random Forest,0.907,0.911,0.917,0.910, XGBoost,0.896,0.901,0.897,0.904, Support Vector Machine,0.909,0.914,0.922,0.908","This table presents a comparison of the performance of different models based on multiple evaluation metrics: Accuracy, F1-score, Precision, and Recall. The table exhibits Logistic Regression, Decision Tree, Random Forest, XGBoost, and Support Vector Machine models, where all models were trained and tested using the same dataset. Based on the results, the Support Vector Machine shows the highest accuracy of 0.909 with the F1-score and Precision score of 0.914 and 0.922, respectively. The Random Forest recorded the highest F1-score (0.911) and Recall score (0.910) with a high Precision score (0.917) and accuracy of 0.907. Overall, the table suggests that each model has its strengths based on the evaluation metrics, and researchers should consider these metrics while choosing the best model suited for their specific task."
770,"caption: Table 4: Model performances based on various evaluation metricstable: Model,F1-Score,Precision,Recall,AUPRC,AUC, Logistic Regression,0.75,0.80,0.71,0.81,0.79, Random Forest,0.81,0.84,0.78,0.83,0.85, Decision Tree,0.69,0.72,0.67,0.74,0.69, Support Vector Machine,0.78,0.79,0.75,0.80,0.77","Table 4 presents the performance of different models based on various evaluation metrics, including F1-Score, Precision, Recall, AUPRC, and AUC. The table consists of four models: Logistic Regression, Random Forest, Decision Tree, and Support Vector Machine. Based on the results, the Random Forest model shows the best overall performance, with an F1-Score of 0.81 and AUC of 0.85. The Logistic Regression model achieved the highest Precision score of 0.80, while the Support Vector Machine attained the highest Recall score of 0.75. Interestingly, the Decision Tree model showed the lowest performance across all the evaluation metrics, with an F1-Score of 0.69 and AUC of 0.69."
771,"caption: Performance results for multiple models based on precision, recall, F1-Score, and ROC-AUC evaluation metrics.table: Model,Precision,Recall,F1-Score,ROC-AUC, SVM,0.74,0.69,0.71,0.85, Random Forest,0.78,0.74,0.76,0.89, XGBoost,0.80,0.75,0.77,0.91, Adaboost,0.70,0.65,0.67,0.84, Neural Network,0.76,0.72,0.72,0.87","The table presents performance results for different models based on precision, recall, F1-score, and ROC-AUC evaluation metrics. The models include SVM, Random Forest, XGBoost, Adaboost, and Neural Network. The Random Forest model shows the best precision score of 0.78, whereas XGBoost achieved the highest precision and F1 score of 0.80 and 0.77, respectively. The Neural Network model achieved the highest recall of 0.72, and XGBoost had the highest ROC-AUC of 0.91. Interestingly, Adaboost model, which is a well-known algorithm, showed the lowest performance results of all the models. Overall, the results suggest that ensemble methods, Random Forest and XGBoost, outperform the other models, and are ideal for the given problem domain."
772,"caption: Performance Comparison of Different Models Based on F1-Score, Precision, and Recall Metrics.table: Model,F1-score,Precision,Recall, Support Vector Machine,0.83,0.84,0.82, Random Forest,0.88,0.90,0.87, Logistic Regression,0.82,0.83,0.81, Decision Trees,0.79,0.81,0.78","Table above presents the performance comparison of different classification models based on F1-score, Precision, and Recall metrics. The table exhibits the Support Vector Machine, Random Forest, Logistic Regression, and Decision Tree models' F1-score, Precision, and Recall scores. Notably, all models were trained and tested using the same dataset. The Random forest model shows the best F1-score of 0.88, Precision of 0.90 and Recall of 0.87. Interestingly, the Decision Tree model achieved the lowest F1-score with a score of 0.79, while the Logistic Regression model had the lowest Precision of 0.83, and Support Vector Machine had the lowest Recall of 0.82. The table highlights the importance of selecting the right model based on a combination of different evaluation metrics."
773,"caption: Table 4: Model Evaluation Metrics Comparisontable: Model,Accuracy,F1,Precision,Recall,AUC, Model 1,0.90,0.85,0.87,0.84,0.92, Model 2,0.86,0.81,0.85,0.78,0.90, Model 3,0.92,0.88,0.91,0.85,0.93, Model 4,0.88,0.84,0.87,0.82,0.91","Table 4 compares the performances of four models based on five different evaluation metrics, including Accuracy, F1-score, Precision, Recall, and AUC. The table shows that Model 3 achieved the highest results in all metrics except for Accuracy. Model 3 achieved an Accuracy of 0.92, F1-score of 0.88, Precision of 0.91, Recall of 0.85, and AUC of 0.93. Model 1 and Model 4 achieved similar results, with Model 1 having the highest AUC of 0.92 and Model 4 having the lowest F1-score of 0.84. Model 2 obtained the lowest results in all metrics, with an Accuracy of 0.86, F1-score of 0.81, Precision of 0.85, Recall of 0.78, and AUC of 0.90. Overall, Model 3 performed the best in this evaluation."
774,"caption: Table 4: Model performance based on different evaluation metrics.table: Model,F1score,Precision,Recall,Accuracy,Specificity, SVM,0.81,0.78,0.84,0.832,0.82, Random Forest,0.85,0.81,0.89,0.863,0.84, Logistic Regression,0.78,0.76,0.84,0.802,0.78, Neural Network,0.84,0.81,0.87,0.865,0.83, Naive Bayes,0.73,0.68,0.81,0.772,0.73","The table above exhibits the performance results of different models based on different evaluation metrics, including F1score, Precision, Recall, Accuracy, and Specificity. The models used for comparison are SVM, Random Forest, Logistic Regression, Neural Network, and Naive Bayes. The results show that the Random Forest model has the highest F1score of 0.85 and Recall of 0.89. On the other hand, the SVM model has the highest Precision of 0.78, and the Neural Network has the highest Accuracy of 0.865 and Specificity of 0.83. Overall, the table demonstrates the performance comparison of multiple models based on various evaluation metrics, providing researchers the opportunity to select the best model as per their requirements."
775,"caption: Performance comparison of Multiple Models Across Different Metrics.table: ```, Model,Metric 1 (score),Metric 2 (score),Metric 3 (score), Model 1,0.65,0.47,0.89, Model 2,0.57,0.59,0.79, Model 3,0.73,0.53,0.91, Model 4,0.81,0.39,0.78, Model 5,0.68,0.67,0.87","The table compares the performance of five different models based on three different evaluation metrics. Model 4 exhibits the best performance in Metric 1 with a score of 0.81, while Model 5 achieved the highest score of 0.67 in Metric 2. Notably, Model 1 and Model 3 show higher scores in Metric 3 than the rest of the models. Model 3 attained the highest score of 0.91 in Metric 3. Overall, the results suggest that there is a trade-off between the different metrics and models' performance. This information could be helpful in selecting the best model for a particular task, depending on the priority of the specific metrics."
776,"caption: Performance evaluation metrics for different classification models.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.77,0.79,0.81,0.76, Decision Tree,0.81,0.80,0.82,0.78, Random Forest,0.85,0.86,0.87,0.85, SVM,0.74,0.73,0.79,0.69, Multi-layer Perceptron,0.84,0.85,0.85,0.85","The table presents the performance evaluation metrics for different classification models, namely Logistic Regression, Decision Tree, Random Forest, SVM and Multi-layer Perceptron (MLP). The evaluation metrics include Accuracy, F1 Score, Precision and Recall. Notably, Random Forest had the highest Accuracy score of 0.85. The model also showed the highest F1 Score, Precision, and Recall. MLP model had the same precision and recall scores with the Random Forest at 0.85. Decision tree performed well also, with the accuracy of 0.81. Logistic Regression achieved the lowest accuracy score of 0.77, and SVM had an accuracy score of 0.74, indicating that these models underperformed compared to other models in the table."
777,"caption: Comparison of different models' performances using F1-score, precision, recall, and accuracy.table: Model,F1-score,Precision,Recall,Accuracy, Random forest,0.85,0.87,0.83,0.89, Logistic regression,0.81,0.85,0.77,0.87, Support Vector Machines,0.83,0.81,0.86,0.88, Gradient Boosting Machines,0.86,0.88,0.84,0.90","The table presents a comparison of different models' performances based on four evaluation metrics: F1-score, precision, recall, and accuracy. The table showcases Random forest, Logistic regression, Support Vector Machines, and Gradient Boosting Machines models, with the results obtained from the same dataset. Focusing on the models, the Gradient Boosting Machines model achieved the highest F1-score and Accuracy (0.86 and 0.90, respectively) while the Random forest model achieved the highest precision (0.87). Interestingly, the lowest precision score was obtained by the Support Vector Machines model (0.81), but it achieved the highest recall (0.86). These results highlight the importance of evaluating models across multiple metrics to achieve a more comprehensive understanding of their performance."
778,"caption: The comparison of model performances based on different evaluation metrics.table: Model,F1 Score,Precision,Recall,Accuracy, Decision Tree (max_depth=3),0.66,0.78,0.58,0.72, Random Forest,0.84,0.87,0.84,0.88, Support Vector Machine (C=1),0.76,0.92,0.64,0.79, Logistic Regression,0.83,0.86,0.83,0.87, Neural Network (2 layers),0.87,0.86,0.90,0.88","The table displays multiple classification models' performances based on different evaluation metrics. The evaluation metrics used are F1 Score, Precision, Recall, and Accuracy. The models used were Decision Tree (max_depth=3), Random Forest, Support Vector Machine (C=1), Logistic Regression, and Neural Network (2 layers). Notably, the Neural Network model performed best with an F1 score of 0.87, a Precision score of 0.86, a Recall score of 0.90, and an Accuracy score of 0.88, showing consistent performance across all evaluation metrics. The Random Forest model had a high Precision score of 0.87, a Recall score of 0.84, and an Accuracy score of 0.88. The Logistic Regression model had F1 and Precision scores of 0.83 and 0.86, respectively, and was particularly high in Recall with a score of 0.83. The Decision Tree model had F1 and Recall scores of 0.66 and 0.58, respectively, and a Precision score of 0.78. Finally, the Support Vector Machine model had an F1 score of 0.76, a Precision score of 0.92, and a Recall score of 0.64."
779,"caption: Comparison of different models' performances based on multiple evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.83,0.80,0.77,0.84, KNN,0.78,0.73,0.67,0.80, Naive Bayes,0.75,0.72,0.69,0.77, Random Forest,0.87,0.84,0.81,0.88, XGBoost,0.88,0.86,0.83,0.89","The table shows the performance of different models such as SVM, KNN, Naive Bayes, Random Forest, and XGBoost. The models' performance is measured based on multiple evaluation metrics such as Accuracy, F1-Score, Precision, and Recall. The Random Forest and XGBoost models have performed better in all evaluation metrics compared to other models. The Random Forest model achieved the highest Accuracy of 0.87, while the XGBoost model achieved the highest Accuracy and F1-Score of 0.88 and 0.86, respectively. The Naive Bayes model has the lowest precision of 0.69, while the KNN model has the lowest F1-Score of 0.73. Overall, the Random Forest and XGBoost models show a promising performance in terms of the evaluation metrics compared to the other models."
780,"caption: Model evaluation metrics for different models.table: Model,Loss,Accuracy,Precision,Recall,F1, Model A,0.24,0.92,0.85,0.77,0.81, Model B,0.18,0.94,0.87,0.82,0.84, Model C,0.27,0.91,0.83,0.74,0.78, Model D,0.15,0.95,0.89,0.84,0.86, Model E,0.32,0.89,0.79,0.72,0.73","Table presents the summary of model performance evaluation metrics, including Loss, Accuracy, Precision, Recall, and F1, for Model A, Model B, Model C, Model D, and Model E. The table shows that Model D achieved the best performance results out of all the models, having the lowest Loss of 0.15 and the highest Accuracy of 0.95. Model D also recorded the highest Precision of 0.89 and Recall of 0.84, resulting in the highest F1 score of 0.86. Model B and Model A come second and third on the overall ranking, respectively. On the other hand, Model C and Model E recorded the poorest performance with lower Accuracy, Precision, Recall, and F1 score."
781,"caption: Table 4: Performance measures from different models based on accuracy, precision, recall, and F1-Score.table: Model,Accuracy,Precision,Recall,F1-Score, Model 1,0.87,0.89,0.83,0.86, Model 2,0.92,0.93,0.91,0.92, Model 3,0.85,0.80,0.94,0.87, Model 4,0.93,0.94,0.93,0.93, Model 5,0.88,0.90,0.86,0.88","Table 4 reports the accuracy, precision, recall, and F1-score for five different models. The models were evaluated using the same dataset. Model 2 produced the highest scores across all metrics, with an accuracy of 0.92, precision of 0.93, recall of 0.91, and F1-score of 0.92. Model 4 was the second-best-performing model with an accuracy of 0.93, precision of 0.94, recall of 0.93, and F1-score of 0.93. While Model 3 achieved the highest recall of 0.94, it had the lowest scores in terms of accuracy, precision, and F1-score."
782,"caption: Performance metrics of different ML modelstable: Model,Accuracy,Recall,F1-score,Precision, SVM,0.75,0.62,0.57,0.72, KNN,0.69,0.55,0.45,0.54, Naive Bayes,0.82,0.70,0.75,0.68, Decision Tree,0.70,0.56,0.44,0.69","The table above compares the performances of various machine learning models through different evaluation metrics such as accuracy, recall, f1-score, and precision. The SVM model showed the best accuracy score of 0.75, while the Naive Bayes model had the highest Recall (0.70) and F1-score (0.75). Interestingly, the KNN model had the lowest performance across all metrics, with a recall of 0.55, followed by the decision tree model with an F1-score of 0.44. The results highlight Naive Bayes as the best-performing model, with a trade-off between recall and precision, which could be valuable in some contexts."
783,"caption: Model performance comparison based on Accuracy, F1-score, Precision, and Recall.table: Model,Accuracy,F1-score,Precision,Recall, Model A,0.86,0.87,0.84,0.91, Model B,0.91,0.89,0.91,0.88, Model C,0.84,0.86,0.82,0.9, Model D,0.88,0.9,0.87,0.91","The table presents a comparative analysis of different models based on accuracy, F1-score, precision, and recall. Model A achieved the highest F1-score of 0.87, however, Model B recorded the best accuracy result of 0.91. Model C showcases the lowest performance in all evaluation metrics, with the lowest accuracy of 0.84, F1-score of 0.86, precision of 0.82, and recall of 0.9. Interestingly, Model D's precision and recall are the closest to one another, with a difference of just 0.04, indicating the model's ability to balance its true positive and false positive predictions."
784,"caption: Table 4: Model performance comparison based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Model A,0.87,0.90,0.81,0.85, Model B,0.83,0.85,0.91,0.88, Model C,0.89,0.92,0.82,0.86, Model D,0.91,0.83,0.94,0.88","Table 4 presents a comparison of different models' performances based on multiple evaluation metrics. The models' performances are compared based on accuracy, precision, recall, and F1-score. Model D achieved the highest accuracy score of 0.91 among all the models. Model C performed better in precision with a score of 0.92, while Model B had the highest recall of 0.91. Interestingly, Model A achieved the highest F1-score of 0.85, whereas having the lowest precision score of 0.90. The table indicates different models may perform differently regarding different metrics, and hence it's important to consider all metrics while deciding the best models."
785,"caption: Table 4: Performance of different machine learning models based on multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score,AUC, LR,0.76,0.73,0.87,0.79,0.84, SVM,0.81,0.78,0.86,0.82,0.86, RF,0.74,0.70,0.89,0.77,0.81, GBM,0.79,0.75,0.88,0.81,0.86, MLP,0.82,0.80,0.85,0.82,0.87","Table 4 provides the model performance of different machine learning models based on multiple evaluation metrics. The table presents Accuracy, Precision, Recall, F1 Score, and AUC of LR (Logistic Regression), SVM (Support Vector Machine), RF (Random Forest), GBM (Gradient Boosting Machine), and MLP (Multi-Layer Perceptron). The models were trained and tested using the same dataset. The MLP model reported the best accuracy of 0.82, while the SVM model’s AUC result was 0.86. The recall metric shows the the RF with 0.89 as having the highest value. The best overall performer is the MLP model, based on multiple evaluation metrics."
786,"caption: Model performance based on traditional machine learning algorithmstable: Model,Accuracy,Precision,Recall,F1 Score, SVM,0.85,0.82,0.87,0.84, KNN,0.78,0.76,0.80,0.78, Decision Trees,0.83,0.80,0.85,0.82, Random Forests,0.89,0.87,0.91,0.89, Naive Bayes,0.72,0.68,0.77,0.72","Table presents model performances of different traditional machine learning algorithms using multiple evaluation metrics. The table reports the accuracy, precision, recall, and F1 score results for Support Vector Machines (SVM), K-Nearest Neighbors (KNN), Decision Trees, Random Forests, and Naive Bayes. Notably, Random Forests performed best with an accuracy score of 0.89, while Naive Bayes had the least accuracy score of 0.72. Interestingly, KNN and Naive Bayes show the least and highest precision scores, respectively. Similarly, Naive Bayes, SVM, and Random Forests show the highest recall scores among all models. Overall, the table demonstrates the significant variations in the performance of different traditional machine learning algorithms on the given dataset."
787,"caption: Table 4: Model performances on various evaluation metrics.table: Model,F1 Score,Precision,Recall,Accuracy, Model A,0.89,0.93,0.86,0.92, Model B,0.92,0.89,0.95,0.91, Model C,0.84,0.87,0.81,0.88, Model D,0.91,0.88,0.95,0.89, Model E,0.93,0.92,0.94,0.94","Table 4 presents different model performances in terms of multiple evaluation metrics. The table exhibits F1 score, precision, recall, and accuracy, where higher values indicate better model performance. Model E shows the best performance across all metrics with F1 score of 0.93, precision of 0.92, recall of 0.94, and accuracy of 0.94. Model B also shows good performance, achieving highest precision and recall with 0.95 in each metric, resulting in F1 score of 0.92. Model A is strong in all metrics except recall, where it shows a value of 0.86. In contrast, Model C exhibits the lowest performance with F1 score of 0.84, precision of 0.87, recall of 0.81, and accuracy of 0.88."
788,"caption: Model performances based on different evaluation metricstable: Models,Accuracy,Precision,Recall,F1-score, SVM,0.78,0.80,0.70,0.74, Random Forest,0.87,0.86,0.89,0.87, Naive Bayes,0.64,0.69,0.54,0.57, Neural Networks,0.80,0.83,0.72,0.76, Decision Trees,0.76,0.70,0.82,0.74","The table displays the evaluation of multiple models based on different metrics such as accuracy, precision, recall, and F1-score. The models consist of SVM, Random Forest, Naive Bayes, Neural Networks, and Decision Trees. Interestingly, the Random Forest achieved the highest accuracy of 0.87, while Naive Bayes scored the lowest accuracy with 0.64. Regarding precision, Neural Network achieved the highest score of 0.83, whereas Naive Bayes had the lowest precision score of 0.69. On the other hand, for recall, Random Forest scored the highest with 0.89, while Naive Bayes scored the lowest with 0.54. The F1-score of Random Forest was the highest with 0.87, whereas Naive Bayes had the lowest score of 0.57."
789,"caption: Comparison of accuracy, precision, recall and F1 score for different models.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.89,0.87,0.91,0.89, Decision Tree,0.85,0.84,0.88,0.86, Random Forest,0.93,0.93,0.94,0.94, XGBoost,0.92,0.91,0.93,0.92, Support Vector Machine (Linear),0.88,0.87,0.91,0.89, Support Vector Machine (RBF),0.93,0.93,0.94,0.94","The table shows the performance of six different classification models in terms of accuracy, precision, recall, and F1 score. The models include Logistic Regression, Decision Tree, Random Forest, XGBoost, Support Vector Machine (Linear), and Support Vector Machine (RBF). Random Forest and Support Vector Machine (RBF) show the highest accuracy and F1 scores of 0.93 and 0.94, respectively. They also have the highest precision and recall scores, except for Support Vector Machine (Linear), which has the highest recall score of 0.91. Logistic Regression and Decision Tree come second with scores ranging from 0.85 to 0.89. Overall, the table findings indicate that Random Forest and Support Vector Machine (RBF) are the best models for this classification task."
790,"caption: Model performances of SVM, KNN, Naive Bayes, Random forest, and XGBoost based on precision, recall, F1-score, and accuracy.table: Model,Precision,Recall,F1-Score,Accuracy, SVM,0.82,0.78,0.79,0.89, KNN,0.76,0.75,0.75,0.87, Naive Bayes,0.72,0.81,0.75,0.84, Random forest,0.86,0.83,0.84,0.91, XGBoost,0.82,0.84,0.82,0.90","The table displays model performances of five different machine learning algorithms, namely SVM, KNN, Naive Bayes, Random forest, and XGBoost. The table compares the models' precision, recall, F1-score, and accuracy metrics. The results show that the Random forest model achieves the highest precision (0.86), recall (0.83), and F1-score (0.84), while the SVM model has the highest accuracy (0.89). The Naive Bayes model performs the poorest, with the lowest precision (0.72), recall (0.81), and F1-score (0.75). The results suggest that the Random forest and SVM models are the most suitable for this task based on the evaluation metrics."
791,"caption: Comparison of different machine learning models based on evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.89,0.91,0.87,0.89, Logistic Regression,0.82,0.80,0.91,0.85, Decision Tree,0.79,0.81,0.78,0.79, Random Forest,0.90,0.92,0.88,0.90, XGBoost,0.88,0.88,0.91,0.89",
792,"caption: Performance metrics of various models.table: Model,Precision,Recall,F1-Score,AUC, Model A,0.85,0.91,0.88,0.92, Model B,0.81,0.84,0.82,0.89, Model C,0.89,0.87,0.88,0.93, Model D,0.78,0.82,0.80,0.87, Model E,0.92,0.85,0.88,0.95","Table with five models that are compared based on four different performance metrics - Precision, Recall, F1-Score, and AUC - that evaluate binary classification results. The table indicates that Model E shows the highest Precision score of 0.92 while Model C has the highest Recall score of 0.87. Model A exhibits the highest F1-Score of 0.88. Lastly, Model E tops the list for AUC score with an impressive result of 0.95. The table gives insights into each model's performance based on various evaluation metrics and is useful for comparing and selecting a model that best fits the problem context."
793,"caption: Table 4: Performance of different models based on evaluation metrics.table: Model,Accuracy,F1 score,Precision,Recall, SVM,0.78,0.78,0.80,0.76, Naive Bayes,0.63,0.65,0.62,0.68, Random Forest,0.82,0.80,0.85,0.76, Decision Tree,0.77,0.75,0.77,0.74","Table 4 shows the performance of different models based on multiple evaluation metrics, namely Accuracy, F1 score, Precision, and Recall. The models include SVM, Naive Bayes, Random Forest, and Decision Tree. The accuracy results show that the Random Forest model has the highest accuracy of 0.82, followed by the SVM model with 0.78. In terms of F1 score, the Naive Bayes model has the highest score of 0.65, while the Random Forest model scores the highest in precision with 0.85. The SVM model has the highest recall score of 0.76. Overall, Random Forest stands out as the best model closely followed by SVM."
794,"caption: Performance of Different Classification Modelstable: Model,Accuracy,F1 score,Precision,Recall, Logistic Regression,0.80,0.79,0.85,0.74, K-Nearest Neighbors,0.73,0.68,0.76,0.62, Random Forest,0.87,0.85,0.90,0.81, Support Vector Machine,0.78,0.75,0.82,0.70, XGBoost,0.89,0.87,0.91,0.83","Table presents a comparison of multiple classification models - Logistic Regression, K-Nearest Neighbors, Random Forest, Support Vector Machine, and XGBoost - on the basis of Accuracy, F1 score, Precision, and Recall metrics. All models were trained and tested on the same dataset, and Random Forest model had the highest accuracy of 0.87, while XGBoost performed well in terms of F1 score with a score of 0.87. Furthermore, XGBoost achieved the highest Precision and Recall scores with 0.91 and 0.83, respectively. Notably, K-Nearest Neighbors had the lowest accuracy of all models with a score of 0.73, while Logistic Regression also showed a relatively good performance in terms of accuracy with a score of 0.80."
795,"caption: Table 4. Model Accuracy, F1-score, Precision, and Recalltable: Model,Accuracy,F1-score,Precision,Recall, SVM,0.82,0.76,0.77,0.76, KNN,0.79,0.72,0.73,0.73, RF,0.83,0.77,0.77,0.78, XGBoost,0.84,0.79,0.79,0.80","Table 4 shows the accuracy, F1-score, precision, and recall of four different models, namely SVM, KNN, RF, and XGBoost. All models were trained and evaluated using the same dataset with a 5-fold cross-validation. The RF model outperformed the others in terms of accuracy, achieving an accuracy score of 0.83. The XGBoost model achieved the highest F1-score (0.79) and a slightly higher accuracy (0.84). Precision and recall were similar among the models, with RF and XGBoost achieving a precision score of 0.77, while SVM and KNN achieved a slightly lower precision score of 0.73. SVM and KNN had the same recall score of 0.76, while RF and XGBoost achieved slightly higher recall scores of 0.78 and 0.80, respectively."
796,"caption: Table 4: Model performance based on different evaluation metrics.table: Model,F1 Score,Precision,Recall,ROC-AUC,PR-AUC, Model 1,0.87,0.86,0.89,0.95,0.86, Model 2,0.92,0.93,0.91,0.91,0.95, Model 3,0.79,0.81,0.77,0.88,0.75, Model 4,0.89,0.92,0.87,0.93,0.89, Model 5,0.91,0.89,0.94,0.90,0.93","Table 4 presents the performance of five different models based on various evaluation metrics, including F1 Score, Precision, Recall, ROC-AUC, and PR-AUC. Model 2 performs the best with the highest scores in F1 Score (0.92), Precision (0.93), and PR-AUC (0.95), while Model 1 performs the best in terms of ROC-AUC with a score of 0.95. On the other hand, Model 3 is under-performing compared to the other models except in terms of Precision. Model 4 and Model 5 perform well across all the evaluation metrics."
797,"caption: Table 4: Performance of Different Models Using Multiple Evaluation Metricstable: Model,Accuracy,F1-score,PR-AUC,ROC-AUC, Logistic Regression,90.6%,0.858,0.824,0.913, Random Forest,92.4%,0.895,0.890,0.928, XGBoost,93.0%,0.902,0.904,0.936, Support Vector Machines,90.9%,0.867,0.835,0.920, Multi-Layer Perceptron,91.8%,0.888,0.871,0.927","Table 4 shows the comparison of different machine learning models' performances evaluated using multiple evaluation metrics. The models include Logistic Regression, Random Forest, XGBoost, Support Vector Machines, and Multi-Layer Perceptron. The evaluation metrics include accuracy, F1-score, PR-AUC, and ROC-AUC. All models were trained on the same dataset and assessed on the same test dataset. XGBoost outperformed other models across all evaluation metrics, achieving an accuracy of 93.0%, F1-score of 0.902, PR-AUC of 0.904, and ROC-AUC of 0.936. Random Forest also performed well across all evaluation metrics, achieving an accuracy of 92.4%, F1-score of 0.895, PR-AUC of 0.890, and ROC-AUC of 0.928."
798,"caption: Model performance measures for various models based on accuracy, F1-score, precision, and recall.table: Model,Accuracy,F1-score,Precision,Recall, A,0.89,0.85,0.83,0.88, B,0.91,0.87,0.84,0.90, C,0.88,0.84,0.81,0.89, D,0.92,0.88,0.86,0.91","The table above showcases the performance of four different models, A, B, C, and D, based on various evaluation metrics. Firstly, model D has the highest accuracy of 0.92, indicating that the model has correctly classified 92% of the test data. Model B had the highest F1-score of 0.87, which is the harmonic mean of precision and recall, indicating a balance between precision and recall. Moreover, model A had a high recall of 0.88, which means it correctly classified 88% of positive samples. Finally, model D had the highest precision of 0.86, indicating that 86% of its positive predictions were correct. Overall, each model performed well based on different metrics, showcasing that different models have different strengths based on evaluation criteria."
799,"caption: Table 4: Model Performance Metricstable: Model,Accuracy,Precision,Recall,F1-score, Random forest,0.87,0.91,0.84,0.87, XGBoost,0.89,0.92,0.87,0.89, Logistic Regression,0.82,0.85,0.78,0.81, Naive Bayes,0.73,0.79,0.61,0.69","Table 4 provides the model performance metrics of four different models. These models were evaluated on accuracy, precision, recall, and F1-score. The Random forest model exhibited the highest accuracy of 0.87 and precision of 0.91 while maintaining a balanced recall of 0.84 and F1-score of 0.87. XGBoost ranked second with an overall accuracy of 0.89. Conversely, the Naive Bayes model demonstrated the lowest levels of accuracy, precision, recall, and F1-score. Logistic Regression model demonstrated lower effectiveness compared to Random forest and XGBoost models, with an accuracy of 0.82 and precision of 0.85."
800,"caption: Comparison of model performances based on different evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, Model A,0.92,0.89,0.91,0.88, Model B,0.85,0.82,0.87,0.78, Model C,0.94,0.91,0.93,0.89, Model D,0.78,0.75,0.81,0.69, Model E,0.91,0.87,0.90,0.84","The table above presents a comparison of different models' performances based on different evaluation metrics, including accuracy, F1-score, precision, and recall. Model A achieved the highest accuracy of 0.92, followed closely by Model C with 0.94. However, Model D obtained the lowest accuracy of 0.78. In terms of F1-score, Model C also came on top with a score of 0.91, while Model D had the lowest F1-score of 0.75. Precision measures how often the model is correct when it predicts positive, and the highest precision was achieved by Model C with a score of 0.93, while Model D once again had the lowest score with 0.81. Finally, recall examines how well the model can detect positive instances, and Model A had the highest recall of 0.88, while Model D had the lowest score of 0.69. Overall, Model C seems to perform the best across all metrics, while Model D had the lowest performance."
801,"caption: Model comparison based on different evaluation metrics.table: Model,PR-AUC,ROC-AUC,F1 Score,Accuracy, Decision Tree,0.874,0.789,0.899,0.802, Bagging Classifier,0.917,0.817,0.936,0.846, Random Forest,0.912,0.845,0.934,0.877, AdaBoost,0.893,0.802,0.912,0.827, XGBoost,0.923,0.875,0.942,0.899","The presented table compares the performance of Decision Tree, Bagging Classifier, Random Forest, AdaBoost, and XGBoost models using various evaluation metrics, such as PR-AUC, ROC-AUC, F1 Score, and Accuracy. The Random Forest model outperformed the other models in PR-AUC, with a score of 0.912. XGBoost has the highest ROC-AUC of 0.875. In terms of F1 Score, XGBoost has the highest score of 0.942. In terms of accuracy, Random Forest has the highest score of 0.877, while XGBoost closely follows it with 0.899. Overall, the table demonstrates that XGBoost and Random Forest are the best-performing models based on the four evaluation metrics."
802,"caption: Table 4: Model performance comparison based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.85,0.87,0.83,0.85, Support Vector Machine,0.81,0.79,0.85,0.82, Random Forest,0.92,0.93,0.92,0.92, K-Nearest Neighbor,0.77,0.80,0.65,0.70","Table 4 compares the performance of different models based on various evaluation metrics. The accuracy, precision, recall, and F1-score were considered in the comparison evaluation. The table indicates that Random Forest has the highest accuracy of 0.92, and Logistic Regression has the highest precision of 0.87. The K-Nearest Neighbor model showed the minimum performance in all evaluation metrics with an accuracy of 0.77, precision of 0.80, recall of 0.65, and F1-score of 0.70. The Support Vector Machine model has a lower recall rate but better precision rate than Logistic Regression. Overall, Random Forest appears to out-perform the other models on these metrics."
803,"caption: Table 4: Model performances on evaluation metricstable: Model,F1-Score,Accuracy,Recall,Precision, Logistic Regression,0.85,0.82,0.87,0.83, Decision Trees,0.72,0.71,0.67,0.78, Random Forest,0.89,0.84,0.92,0.87, Support Vector Machines,0.87,0.83,0.82,0.89","Table 4 shows the performances of four different models on multiple evaluation metrics, including F1-Score, Accuracy, Recall, and Precision. The models include Logistic Regression, Decision Trees, Random Forest, and Support Vector Machines. Notably, the Random Forest model achieved the best F1-Score of 0.89 and Recall of 0.92, while Support Vector Machines achieved the highest Accuracy of 0.83 and Precision of 0.89. Interestingly, the Logistic Regression model achieved a comparable F1-Score to Support Vector Machines while having a lower Accuracy and Precision score. Lastly, Decision Trees showed the lowest F1-Score among the models."
804,"caption: Performance metrics of models A-E on the test set.table: Model,Accuracy,F-1 Score,Precision,Recall, Model A,0.92,0.87,0.90,0.84, Model B,0.87,0.84,0.80,0.89, Model C,0.94,0.89,0.92,0.87, Model D,0.90,0.86,0.88,0.84, Model E,0.89,0.82,0.83,0.81",
805,"caption: Performance comparison of different machine learning models using various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.92,0.95,0.93,0.94, Random Forest,0.89,0.88,0.89,0.88, KNN,0.83,0.88,0.84,0.85, Naive Bayes,0.75,0.81,0.73,0.76, Decision Tree,0.78,0.76,0.78,0.77",
806,"caption: Table 4: Model performance evaluation using Precision, Recall, F1-Score and Accuracy metricstable: Model,Precision,Recall,F1-Score,Accuracy, Random Forest,0.92,0.84,0.88,0.89, Support Vector Machines,0.89,0.76,0.82,0.85, Logistic Regression,0.85,0.92,0.88,0.87, Multi-Layer Perceptron,0.93,0.88,0.91,0.91, Decision Tree,0.87,0.82,0.84,0.85","Table 4 presents the model performance evaluation of five different models using Precision, Recall, F1-Score, and Accuracy metrics. The table shows that the Multi-Layer Perceptron model achieved the highest precision score of 0.93, while the Random Forest model achieved the highest accuracy score of 0.89. Interestingly, Logistic Regression achieved the highest recall score of 0.92, while the F1-Score score of all models was very similar, with MLP achieving the highest score of 0.91. The results suggest that the Multi-Layer Perceptron model could be a good choice for high precision tasks, while the Random Forest model could be suitable for high accuracy tasks."
807,"caption: Model evaluation metrics for different classifiers on the task of sentiment analysis.table: ```, Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.789,0.738,0.797,0.761, Naive Bayes,0.621,0.795,0.345,0.479, Random Forest,0.876,0.892,0.831,0.861, SVM (linear),0.796,0.748,0.824,0.784, SVM (poly),0.635,0.632,0.966,0.764, SVM (rbf),0.818,0.832,0.802,0.817","The table presents the performance of different models evaluated using multiple evaluation metrics, including accuracy, precision, recall, and F1-score for sentiment analysis. The Logistic Regression model achieved an accuracy of 0.789 and a precision score of 0.738. In contrast, the Random Forest model had the highest accuracy of 0.876 and the highest precision score of 0.892. However, the Random Forest model had a slightly lower recall score than the Logistic Regression model, indicating it predicted fewer positive instances. Overall, the performance of the SVM (rbf) model was comparable to the Random Forest model scoring high in all evaluation metrics. The Naive Bayes model achieved the lowest accuracy and F1-score scores."
808,"caption: Table 4: Performance evaluation of different models using various metricstable: Model Name,Accuracy,F1-Score,Recall,Specificity,AUROC, Logistic Regression,0.800,0.750,0.810,0.790,0.853, Decision Tree,0.787,0.722,0.725,0.742,0.749, Random Forest,0.823,0.780,0.830,0.820,0.876, Gradient Boosting,0.805,0.765,0.804,0.803,0.846, Neural Network,0.825,0.789,0.819,0.832,0.881","Table 4 presents the results of the evaluation of different models. The models are evaluated using five different evaluation metrics: Accuracy, F1-Score, Recall, Specificity, and AUROC. The table includes five models, namely Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Neural Network. Interestingly, the Neural Network model shows the best performance across all metrics, achieving the highest accuracy of 0.825, F1-score of 0.789, Recall of 0.819, Specificity of 0.832, and AUROC of 0.881. On the other hand, the Decision Tree model showed the poorest performance in terms of Accuracy, F1-score, and AUROC, while Random Forest showed the poorest performance in terms of Recall and Specificity metrics."
809,"caption: Table 4: Performance comparison of different classification models using multiple evaluation metrics.table: Models,F1 Score,Precision,Recall,Accuracy, SVM,0.89,0.92,0.87,0.91, KNN,0.81,0.79,0.87,0.82, Decision Tree,0.83,0.85,0.82,0.87, Naive Bayes,0.77,0.76,0.86,0.81, Random Forest,0.93,0.93,0.93,0.94","Table 4 presents comparative performance of multiple classification models, including SVM, KNN, Decision Tree, Naive Bayes, and Random Forest using different evaluation metrics such as F1 score, Precision, Recall and Accuracy. Notably, Random Forest shows the best performance across all metrics with an F1 score of 0.93, Precision and Recall scores of 0.93 and an Accuracy score of 0.94. SVM model stands second with overall good performance except the Recall score. Interestingly, Naive Bayes model shows higher Recall but lower scores on the other metrics. The Decision Tree model retains an acceptable balance between the four metrics with an Accuracy score of 0.87."
810,"caption: Table 4: Comparison of multiple different models’ performance evaluated across different metrics.table: Model,Precision,Recall,F1-score,Accuracy, Logistic Regression,0.85,0.72,0.77,0.88, Decision tree,0.78,0.68,0.72,0.80, SVM,0.86,0.74,0.80,0.90, Random Forest,0.90,0.82,0.85,0.92",
811,"caption: Table 4: Model performance comparison based on different evaluation metrics.table: Model,Accuracy Score,F1-Score,Precision,Recall, Model 1,0.868,0.863,0.859,0.868, Model 2,0.890,0.885,0.878,0.892, Model 3,0.901,0.896,0.888,0.905, Model 4,0.880,0.875,0.869,0.881, Model 5,0.875,0.870,0.866,0.871","Table 4 presents a comparison of multiple models' performances based on different evaluation metrics. The table includes five different models and their accuracy score, F1-score, precision, and recall. Interestingly, Model 3 achieved the highest accuracy score, F1-score, and recall score, with a score of 0.901, 0.896, and 0.905, respectively. Model 2 and Model 5 achieved an accuracy score of 0.890 and 0.875, respectively, with comparable F1, precision, and recall scores. Notably, Model 1 and Model 4 achieved lower accuracy scores of 0.868 and 0.880, respectively, and performed similarly in terms of the F1-score, precision, and recall. Overall, the results suggest that Model 3 performed better than the other models in terms of the different evaluation metrics presented in the table."
812,"caption: Table 4. Model performances evaluated using different metrics.table: Model,Precision (P),Recall (R),F1-score,AUC,Accuracy, Logistic Regression,0.62,0.54,0.56,0.72,0.68, K-NN,0.68,0.59,0.62,0.73,0.72, Decision Tree,0.69,0.61,0.64,0.70,0.71, Random Forest,0.74,0.63,0.67,0.78,0.75, XGBoost,0.76,0.69,0.72,0.81,0.78","Table 4 displays the model performances evaluated using different metrics. We used Precision (P), Recall (R), F1-score, Area Under the ROC Curve (AUC), and Accuracy as evaluation metrics. It is observed that the XGBoost model achieved the best performance results, with the highest scores for all metrics except Precision (P), which the Random Forest model outperformed. The highest AUC was obtained by the XGBoost model with a score of 0.81, and the highest Accuracy was obtained by the XGBoost model with a score of 0.78. Logistic Regression had the worst performance among the models, with the lowest scores for all metrics except Precision (P), in which it performed slightly better than Decision Tree and K-NN."
813,"caption: Model Performance Comparison based on Various Evaluation Metricstable: Model,Acc,F1-score,Precision-score,Recall-score, Logistic Regression,0.85,0.84,0.85,0.83, Random Forest,0.89,0.88,0.89,0.88, XGBoost,0.88,0.87,0.87,0.89, Support Vector Machine,0.87,0.89,0.87,0.90","The table compares the performance of four different models: Logistic Regression, Random Forest, XGBoost, and Support Vector Machine based on evaluation metrics such as Accuracy, F1-Score, Precision-Score, and Recall-Score. The Random Forest model achieved the highest accuracy of 0.89, whereas the Support Vector Machine achieved the highest F1-score and Recall-score of 0.89 and 0.90, respectively. Notably, the Logistic Regression model had high precision-score of 0.85. Overall, these results emphasize the importance of selecting evaluation metrics that align with the specific modeling goals."
814,"caption: Table 4: Model comparison based on various evaluation metrics.table: Models,F1 Score,Precision,Recall,Accuracy, Logistic Regression,0.81,0.85,0.77,0.86, Random Forest,0.84,0.83,0.85,0.87, Support Vector Machines,0.78,0.88,0.7,0.83, Multi-layer Perceptron,0.82,0.84,0.80,0.85, AdaBoost,0.83,0.80,0.86,0.86","Table 4 presents the comparison of five different models based on multiple evaluation metrics. The evaluation metrics in the table include F1 Score, Precision, Recall, and Accuracy. The models evaluated are Logistic Regression, Random Forest, Support Vector Machines, Multi-layer Perceptron, and AdaBoost. Interestingly, the Random Forest model achieved the highest F1 score with a score of 0.84, whereas the Support Vector Machines model attained the highest Precision score of 0.88. With a Recall score of 0.86, AdaBoost produced the highest value among the models. Finally, both Logistic Regression and Support Vector Machines models' Accuracy scores are lower than the other models."
815,"caption: Comparison of the performance metrics of five models.table: Model,F1 score,Precision,Recall,AUC,Accuracy, Model 1,0.78,0.85,0.73,0.89,0.82, Model 2,0.73,0.76,0.70,0.86,0.79, Model 3,0.82,0.78,0.87,0.91,0.85, Model 4,0.71,0.69,0.73,0.81,0.77, Model 5,0.80,0.83,0.77,0.88,0.83","The table above shows the F1 score, Precision, Recall, AUC, and Accuracy of five different models. Model 1 had the highest F1 score of 0.78, while Model 3 had the highest Precision and Recall of 0.78 and 0.87, respectively. Model 3 also had the highest AUC of 0.91. Model 2 had the lowest performance results in all metrics, except for Recall. Model 4 had a relatively low F1 score of 0.71 and AUC of 0.81 compared to the other models. Model 5 had a consistent high performance in all metrics, including F1 score, Precision, Recall, and AUC, with slightly lower Accuracy of 0.83. Overall, Model 3 and Model 5 performed better than the other models in this evaluation."
816,"caption: Comparison of different models' performances based on evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.89,0.91,0.92,0.90, Random Forest,0.88,0.90,0.91,0.89, Logistic Regression,0.81,0.83,0.86,0.81, Naive Bayes,0.84,0.87,0.85,0.89","Table 4 shows a comparison of the performances of SVM, Random Forest, Logistic Regression, and Naive Bayes models based on four different evaluation metrics: Accuracy, F1 Score, Precision, and Recall. The table exhibits that the SVM and Random Forest models display the highest accuracy of 0.89 and 0.88, respectively. The Naive Bayes model achieved the highest F1 score of 0.87, while the Logistic Regression and Naive Bayes models have the highest Precision and Recall scores, respectively. Therefore, based on their evaluation metrics, the models' performance varies in Table 4."
817,"caption: Performance of different models based on multiple evaluation metrics.table: Model,Accuracy,F1 Score,AUC Score,Precision, Support Vector Machines,0.89,0.82,0.91,0.80, Random Forest,0.92,0.86,0.89,0.88, Neural Network,0.87,0.81,0.88,0.78, Naive Bayes,0.78,0.55,0.83,0.69","The table exhibits the performance of four different models based on four evaluation metrics, including accuracy, F1 score, AUC score, and Precision. Higher values for all the evaluation metrics imply better model performance. Notably, the Random Forest model shows the best accuracy score of 0.92, followed closely by Support Vector Machines with an accuracy of 0.89. On the other hand, Neural Network has the highest AUC score of 0.88, with Random Forest having the lowest AUC score of 0.89. Furthermore, Naive Bayes model reports the lowest performance in all evaluation metrics, indicating the poor generalization of the model."
818,"caption: Table comparing performance results of five different models based on multiple metrics - accuracy, precision, recall, F1-score and AUC.table: Model,Accuracy,Precision,Recall,F1-Score,AUC, Model 1,0.95,0.93,0.97,0.95,0.98, Model 2,0.90,0.85,0.95,0.90,0.96, Model 3,0.92,0.90,0.93,0.91,0.97, Model 4,0.86,0.80,0.92,0.85,0.94, Model 5,0.93,0.88,0.94,0.91,0.96","The table presents a comparison of five different models in terms of their accuracy, precision, recall, F1-score and AUC. Model 1 shows the best overall performance with the highest accuracy of 0.95, precision of 0.93, recall of 0.97, F1-Score of 0.95, and AUC of 0.98. Model 2 and Model 5 demonstrate similar performances in terms of accuracy, but Model 2 has the lowest F1-Score. Model 4 has the lowest accuracy and F1-Score measures. However, it obtains high precision and recall scores. Model 3 has moderate performance in all measures, obtaining accuracy, precision, recall, F1-score, and AUC values of 0.92, 0.90, 0.93, 0.91, and 0.97, respectively."
819,"caption: Table comparing different models' performance metrics.table: Model,Precision,Recall,F1-score,ROC-AUC,PR-AUC, Logistic Regression,0.75,0.68,0.71,0.82,0.67, Random Forest,0.80,0.76,0.78,0.85,0.71, SVM,0.72,0.77,0.74,0.79,0.63, MLP,0.83,0.85,0.84,0.89,0.75, Decision Tree,0.65,0.63,0.64,0.71,0.55","The table presents a comparison of multiple machine learning models' performance metrics, including Precision, Recall, F1-score, ROC-AUC, and PR-AUC. The machine learning models include Logistic Regression, Random Forest, SVM, MLP, and Decision tree. From the table, we can observe that MLP has the highest Precision, Recall, and F1-score metrics compared to the other models, with values of 0.83, 0.85, and 0.84, respectively. The Random forest model has the highest ROC-AUC and PR-AUC metrics, with metrics of 0.85 and 0.71, respectively. In contrast, the Decision tree model has the lowest performance in all the metrics, with the lowest Precision, Recall, F1-score, ROC-AUC, and PR-AUC.metrics."
820,"caption: Model performance on classification task with different evaluation metricstable: Model,Accuracy,Precision,F1-score, Logistic Regression,0.85,0.82,0.78, Random Forest,0.89,0.87,0.86, Support Vector Machines,0.82,0.80,0.75, Gradient Boosting,0.91,0.90,0.88","The table provides a comparison of different model performances based on multiple evaluation metrics, including Accuracy, Precision, and F1-score. Models such as Logistic Regression, Random Forest, Support Vector Machines (SVM), and Gradient Boosting are compared in terms of their performance metrics. The Gradient Boosting model achieved the highest performance result in all metrics, with an accuracy of 0.91, precision of 0.90, and F1-score 0.88. While the Random Forest model performance produced the second-best accuracy result of 0.89 and F1-score 0.86, it had the highest precision result of 0.87. Interestingly, although SVM achieved the lowest performance result, it had a competitive precision score of 0.80."
821,"caption: Performance comparison of SVM, Naive Bayes, and Random Forest models based on Accuracy, F1-Score, and Cohen's Kappa scores.table: Model,Accuracy,F1-Score,Cohen's Kappa, SVM,0.78,0.76,0.55, Naive Bayes,0.72,0.68,0.47, Random Forest,0.85,0.83,0.70","The presented table compares the performance of 3 models -- SVM, Naive Bayes, and Random Forest -- based on Accuracy, F1-Score, and Cohen's Kappa metrics. The SVM model achieved the highest accuracy of 0.78, while Random Forest obtained the highest accuracy of 0.85. Regarding the F1-score, Random Forest outperformed all models with a score of 0.83, followed by SVM and Naive Bayes with scores of 0.76 and 0.68, respectively. Notably, all models performed relatively low with Cohen's kappa score. However, Random Forest still fared better compared to other models, with a score of 0.70."
822,"caption: Model Performance utilizing Multiple Evaluation Metricstable: Algorithm,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.92,0.93,0.91,0.92, Naive Bayes,0.78,0.70,0.88,0.78, Decision Trees,0.81,0.79,0.83,0.81, Random Forest,0.93,0.97,0.88,0.92, Gradient Boosting,0.94,0.96,0.91,0.94","Table displays the performance of different models using multiple evaluation metrics. The table includes Logistic Regression, Naive Bayes, Decision Trees, Random Forest, and Gradient Boosting models. The evaluation metrics shown in the table include accuracy, precision, recall, and F1 score. The best-performing model in terms of overall evaluation metrics is Gradient Boosting with an accuracy of 0.94, precision of 0.96, recall of 0.91, and F1 score of 0.94. The Naive Bayes model scored the lowest with an accuracy of 0.78, precision of 0.70, recall of 0.88, and F1 score of 0.78. The Logistic Regression and Random Forest models performed well both accuracy-wise and precision-wise with scores above 0.92 and 0.97, respectively. Overall, the Gradient Boosting model had the best performing results."
823,"caption: Performances of different models based on accuracy, precision, recall, and F1-score.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.85,0.79,0.75,0.77, Decision Tree,0.81,0.73,0.66,0.68, Random Forest,0.89,0.86,0.82,0.83, KNN,0.83,0.76,0.72,0.74, SVM,0.88,0.82,0.79,0.80","The above table presents a comparison of the performances of different models concerning accuracy, precision, recall, and F1-score. The table includes five models: Logistic Regression, Decision Tree, Random Forest, KNN, and SVM. The best performing model in terms of accuracy and F1-score is the Random Forest model with scores of 0.89 and 0.83, respectively. The Logistic Regression model achieved the highest precision score of 0.79, and the Random Forest model achieved the highest recall score of 0.82. The SVM model scored well in all evaluation metrics, especially in terms of accuracy, precision, and F1-score."
824,"caption: Table 4: Model evaluation using multiple metricstable: Model,F1-score,Accuracy,Precision,ROC-AUC, Model A,0.83,0.76,0.77,0.82, Model B,0.78,0.74,0.75,0.79, Model C,0.81,0.71,0.73,0.85, Model D,0.89,0.82,0.83,0.87, Model E,0.87,0.79,0.82,0.88","Table 4 compares the performance of five different models using multiple evaluation metrics: F1-score, Accuracy, Precision, and ROC-AUC. The table highlights that Model D ranks first for all of the evaluation metrics, with the highest F1-score (0.89), Accuracy (0.82), Precision (0.83), and ROC-AUC (0.87). Model E also achieves high scores, with an F1-score of 0.87, Accuracy of 0.79, Precision of 0.82, and ROC-AUC of 0.88. In contrast, Model B scores the lowest for F1-score and ROC-AUC, with 0.78 and 0.79, respectively. Model C has the lowest accuracy achieved (0.71) despite having a relatively good ROC-AUC score (0.85)."
825,"caption: Table 4: Model performance comparison for different evaluation metricstable: Model,F1-Score,Precision,Recall,ROC-AUC,PR-AUC, Decision Tree,0.745,0.708,0.787,0.785,0.696, Random Forest,0.811,0.784,0.861,0.886,0.809, Logistic Regression,0.795,0.755,0.844,0.867,0.784, Support Vector Machines,0.779,0.747,0.814,0.867,0.765","Table 4 presents a performance comparison of different models based on the evaluation metrics of F1-Score, Precision, Recall, ROC-AUC, and PR-AUC. The table shows the performance results of Decision Tree, Random Forest, Logistic Regression, and Support Vector Machines. Random Forest achieved the highest F1-Score of 0.811, Precision score of 0.784, and Recall score of 0.861. The Random Forest model also recorded the best ROC-AUC of 0.886 and PR-AUC result of 0.809. On the other hand, the Decision Tree model performed the poorest among all the models with an F1-Score of 0.745, whereas Logistic Regression's performance is in the middle for all the evaluation metrics."
826,"caption: Table 4. Performance comparison of various models using multiple evaluation metrics.table: Model,Precision,Recall,F1 Score,Accuracy, Decision Tree,0.89,0.87,0.88,0.85, Logistic Regression,0.92,0.93,0.92,0.90, Naive Bayes,0.79,0.85,0.82,0.78, Random Forest,0.96,0.97,0.96,0.95, XGBoost,0.94,0.95,0.94,0.94","Table 4 displays the performance comparison of several models on a given dataset. The models compared include Decision Tree, Logistic Regression, Naive Bayes, Random Forest, and XGBoost. Evaluation metrics such as Precision, Recall, F1 Score, and Accuracy are used to compare the models' performance. Notably, Random Forest performed the best, achieving the highest score across all metrics. The Logistic Regression and XGBoost models are closely following Random Forest in terms of performance. Naive Bayes shows the lowest performance, with the lowest accuracy score of 0.78. Thus, it can be concluded that Random Forest can be a suitable model for the given dataset, while Naive Bayes may not be a suitable choice for this dataset based on the given metrics."
827,"caption: Model Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1 Score, SVM,0.90,0.88,0.96,0.92, Decision Tree,0.78,0.76,0.81,0.78, Random Forest,0.92,0.92,0.93,0.92, K-Nearest Neighbor,0.85,0.83,0.89,0.86, Naive Bayes,0.81,0.79,0.85,0.82","Table presents the evaluation metrics for SVM, Decision Tree, Random Forest, K-Nearest Neighbor, and Naive Bayes models. The models' performance was evaluated using Accuracy, Precision, Recall, and F1-Score metrics on a binary classification task. Random Forest model shows the highest accuracy score with 0.92. Among other models, SVM and K-Nearest Neighbor performed well with an accuracy score of 0.90 and 0.85, respectively. Concerning precision and recall measures, Random Forest obtained the highest score with 0.92 and 0.93, respectively. Naive Bayes had the lowest accuracy, precision, and recall score amongst the models."
828,"caption: Comparison of the accuracy, F1 Score, Precision and Recall of different models.table: Model Name,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.86,0.85,0.93,0.80, Random Forest,0.93,0.92,0.95,0.90, SVM,0.89,0.89,0.91,0.87, XGBoost,0.95,0.94,0.96,0.93","Table presents a comparison of different models' performance based on various evaluation metrics such as accuracy, F1 Score, precision, and recall. The table includes Logistic Regression, Random Forest, SVM, and XGBoost models. Random Forest showed the highest accuracy of 0.93 and F1 Score of 0.92 followed by XGBoost with 0.95 and 0.94 respectively. Logistic regression had the highest precision of 0.93, whereas Random Forest and XGBoost had the highest recall of 0.90 and 0.93, respectively. The table suggests that Random Forest and XGBoost are the most accurate models among the considered models."
829,"caption: Performance metrics of different models.table: Model,Accuracy,F1-Score,Precision,Recall, Model 1,0.85,0.86,0.84,0.88, Model 2,0.76,0.82,0.78,0.86, Model 3,0.92,0.94,0.93,0.95, Model 4,0.83,0.85,0.81,0.89, Model 5,0.90,0.91,0.89,0.93",
830,"caption: Model Evaluation Metricstable: Model Name,Accuracy (%),F1 Score,Recall Score,Precision Score, Model A,87.2,0.757,0.759,0.755, Model B,86.4,0.730,0.679,0.792, Model C,85.6,0.718,0.670,0.774, Model D,89.3,0.784,0.782,0.787, Model E,88.9,0.785,0.785,0.786","This table summarizes the performances of five different models (Model A, Model B, Model C, Model D, and Model E) based on multiple evaluation metrics. The evaluation metrics used are accuracy, F1 score, recall score, and precision score. Model D shows the best performance in all evaluation metrics, with an accuracy of 89.3%, F1 score of 0.784, recall score of 0.782, and precision score of 0.787. Model E has the highest F1 score and recall scores with a score of 0.785 on both evaluation metrics. Although Model B and Model C have similar accuracy, their F1 score, recall score, and the precision score have considerable differences. Notably, Model A has a higher accuracy score than Model B and Model C, but its F1 score is on par with Model B's score."
831,"caption: Evaluation metrics of various machine learning models.table: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.89,0.88,0.84,0.93, Random Forest,0.92,0.91,0.88,0.94, SVM,0.91,0.90,0.87,0.93, KNN,0.86,0.84,0.80,0.89, XGBoost,0.93,0.92,0.91,0.93","The table presents the evaluation metrics of different machine learning models - Logistic Regression, Random Forest, SVM, KNN, and XGBoost. The evaluation metrics include Accuracy, F1-score, Precision, and Recall. The results indicate that XGBoost achieved the highest accuracy of 0.93, and Random Forest followed closely with an accuracy of 0.92. For F1-score, XGBoost again performed the best achieving a score of 0.92. While in recall, Random Forest achieved the highest recall score of 0.94, and Logistic Regression achieved the highest precision score of 0.84. Overall, the results provide valuable insights into the performance of different machine learning models and their strengths on specific evaluation metrics."
832,"caption: Model performance summary from various classifiers.table: Model,Accuracy,Precision,Recall,F1-score, LogReg,0.87,0.89,0.82,0.85, SVM,0.88,0.91,0.81,0.85, RF,0.89,0.93,0.83,0.87, AdaBoost,0.86,0.90,0.81,0.85, Gradient Boosting,0.88,0.92,0.82,0.86","This table summarizes the performance of different classifiers in a binary classification problem. The models used were Logistic Regression, Support Vector Machine (SVM), Random Forest (RF), AdaBoost, and Gradient Boosting. The evaluation metrics used were Accuracy, Precision, Recall, and F1-score. RF achieved the highest Accuracy of 0.89, Precision of 0.93, Recall of 0.83, and F1-score of 0.87. SVM and Gradient Boosting showed competitive Accuracy, Precision, and F1-score results across all models. Nonetheless, this analysis suggests that RF would be a suitable model for prediction purposes."
833,"caption: A comparison of model performances based on multiple evaluation metrics.table: Model,Accuracy (%),F1-score (%),Precision (%),Recall (%), Model A,82.5,78.3,84.2,73.2, Model B,84.7,80.2,81.6,78.9, Model C,81.8,75.9,85.4,68.7, Model D,83.2,77.6,83.1,72.8","Table 1 presents a comparison of model performances in terms of multiple evaluation metrics such as accuracy, F1-score, precision, and recall. Four different models, namely Model A, Model B, Model C, and Model D, have been evaluated. The table exhibits the respective evaluation metric values for each model. Model B shows the highest accuracy, scoring 84.7%, while Model C has the lowest accuracy of 81.8%. On the other hand, Model A has the highest precision value at 84.2%, while Model C has the highest recall score of 68.7%. In terms of F1-score, Model B achieves the highest score of 80.2%, while the lowest score of 75.9% is obtained by Model C. The table highlights the importance of evaluating the model based on various metrics to obtain a more comprehensive evaluation of model performance."
834,"caption: Table 4: Performance comparison of different classification models using different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.89,0.89,0.87,0.88, Random Forest,0.92,0.93,0.91,0.92, SVM,0.87,0.88,0.83,0.85, Naive Bayes,0.82,0.82,0.85,0.83, K-NN,0.90,0.91,0.88,0.89","This table presents the classification models' performance comparison using multiple evaluation metrics. The models in the table include Logistic Regression, Random Forest, SVM, Naive Bayes, and K-NN, while the evaluation metrics are Accuracy, Precision, Recall, and F1 score. The Random Forest model outperforms the other models in all the evaluation metrics, except for Precision, where K-NN performs best. Notably, Naive Bayes has the lowest Accuracy, whereas Random Forest attains the highest Accuracy score. The table indicates that the Random Forest model is the most suitable choice for the given dataset."
835,"caption: Comparison of Five Different Models based on Different Evaluation Metricstable: Model,F1-score,Recall,Precision,Accuracy, Model A,0.85,0.89,0.82,0.84, Model B,0.83,0.87,0.80,0.85, Model C,0.79,0.88,0.72,0.82, Model D,0.84,0.86,0.83,0.86, Model E,0.87,0.82,0.92,0.87","The presented table shows a comparison of five different models based on four different evaluation metrics: F1-score, recall, precision, and accuracy. Each model's performance varies across the selected evaluation metric. Model E shows the best F1-score of 0.87, while Model A and Model D have a close F1-score of 0.85 and 0.84, respectively. On the other hand, Model A and Model D exhibit the highest recall of 0.89 and 0.86, respectively. Model E achieves the highest precision of 0.92, and Model A has the highest accuracy of 0.84. The comparison of different models based on multiple evaluation metrics provides a comprehensive understanding of their performance, aiding the selection of the best performing model."
836,"caption: Comparison of Model Performance using Various Metricstable: Model,F1-Score,Precision,Recall,Accuracy, Model A,0.85,0.87,0.83,0.90, Model B,0.81,0.80,0.82,0.85, Model C,0.76,0.78,0.74,0.80, Model D,0.89,0.91,0.87,0.93, Model E,0.83,0.81,0.85,0.88","Table X demonstrates the performance of Model A to E with different evaluation metric scores. The performance metrics F1-Score, Precision, Recall and Accuracy were used to compare the models. Among the presented models, Model A demonstrated the highest F1-Score of 0.85, along with a Precision of 0.87, Recall of 0.83 and Accuracy of 0.90. Meanwhile, Model D achieved the highest scores for all four evaluation metrics with a F1-Score of 0.89, Precision of 0.91, Recall of 0.87, and Accuracy of 0.93. Model B and Model E performed similarly with F1-Scores of 0.81 and 0.83, respectively."
837,"caption: Table 4: Model performance using different evaluation metricstable: Model,Accuracy Score,F1-Score,MCC Score, Decision Tree,0.82,0.72,0.63, Random Forest,0.92,0.88,0.81, Gradient Boosting,0.89,0.82,0.74, Logistic Regression,0.87,0.80,0.70, KNN,0.84,0.76,0.63, SVM,0.91,0.87,0.80","Table 4 showcases the performance of six models utilizing different evaluation metrics - Accuracy, F1-score, and Matthews Correlation Coefficient (MCC). The models are Decision Tree, Random Forest, Gradient Boosting, Logistic Regression, KNN, and SVM. The Random Forest achieved the highest accuracy score of 0.92, F1-score of 0.88, and MCC score of 0.81. Although SVM had the second-highest accuracy score of 0.91, it showed the highest F1-score and MCC score of 0.87 and 0.80, respectively. Interestingly, Decision Tree accomplished the lowest score in all evaluation metrics among all models. Overall, the results indicate that Random Forest and SVM models are more promising as they outperformed other models in most evaluation metrics."
838,"caption: Model performances based on different evaluation metricstable: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.85,0.82,0.87,0.78, Random Forest,0.91,0.91,0.92,0.9, SVM (RBF),0.87,0.85,0.86,0.84, XGBoost,0.93,0.92,0.93,0.91, Multilayer Perceptron,0.88,0.86,0.91,0.81","The table presents model performances based on different evaluation metrics. It includes multiple different machine learning models: Logistic Regression, Random Forest, SVM (RBF), XGBoost, and Multilayer Perceptron. The models were evaluated using four different metrics: Accuracy, F1 Score, Precision, and Recall, with the highest possible score being 1.0. The results show that each model exhibits different performance results for each of the evaluation metrics. Notably, the XGBoost model outperforms all other models significantly, obtaining the highest values for all metrics. The Random Forest model also exhibits strong performance across all metrics, albeit not as strong as that of XGBoost. However, the results suggest that when choosing a model, it is crucial to consider which evaluation metric is most important to the task at hand."
839,"caption: Table 4: Performance comparison of different models for binary classification problem.table: Model,F1-score (class 0),F1-score (class 1),Precision,Recall,Accuracy, Logistic Regression,0.84,0.77,0.82,0.79,0.80, Support Vector Machine (linear),0.89,0.63,0.86,0.76,0.78, Random Forest,0.95,0.78,0.91,0.89,0.90, XGBoost,0.93,0.83,0.87,0.89,0.91, Artificial Neural Network,0.89,0.72,0.83,0.81,0.82","Table 4 summarizes the performance comparison of various models for a binary classification problem evaluated using multiple metrics. The models include Logistic Regression, Support Vector Machine (SVM) with a linear kernel, Random Forest, XGBoost, and Artificial Neural Network (ANN). The table presents metrics such as F1-scores, Precision, Recall, and Accuracy for both classes (0 and 1). Random Forest exhibits the highest accuracy of 90%. Although XGBoost has a slightly lower accuracy of 91%, it has higher F1-scores for both classes than the other models. The SVM model has the highest F1-score for class 0 and Artificial Neural Network for class 1."
840,"caption: Table 4: Evaluation metrics for different machine learning classifiers.table: Model,Precision,Recall,F1 Score,Accuracy, SVM,0.84,0.83,0.83,0.85, Logistic Reg.,0.87,0.85,0.85,0.86, AdaBoost,0.82,0.80,0.80,0.82, Random Forest,0.89,0.88,0.88,0.89, Gradient Boosting,0.88,0.87,0.87,0.89","Table 4 demonstrates the performance of different machine learning classifiers based on multiple evaluation metrics. The models are evaluated using Precision, Recall, F1-Score, and Accuracy metrics. The table displays the performance results for SVM, Logistic Regression, AdaBoost, Random Forest, and Gradient Boosting models. Interestingly, the Random Forest model had the best F1-Score, Precision, and Accuracy results of 0.88, 0.89, and 0.89, respectively. On the other hand, SVM achieved the best Recall score of 0.83, indicating it successfully identified the actual positive samples. Logistic Regression and Gradient Boosting models also demonstrated relatively good performance across all evaluation metrics."
841,"caption: Comparison of the performance results for different models using multiple evaluation metrics.table: Model,F1-score,Precision,Recall,Accuracy, SVM,0.841,0.851,0.833,0.877, Logistic Regression,0.861,0.838,0.886,0.881, Decision Tree,0.801,0.792,0.811,0.871, Naive Bayes,0.796,0.760,0.835,0.859, Random Forest,0.874,0.890,0.859,0.897","The table above compares the performance results of different classification models, namely SVM, Logistic Regression, Decision Tree, Naive Bayes, and Random Forest based on four evaluation metrics - F1-score, Precision, Recall, and Accuracy. The highest F1-score of 0.874 was attained by Random Forest, followed by Logistic Regression with a score of 0.861. Similarly, Random Forest produced the highest Precision score of 0.890. Moreover, it achieved the highest Recall score of 0.859. Additionally, it had the highest Accuracy score of 0.897. Interestingly, SVM and Naive Bayes underperformed for all evaluation metrics when compared to the other models."
842,"caption: Model performance comparison based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Model A,0.90,0.89,0.89,0.89, Model B,0.87,0.88,0.86,0.87, Model C,0.92,0.91,0.92,0.91, Model D,0.82,0.83,0.82,0.82, Model E,0.95,0.96,0.95,0.95","The table provides a comparison of multiple models based on different evaluation metrics. These metrics include Accuracy, Precision, Recall, and F1-Score. Model E has achieved the best overall performance compared to other models with a high accuracy score of 0.95 and the highest precision score of 0.96. Model D has the lowest overall performance with an accuracy score of 0.82 and the lowest recall score of 0.82. The models' individual metrics' performance can be used to determine which model is best suitable for the intended use case, with Model E performing the best overall."
843,"caption: Model comparison using multiple evaluation metricstable: Model,Accuracy,Precision,Recall,F1-score,AUC, SVM,0.874,0.886,0.775,0.826,0.910, KNN,0.829,0.823,0.756,0.787,0.878, RF,0.898,0.901,0.856,0.877,0.922, XGB,0.915,0.931,0.851,0.888,0.930, MLP,0.845,0.841,0.797,0.813,0.869","The table provides a comparison of different models' performance based on multiple evaluation metrics, including Accuracy, Precision, Recall, F1-score, and AUC. The evaluated models include SVM, KNN, RF, XGB, and MLP, and all models were evaluated using the same dataset. Interestingly, the XGB model shows the highest accuracy with a score of 0.915, whereas RF presents the best Precision, Recall, F1-score, and AUC results with scores of 0.901, 0.856, 0.877, and 0.922, respectively. The SVM model also presents excellent results in all metrics with an AUC score of 0.910. On the other hand, KNN and MLP show lower results in all evaluated metrics compared to the other models."
844,"caption: Model performance evaluation using various metricstable: Model,F1-score,Accuracy,Precision,Recall, Model A,0.84,0.89,0.86,0.83, Model B,0.78,0.82,0.76,0.80, Model C,0.92,0.91,0.91,0.93, Model D,0.75,0.87,0.72,0.79, Model E,0.86,0.88,0.83,0.89","The table above compares the performance of multiple models based on different evaluation metrics. The discussed metrics are F1-score, accuracy, precision, and recall. The table encompasses Model A through E and shows their respective F1-score, accuracy, precision, and recall scores achieved through training on a similar dataset. Model C shows the highest F1-score of 0.92, while Model A has the highest accuracy of 0.89. Model C and E show the highest precision of 0.91 and 0.83, respectively, while Model C and A exhibit the highest recall of 0.93 and 0.83, respectively. The results suggest that each model has varying strengths and weaknesses depending on the evaluation metric used to assess them."
845,"caption: Performance results of different models based on different evaluation metrics.table: Model,Accuracy Score,F1-Score,Specificity,Sensitivity, Model A,0.86,0.87,0.89,0.83, Model B,0.78,0.76,0.76,0.80, Model C,0.92,0.91,0.96,0.86, Model D,0.82,0.83,0.84,0.80, Model E,0.89,0.88,0.83,0.93","The above table presents performance results of five different models based on various evaluation metrics, including Accuracy Score, F1-Score, Specificity, and Sensitivity. Notably, Model C had the highest Accuracy Score and F1-Score of 0.92 and 0.91, respectively. Model A performed well in Specificity with a score of 0.89, while Model E excelled in Sensitivity with a score of 0.93. Meanwhile, Model B had the lowest Accuracy Score of 0.78, while Model D had the lowest F1-Score of 0.83. Overall, the results suggest that Model C performs the best across all evaluation metrics, while Model B underperforms compared to other models."
846,"caption: Evaluation metrics for different machine learning models on a classification task.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.92,0.94,0.92,0.96, Random Forest,0.87,0.89,0.90,0.87, Naive Bayes,0.83,0.85,0.83,0.87, Decision Tree,0.85,0.86,0.86,0.85, KNN,0.77,0.76,0.78,0.74","The table summarizes the performances of five different machine learning models (SVM, Random Forest, Naive Bayes, Decision Tree, and KNN) trained and tested on a classification task. The table displays the models' accuracy, F1-Score, precision, and recall on the test set. Overall, the SVM model shows the best accuracy, F1-Score, precision, and recall among all models with 0.92, 0.94, 0.92, and 0.96, respectively. The Random Forest model has the second-best accuracy, F1-Score, and precision, with 0.87, 0.89, and 0.90, respectively, while Naive Bayes achieved the third-best recall score with 0.87. The KNN model has the lowest accuracy, F1-Score, and precision among all models, proving to be the least effective model."
847,"caption: The table showing the performance of various supervised machine learning models using different metrics.table: Model,Metric,Result, Logistic Regression,Accuracy,0.75, Decision Tree,Accuracy,0.72, SVM,Accuracy,0.78, KNN,Accuracy,0.61, Random Forest,Accuracy,0.81, MLP,Accuracy,0.80, Logistic Regression,F1 Score,0.70, Decision Tree,F1 Score,0.65, SVM,F1 Score,0.77, KNN,F1 Score,0.44, Random Forest,F1 Score,0.79, MLP,F1 Score,0.78","The table compares the performances of six different supervised machine learning models using two different evaluation metrics--accuracy and F1 score. The models are Logistic Regression, Decision Tree, Support Vector Machine (SVM), K-Nearest Neighbor (KNN), Random Forest, and Multilayer Perceptron (MLP). The highest accuracy was obtained using SVM with a score of 0.78, while the highest F1 score was obtained using Random Forest with a score of 0.79. KNN showed the lowest accuracy score of 0.61 and F1 score of 0.44, indicating it was less effective for this particular dataset."
848,"caption: Model comparison based on different evaluation metrics.table: Model,F1_score,Recall,Precision,Accuracy, SVM,0.82,0.75,0.91,0.81, KNN,0.71,0.75,0.68,0.72, Naive Bayes,0.54,0.88,0.41,0.57, Decision Tree,0.64,0.67,0.62,0.68, Random Forest,0.78,0.84,0.75,0.78","The table presents a comparison of five different models based on four distinct evaluation metrics - F1_score, Recall, Precision, and Accuracy. The table shows that SVM gives the best precision with a score of 0.91, while Random Forest model has the highest recall with a value of 0.84. Both of these models show a relatively high F1_score of 0.82 and 0.78, respectively. Interestingly, the Naive Bayes model has the lowest accuracy of 0.57, while the KNN model's accuracy is 0.72. Overall, the Random Forest model performs relatively well in terms of F1_score, recall, precision, and accuracy, with scores of 0.78, 0.84, 0.75, and 0.78, respectively."
849,"caption: A comparison of different machine learning models' performances based on multiple evaluation metrics.table: Model,F1-score,Accuracy,Recall,Precision, SVM,0.82,0.73,0.70,0.83, K-NN,0.77,0.69,0.64,0.87, Decision Tree,0.78,0.74,0.72,0.83, Random Forest,0.86,0.79,0.75,0.97, Gradient Boost,0.84,0.77,0.74,0.93","The table shows the F1-score, accuracy, recall, and precision of different machine learning models, namely SVM, K-NN, Decision Tree, Random Forest and Gradient Boost algorithms. Notably, the Random Forest algorithm demonstrated the best performance based on F1-score, accuracy, precision with scores of 0.86, 0.79, and 0.97, respectively, while SVM algorithm demonstrated the best performance in terms of recall, with a score of 0.70. The K-NN algorithm presents the lowest F1-score, with a score of 0.77. Lastly, the Gradient Boost algorithm achieved a high level of accuracy and precision with scores of 0.77 and 0.93, respectively. Overall, each machine learning algorithm presents different strengths and weaknesses."
850,"caption: Performance comparison of different models based on various evaluation metrics.table: Model,Precision,Recall,F1,AUC, SVM,0.79,0.85,0.82,0.91, Logistic Regression,0.77,0.82,0.79,0.89, Random Forest,0.84,0.80,0.82,0.90, Gradient Boosting,0.83,0.82,0.82,0.92, Neural Network,0.86,0.79,0.82,0.91","Table presents a performance comparison of multiple models using various evaluation metrics. SVM, Logistic Regression, Random Forest, Gradient Boosting, and Neural Network models were evaluated based on their Precision, Recall, F1, and AUC performance results. The table shows that the Neural Network model outperformed all other models and achieved the highest Precision of 0.86 and AUC of 0.91. The Random Forest and Gradient Boosting models also had comparable average Precision and AUC scores. The SVM model had the lowest reported Precision score, while Logistic Regression had the lowest AUC score. It is worth noting that all models had comparable Recall and F1 scores."
851,"caption: Performance results of different machine learning models using four evaluation metrics: accuracy, precision, recall, and F1 scoretable: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.93,0.91,0.95,0.93, Naive Bayes,0.88,0.85,0.89,0.87, Support Vector Machines (SVM),0.94,0.93,0.95,0.94, Random Forest,0.95,0.94,0.96,0.95, Multi-layer Perceptron (MLP),0.94,0.92,0.95,0.93","Table x displays the performance results of five different machine learning models based on four evaluation metrics: accuracy, precision, recall, and F1 score. The models covered in the table are Logistic Regression, Naive Bayes, Support Vector Machines (SVM), Random Forest, and Multi-layer Perceptron (MLP). The table presents that all models achieve an accuracy rate of at least 0.88, with the best performing model being Random Forest with 0.95 accuracy. The Random Forest model also achieved the highest precision, recall, and F1 score. However, it is important to note that other models like SVM and MLP demonstrated competitive performances across various evaluation metrics."
852,"caption: Table 4: Performance comparison of different machine learning models using various evaluation metrics.table: Model,Precision,Recall,F1-Score,Accuracy, SVM,0.85,0.78,0.81,0.84, KNN,0.72,0.60,0.65,0.70, RF,0.91,0.82,0.85,0.88, XGB,0.87,0.86,0.86,0.88","Table 4 presents a performance comparison of different machine learning models using various evaluation metrics, namely precision, recall, F1-score, and accuracy. The table highlights the models' performance that include SVM, KNN, RF and XGB. Notably, the Random Forest (RF) model shows the best precision score of 0.91 and the highest accuracy score of 0.88. The XGBoost (XGB) model produced the highest F1-Score of 0.86, demonstrating its ability to balance precision and recall. The SVM and KNN models also produced reasonable results, with an overall satisfactory performance compared to the other models."
853,"caption: Performance comparison of different classification models based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.85,0.86,0.83,0.84, SVM,0.82,0.80,0.85,0.83, Decision Tree,0.78,0.81,0.76,0.78, Random Forest,0.87,0.88,0.84,0.86, XGBoost,0.88,0.89,0.86,0.87","The table above shows the performance comparison of different classification models based on evaluation metrics such as Accuracy, Precision, Recall, and F1 Score. The table includes Logistic Regression, SVM, Decision Tree, Random Forest, and XGBoost models trained and tested on the same dataset. Interestingly, the XGBoost model achieved the highest accuracy score of 0.88, followed by the Random Forest model with 0.87. Similarly, the XGBoost model had the highest precision and recall scores, with 0.89 and 0.86, respectively. However, the Decision Tree model shows the lowest performance results across all evaluation metrics. Overall, the Random Forest and XGBoost models appear to be the best performers across all evaluation metrics."
854,"caption: Comparison of model performances using different evaluation metrics.table: Model,Accuracy,Precision,Recall,Specificity,F1-Score, Model A,0.87,0.89,0.82,0.92,0.85, Model B,0.92,0.85,0.97,0.84,0.91, Model C,0.83,0.92,0.72,0.94,0.81, Model D,0.95,0.93,0.96,0.87,0.94","Table 4 presents the comparison of Model A, Model B, Model C, and Model D performances. The table exhibits an evaluation of model performance using multiple metrics, including Accuracy, Precision, Recall, Specificity, and F1-Score. Interestingly, Model D shows the best performance with an Accuracy of 0.95, outperforming all other models. Additionally, Model A and Model B display high Precision of 0.89 and 0.85, respectively, whereas Model C exhibits a high Specificity of 0.94. However, Model B shows a high Recall of 0.97 and a high F1-Score of 0.91."
855,"caption: Table 4: Model performance comparison using different evaluation metrics.table: Model,Accuracy,F1 score,Precision,Recall, Logistic Regression,0.853,0.838,0.843,0.855, Decision Tree,0.784,0.795,0.793,0.788, Random Forest,0.905,0.905,0.917,0.894, XGBoost,0.898,0.896,0.901,0.892, Support Vector Machine,0.863,0.848,0.876,0.822","Table 4 presents the performance comparison of five different models using various evaluation metrics, including Accuracy, F1-score, Precision, and Recall. The models discussed in this table are Logistic Regression, Decision Tree, Random Forest, XGBoost, and Support Vector Machine (SVM). The Random Forest model was found to have the highest Accuracy of 0.905, and F1-score of 0.905, while Precision and Recall are 0.917 and 0.894, respectively. However, XGBoost and Logistic Regression are notable with their high F1-scores and SVM with its remarkable Precision performance."
856,"caption: Performance results of multiple models based on different evaluation metricstable: Model,Accuracy,F1 Score,Precision,Recall, Model 1,0.82,0.81,0.83,0.79, Model 2,0.85,0.84,0.83,0.85, Model 3,0.78,0.76,0.79,0.74, Model 4,0.89,0.87,0.92,0.83, Model 5,0.86,0.85,0.81,0.89","The table above presents the performance results of multiple models based on different evaluation metrics. The evaluation metrics include accuracy, F1 Score, precision, and recall. The models include model 1, model 2, model 3, model 4, and model 5. Model 4 performed the best with an accuracy of 0.89, an F1 score of 0.87, a precision of 0.92, and a recall of 0.83. However, Model 2 outperformed other models in terms of F1 Score and recall with a score of 0.84 and 0.85, respectively, while Model 4 achieved the highest precision score of 0.92."
857,"caption: Table 4: Model performance based on different evaluation metrics.table: Model,Precision,Recall,F1 Score,ROC_AUC,PR_AUC, Random Forest,0.83,0.89,0.86,0.91,0.79, SVM,0.81,0.72,0.76,0.85,0.71, Multilayer Perceptron,0.73,0.79,0.71,0.80,0.68, Logistic Regression,0.84,0.61,0.71,0.75,0.66","Table 4 presents a comparison of the performance of four models in terms of five different evaluation metrics. The evaluated models include Random Forest, SVM, Multilayer Perceptron, and Logistic Regression. The listed metrics include Precision, Recall, F1 Score, ROC-AUC, and PR-AUC. The results show that Random Forest model has the highest scores in Precision (0.83), Recall (0.89), F1 Score (0.86), and ROC-AUC (0.91). Nevertheless, Logistic Regression has the highest PR-AUC (0.66) score. Interestingly, the SVM model has a relatively balanced performance across all metrics evaluated."
858,"caption: Table 4: Performance of different models on multiple evaluation metrics.table: Model,Accuracy,F1 score,Recall,Precision, Random forest,0.88,0.87,0.88,0.87, Naive Bayes,0.76,0.78,0.76,0.80, Logistic Regression,0.82,0.81,0.82,0.79, K-Nearest Neighbours,0.79,0.76,0.79,0.74, Decision Tree,0.86,0.85,0.86,0.84","Table 4 showcases the performance of different models in achieving high accuracy, F1 score, recall, and precision. The evaluation metrics measure how well the model predicts the correct outcome. The table displays Random forest, Naive Bayes, Logistic Regression, K-Nearest Neighbours, and Decision Tree models' performances. Notably, Random forest model observed the highest accuracy and F1 score values of 0.88 and 0.87, respectively, while Naive Bayes achieved the highest precision score of 0.80. Surprisingly, Decision Tree showed the best recall score with a value of 0.86. The results show that no single model could obtain the highest score in all evaluation metrics."
859,"caption: Model performance based on accuracy, precision, recall and F1-score evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic,0.849,0.773,0.670,0.717, Random Forest,0.932,0.914,0.881,0.897, SVM,0.856,0.784,0.694,0.723, Naive Bayes,0.810,0.719,0.634,0.652, Neural Network,0.943,0.926,0.909,0.916","The table above presents the model performances of Logistic Regression, Random Forest, Support Vector Machine (SVM), Naive Bayes, and Neural Network based on four evaluation metrics: Accuracy, Precision, Recall, and F1-Score. The Random Forest model performs best with an accuracy of 0.932, precision of 0.914, recall of 0.881, and F1-score of 0.897. The Neural Network model also shows excellent performance with an accuracy of 0.943 and a high score for the other three metrics. Interestingly, the Logistic Regression model has a relatively low recall score compared to the remaining models, which might be useful information in selecting the appropriate model for the problem at hand."
860,"caption: Performance comparison of different models based on multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.859,0.867,0.823,0.844, Random Forest,0.915,0.917,0.892,0.904, SVM,0.877,0.882,0.853,0.865, Naive Bayes,0.802,0.788,0.826,0.807, Decision Tree,0.889,0.898,0.876,0.882","Table above shows the evaluation results of different models on accuracy, precision, recall, and F1-score. The comparison is made on the same dataset, and all the models are trained and tested using it. Random Forest has the best accuracy with a score of 0.915, and its precision and recall values are also the highest among the models. The Logistic Regression model had the highest precision score of 0.867, while the Naive Bayes model had the lowest accuracy and F1-score. SVM and Decision Tree models performed decently with scores ranging between 0.877-0.889. Overall, the Random Forest model seems to provide the best performance across multiple evaluation metrics."
861,"caption: Comparison of multiple models performance on various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, SVM,0.87,0.85,0.89,0.87, Random Forest,0.89,0.86,0.91,0.88, XGBoost,0.91,0.88,0.92,0.90, LSTM,0.87,0.83,0.91,0.87, CNN,0.88,0.84,0.91,0.87","The table presents the performance of multiple models across different evaluation metrics, including Accuracy, Precision, Recall, and F1 Score. The models compared are SVM, Random Forest, XGBoost, LSTM, and CNN. From the table, XGBoost shows the best overall performance with an accuracy score of 0.91, followed closely by Random Forest with a score of 0.89. On the other hand, LSTM and SVM perform comparatively worse with an accuracy score of 0.87. Interestingly, the SVM model had the highest precision score, while the XGBoost model had the highest recall and F1 scores. Overall, the table shows that the XGBoost model performs the best across different evaluation metrics."
862,"caption: Comparison of Model Performance on the Test Datasettable: Model,F1-score,Precision,Recall,Accuracy, Random Forest,0.92,0.94,0.91,0.92, Support Vector Machine (SVM),0.94,0.91,0.98,0.92, Decision Tree,0.87,0.89,0.86,0.88, Naive Bayes,0.78,0.85,0.73,0.82","The table presents the comparison of four different models' performance, including Random Forest, Support Vector Machine (SVM), Decision Tree, and Naive Bayes. The models were evaluated based on multiple metrics such as F1-score, precision, recall, and accuracy on the test dataset. Interestingly, the SVM model achieved the best F1-score of 0.94, while the Naive Bayes had the lowest F1-score of 0.78. The Random Forest and Decision Tree models show similar F1-scores of 0.92 and 0.87, respectively. Also, all models exhibit higher precision scores than the recall scores, except the SVM model that shows the opposite trend. Finally, the SVM model has the highest recall score of 0.98, proving its ability to identify relevant cases effectively."
863,"caption: Comparison of different models based on different evaluation metricstable: Model Name,Precision,Recall,F1-Score,Mean Absolute Error,Mean Squared Error, Model A,0.87,0.93,0.90,0.12,0.20, Model B,0.89,0.94,0.91,0.10,0.18, Model C,0.86,0.92,0.89,0.14,0.22, Model D,0.91,0.95,0.93,0.09,0.16, Model E,0.84,0.90,0.87,0.16,0.27","Table exhibits five different models' performances based on various evaluation metrics such as Precision, Recall, F1-Score, Mean Absolute Error and Mean Squared Error. All five models have distinct scores of the evaluation metrics, and it's interesting to note that Model D outperforms all other models in all criteria except the Mean Absolute Error. On the other hand, Model E shows the highest Mean Absolute Error, Mean Squared Error, and the lowest Precision, Recall, and F1-Score. The results suggest that Model D is the best performer, followed by Model B, and Model A in terms of overall evaluation metrics."
864,"caption: Model Performance on Test Datasettable: Model,Accuracy,F1 Score,Recall,Precision, SVM,0.95,0.73,0.70,0.76, KNN,0.88,0.61,0.59,0.64, RF,0.97,0.85,0.81,0.89, GB,0.94,0.76,0.74,0.78, NN,0.92,0.67,0.64,0.70",
865,"caption: Table 4: Performance evaluation of different models on a binary classification task.table: Model,Accuracy,F1 Score,AUC-ROC, SVM,0.892,0.902,0.724, RF,0.901,0.903,0.828, LR,0.875,0.871,0.682, MLP,0.897,0.900,0.751, KNN,0.874,0.850,0.621","Table 4 shows the performance evaluation of five different machine learning models on a binary classification task. The models were evaluated using three different metrics, including accuracy, F1 score, and AUC-ROC score. Random Forest model outperformed other models, achieving 90.1% accuracy, 90.3% F1 score, and 82.8% AUC-ROC score. The MLP model had the highest accuracy of 89.7%. The SVM model has the lowest AUC-ROC value of 72.4%. Interestingly, the KNN had the lowest accuracy of 87.4% but achieved a better F1-score of 85.0%. Overall, the table shows that different models have different strengths and weaknesses, and the choice of metric is crucial in selecting the best model for a given task."
866,"caption: Table 4. Comparison of different models' classification performance using various evaluation metrics.table: Model,Precision,Recall,F1-Score,Accuracy, Model A,0.75,0.80,0.77,0.82, Model B,0.69,0.71,0.70,0.78, Model C,0.81,0.76,0.78,0.84, Model D,0.79,0.85,0.82,0.86, Model E,0.87,0.88,0.87,0.89","Table 4 displays the comparison of different models' classification performance based on multiple evaluation metrics, including Precision, Recall, F1 score, and Accuracy. Model A achieved the highest precision score of 0.75 and the highest accuracy score of 0.82. Model E obtained the highest precision score of 0.87 and the highest Recall score of 0.88. Model D has the highest F1 score of 0.82. Interestingly, Model C shows an equal balance in precision and recall with a precision score of 0.81 and recall score of 0.76. Overall, the table demonstrates Model E's best overall performance with the highest scores in all evaluation metrics except precision where Model A outperforms it."
867,"caption: Table 4: Model performance comparison based on different evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Model A,0.82,0.76,0.87,0.67, Model B,0.79,0.72,0.82,0.64, Model C,0.87,0.81,0.89,0.75, Model D,0.91,0.86,0.93,0.79, Model E,0.88,0.82,0.91,0.75","Table 4 presents a comparison of five different models based on multiple evaluation metrics, including Accuracy, F1 Score, Precision, and Recall. The table shows that Model D has the best performance in all the evaluation metrics, achieving an accuracy of 0.91, F1 Score of 0.86, Precision of 0.93, and Recall of 0.79. Model C has the second-best performance, with an accuracy of 0.87, F1 Score of 0.81, Precision of 0.89, and Recall of 0.75. Notably, Model E has the highest Precision score of 0.91, while Model A has the highest Recall score of 0.67. Overall, the table highlights the significant variation in model performance based on different evaluation metrics, emphasizing the importance of considering multiple metrics in model selection."
868,"caption: Performance of various models on binary classification task.table: Model,Accuracy,F1 Score,Precision,Recall, Decision Tree,0.70,0.68,0.74,0.62, Random Forest,0.75,0.74,0.77,0.71, SVM,0.73,0.71,0.76,0.66, Logistic Reg.,0.72,0.70,0.74,0.66, Naive Bayes,0.67,0.65,0.70,0.60","The table above shows the performance of five different models, Decision Tree, Random Forest, SVM, Logistic Regression, and Naive Bayes, on a binary classification task. The models were evaluated using multiple criteria, including Accuracy, F1 Score, Precision, and Recall. Notably, the Random Forest algorithm outperforms the other models with the highest accuracy score of 0.75 and F1 score of 0.74. However, the Naive Bayes model shows the weakest performance across all evaluation metrics, with the lowest accuracy (0.67), F1 score (0.65), precision (0.70), and recall (0.60) scores. Overall, the Random Forest model outperforms the other models in this binary classification task."
869,"caption: Performance Evaluation Metrics for Five Different Models.table: ```, Model Name,Precision,Recall,F1 Score,Matthews Correlation Coefficient, Model 1,0.75,0.80,0.77,0.63, Model 2,0.78,0.82,0.80,0.68, Model 3,0.80,0.84,0.82,0.72, Model 4,0.74,0.72,0.73,0.54, Model 5,0.77,0.79,0.78,0.64","The table presents a comparison of the performance evaluation metrics for five different models. The evaluation metrics include Precision, Recall, F1 Score, and Matthews Correlation Coefficient. The Metrics were computed using the same testing dataset. Notably, Model 3 has the highest score in all evaluation metrics, where its precision is 0.80, recall is 0.84, f1 score is 0.82, and the Matthews Correlation Coefficient is 0.72. Model 4, on the other hand, exhibits the lowest performance, with precision 0.74, recall 0.72, f1 score 0.73, and Matthews Correlation Coefficient 0.54.  Overall, this table provides valuable insights into the strengths and weaknesses of these models in performing different evaluation metrics."
870,"caption: Performance of different classification models on dataset XYZtable: Model,Accuracy,Precision,Recall,F1-score, SVM,0.93,0.88,0.92,0.90, Random Forest,0.94,0.90,0.94,0.91, XGBoost,0.95,0.92,0.95,0.93, Naive Bayes,0.87,0.82,0.87,0.82, Neural Network,0.96,0.94,0.96,0.93","Table shows the performance comparison of multiple classification models on dataset XYZ using various evaluation metrics: Accuracy, Precision, Recall, and F1-score. The SVM model obtained the lowest accuracy score of 0.93 with 0.88 precision, 0.92 recall, and 0.90 F1-Score. However, the neural network model achieved the highest accuracy of 0.96 with 0.94 precision, 0.96 recall, and 0.93 F1-score. Among all models, Naive Bayes had the lowest performance with accuracy, precision, F1-score, and recall scores of 0.87, 0.82, 0.82, and 0.87, respectively. The table indicates that XGBoost and Random Forest had better performance scores than SVM but were outperformed by a neural network model."
871,"caption: Model performance based on different evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.87,0.83,0.85,0.81, Random Forest,0.92,0.89,0.93,0.86, Logistic Regression,0.82,0.76,0.78,0.74, Decision Tree,0.84,0.81,0.83,0.79, XGBoost,0.93,0.91,0.92,0.90","The table showcases the evaluation performance of SVM, Random Forest, Logistic Regression, Decision Tree, and XGBoost models based on various evaluation metrics. The evaluation metrics include accuracy, F1 Score, precision, and recall. The highest accuracy score was achieved by XGBoost with a score of 0.93. Additionally, the XGBoost model also achieved the highest F1 Score with a score of 0.91. The highest precision score was achieved by Random Forest with a score of 0.93, and the highest recall score was achieved by Random Forest with a score of 0.86. On the other hand, the Logistic Regression model showed the lowest performance in most metrics, with an accuracy score of 0.82. Overall, the table demonstrates different models' relative performance in multiple evaluation metrics, providing an insightful overview of the models."
872,"caption: Table 4: Comparison of performances of different models based on multiple evaluation metrics.table: Model A,Model B,Model C,Model D, Metric 1,0.80,0.65,0.75,0.70, Metric 2,0.76,0.87,0.71,0.91, Metric 3,0.82,0.69,0.76,0.78","Table 4 compares Model A, Model B, Model C, and Model D performances based on multiple evaluation metrics. Three different metrics, namely Metric 1, Metric 2, and Metric 3, were used to assess the models' performance. Model A performed the best in Metric 1 with a result of 0.8. Model B, on the other hand, had the highest score in Metric 2 by achieving 0.87. Model D performed the best in Metric 3 with a score of 0.78. Overall, the table shows varying performances of the different models in different evaluation metrics."
873,"caption: Performance comparison of different models using multiple evaluation metrics.table: Model Name,Accuracy,F1-score,Precision,Recall, Logistic regression,0.85,0.84,0.87,0.81, Random forest,0.91,0.90,0.91,0.89, KNN (k=5),0.78,0.76,0.80,0.74, SVM with RBF Kernel,0.87,0.87,0.87,0.88",
874,"caption: Table 4: Model performance summary based on multiple evaluation metrics.table: Models,Accuracy,F1 Score,Precision,Recall, Naive Bayes,0.80,0.77,0.82,0.76, Decision Tree,0.83,0.81,0.85,0.80, Random Forest,0.88,0.87,0.89,0.87, SVM,0.86,0.84,0.86,0.83, Neural Network,0.89,0.88,0.89,0.88","Table 4 presents a summary of model performances, evaluated using different metrics, including accuracy, F1 Score, precision, and recall. The table exhibits five different models: Naive Bayes, Decision Tree, Random Forest, SVM, and Neural Network. Among these models, the Neural Network model achieved the highest accuracy of 0.89. Interestingly, the Random Forest model achieved the highest F1 Score, precision, and recall values of 0.87, 0.89, and 0.87, respectively. The Decision Tree model also showed good performance in all metrics, while the Naive Bayes model showed the lowest scores in most of the metrics. Overall, the table provides an overview of the model performances based on multiple evaluation metrics, helping to identify the most suitable model for the given problem."
875,"caption: Performance of different models based on multiple evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.92,0.90,0.91,0.92, KNN,0.84,0.80,0.81,0.83, RF,0.86,0.82,0.84,0.88, ANN,0.90,0.87,0.88,0.91","The table compares the model performances based on multiple evaluation metrics such as accuracy, F1-score, precision, and recall. It includes SVM, KNN, RF, and ANN models, and their respective scores on the evaluation metrics. The SVM model obtained the highest accuracy and recall with 0.92, while the KNN model scored the lowest in all metrics except for recall. Interestingly, the RF model achieved the highest precision score with 0.84 and was not far behind the other models concerning the accuracy. Overall, the ANN model performed consistently well across all the evaluation metrics, achieving an accuracy score of 0.90 and an F1-score of 0.87."
876,"caption: Table 4: Model performance based on different evaluation metrics.table: Model,Accuracy,Recall,Precision,F1-score,AUC, Model 1,0.90,0.65,0.75,0.70,0.88, Model 2,0.92,0.70,0.80,0.74,0.91, Model 3,0.85,0.75,0.65,0.69,0.81, Model 4,0.94,0.85,0.90,0.87,0.92, Model 5,0.88,0.50,0.70,0.58,0.85","Table 4 presents the performance of various models based on different evaluation metrics such as Accuracy, Recall, Precision, F1-score, and AUC. Each Model was evaluated using the same dataset. The models' performances range from an accuracy score of 0.85 for Model 3 to 0.94 for Model 4. Model 2 has the highest recall score of 0.70, while Model 5 had the lowest recall score of 0.50. On the other hand, Model 4 had the highest precision score of 0.90, and Model 3 had the lowest precision score of 0.65. Moreover, Model 4 shows the highest F1-score of 0.87, and Model 5 shows the lowest F1-score of 0.58. Finally, Model 2 shows the highest AUC score of 0.91, and Model 3 shows the lowest AUC score of 0.81."
877,"caption: Model performance based on different evaluation metrics on the test set.table: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.82,0.71,0.79,0.64, Random Forest,0.87,0.80,0.82,0.80, SVM,0.81,0.66,0.77,0.58, Decision Tree,0.79,0.72,0.72,0.74, MLP,0.87,0.79,0.83,0.76","The table displays the test set performance of five different models concerning Accuracy, F1-score, Precision, and Recall. Logistic Regression achieved the best accuracy of 0.82, while the Random Forest model's F1-score tops the table with 0.80. In terms of Precision, MLP shows the best result with 0.83. On the other hand, the Decision Tree achieved the best recall score with 0.74. These results suggest that the models can perform differently concerning evaluation metrics and that it is necessary to consider multiple performance measures while selecting the best model for a given task."
878,"caption: Table 4: Performance Comparison of Different Models using Multiple Metricstable: Model,Precision,Recall,F1-Score,Accuracy, Logistic Regression,0.85,0.83,0.84,0.89, Decision Tree,0.75,0.8,0.77,0.87, Random Forest,0.9,0.89,0.89,0.94, K-NN,0.81,0.72,0.76,0.85, SVM,0.87,0.93,0.89,0.9, Naïve Bayes,0.65,0.98,0.79,0.74","Table 4 outlines a comparison of different classification models using multiple metrics. The metrics used in the table are precision, recall, f1-score, and accuracy. From the results, the Random Forest classifier performs best, achieving the highest precision of 0.9, recall of 0.89, f1-score of 0.89, and accuracy of 0.94. The SVM model is also notable, with precision of 0.87 and recall of 0.93, leading to an f1-score of 0.89. Notably, the Naïve Bayes model shows the highest recall of 0.98, but the lowest precision and f1-score. In contrast, K-NN model achieves relatively lower precision, recall, and f1-score than others."
879,"caption: Comparison of Model Performance on the Test Datasettable: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.80,0.81,0.62,0.70, Random Forest,0.82,0.78,0.72,0.75, SVM,0.70,0.81,0.33,0.47, K-Nearest Neighbors,0.75,0.68,0.63,0.65, Naive Bayes,0.68,0.59,0.85,0.70","The table compares the performance of five different models (Logistic Regression, Random Forest, SVM, K-Nearest Neighbors, and Naive Bayes) on a test dataset. The evaluation metrics used to assess model performance in this table are accuracy, precision, recall, and F1-score. Notably, the Random Forest model outperformed the other examined models in terms of accuracy, with a score of 0.82. However, the Logistic Regression model had the highest precision (0.81) and F1-score (0.70) among the models compared. The highest recall score of 0.85 was obtained by the Naive Bayes model. This table provides valuable insights into the distinctive performance of the investigated models on the test dataset."
880,"caption: Comparing the performance of different models using various metrics.table: Model,Accuracy,Precision,Recall,F1-Score,AUC Score, Random Forest,0.893,0.907,0.869,0.888,0.946, SVM,0.879,0.905,0.822,0.862,0.928, XGBoost,0.899,0.896,0.907,0.901,0.948, Logistic Reg.,0.871,0.907,0.781,0.839,0.924, MLP,0.896,0.895,0.906,0.900,0.944","The table presents a comparison of the accuracy, precision, recall, F1-score, and AUC score for five different models, namely Random Forest, SVM, XGBoost, Logistic Regression, and MLP. The models are evaluated using the same dataset, and each model's performance metrics are calculated independently. Notably, the Random Forest model shows the highest AUC score of 0.946, while the SVM has the lowest AUC score of 0.928. XGBoost and MLP show similar performance with AUC scores of 0.948 and 0.944, respectively. Interestingly, the Logistic Regression model has the lowest recall score of 0.781, indicating that the model struggles with correctly identifying positive instances. Overall, the table provides valuable insights into how each model performs concerning multiple evaluation metrics."
881,"caption: Table 4: Performance comparison of different classification models based on multiple metrics.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.85,0.85,0.86,0.84, KNN,0.76,0.77,0.75,0.81, RF,0.93,0.93,0.93,0.93, LR,0.89,0.89,0.89,0.91, NB,0.67,0.69,0.67,0.71","Table 4 presents a performance comparison of five classification models based on multiple metrics. The metrics presented here include Accuracy, F1 Score, Precision, and Recall. The table shows that the RF model has the best performance across all the presented metrics with an accuracy, an F1 score, precision, and recall score of 0.93. The SVM model also shows an impressive accuracy score of 0.85 followed by the LR model with an accuracy score of 0.89. The NB model underperforms compared to the other models, scoring the lowest values across all metrics with an accuracy score of just 0.67. The results demonstrate that the RF model is the best performing model, while the NB model is the weakest."
882,"caption: Model comparison based on evaluation metrics.table: Models,Parameters,Accuracy,Precision,Recall, Model 1,param1,0.80,0.82,0.75, Model 2,param2,0.85,0.84,0.87, Model 3,param3,0.81,0.86,0.78, Model 4,param4,0.90,0.91,0.93, Model 5,param5,0.87,0.88,0.88","Table presents a comparison of five models based on accuracy, precision and recall metrics. Each model has different parameters. The highest accuracy score of 0.90 was achieved by Model 4, while Model 2 showed the highest precision and recall scores of 0.84 and 0.87 respectively. Interestingly, Model 1 had a relatively higher accuracy than Model 3, despite its lower precision and recall scores. Overall, this table provides a valuable comparison of different metrics across various models and highlights the importance of evaluating multiple metrics when assessing model performance."
883,"caption: Model performance summary on a classification task.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.87,0.85,0.89,0.81, Naïve Bayes,0.82,0.80,0.84,0.76, Random Forest,0.92,0.90,0.93,0.88, XGBoost,0.93,0.91,0.94,0.88, Ensemble,0.94,0.92,0.95,0.89","Table 4 presents a summary of the performance of SVM, Naive Bayes, Random Forest, XGBoost, and an ensemble model. Each model's accuracy, F1 score, precision, and recall were evaluated on a classification task, where higher scores for each metric are better. Notably, the ensemble achieved the highest mean performance on all evaluation metrics, with accuracy, F1 score, precision, and recall scores of 0.94, 0.92, 0.95, and 0.89, respectively. The Random Forest and XGBoost models also demonstrated excellent performance across different metrics. The SVM model achieved the highest precision score, while the Naïve Bayes model had the lowest performance among the models."
884,"caption: Model performance based on different evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.862,0.858,0.871,0.864, RF,0.879,0.884,0.870,0.876, KNN,0.841,0.836,0.850,0.843, MLP,0.894,0.898,0.890,0.894","The presented table reports the evaluation metrics of four different models - SVM, RF, KNN, and MLP. Each model was evaluated for its accuracy, precision, recall, and F1-score. Indeed, the accuracy metric for MLP is the highest with a score of 0.894. Similarly, MLP demonstrated the highest precision at 0.898 and recall at 0.890. Interestingly, the RF model showed the highest F1-score of 0.876, which is a harmonic mean of precision and recall. Additionally, SVM presented comparable results with minor differences in accuracy, precision, recall, and F1-score. Finally, KNN lagged behind compared to the other models in all the evaluation metrics."
885,"caption: Model performances based on multiple evaluation metricstable: Model,Accuracy,Precision,Recall,F1 Score,AUC, Random Forest,0.93,0.94,0.93,0.93,0.97, Support Vector Machine,0.86,0.85,0.90,0.87,0.93, Multilayer Perceptron,0.90,0.88,0.91,0.89,0.94, Gaussian Naive Bayes,0.82,0.75,0.89,0.81,0.92, K-Nearest Neighbors,0.89,0.88,0.87,0.87,0.94","Table presents a comparison of various machine learning models' performances based on multiple evaluation metrics, including accuracy, precision, recall, F1 score, and AUC. Among the models, the Random Forest model reached the highest accuracy score of 0.93, precision of 0.94, recall of 0.93, F1 Score of 0.93, and AUC score of 0.97. The Gaussian Naive Bayes model, on the other hand, had the lowest accuracy of 0.82 and F1 Score of 0.81. Interestingly, the SVM model had the second-highest AUC score of 0.93 and performed well in precision and recall, indicating that it could be useful in identifying specific target classes. Overall, the table demonstrates that the Random Forest model is the best-performing model among the five models considered."
886,"caption: Model performances based on multiple evaluation metrics.table: Model Name,F1 Score,Precision,Recall,Accuracy, Random Forest,0.85,0.89,0.82,0.90, Logistic Regression,0.80,0.84,0.77,0.85, K-Nearest Neighbor,0.72,0.80,0.66,0.75, Support Vector Machine,0.82,0.88,0.78,0.88","The above table presents the performance results of four different models based on evaluation metrics such as F1 Score, Precision, Recall, and Accuracy. Among these models, Random Forest performed the best with an F1 score of 0.85, precision of 0.89, recall of 0.82, and accuracy of 0.90. Interestingly, K-Nearest Neighbors achieved the lowest F1 score of 0.72. Therefore, Random Forest appears to be the best performing model in this comparison."
887,"caption: Model performances based on different evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall,AUC Score, Decision Tree,0.84,0.87,0.89,0.85,0.73, Random Forest,0.91,0.93,0.95,0.91,0.85, Logistic Regression,0.86,0.90,0.89,0.91,0.77, Naive Bayes,0.82,0.88,0.85,0.92,0.72, Support Vector Machine,0.88,0.91,0.93,0.90,0.79",
888,"caption: Performance metrics of different models.table: Model,Accuracy,F1-Score,Precision,Recall,AUC-ROC, Model A,0.85,0.82,0.87,0.78,0.91, Model B,0.79,0.74,0.71,0.78,0.82, Model C,0.91,0.93,0.91,0.95,0.94, Model D,0.80,0.75,0.70,0.82,0.88, Model E,0.88,0.84,0.90,0.79,0.89","The table above showcases different models' performance in terms of five evaluation metrics, including Accuracy, F1-score, Precision, Recall, and AUC-ROC. The table includes Model A to E, and it is clear that Model C performed the best across all five metrics with an accuracy score of 0.91, F1-score of 0.93, Precision of 0.91, Recall of 0.95, and AUC-ROC score of 0.94. Model B, on the other hand, had the lowest performance, with an accuracy score of 0.79, F1-score of 0.74, Precision of 0.71, Recall of 0.78, and AUC-ROC score of 0.82. Interestingly, Models A, D, and E had a similar level of overall performance with accuracy scores of 0.85, 0.80, and 0.88, respectively."
889,"caption: Comparison of model performances on the classification tasktable: Model,Accuracy,F1-score,Precision,Recall, Logistic Reg.,0.87,0.85,0.89,0.82, Decision Tree,0.81,0.80,0.78,0.83, Random Forest,0.89,0.88,0.91,0.85, KNN,0.82,0.80,0.78,0.84, SVM,0.91,0.90,0.94,0.86","The table above compares the performances of five different machine learning models on a classification task based on multiple evaluation metrics. The models include Logistic Regression, Decision Tree, Random Forest, KNN, and SVM. Evaluation metrics used in this size-simulation experiment are accuracy, F1-score, precision, and recall. SVM performed the best in accuracy, achieving 0.91. In precision, Random Forest provided the highest score of 0.91 while SVM had the most substantial recall score of 0.86. Overall, Random Forest and SVM have high overall model performances in classification."
890,"caption: Model performance comparison.table: **Model**,**Accuracy**,**Precision**,**Recall**,**F1-Score**, Model A,0.83,0.87,0.78,0.82, Model B,0.86,0.84,0.87,0.85, Model C,0.81,0.80,0.89,0.84, Model D,0.88,0.92,0.84,0.88","The table displays the evaluation metrics (accuracy, precision, recall, and F1-score) for four different models - Model A, Model B, Model C and Model D. Model D shows the best overall performance with high accuracy of 0.88, high precision of 0.92, and high F1-Score of 0.88. Model B has the highest recall of 0.87, while Model C has the lowest accuracy of 0.81. The table assists in comparing model performances based on multiple evaluation metrics, which gives a better understanding of the models' strengths and limitations."
891,"caption: Performance comparison of different regression models on a dataset.table: Model Name,Mean Absolute Error (MAE),Mean Squared Error (MSE),R-squared (R2), Linear Regression,1.2367,3.4672,0.8026, Ridge Regression,1.2458,3.6011,0.7947, Lasso Regression,1.2639,3.7240,0.7864, ElasticNet Regression,1.3462,4.1242,0.7464","The table above shows a comparison of different regression models' performance based on their MAE, MSE, and R-squared on a particular dataset. The models include Linear Regression, Ridge Regression, Lasso Regression, and ElasticNet Regression. The evaluation metrics for the models include MAE, MSE, and R-squared. The results show that Linear Regression performed the best with the lowest MAE of 1.2367 and the highest R2 of 0.8026. Ridge and Lasso regression models show comparable results to the Linear Regression model, although they scored slightly higher MAE and lower R2 values. ElasticNet Regression model shows slightly worse performance with a higher MAE and lower R2."
892,"caption: Model Performance Using Different Evaluation Metricstable: Model,Accuracy (%),Precision (%),Recall (%),F1-Score, A,92.0,86.0,89.0,87.5, B,89.5,90.2,82.7,86.3, C,91.2,78.5,93.4,85.0, D,88.9,92.3,84.8,88.4, E,89.8,86.7,86.7,86.7","The table presents the performance results of models A, B, C, D, and E based on different evaluation metrics, namely Accuracy, Precision, Recall, and F1-Score. Model A has the highest accuracy score of 92.0%, while model D has the highest precision score of 92.3%. Model C has the highest recall score of 93.4%. However, model E shows the highest F1-Score of 86.7%, which is the harmonic mean of Precision and Recall. Despite having a lower score in each evaluation metric than the other models, model B still exhibited decent performance with an overall F1-Score of 86.3%."
893,"caption: Comparison of different machine learning models' performances using multiple evaluation metrics.table: Model Name,Accuracy,F1-Score,Precision,Recall,ROC AUC, Logistic Regression,0.82,0.83,0.76,0.90,0.87, Random Forest,0.87,0.88,0.83,0.93,0.93, SVM,0.84,0.85,0.80,0.92,0.88, Naive Bayes,0.75,0.77,0.71,0.84,0.81, K-Nearest Neighbors,0.80,0.80,0.76,0.85,0.84","The table presents the performance comparison of five different machine learning models in terms of their accuracy, F1-score, precision, recall, and ROC AUC. Here, Random Forest and SVM show the highest accuracy rates of 0.87 and 0.84, respectively, while Naive Bayes demonstrates the lowest accuracy of 0.75. In terms of F1-score, the Random Forest model achieves the highest score of 0.88, followed closely by Logistic Regression with an F1-score of 0.83. The highest precision score is also achieved by the Random Forest model at 0.83. In contrast, Naive Bayes and Logistic Regression yield the lowest precision scores of 0.71 and 0.76, respectively. SVM and Random Forest yield the highest recall scores of 0.92 and 0.93, respectively, whilst Naive Bayes shows the lowest recall score of 0.84. Lastly, the Random Forest model displays the highest ROC AUC of 0.93, while SVM, Naive Bayes, and K-Nearest Neighbours exhibit ROC AUC of 0.88, 0.81, and 0.84, respectively."
894,"caption: Comparison of model performance based on different evaluation metrics.table: Model,Accuracy,F1 score,Precision,Recall, SVM,0.89,0.91,0.93,0.89, Naïve Bayes,0.80,0.83,0.76,0.90, Random Forest,0.92,0.93,0.95,0.92, ANN,0.88,0.91,0.89,0.92, KNN,0.82,0.85,0.79,0.92","Table presents results from five different models, namely SVM, Naïve Bayes, Random Forest, ANN, and KNN. These models were evaluated based on accuracy, F1 score, precision, and recall metrics. The Random Forest model showed the highest accuracy with a score of 0.92, while SVM had the highest precision with a score of 0.93. The Naïve Bayes model had the lowest performance among the models, with an accuracy score of 0.80 and an F1 score of 0.83. Interestingly, KNN had the highest recall with 0.92, although its overall performance was lower than that of the Random Forest and SVM models. The table exhibits different model performance results based on selected evaluation metrics, providing comparative insights into the strengths and weaknesses of each model."
895,"caption: Model performance of different classification models based on accuracy, precision, recall, and F1 score.table: Model,Accuracy,Precision,Recall,F1 Score, Random forest 1,0.87,0.65,0.72,0.68, Random forest 2,0.88,0.67,0.76,0.71, XGBoost 1,0.86,0.64,0.70,0.67, XGBoost 2,0.89,0.68,0.78,0.73, SVM,0.85,0.63,0.69,0.66, Naive Bayes,0.82,0.60,0.67,0.63","Table X presents the model performances of multiple classification algorithms in terms of accuracy, precision, recall, and F1 score. Notably, the table shows the results of two Random forest models, two XGBoost models, an SVM model, and a Naive Bayes model. Among all models, Random forest 2 showed the highest accuracy (0.88), precision (0.67), recall (0.76), and F1 score (0.71). Also, both XGBoost models (XGBoost 1 and XGBoost 2) achieved relatively high scores across all evaluation metrics compared to other models. Interestingly, the Naive Bayes model resulted in the lowest performance across all metrics, with accuracy, precision, recall, and F1 score of 0.82, 0.60, 0.67, and 0.63, respectively. Overall, the table highlights the varying performances of classification models and emphasizes the importance of implementing multiple evaluation metrics."
896,"caption: Table 4: Model Performance Comparison using Multiple Metricstable: Model,Precision (mean),Recall (mean),F1-score (mean),Accuracy (mean), LR,0.85,0.84,0.84,0.83, SVM,0.80,0.78,0.77,0.79, RF,0.89,0.90,0.89,0.88, XGB,0.87,0.88,0.86,0.86","Table 4 shows the performance comparison of multiple models across different metrics. The table presents four models, namely logistic regression (LR), support vector machine (SVM), random forest (RF), and XGBoost (XGB). These models were trained and tested using a given dataset. The evaluation metrics considered in the table include precision, recall, F1-score, and accuracy. Notably, across all four models, the highest precision was observed using the RF model, and the best recall using the LR model. The best F1-score was achieved using the SVM model, while the RF model achieved the highest accuracy. Overall, the RF model presented the best-average performance across the metrics considered in the table."
897,"caption: Comparison Table of Multiple Models with Different Evaluation Metricstable: Model,Accuracy,F1 Score,AUC Score, Model A,0.84,0.82,0.76, Model B,0.81,0.78,0.72, Model C,0.89,0.87,0.81, Model D,0.92,0.91,0.84, Model E,0.85,0.80,0.75","The table presents a comparison of five different models, Model A to E, based on their accuracy, F1 score, and AUC score. The results show that Model D has the highest accuracy of 0.92 and F1 score of 0.91, whereas Model C achieved the highest AUC score of 0.81. Model B has the lowest performance scores across all metrics. It is interesting to note that there is a large discrepancy in the accuracy and F1 scores between Model C and the other models. In contrast, the differences in AUC scores are relatively smaller. This suggests that Model C performs well in distinguishing between positive and negative samples, while the other models have more balanced performance."
898,"caption: Evaluation metrics of different classification models.table: Model,Accuracy,Precision,Recall,F1 Score, SVM,0.92,0.89,0.89,0.89, Random Forest,0.94,0.91,0.92,0.91, Decision Tree,0.87,0.85,0.83,0.84, Logistic Regression,0.91,0.88,0.87,0.87, Neural Network,0.95,0.93,0.93,0.93","The table displays the evaluation metrics, Accuracy, Precision, Recall, and F1 Score, from five different classification models: SVM, Random Forest, Decision Tree, Logistic Regression, and Neural Network. All models were trained on a fixed dataset, and their performances were evaluated using similar protocols. Notably, the Neural Network model showed the best performance across all evaluation metrics with the highest Accuracy score of 0.95, Precision score of 0.93, Recall score of 0.93, and F1 score of 0.93. Random Forest was the second-best model, with accuracy and precision scores of 0.94 and 0.91, respectively. The Decision Tree model achieved the lowest performance, with an accuracy score of 0.87 and an F1 score of 0.84."
899,"caption: A comparison of various classification models based on multiple evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.85,0.86,0.83,0.89, Decision Tree,0.80,0.77,0.79,0.75, Random Forest,0.89,0.89,0.90,0.88, Support Vector Machine,0.83,0.84,0.81,0.86, Multilayer Perceptron,0.87,0.88,0.86,0.89","The table above provides a comparison of different classification models based on multiple evaluation metrics such as accuracy, F1 score, precision, and recall. The models evaluated are Logistic Regression, Decision Tree, Random Forest, Support Vector Machine, and Multilayer Perceptron. The Random Forest model performed the best among all the models with accuracy of 0.89, F1 score of 0.89, precision of 0.9 and recall of 0.88. Logistic regression model attained 0.86 F1 score which is still very impressive."
900,"caption: A comparison of accuracy, F1-score, recall, and precision metrics for various models.table: Model,Accuracy,F1-score,Recall,Precision, Model A,0.85,0.87,0.89,0.85, Model B,0.84,0.86,0.90,0.83, Model C,0.87,0.88,0.88,0.89, Model D,0.81,0.82,0.86,0.80, Model E,0.88,0.91,0.93,0.90","Table shows the performances of different models based on accuracy, F1-score, recall, and precision evaluation metrics. Models A-E were trained on the same dataset, and their performances were evaluated using the same set of metrics. Model E shows the best overall performance with an accuracy of 0.88 and an F1-score of 0.91. Interestingly, Model D had the lowest accuracy score with 0.81 while Model C had the highest precision score with 0.89. Overall, this table helps to compare and contrast the models' performances based on different evaluation metrics."
901,"caption: Table 4: Performance Evaluation of Different Machine Learning Modelstable: Model,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.75,0.69,0.71,0.71, Decision Tree,0.78,0.73,0.73,0.74, Random Forest,0.80,0.76,0.76,0.78, SVM,0.73,0.65,0.67,0.68","Table 4 shows the performance evaluation of four different machine learning models on a given dataset using multiple evaluation metrics, including Accuracy, F1-Score, Precision, and Recall. The models used in this comparison include Logistic Regression, Decision Tree, Random Forest, and SVM. The Random Forest model showed the best performance on all metrics, achieving the highest values for accuracy (0.80), F1-score (0.76), precision (0.76), and recall (0.78). Decision tree also performed well, with an accuracy of 0.78, while SVM had the weakest performance on all metrics."
902,"caption: Table 4. Performance of different machine learning models using various evaluation metrics on the given dataset.table: Model,Accuracy,Recall,Precision,F1-score, SVM,0.95,0.90,0.94,0.92, Random Forest,0.94,0.89,0.93,0.91, MLP Classifier,0.92,0.86,0.90,0.87, Decision Tree,0.89,0.82,0.86,0.84","Table 4 shows the performances of four different machine learning models - Support Vector Machines (SVM), Random Forest, MLP Classifier, and Decision Tree - on the given dataset, each evaluated based on multiple metrics - Accuracy, Recall, Precision, and F1-score. The results indicate that the SVM model outperforms all other models with an accuracy of 0.95, while the decision tree model has the lowest accuracy at 0.89. Interestingly, there is an evident trade-off between precision and recall in all models. The Random Forest and SVM models have high precision scores of 0.93 and 0.94, respectively, but lower recall scores compared to the MLP Classifier and Decision Tree models."
903,"caption: Table 4: Model performances using multiple evaluation metrics.table: Models,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.84,0.81,0.79,0.84, Decision Tree,0.78,0.74,0.72,0.76, Random Forest,0.89,0.87,0.88,0.86, KNN,0.82,0.79,0.81,0.77, Naive Bayes,0.76,0.73,0.74,0.73","Table 4 compares the performances of different models using multiple evaluation metrics, namely, Accuracy, F1-score, Precision, and Recall. The table shows that the Random Forest model outperforms the other models with an accuracy of 0.89, F1-score of 0.87, and precision of 0.88. Furthermore, the Logistic Regression model had a consistent performance in all evaluation metrics, with a recall value of 0.84, which is the highest among all models. Despite having a lower accuracy score, the Decision Tree model had a reasonable recall value of 0.76. The KNN model demonstrated good precision score of 0.81 but had low recall of 0.77. Lastly, the Naive Bayes model had the lowest performance in all evaluation metrics."
904,"caption: Table 4: Performance metrics of different models based on accuracy, F1 score, precision, and recall.table: Model,Accuracy,F1 score,Precision,Recall, Model 1,0.86,0.82,0.87,0.78, Model 2,0.88,0.84,0.88,0.81, Model 3,0.91,0.87,0.91,0.82, Model 4,0.83,0.77,0.85,0.73, Model 5,0.90,0.85,0.93,0.79","Table 4 shows the performance metrics of five different models based on accuracy, F1 score, precision, and recall. The models were trained and tested on the same dataset to ensure a fair comparison. Notably, Model 3 shows the highest accuracy of 0.91, followed by Model 5 with 0.90. Similarly, Model 3 also performs well in terms of F1 score (0.87), precision (0.91), and recall (0.82). On the other hand, Model 4 has the lowest accuracy of 0.83 and F1 score, precision, and recall of 0.77, 0.85, and 0.73, respectively. Overall, these performance metrics can help in selecting the best model for the given task."
905,"caption: Evaluation metrics of different models using a breast cancer datasettable: Model,Accuracy,Precision,Recall,F1-Score, SVM,84.7%,0.89,0.84,0.86, RF,85.3%,0.87,0.89,0.88, XGB,86.1%,0.92,0.85,0.86, MLP,83.6%,0.81,0.87,0.83, KNN,80.9%,0.78,0.80,0.78","The table presents the evaluation metrics of five different machine learning models for predicting breast cancer using a given dataset. The evaluation metrics used in this context include accuracy, precision, recall, and F1-score. The XGB model has the highest accuracy with 86.1%, while the SVM model has the lowest accuracy with 84.7%. For precision, the XGB model again performed the best with 0.92, whereas the MLP model had the worst with 0.81. The RF model achieved the highest recall rate with 0.89, while the SVM and MLP models had the lowest recall rate with 0.84. Lastly, for F1-score, the RF model gained the highest with 0.88, while the MLP model had the lowest with 0.83."
906,"caption: Performance comparison of different classification models based on four evaluation metricstable: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.78,0.77,0.81,0.74, Random Forest,0.82,0.81,0.83,0.79, MLP,0.85,0.83,0.85,0.82, XGBoost,0.84,0.82,0.84,0.81, KNN,0.73,0.72,0.76,0.70, Naive Bayes,0.65,0.57,0.70,0.49","The table above shows performance comparison of six different models using accuracy, F1-Score, precision, and recall metrics. Among all models, MLP exhibits the highest accuracy of 0.85, while Random Forest has the highest F1-Score of 0.81 with  precision and recall values of 0.83 and 0.79, respectively. Naive Bayes shows the lowest performance with the accuracy, F1-Score, precision, and recall of 0.65, 0.57, 0.70, and 0.49, respectively. Notably, the results suggest that Random Forest and MLP outperform other models in terms of the four evaluation metrics."
907,"caption: Model performance based on different evaluation metricstable: Model,Precision,Recall,F1-Score,Accuracy, SVM,0.84,0.79,0.81,0.78, Decision Tree,0.76,0.84,0.79,0.74, Random Forest,0.89,0.92,0.90,0.90, Logistic Regression,0.90,0.87,0.88,0.89","This table shows the performance of four different models based on four evaluation metrics, namely precision, recall, F1-score, and accuracy. The evaluated models are the SVM, decision tree, random forest, and logistic regression. Notably, the random forest model performed best in all four evaluation metrics, with precision of 0.89, recall of 0.92, F1-score of 0.90, and accuracy of 0.90. The logistic regression model also showed impressive results, with precision, recall, F1-score, and accuracy scores of 0.90, 0.87, 0.88, and 0.89, respectively. In contrast, the decision tree model performed the poorest, achieving an F1-score of 0.79."
908,"caption: Model performances based on different evaluation metrics.table: Model,Recall,F1-Score,Accuracy,Precision, Model 1,0.85,0.82,0.90,0.80, Model 2,0.70,0.75,0.68,0.72, Model 3,0.92,0.88,0.94,0.86, Model 4,0.60,0.68,0.59,0.65, Model 5,0.95,0.93,0.96,0.90","This table shows the recall, F1-score, accuracy, and precision for five models. Model 1 and Model 3 show the highest recall scores of 0.85 and 0.92, respectively. Model 5 has the highest precision with a score of 0.90. Meanwhile, Model 2 had the lowest scores in all metrics except for precision. Model 5 had the highest scores in all metrics except for precision, but it wasn't better than Model 3 in recall. Overall, Model 3 had the best performance across all metrics except precision, and Model 5 had the highest precision score."
909,"caption: Table 4: Performance comparison of different models.table: Model,Precision,Recall,F1-score,Accuracy,ROC-AUC, SVM,0.91,0.87,0.89,0.81,0.72, RF,0.92,0.91,0.89,0.85,0.79, LR,0.89,0.84,0.87,0.79,0.70, DT,0.90,0.89,0.89,0.83,0.76, MLP,0.91,0.92,0.90,0.87,0.82","Table 4 presents a performance comparison of different models, which includes SVM, RF, LR, DT, and MLP, evaluated on multiple metrics. Precision, Recall, F1-Score, Accuracy, and ROC-AUC were used to evaluate models in the binary classification problem. The SVM model had the highest precision score of 0.91, and the MLP model had the best recall and F1-Score of 0.92 and 0.90, respectively. On the other hand, the Random Forest model showed better accuracy of 0.85 than other models while MLP was better in ROC-AUC with the score of 0.82. Overall, it can be concluded that the MLP model performed the best with the highest scores in the majority of the metrics."
910,"caption: Table 4: Model performances based on different evaluation metricstable: Model 1,Model 2,Model 3,Model 4,Model 5, Metric 1,0.81,0.92,0.76,0.68,0.91, Metric 2,0.75,0.87,0.69,0.63,0.89, Metric 3,0.82,0.91,0.73,0.59,0.94, Metric 4,0.78,0.89,0.72,0.65,0.92","Table 4 displays the performances of five different models based on four evaluation metrics. The models are denoted as Model 1 to Model 5, while the evaluation metrics are represented by Metric 1 to Metric 4. The best performing models in the table differ depending on the evaluation metric. Model 5 has the highest score in Metric 1 at 0.91, while Model 2 and Model 5 tie for the best score in Metric 2 at 0.87. Model 5 also has the highest scores in Metric 3 and Metric 4 at 0.94 and 0.92, respectively. Overall, the table suggests that Model 5 performed the best among the compared models across the evaluated metrics."
911,"caption: Table 4: Model Comparison based on Different Evaluation Metricstable: ```, Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.87,0.86,0.88,0.85, Random Forest,0.91,0.90,0.92,0.88, SVM (Linear),0.85,0.84,0.86,0.82, Decision Tree,0.89,0.88,0.90,0.86, XGBoost,0.93,0.92,0.94,0.90","Table 4 compares multiple models based on various evaluation metrics such as accuracy, F1 score, precision, and recall. The table includes Logistic Regression, Random Forest, SVM (Linear), Decision Tree, and XGBoost models. The results show that XGBoost performs best among the models, achieving an accuracy of 0.93, F1-score of 0.92, precision of 0.94, and recall of 0.90. Notably, Random Forest and Decision Tree models give good results on all metrics and come second in terms of performance behind XGBoost. Logistic Regression and SVM (Linear) perform relatively lower than the other models."
912,"caption: Model performance comparison using different evaluation metrics.table: Model,Precision Score,Recall Score,F1-Score,Accuracy, Logistic Regression,0.85,0.92,0.88,0.77, Support Vector Machine,0.82,0.88,0.85,0.75, Random Forest,0.88,0.91,0.89,0.81, Gradient Boosting,0.86,0.90,0.87,0.79","Table shows the performance comparison of four different models: Logistic Regression, Support Vector Machine, Random Forest, and Gradient Boosting. The models were evaluated using multiple evaluation metrics: precision score, recall score, F1-score, and accuracy. The Random Forest model demonstrated the highest precision score of 0.88 and recall score of 0.91, achieving an F1 score of 0.89 and an accuracy of 0.81. On the other hand, Support Vector Machine was the worst-performing model with a precision score of 0.82, recall score of 0.88, F1 score of 0.85, and accuracy of 0.75. Overall, Random Forest performed best across all evaluation metrics compared to the other models."
913,"caption: Performance comparison of different classification models.table: Model,Accuracy,Precision,Recall,F1 Score, XGBoost,0.92,0.8,0.94,0.87, Logistic Regression,0.89,0.82,0.85,0.83, Random Forest,0.91,0.79,0.92,0.85, Support Vector Machine,0.88,0.77,0.81,0.79, Naive Bayes,0.82,0.63,0.94,0.75","The table presents a comparison of various classification models based on different evaluation metrics. Five models, including XGBoost, Logistic Regression, Random Forest, Support Vector Machine, and Naive Bayes, were evaluated using the same dataset. The evaluation metrics include Accuracy, Precision, Recall, and F1 Score. The best performing model for Accuracy was XGBoost with a score of 0.92. However, for Precision, Random Forest was the best performing model with a score of 0.79. For Recall, Naive Bayes model achieved the highest score with a value of 0.94. Finally, XGBoost had the highest F1 Score of 0.87. Overall, these results indicate that the XGBoost is the most accurate model among the considered models, while the Naive Bayes is the most effective model in correctly identifying positive samples, and the Random Forest is the most precise model in the classification."
914,"caption: Model performances using different scoring metrics.table: Model,Accuracy,Precision,Recall,F1 Score, SVM,0.90,0.92,0.87,0.89, Logistic Regression,0.88,0.90,0.85,0.87, Random Forest,0.91,0.93,0.89,0.91, Neural Network,0.92,0.91,0.93,0.92","The table presents a comparison of the model performances of SVM, Logistic Regression, Random Forest, and Neural Network. The comparison is based on different evaluation metrics, including Accuracy, Precision, Recall, and F1 Score. Notably, the Neural Network model has the highest accuracy of 0.92, followed by the Random Forest model with 0.91 while the SVM model has an accuracy of 0.90 and the Logistic Regression model has 0.88. The Random Forest model shows the highest value in all the other metrics mentioned. Interesting to note that the Neural Network model almost achieved the highest scores, but unfortunately, its precision score is slightly lower than that of the SVM and the Random Forest."
915,"caption: Model performances using different spatial features extraction methods and classifiers.table: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.81,0.79,0.74,0.76, K-Nearest Neighbors,0.67,0.56,0.62,0.59, Random Forest,0.84,0.83,0.78,0.8, Support Vector Machines,0.8,0.76,0.8,0.78, XGBoost,0.86,0.85,0.8,0.82","The table reports the performance of five different models on a binary classification task. The models' accuracy, precision, recall, and F1-score metrics are presented. Random Forest achieved the highest accuracy rate, precision and F1 scores compared to the other models, while XGBoost obtained the highest recall rate. Notably, K-Nearest Neighbors exhibited the lowest performance metrics compared to the other models. This table's results suggest the superiority of ensemble learning methods like Random Forest and Gradient Boosting over traditional techniques like Logistic regression and SVMs."
916,"caption: Model performance on evaluation metricstable: Model,Accuracy,Precision,Recall,F1 Score, SVM (linear),0.89,0.92,0.88,0.90, SVM (radial),0.88,0.91,0.87,0.89, Random Forest,0.91,0.94,0.92,0.93, Logistic Regression,0.87,0.90,0.86,0.88, XGBoost,0.92,0.95,0.93,0.94","Table indicates the model performance on evaluation metrics for five different models; SVM (linear), SVM (radial), Random Forest, Logistic Regression, and XGBoost. The metrics used to measure the model's performance are accuracy, precision, recall, and F1 score. The Random Forest and XGBoost models show the best performance across all of the evaluation metrics, highlighting the importance of ensemble models in complex prediction tasks. While SVM (linear) and Logistic Regression models show moderate accuracy and precision, both models have a low recall score, indicating weak performance in classifying the dataset's minority class. Additionally, the SVM (radial) model exhibits lower performance in all evaluation metrics compared to other models in the table."
917,"caption: Model performance of different classifiers based on evaluation metricstable: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.9648,0.9543,0.9799,0.9308, DT,0.9127,0.8665,0.8803,0.8534, KNN,0.9345,0.9104,0.9567,0.8703, NB,0.8453,0.7845,0.6514,0.9682, RF,0.9882,0.9842,0.9921,0.9764",
918,"caption: Table 4: Model evaluation metrics on the test datasettable: Model,F1,Precision,Recall,Accuracy, Logistic Regression,0.87,0.85,0.89,0.90, Random Forest,0.88,0.91,0.85,0.92, XGBoost,0.89,0.92,0.87,0.93, Decision Tree,0.83,0.80,0.86,0.88","Table 4 compares the performances of four different models, namely Logistic Regression, Random Forest, XGBoost, and Decision Tree, on the test dataset. The table provides the evaluation metrics such as F1 score, precision, recall, and accuracy for each model. Notably, Random Forest and XGBoost models consistently perform better than other models across all evaluation metrics. The XGBoost shows the best F1 score (0.89) and accuracy (0.93) among all models, while the Random Forest shows the best precision (0.91) and recall (0.85). In contrast, the Decision Tree model shows the lowest performance among all models."
919,"caption: Table 4: Model performance using different evaluation metricstable: Model,Accuracy,F1 Score,AUC, Logistic Regression,0.86,0.84,0.92, Decision Tree,0.83,0.82,0.76, Random Forest,0.92,0.91,0.95, XGBoost,0.91,0.90,0.94","Table 4 presents multiple models' performance using three different evaluation metrics, namely Accuracy, F1 Score, and AUC. The table exhibits Logistic Regression, Decision Tree, Random Forest, and XGBoost models' performances. Notably, all models were trained and tested using the same dataset. Random Forest performed the best among all models, achieving the highest accuracy of 0.92, F1 Score of 0.91, and AUC of 0.95. XGBoost also performed exceptionally, achieving high scores for all three metrics, with an accuracy of 0.91, F1 Score of 0.90, and AUC of 0.94. Logistic Regression performed the best in terms of accuracy, achieving an accuracy score of 0.86, although its F1 Score and AUC were slightly lower than the best models. The Decision Tree model showed the lowest scores for all the metrics, with an accuracy of 0.83, F1 Score of 0.82, and AUC of 0.76."
920,"caption: Table 4: Model evaluation metrics on the test dataset.table: Model,Precision,Recall,F1 Score, Logistic Regression,0.87,0.92,0.89, Decision Tree,0.82,0.88,0.85, Naive Bayes,0.79,0.82,0.79, Random Forest,0.90,0.93,0.91, Support Vector Machines,0.88,0.90,0.88, AdaBoost,0.91,0.92,0.91","The table displays the performance metrics of six different models on a test dataset. The models include Logistic Regression, Decision Tree, Naive Bayes, Random Forest, Support Vector Machines, and AdaBoost. Three evaluation metrics are presented, including Precision, Recall, and F1 Score. The Random Forest model outperformed the other models with the highest Precision of 0.90, Recall of 0.93, and F1 Score of 0.91. The AdaBoost model follows closely with a good performance with the Precision of 0.91, Recall of 0.92, and F1 Score of 0.91. It is notable that Decision Tree and Naive Bayes models performed worse than the other models."
921,"caption: Model performance metrics using different classifierstable: Model,Accuracy,Precision,Recall,F1-score, Random forest,0.92,0.88,0.94,0.91, XGBoost,0.91,0.89,0.90,0.90, SVM,0.88,0.83,0.90,0.86, Logistic Regression,0.86,0.82,0.88,0.85","Table presents accuracy, precision, recall, and F1-score for four different models: Random forest, XGBoost, SVM, and Logistic Regression. The models were trained and tested on the same dataset, and the different evaluation metrics illustrate the strengths and weaknesses of each model. Notably, Random forest obtained the highest accuracy of 0.92 and recall of 0.94, implying that this model has a high true positive rate. On the other hand, SVM achieved the lowest accuracy score of 0.88, but its precision of 0.83 was the strongest from all the models, indicating a low false positive rate. Overall, the different evaluation metrics demonstrate the trade-offs between precision, recall, and accuracy for each classifier model presented in the table."
922,"caption: Model comparison based on evaluation metrics.table: Model,F1-score,Accuracy,Precision,Recall,AUC, A,0.89,0.95,0.92,0.86,0.96, B,0.72,0.85,0.69,0.76,0.84, C,0.94,0.96,0.93,0.95,0.98, D,0.86,0.87,0.83,0.9,0.89, E,0.78,0.82,0.71,0.87,0.83","Table presents a comparison of different models based on various evaluation metrics - F1-score, accuracy, precision, recall, and AUC. Model A shows the best overall performance in terms of F1-score (0.89), accuracy (0.95), precision (0.92), recall (0.86), and AUC (0.96). Model C exhibits the highest F1-score of 0.94, while model E shows the lowest performance in all evaluation metrics except recall. Interestingly, model D shows a high recall of 0.9, whereas, in comparison, model B has the lowest recall of 0.76. In summary, the comparison of the models indicates that Model A has the best overall performance, while specific models performed better in specific evaluation metrics."
923,"caption: Table 4: Model evaluation metrics comparison.table: ```, Model,Accuracy,F1 Score,Precision,Recall,AUC Score, Model 1,0.85,0.87,0.81,0.95,0.93, Model 2,0.89,0.91,0.86,0.96,0.92, Model 3,0.78,0.81,0.75,0.88,0.87, Model 4,0.93,0.94,0.92,0.97,0.94","Table 4 compares the evaluation metrics of four different models. The evaluation metrics include Accuracy, F1 Score, Precision, Recall, and AUC Score. Model 1 achieved an accuracy of 0.85, F1 Score of 0.87, Precision score of 0.81, Recall score of 0.95, and AUC Score of 0.93. Model 2 outperformed model 1 in all metrics except AUC Score, achieving an accuracy of 0.89, F1 Score of 0.91, Precision of 0.86, Recall of 0.96, and AUC Score of 0.92. Model 3 had the lowest performance in all performance metrics, except Recall, with an accuracy of 0.78, F1 Score of 0.81, Precision of 0.75, Recall of 0.88, and AUC Score of 0.87. Model 4 performed best in all performance metrics except precision, achieving an Accuracy of 0.93, F1 Score of 0.94, Precision of 0.92, Recall of 0.97, and AUC Score of 0.94."
924,"caption: Performance of different models on the classification of email messagestable: Model,Accuracy,F1 score,Precision,Recall, SVM,0.85,0.83,0.82,0.85, KNN,0.78,0.75,0.76,0.74, Naive Bayes,0.92,0.90,0.93,0.88, Random Forest,0.94,0.93,0.93,0.95",
925,"caption: Model performance on different evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.82,0.81,0.85,0.79, KNN,0.78,0.77,0.79,0.75, Decision trees,0.81,0.80,0.83,0.77, Naive Bayes,0.77,0.73,0.78,0.68, Random Forest,0.89,0.88,0.91,0.86","The table presents the performance of five different machine learning models on various evaluation metrics. The evaluation metrics include accuracy, F1 score, precision, and recall. The results show that the Random Forest model outperforms other models in all evaluation metrics, achieving the highest accuracy of 0.89, F1 score of 0.88, precision of 0.91, and recall of 0.86.  SVM achieved the second-highest accuracy of 0.82 and precision of 0.85, while Decision trees performed well in F1 score (0.80) and precision (0.83). KNN and Naive Bayes models achieved the lowest accuracy, F1 score, precision, and recall. Overall, the Random Forest model is the best performer based on the presented evaluation metrics."
926,"caption: Table 4: Model Performance Comparison Using Different Evaluation Metricstable: Model,Accuracy,F1 Score,Precision,Recall,AUC Score, Decision Tree Classifier,0.72,0.71,0.75,0.69,0.72, Random Forest Classifier,0.83,0.82,0.85,0.81,0.85, Support Vector Machine,0.76,0.75,0.77,0.75,0.76, Logistic Regression,0.80,0.80,0.80,0.80,0.87","Table 4 compares the performance of four classification models using different evaluation metrics, including accuracy, F1 score, precision, recall, and AUC score. The models evaluated are Decision Tree Classifier, Random Forest Classifier, Support Vector Machine (SVM), and Logistic Regression. Out of the four models, Random Forest Classifier performed best, achieving the highest accuracy score of 0.83, the highest F1 score and precision score of 0.82 and 0.85, respectively, and a high recall score of 0.81. Meanwhile, Logistic Regression achieved the highest AUC score among all models with 0.87. The comparison indicates that the Random Forest Classifier might be the best-suited model for this classification task."
927,"caption: Model performance comparison based on different evaluation metricstable: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.80,0.78,0.76,0.81, Logistic Regression,0.75,0.73,0.71,0.76, Naive Bayes,0.72,0.70,0.68,0.74, Decision Tree,0.68,0.64,0.62,0.67, Random Forest,0.84,0.81,0.79,0.84, XGBoost,0.86,0.83,0.82,0.85","This table presents a performance comparison of six different models based on their accuracy, F1-score, precision, and recall metrics. The models include SVM, Logistic Regression, Naive Bayes, Decision Tree, Random Forest, and XGBoost. The highest performance results are obtained by the Random Forest model, which had an accuracy of 0.84, F1-score of 0.81, precision of 0.79, and recall of 0.84, closely followed by the XGBoost model, which had an accuracy of 0.86, F1-score of 0.83, precision of 0.82, and recall of 0.85. However, SVM model have the highest recall score of 0.81 among all the models. Logistic regression and Decision Tree models performed relatively poorly on all metrics, with accuracy scores of 0.75 and 0.68, respectively. Naive Bayes model also have the lowest accuracy score of 0.72 among all the models. Overall, the Random Forest and XGBoost models show their superiority in achieving better performance on all the evaluation metrics."
928,"caption: Model performances based on different evaluation metricstable: Evaluation metrics,Model 1,Model 2,Model 3,Model 4, Accuracy,0.85,0.75,0.71,0.92, Precision,0.87,0.81,0.70,0.94, Recall,0.78,0.68,0.65,0.87, F1 score,0.81,0.74,0.67,0.91","Table above provides a comparison of different models' performances based on various evaluation metrics, such as accuracy, precision, recall, and F1 score. The table shows four models, represented by Model 1, Model 2, Model 3, and Model 4. Model 4 demonstrates higher values for all evaluations metrics, securing the highest accuracy of 0.92, precision of 0.94, recall of 0.87, and F1 score of 0.91. Additionally, interestingly, Model 1 performs well in terms of accuracy and precision, while Model 2 shows the lowest performance across all evaluation metrics."
929,"caption: Model performance comparison based on various evaluation metricstable: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.89,0.91,0.88,0.89, Decision Tree,0.86,0.88,0.81,0.84, Random Forest,0.92,0.93,0.90,0.91, Naive Bayes,0.80,0.79,0.82,0.80, SVM,0.91,0.93,0.89,0.91","The table compares five different machine learning models based on various evaluation metrics for a given dataset. The models include Logistic Regression, Decision Tree, Random Forest, Naive Bayes, and SVM, each evaluated based on Accuracy, Precision, Recall, and F1 score. Results indicate that Random Forest performed better than the other models concerning all evaluation metrics, with an accuracy score of 0.92, precision score of 0.93, recall score of 0.90, and F1 score of 0.91. SVM also performed well with all metrics above 0.89, except Precision (0.93). Naive Bayes, on the other hand, had the lowest model performance concerning all evaluation metrics, with an accuracy score of 0.80, precision score of 0.79, recall score of 0.82, and F1 score of 0.80."
930,"caption: Comparison of performance metrics across different machine learning models.table: Model Name,F1-score,Accuracy,Precision,Recall, Random Forest,0.82,0.83,0.81,0.83, Logistic Regression,0.79,0.81,0.76,0.83, Naive Bayes,0.75,0.76,0.72,0.81, SVM (Linear),0.81,0.82,0.79,0.81, XGBoost,0.84,0.85,0.82,0.87","The table provides a comparison of different machine learning models' performance metrics. F1-Score, accuracy, precision, and recall were used to evaluate the models. The Random Forest model has the highest accuracy of 0.83 and an F-1 score of 0.82, closely followed by the XGBoost model, which has the highest F-1 score of 0.84 and accuracy of 0.85. The Naive Bayes model has the poorest metrics compared to the other models, with an F-1 score of 0.75 and an accuracy of 0.76. SVM and Logistic Regression models had comparable performance metrics with F-1 scores of 0.81 and 0.79, respectively."
931,"caption: Comparison of different models using accuracy, precision, recall, and F1 Score metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Model A,0.86,0.83,0.89,0.86, Model B,0.92,0.94,0.88,0.91, Model C,0.89,0.88,0.91,0.89, Model D,0.94,0.96,0.93,0.94","Table above presents a comparison of different models based on different evaluation metrics, including Accuracy, Precision, Recall, and F1 Score. The table highlights four models, Model A, B, C, and D, and their corresponding performances with respect to these evaluation metrics. The results indicate that model D exhibits the highest accuracy score of 0.94, whereas Model B demonstrates the highest precision of 0.94 and the best F1 Score of 0.91. Model A demonstrates a trade-off between precision and recall, with relatively high scores of both metrics at 0.83 and 0.89, respectively. Lastly, Model C demonstrates overall decent performances for all metrics with an accuracy score of 0.89 and F1 Score of 0.89."
932,"caption: Model performance with different evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score,AUC-ROC, Logistic_Regression,0.86,0.90,0.81,0.85,0.91, Decision_Tree,0.74,0.73,0.71,0.70,0.75, SVM,0.89,0.91,0.84,0.87,0.88, KNN,0.78,0.82,0.76,0.77,0.79, Random_Forest,0.91,0.92,0.89,0.90,0.95",
933,"caption: Model performances based on different evaluation metrics.table: Model,Accuracy,Precission,Recall,F1-Score,AUC-ROC, Logistic regression,0.892,0.898,0.867,0.882,0.945, Random Forest,0.906,0.902,0.90,0.900,0.938, Gradient Boosting,0.888,0.895,0.872,0.882,0.932, Support Vector Machine,0.879,0.879,0.879,0.878,0.914","The table exhibits the performance of four models, namely Logistic regression, Random Forest, Gradient Boosting, and Support Vector Machine, based on different evaluation metrics, including Accuracy, Precision, Recall, F1-Score, and AUC-ROC. Notably, the table shows that all models performed well, with accuracy ranging from 0.879 to 0.906, indicating high prediction accuracy. Additionally, the table shows that Random Forest performed well across all evaluation metrics, especially in Precision, with a score of 0.902. While the SVM model's scores were consistent across all evaluation metrics, especially in Recall, with a score of 0.879, it still recorded the lowest performance among the models."
934,"caption: Model Performance Metricstable: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.76,0.80,0.71,0.75, KNN,0.68,0.71,0.59,0.64, Naive Bayes,0.81,0.76,0.91,0.83, Decision Tree,0.62,0.54,0.75,0.63, Random Forest,0.79,0.75,0.85,0.80","The table above showcases the performance results of five different machine learning models, including SVM, KNN, Naive Bayes, Decision Tree, and Random Forest. The evaluation metrics include accuracy, precision, recall, and F1-score. Notably, Naive Bayes has the highest accuracy with a score of 0.81. The Random Forest model has the best F1-score. On the other hand, the Decision Tree model has the lowest accuracy and F1-score but the highest recall, while the KNN model has the lowest precision. The table helps in determining the best machine learning model for the task at hand based on specific evaluation metrics."
935,"caption: Table 4: Model Performance on Multiple Evaluation Metricstable: Model,Accuracy,F1-score,Precision,Recall, Model A,0.86,0.85,0.87,0.83, Model B,0.78,0.79,0.76,0.83, Model C,0.92,0.93,0.94,0.92, Model D,0.79,0.80,0.78,0.83, Model E,0.88,0.89,0.87,0.91","Table 4 displays the performance evaluation results of five different models based on various evaluation metrics, including Accuracy, F1-score, Precision, and Recall. Model C shows the highest accuracy score with 0.92, while Model D has the lowest accuracy score of 0.79. By contrast, Model C demonstrates the highest F1-score of 0.93, which also exhibits the highest Precision score of 0.94. Model E achieved the highest Recall score of 0.91. Interestingly, Model A shows high scores in all metrics except recall, indicating that the model may have difficulty identifying the relevant items."
936,"caption: Performance metrics comparison of different classification modelstable: Model,Accuracy,Precision,Recall,F1-Score, Random Forest,0.936,0.903,0.954,0.928, XGBoost,0.931,0.901,0.936,0.916, Support Vector Machine,0.921,0.893,0.910,0.896, Naive Bayes,0.860,0.834,0.852,0.841, Logistic Regression,0.912,0.889,0.912,0.890","The table above demonstrates the comparison of different classification models' performance metrics on a given dataset. The models include Random Forest, XGBoost, Support Vector Machine, Naive Bayes, and Logistic Regression. The evaluation metrics recorded for each model include Accuracy, Precision, Recall, and F1-Score. The Random Forest model produced the highest Accuracy, Precision, Recall, and F1-Score. Interestingly, the Naive Bayes model has a lower Accuracy of 0.860 than the other models, while the XGBoost and the Support Vector Machine models have an Recall score less than 0.936. Overall, the table explicitly indicates the different models and their performance results, which can aid researchers in making informed decisions about model selection."
937,"caption: Model evaluation metrics using the test dataset.table: Models,Accuracy,Precision,Recall,F1 Score, Logistic,0.92,0.87,0.78,0.82, Decision Tree,0.84,0.68,0.72,0.67, Random Forest,0.94,0.93,0.88,0.91, SVM,0.81,0.78,0.65,0.66, Gradient Boost,0.96,0.95,0.91,0.93","The table summarizes the performance of different machine learning models on various evaluation metrics such as Accuracy, Precision, Recall, and F1 Score using the test dataset. Five models, namely Logistic Regression, Decision Tree, Random Forest, Support Vector Machine (SVM), and Gradient Boost, were evaluated. Interestingly, the Random Forest model outperformed all other models in all of the evaluation metrics with the highest accuracy of 0.94 and F1 score of 0.91. Additionally, the Gradient Boost model also performed well with an accuracy of 0.96, a Precision score of 0.95, a Recall score of 0.91, and an F1 score of 0.93. The table highlights the importance of evaluating models across multiple metrics to get a well-rounded understanding of their performance."
938,"caption: Table 4: Performance comparison of different models based on multiple evaluation metrics.table: Model,F1 Score,Precision,Recall,Accuracy, ModelA,0.85,0.86,0.87,0.91, ModelB,0.78,0.79,0.82,0.88, ModelC,0.89,0.90,0.88,0.92, ModelD,0.76,0.75,0.81,0.87, ModelE,0.86,0.84,0.90,0.91","Table 4 presents the performance comparison of five different models based on several evaluation metrics, including F1 score, precision, recall, and accuracy. The table exhibits that ModelC attains the highest F1 score of 0.89 among all the models, while ModelsA and E follow closely with F1 scores of 0.85 and 0.86, respectively. Concerning precision score, ModelC scores the highest with 0.90, indicating that it achieved the least false positive rate among the model performance. ModelB has the lowest precision of 0.79. In terms of recall, ModelE shows the highest score, which is 0.90, indicating that it can identify the highest true positive rate. ModelD has the lowest recall score of 0.81. Additionally, ModelC reports the highest accuracy of 0.92, indicating that it has achieved the highest numbers of correctly predicted classes."
939,"caption: Performance metrics of different models.table: Model,Accuracy,F1-score,Precision,Recall,AUC-ROC,PR-AUC, Logistic Regression,0.76,0.67,0.71,0.64,0.82,0.78, Random Forest,0.85,0.82,0.85,0.80,0.90,0.86, SVM,0.81,0.75,0.78,0.73,0.87,0.81, XGBoost,0.87,0.85,0.87,0.83,0.92,0.89","The table above presents the performance metrics of four different models- Logistic Regression, Random Forest, SVM, and XGBoost. The models were evaluated based on various metrics, including accuracy, F1-score, precision, recall, AUC-ROC, and PR-AUC. Interestingly, the Random forest and XGBoost models both achieved high scores across all the evaluated metrics, with XGBoost achieving the highest accuracy of 0.87 and F1-score of 0.85. The Logistic Regression model had the lowest performance scores. Overall, this table suggests Random forest and XGBoost are promising models and can be considered for further analysis."
940,"caption: Table 4: Performance Metrics of Different Modelstable: Model Name,Precision,F1-Score,Recall,Accuracy,AUC, Model 1,0.85,0.86,0.88,0.87,0.92, Model 2,0.92,0.91,0.90,0.93,0.95, Model 3,0.78,0.82,0.85,0.81,0.89, Model 4,0.83,0.88,0.86,0.85,0.91, Model 5,0.95,0.94,0.93,0.96,0.97","The presented table depicts the results of five different models evaluated using various metrics. The models were evaluated on precision, F1-Score, recall, accuracy, and AUC scores. Model 5 had the highest precision, F1-Score, recall, accuracy, and AUC, indicating that model 5 performed exceptionally well. Conversely, Model 3 exhibited the lowest results in all the metrics, implying that it was the worst performing model. The results provide insight into the performance of various models and can help select the best-performing model for a specific task."
941,"caption: Table 4: Model performance based on different evaluation metricstable: Model,Accuracy,F1-score,Precision,Recall, Logistic_Regression,0.74,0.85,0.76,0.95, SVM,0.62,0.60,0.60,0.6, Random Forest,0.89,0.88,0.91,0.86, Naive Bayes,0.68,0.75,0.82,0.6, AdaBoost,0.82,0.82,0.81,0.83","Table 4 presents a comparative analysis of five distinct models based on different evaluation metrics. The models include Logistic Regression, Support Vector Machine, Random Forest, Naive Bayes, and AdaBoost classifiers. The evaluation metrics displayed in the table are Accuracy, F1-score, Precision, and Recall. Notably, Random Forest outperformed the other models on the most evaluation metrics. It achieved the highest Accuracy of 0.89 and Precision of 0.91. Logistic Regression was the second-best model with the highest F1-score of 0.85, while AdaBoost had the highest Recall of 0.83. SVM and Naive Bayes performed poorly in comparison to the other models."
942,"caption: Performance Metrics of modelstable: Model,Accuracy,Precision,Recall,F1-Score, Model 1,0.85,0.80,0.75,0.77, Model 2,0.91,0.90,0.85,0.87, Model 3,0.87,0.85,0.80,0.82, Model 4,0.94,0.93,0.88,0.90, Model 5,0.90,0.87,0.85,0.84","The table shows the performance metrics of multiple models based on the evaluation metrics of accuracy, precision, recall, and F1-score. All models exhibited high accuracy; Model 4 illustrated the highest accuracy with a score of 0.94, while Model 1 had the lowest accuracy of 0.85. When it comes to precision, Model 2 had the highest score, indicating the least amount of false positives. Model 1, 3, and 5 had a similar precision score, indicating they had a comparable level of false positives. Recall evaluates the number of actual positives in the data set compared to the false negatives. In this scenario, Model 4 had the highest recall score of 0.88, while Models 1 and 3 both had scores of 0.75 and 0.80, respectively. The F1-Score metric combines both precision and recall, and it shows that Model 4 had the highest score of 0.90, while Model 1 had the lowest score of 0.77."
943,"caption: Table 4: Model performances based on different evaluation metrics.table: Model Name,Accuracy,F1-score,Precision,Recall, Model A,0.87,0.85,0.92,0.80, Model B,0.89,0.86,0.90,0.82, Model C,0.92,0.90,0.95,0.86, Model D,0.84,0.83,0.87,0.80, Model E,0.91,0.89,0.94,0.85","Table 4 provides model performance based on different evaluation metrics for Model A, Model B, Model C, Model D, and Model E. The evaluation metrics include accuracy, F1-score, precision, and recall. Each model's accuracy score is higher than 0.84, with Model C having the highest accuracy of 0.92. Model C was also able to achieve the highest F1-score of 0.90, followed closely by Model E with a score of 0.89. Similarly, Model C obtained the highest precision score of 0.95, and Model E demonstrated the highest recall score of 0.85. Overall, Model C shows the best performance in all evaluation metrics."
944,"caption: Comparison of model performance based on multiple evaluation metrics.table: Models,Precision,Recall,F1-score,Specificity, Model 1,0.83,0.75,0.78,0.85, Model 2,0.75,0.80,0.76,0.72, Model 3,0.92,0.60,0.73,0.96, Model 4,0.67,0.85,0.75,0.55","The table compares the performance of four different models based on multiple evaluation metrics, including Precision, Recall, F1-score, and Specificity. Model 1 shows the highest Precision of 0.83, while Model 3 has the highest recall of 0.6. Interestingly, Model 3 also shows the highest F1-score of 0.73. Limited by a low Specificity score of 0.72, Model 2 performs the worst among all models where F1-score and Recall are concerned. In contrast, Model 4 has the highest Specificity of 0.55 but the lowest Recall of 0.85. Overall, Model 1 and Model 3 show relatively good performance, while Model 2 and Model 4 require further improvement."
945,"caption: Table 4: Model performances based on different evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.85,0.84,0.86,0.83, Decision Tree,0.78,0.79,0.76,0.82, Random Forest,0.87,0.88,0.86,0.90, Gradient Boosting,0.89,0.90,0.89,0.91, Support Vector Machines,0.81,0.82,0.80,0.84","Table 4 demonstrates a head-to-head comparison of five machine learning models based on several evaluation metrics. The table's models presented are Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Support Vector Machines. The table includes accuracy, F1-Score, precision, recall measures. Interestingly, Gradient Boosting is the top-performing model with an accuracy and F1-score of 0.89 and 0.90, respectively. On the other hand, Decision Tree is the worst performing model with an accuracy of 0.78 and F1-Score of 0.79. Additionally, Random Forest, Logistic Regression, and Support Vector Machines have shown close performances with small differences among each other."
946,"caption: Table 4: Model performances based on different evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score, Model A,0.93,0.92,0.93,0.93, Model B,0.95,0.94,0.94,0.94, Model C,0.91,0.90,0.91,0.91, Model D,0.94,0.91,0.93,0.92, Model E,0.92,0.88,0.92,0.90","Table 4 displays the performances of five different models using different evaluation metrics, including accuracy, precision, recall, and F1-score. Model B demonstrated the best accuracy of 0.95, with Model D coming in second with 0.94 accuracy. Model A achieved the highest precision of 0.92, whereas Model E had the least precision of 0.88. On the other hand, Model E had the highest recall of 0.92, while Model C had the least recall of 0.91. Finally, combining precision and recall in the F1-score metrics, Model A had the highest F1-score of 0.93 whereas Model E had the lowest at 0.90."
947,"caption: Model performance based on different evaluation metrics.table: Model,Accuracy,F1 Score,Recall,Precision, SVM,0.92,0.91,0.88,0.93, Naive Bayes,0.82,0.80,0.72,0.90, Random Forest,0.95,0.94,0.92,0.96, Neural Network,0.97,0.96,0.94,0.97, Decision Tree,0.88,0.84,0.81,0.87","Table presents the performance results of SVM, Naive Bayes, Random Forest, Neural Network, and Decision Tree models based on different evaluation metrics. The evaluation metrics used are accuracy, F1 Score, Recall, and Precision. The Random Forest model has the highest accuracy of 0.95, followed by the Neural Network model with 0.97. On the other hand, Naive Bayes has the lowest accuracy at 0.82. Similarly, for F1 Score and Recall, the Neural Network model outperforms other models, achieving the highest score of 0.96 and 0.94, respectively. The Random Forest model had the highest Precision score, which indicates its ability to minimize false positives. The table's results contribute significantly to choosing the best model for different conditions, including data imbalance and feature engineering techniques."
948,"caption: Performance of different machine learning models on the classification of heart disease dataset using multiple evaluation metrics.table: Model,Precision,Recall,Accuracy,F1 Score,Cohen's Kappa, Logistic regression,0.75,0.80,0.76,0.77,0.54, Decision tree,0.67,0.72,0.70,0.69,0.39, Random forest,0.82,0.82,0.85,0.82,0.71, Neural network (MLP),0.80,0.84,0.83,0.82,0.67","The table depicts the performance results of four machine learning models based on multiple evaluation metrics for classification of heart disease. The evaluation metrics include precision, recall, accuracy, F1 score, and Cohen's Kappa. The highest precision score was obtained from the random forest model (0.82), while the logistic regression model achieved the lowest precision score (0.75). The neural network (MLP) model achieved the highest recall score of 0.84, while the decision tree model recorded the lowest recall score of 0.72. The random forest model achieved the highest accuracy score (0.85), followed by the neural network (MLP) model with 0.83. The F1 score range was 0.69 to 0.82. The highest Cohen's Kappa score was obtained via the random forest model, indicating substantial agreement between predicted and observed data."
949,"caption: Performance Metrics of Different Modelstable: Model Name,Accuracy,Precision,Recall,F1-Score, Logistic Regression,80.5%,0.82,0.65,0.72, Random Forest,78.6%,0.75,0.69,0.71, SVM,81.2%,0.81,0.67,0.72, Naive Bayes,76.3%,0.69,0.74,0.71","The table presents the model performances evaluated on multiple metrics, including Accuracy, Precision, Recall, and F1-score. Four models including Logistic Regression, Random Forest, SVM, and Naive Bayes were tested and compared for their performances. SVM achieved the highest accuracy of 81.2%, while Logistic Regression showed the best Precision score of 0.82. Naive Bayes had the highest Recall with a score of 0.74, while Random Forest gained the highest F1-score of 0.71. Overall, all models showed decent results, and the choice of the model depends on the use case and the required performance metric."
950,"caption: Comparison of different models' performance based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score,AUC, Logistic Regression,0.86,0.87,0.84,0.85,0.92, Decision Tree,0.78,0.76,0.80,0.77,0.82, Random Forest,0.89,0.93,0.83,0.85,0.94, K-Nearest Neighbors,0.72,0.68,0.81,0.73,0.75",
951,"caption: Table 4: Model performance for binary classification task using different evaluation metrics.table: Model,F1-Score,Accuracy,Precision,Recall, Logistic Regression,0.82,0.80,0.87,0.79, Random Forest,0.87,0.85,0.83,0.91, Gradient Boosting,0.89,0.87,0.88,0.91, SVM,0.85,0.83,0.82,0.88, Neural Network,0.90,0.88,0.88,0.92","Table 4 compares the performance of different models' for a binary classification task using multiple evaluation metrics. The models include Logistic Regression, Random Forest, Gradient Boosting, SVM, and Neural Network. The table exhibits F1-Score, Accuracy, Precision, and Recall for each of the models. The Neural Network performed best in terms of F1-Score with a score of 0.90, closely followed by Gradient Boosting with a score of 0.89. Nonetheless, all the models perform relatively well with F1-Scores above 0.80. It is noteworthy that the Random Forest and Gradient Boosting models have high Recall scores, indicating that they are good at correctly classifying positive cases."
952,"caption: Performance evaluation of different models using multiple evaluation metrics.table: Model,Accuracy,F1-Score,Recall,Precision, LogReg,0.89,0.87,0.91,0.86, SVM,0.85,0.83,0.88,0.81, CNN,0.92,0.90,0.93,0.88, LSTM,0.91,0.89,0.92,0.87, RF,0.93,0.91,0.93,0.90","Table 4 compares different models' performance evaluation based on multiple evaluation metrics, including Accuracy, F1-Score, Recall, and Precision. The table presents LogReg, SVM, CNN, LSTM, and RF models' performance results. Interestingly, the CNN model achieved the highest accuracy, F1-Score, Recall, and Precision scores with a close score to RF. The RF model shows the best Recall score of 0.93, while the CNN model had the best Accuracy, F1-Score, and Precision scores of 0.92, 0.90, and 0.88, respectively. Overall, these models' results suggest that CNN and RF models are the best-performing models based on Accuracy and F1-Score evaluation metrics."
953,"caption: Comparison of performance metrics of different modelstable: Model,F1 Score,Accuracy,Precision,Recall, Model A,0.85,0.82,0.78,0.95, Model B,0.79,0.84,0.85,0.74, Model C,0.91,0.87,0.90,0.92, Model D,0.83,0.80,0.72,0.96, Model E,0.76,0.76,0.68,0.88","Table 1 illustrates the performance of five different models that were used to predict the target variable. The table displays F1 score, accuracy, precision, and recall for each model. Model C has the highest F1 score, accuracy, and precision of 0.91, 0.87, and 0.90, respectively. On the other hand, Model E appears to be the worst-performing model with the lowest F1 score of 0.76 and accuracy of 0.76. However, Model A shows the highest recall score of 0.95. It suggests that the model can identify all the actual positive cases, which is very important in some applications."
954,"caption: Comparison of Model Performance using Various Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1, Model A,0.85,0.88,0.82,0.85, Model B,0.83,0.85,0.84,0.83, Model C,0.87,0.90,0.85,0.87, Model D,0.82,0.84,0.83,0.82, Model E,0.89,0.91,0.88,0.89","The table displays the evaluation metrics for five different models, including accuracy, precision, recall, and F1. Model A has the highest accuracy of 0.85, while Model E has the highest accuracy score of 0.89. Interestingly, Model E is also observed to have the highest values for precision, recall, and F1 score with scores of 0.91, 0.88, and 0.89, respectively. On the other hand, Model D shows the lowest accuracy and F1 score with 0.82. Model B has the second-highest accuracy of 0.83, with 0.85 precision and 0.84 recall score, resulting in an F1 score of 0.83. Model C provides an accuracy score of 0.87 but falls slightly behind other models with precision, recall, and F1 scores of 0.90, 0.85, and 0.87, respectively. Overall, the table illustrates that Model E is the best performing model based on all evaluation metrics."
955,"caption: Model evaluation metrics of various classification models.table: Model,Accuracy,F1-score,Precision,Recall,AUC-ROC, Random Forest,0.92,0.91,0.94,0.88,0.97, XGBoost,0.89,0.88,0.92,0.85,0.94, Logistic Regression,0.87,0.85,0.88,0.82,0.93, Support Vector Machine,0.85,0.83,0.86,0.80,0.92, K-Nearest Neighbors,0.82,0.81,0.84,0.77,0.89",
956,"caption: Model performance by evaluation metrictable: Model,Accuracy,Precision,Recall,F1, Logistic Regression,0.85,0.88,0.82,0.85, Decision Tree,0.83,0.80,0.88,0.84, Random Forest,0.87,0.90,0.85,0.87, Support Vector Machine,0.87,0.89,0.87,0.88, XGBoost,0.88,0.91,0.86,0.88","The table presents the accuracy, precision, recall, and F1 scores for five different models: Logistic Regression, Decision Tree, Random Forest, Support Vector Machine (SVM), and XGBoost. The models were evaluated on a given dataset, and the results are shown for each evaluation metric. Interestingly, the table shows that the XGBoost model outperforms the other models in all evaluation metrics, with an accuracy score of 0.88, precision score of 0.91, recall score of 0.86, and F1 score of 0.88. The Random Forest model performed relatively well with an accuracy score of 0.87, while the Decision Tree model performed poorly with a recall score of 0.88. Overall, the results suggest that the XGBoost model is the best-performing model in this context."
957,"caption: Classification results of different models.table: Model,Accuracy,F1 Score,Precision,Recall, Random Forest,0.89,0.895,0.891,0.902, K-Nearest Neighbor,0.63,0.482,0.511,0.462, SVM (Linear),0.72,0.699,0.718,0.681, Naive Bayes,0.45,0.257,0.398,0.187, Neural Network,0.91,0.912,0.905,0.920",
958,"caption: Table 4: Performance measures for different models.table: Model,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.85,0.86,0.84,0.89, Random Forest,0.89,0.91,0.89,0.93, Support Vector Machine,0.84,0.85,0.83,0.88, Decision Tree,0.83,0.84,0.82,0.87, XGBoost,0.91,0.92,0.91,0.93","Table 4 presents the performance measures, including Accuracy, F1-Score, Precision and Recall, obtained from five different models, namely Logistic Regression, Random Forest, Support Vector Machine, Decision Tree and XGBoost. All models were trained and tested using the same dataset. The XGBoost model exhibits the best performance in terms of all measures with an accuracy of 0.91, F1-Score of 0.92, Precision of 0.91 and Recall of 0.93. The Random Forest model also produces high measures, with accuracy and F1-Score of 0.89 and 0.91, respectively, followed by the Logistic Regression model with accuracy, F1-Score, precision, and recall of 0.85, 0.86, 0.84, and 0.89, respectively. The SVM and Decision Tree models produce relatively lower measures compared to other models."
959,"caption: Comparison of Different Machine Learning Modelstable: Models,Accuracy,F1-score,Precision,Recall, Model 1,0.89,0.87,0.96,0.79, Model 2,0.79,0.74,0.83,0.67, Model 3,0.91,0.88,0.95,0.82, Model 4,0.86,0.83,0.92,0.76, Model 5,0.94,0.91,0.98,0.85","Table presents a comparison of five different machine learning models' (Model 1-5) performance concerning evaluation metrics like accuracy, F1-score, precision, and recall. Notably, Model 5 shows the highest accuracy, F1-score, precision, and recall of 0.94, 0.91, 0.98, and 0.85, respectively. On the other hand, Model 2 performs the weakest with the lowest accuracy, F1-score, precision, and recall of 0.79, 0.74, 0.83, and 0.67, respectively. All the models' performance results differ, and the comparison table highlights the importance of metrics interpretation in selecting the most optimal model."
960,"caption: Model performance of different classifiers on the datasettable: Model,Accuracy,F1 Score,Precision,Recall,AUC Score, Logistic Regression,0.85,0.8,0.89,0.73,0.92, SVM,0.87,0.83,0.93,0.75,0.90, Naive Bayes,0.82,0.79,0.87,0.70,0.88, Random Forest,0.90,0.88,0.92,0.84,0.94, XGBoost,0.88,0.85,0.91,0.80,0.93","The table presents the evaluation metrics of multiple classifiers that were trained and tested on the dataset. The metrics include accuracy, F1 score, precision, recall, and AUC score. Among the models, Random Forest achieved the highest accuracy (0.90) and AUC score (0.94), followed closely by XGBoost (0.88). The Logistic Regression and SVM models exhibited high precision values, while the Naive Bayes model showed the lowest performance across all metrics. Overall, the results reveal that Random Forest and XGBoost models perform well on this dataset, considering their consistent high performance across different metrics."
961,"caption: Table 4. Model performances based on multiple evaluation metrics.table: Model,Accuracy,F1-score,AUC-ROC, Naive Bayes,0.75,0.67,0.82, SVM (linear kernel),0.85,0.82,0.91, SVM (polynomial kernel),0.80,0.77,0.87, KNN,0.81,0.77,0.88, Random Forest,0.91,0.89,0.95, CNN,0.93,0.91,0.96","Table 4 demonstrates the classification task's model performances based on three evaluation metrics -- accuracy, F1-score, and AUC-ROC. Six different models were used for this analysis: Naive Bayes, SVMs with a linear and polynomial kernel, K-Nearest Neighbors, Random Forest, and Convolutional Neural Networks (CNN). The Random Forest and CNN models performed the best in the task, with accuracy scores of 0.91 and 0.93, respectively. The results obtained from the SVM model with a linear kernel follow the top-performing models closely. However, the SVM model with a polynomial kernel shows relatively lower performance results but still manages to accomplish satisfactory F1-score and AUC-ROC values of 0.77 and 0.87, respectively."
962,"caption: Performance of Various Classification Models based on Different Evaluation Metricstable: Model Name,F1-Score,Recall,Precision,Accuracy, Logistic Regression,0.83,0.82,0.84,0.84, Random Forest,0.88,0.87,0.89,0.89, XGBoost,0.91,0.91,0.90,0.91, Multilayer Perceptron (MLP),0.85,0.85,0.85,0.85","The table reports the performance evaluation metrics, including F1-score, Recall, Precision, and Accuracy for various classification models, namely, Logistic Regression, Random Forest, XGBoost, and Multilayer Perceptron, denoted as MLP. The performance of these models is evaluated on the same dataset. Interestingly, XGBoost achieved the highest F1-Score, Recall, and Accuracy with scores of 0.91, 0.91, and 0.91 respectively. Random forest model had the highest precision, with a score of 0.89. Among all models, XGBoost has shown the most robust performance across all metrics, making it the best model for the given dataset."
963,"caption: Comparison of different models' performance based on evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.91,0.93,0.89,0.91, Random Forest,0.89,0.91,0.86,0.88, KNN,0.84,0.88,0.77,0.82, Decision Tree,0.83,0.86,0.79,0.82, Naive Bayes,0.76,0.78,0.71,0.73","The table presents the performances of five different models-SVM, Random Forest, KNN, Decision Tree, and Naive Bayes-based on four evaluation metrics-accuracy, precision, recall, and F1-score. The SVM model produced the best accuracy (0.91) and precision (0.93) results. On the other hand, the Naive Bayes model recorded lower accuracy (0.76), precision (0.78), recall (0.71), and F1-score (0.73) than the other models. Interestingly, the KNN model exhibited less accuracy (0.84) than the Decision Tree model (0.83), but KNN produced a higher precision (0.88) and recall (0.77) than the Decision Tree model."
964,"caption: Model performances based on multiple metricstable: Model,F1-score,Precision,Recall,Accuracy,AUC, Logistic Regression,0.87,0.84,0.90,0.86,0.91, Decision Trees,0.76,0.78,0.74,0.77,0.81, Random Forest,0.92,0.92,0.91,0.91,0.89, Support Vector Machine,0.83,0.82,0.84,0.83,0.88, Gradient Boosting,0.89,0.86,0.91,0.88,0.91","The table above shows the performance comparison of multiple models based on various evaluation metrics. The metrics used include F1-score, Precision, Recall, Accuracy and AUC. The models tested include Logistic Regression, Decision Trees, Random Forest, Support Vector Machine and Gradient Boosting. The model with the best results varies for each metric, with Random Forest scoring the highest F1-score (0.92), Gradient Boosting achieving the highest Precision (0.86), Logistic Regression having the highest Recall (0.90), Logistic Regression having the highest Accuracy (0.86), and finally Gradient Boosting having the highest AUC (0.91). These results can be utilized to determine the most suitable model based on the specific evaluation metric being considered."
965,"caption: Model performances based on different evaluation metrics.table: Model,Accuracy (%),F1 Score,Precision,Recall, SVM,92.3,0.91,0.89,0.93, MLP,92.5,0.92,0.89,0.95, KNN,89.6,0.88,0.83,0.94, RF,88.4,0.87,0.81,0.94, LR,85.7,0.84,0.78,0.92","Table 1 displays the model accuracies, F1 Scores, Precision, and Recall for five different classification models (SVM, MLP, KNN, RF, and LR). The accuracy of the models ranged from 85.7% to 92.5%, indicating better predictability of MLP than others. However, SVM outperformed all other models in terms of Precision and Recall with values of 0.89 and 0.93, respectively. RF’s low accuracy and F1 score demonstrate its inability to classify this dataset effectively. Compared to other models, LR shows the poorest performance across all metrics."
966,"caption: Table 4: Multiple model performances based on Accuracy, Precision, Recall, and F1-Score evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, SVM-linear,0.81,0.83,0.82,0.82, SVM-rbf,0.87,0.89,0.87,0.87, Random Forest,0.84,0.86,0.84,0.84, XGBoost,0.88,0.90,0.88,0.88, MLP,0.85,0.87,0.85,0.85","Table 4 presents the performance results of multiple models based on Accuracy, Precision, Recall, and F1-Score evaluation metrics. The models include SVM-linear, SVM-rbf, Random Forest, XGBoost, and MLP. All models were trained and tested using the same dataset. The SVM-rbf achieved the highest Accuracy score of 0.87 and the highest Precision score of 0.89, while XGBoost had the highest Recall score of 0.88. The performance of SVM-rbf and XGBoost was followed closely by MLP, which presented good results for all evaluation metrics. The SVM-linear model achieved slightly lower performance, still showing a good overall performance."
967,"caption: Table 4. Model performance based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.891,0.897,0.833,0.864, Random Forest,0.917,0.912,0.879,0.894, Support Vector Machine,0.855,0.862,0.785,0.808, Multilayer Perceptron,0.825,0.838,0.712,0.762, Naive Bayes,0.782,0.785,0.641,0.678","Table 4 summarizes the performance of five machine learning models trained and tested on the same dataset. The table shows the models' accuracy, precision, recall, and F1 score metric's performance. The Random Forest model had the highest accuracy with a score of 0.917, while the Logistic Regression model performed best for precision, recall, and F1 score. The Multilayer Perceptron model had the lowest performance for all the evaluation metrics except accuracy, where it only outperformed Naive Bayes. Additionally, The Support Vector Machine and Naive Bayes models underperformed in all metrics compared to the other models."
968,"caption: Table 4: Model performances measured by accuracy, F1-Score, Precision, and Recall.table: Model,Accuracy,F1-Score,Precision,Recall, Model A,0.75,0.77,0.79,0.75, Model B,0.81,0.79,0.81,0.77, Model C,0.89,0.88,0.90,0.87, Model D,0.88,0.87,0.87,0.89, Model E,0.92,0.91,0.94,0.89","Table 4 presents the performances of multiple models, evaluated using different metrics including accuracy, F1-Score, precision, and recall. Model A shows an accuracy of 0.75 and an F1-Score of 0.77. Model B shows higher accuracy of 0.81 and precision of 0.81, but lower F1-Score of 0.79 and recall of 0.77. Model E shows the best accuracy of 0.92 and the best precision of 0.94, but the lowest recall of 0.89. Overall, Model E outperforms all other models for accuracy, precision, and F1-Score, while Model C has the highest recall score of 0.87"
969,"caption: Table 4: Classification model evaluation metrics for different classifiers.table: Model,Precision,Recall,F1-score,ROC-AUC, SVM,0.77,0.70,0.75,0.83, KNN,0.67,0.72,0.69,0.72, RF,0.82,0.78,0.80,0.85, AdaBoost,0.75,0.80,0.77,0.84","Table 4 displays evaluation metrics such as precision, recall, f1-score, and ROC-AUC for different classifiers. The table includes Support Vector Machine (SVM), K-Nearest Neighbors (KNN), Random Forest (RF), and AdaBoost algorithms. The SVM model shows the best ROC-AUC score of 0.83, while the RF model demonstrates the highest precision, recall, and f1-score scores of 0.82, 0.78, and 0.80, respectively. Interestingly, the AdaBoost model achieved the second-best ROC-AUC score of 0.84 and the highest recall score of 0.80. It is worth noting that the models' performances differ significantly based on their evaluation metrics, indicating the importance of choosing appropriate metrics for specific tasks."
970,"caption: Performance of different classification models on the given dataset based on four evaluation metrics.table: Model,Accuracy,F1 score,Precision,Recall, Logistic Regression,0.86,0.85,0.87,0.86, Random Forest,0.91,0.90,0.92,0.91, Decision Tree,0.79,0.76,0.77,0.79, Support Vector Machine,0.87,0.86,0.89,0.87, Multi-layer Perceptron,0.84,0.83,0.86,0.84","The table presents the comparison of different classification models' performance on the given dataset based on four evaluation metrics, including Accuracy, F1 score, Precision, and Recall. The models' performance was evaluated on the same dataset, and their respective values for each metric are presented in the table. The Random Forest model performed the best with the highest accuracy, F1 score, precision, and recall scores of 0.91, 0.90, 0.92, and 0.91, respectively. Logistic Regression model also performed well with an accuracy of 0.86 and the highest precision score of 0.87. On the other hand, the Decision Tree model had poor performance compared to other models with an accuracy of 0.79 and F1-score of 0.76. Overall, the table highlights the need for careful selection of classification models based on the evaluation metric of interest."
971,"caption: Performance results of various machine learning models using F1-score, precision, and recall metrics.table: Model,F1-score,Precision,Recall, SVM,0.81,0.85,0.79, Logistic Regression,0.78,0.82,0.74, Random Forest,0.90,0.88,0.91, Multi-layer Perceptron,0.82,0.76,0.74, Naive Bayes,0.72,0.68,0.78","The table displays the performance comparison of various machine learning models using F1-score, precision, and recall metrics. SVM achieved the highest F1-score of 0.81, followed by Random Forest with a score of 0.90. However, Random Forest has an equally high precision and recall score of 0.88 and 0.91, respectively. Multilayer perceptron (MLP) has the lowest F1-score of 0.82, lower than other models such as Logistic Regression, SVM, and Naive Bayes. Naive Bayes performed the poorest with the lowest F1-score of 0.72 and the lowest precision score of 0.68. SVM has the highest accuracy in predicting the positive class with a precision score of 0.85, while Naive Bayes has the highest recall score of 0.78 in detecting the positive class."
972,"caption: Model performance comparison using accuracy, F1 score, precision, and recall.table: Models,Accuracy,F1 score,Precision,Recall, Model 1,0.85,0.86,0.82,0.90, Model 2,0.91,0.89,0.92,0.86, Model 3,0.89,0.91,0.86,0.96, Model 4,0.93,0.95,0.91,0.99, Model 5,0.88,0.85,0.91,0.80","The table presents the performances of five different models evaluated based on their accuracy, F1 score, precision, and recall. Model 4 demonstrated the highest accuracy of 0.93, followed by Model 2 with 0.91. Model 4 also achieved the highest F1 score of 0.95 and Recall of 0.99. Model 3 had the highest precision score of 0.86 and Model 2 achieved the highest Recall score of 0.86. It is interesting to note that Model 5 had the lowest accuracy and F1 score but achieved a higher precision score compared to other models. This table helps to compare model performance based on different evaluation metrics and assists in selecting the best model for a given task."
973,"caption: Model performance based on different ML models and various evaluation metrics.table: Model,Precision,Recall,F1-score,ROC-AUC,PR-AUC, Logistic Regression,0.71,0.66,0.68,0.79,0.70, Decision Trees,0.73,0.71,0.72,0.84,0.76, Random Forests,0.76,0.78,0.77,0.86,0.80, XGBoost,0.78,0.81,0.80,0.88,0.83, Multi-layer Perceptron,0.72,0.81,0.76,0.81,0.75",
974,"caption: Table 4: Model evaluation metricstable: Models,Precision,Recall,F1 Score,AUROC,AUPR, Model A,0.92,0.86,0.89,0.81,0.78, Model B,0.72,0.87,0.79,0.92,0.89, Model C,0.88,0.82,0.85,0.76,0.72, Model D,0.94,0.76,0.84,0.84,0.80, Model E,0.81,0.62,0.70,0.69,0.68","Table 4 showcases five different models and their evaluation metrics in terms of Precision, Recall, F1 Score, AUROC, and AUPR. Model A has the highest precision score among the models with a value of 0.92. Model D shows the highest precision, AUROC, and AUPR score of 0.94, 0.84, and 0.80, respectively. Model B has the highest recall score of 0.87. Model C has the lowest performance in terms of all the evaluation metrics, while Model E achieves the second-lowest scores for all evaluation metrics except for AUPR, where it has the lowest score of 0.68. Overall, Model D demonstrates the best overall performance compared to other models."
975,"caption: Table 4: Evaluation metrics for different classification modelstable: Model,Accuracy,F1-score,AUC-ROC, SVM,0.91,0.88,0.95, KNN,0.79,0.70,0.83, Decision Tree,0.85,0.81,0.86, Random Forest,0.94,0.92,0.98, Adaboost,0.89,0.85,0.93","Table 4 displays the evaluation metrics - accuracy, F1-score, and AUC-ROC - for five different classification models. The models assessed include Support Vector Machine (SVM), K-Nearest Neighbor (KNN), Decision Tree, Random Forest, and AdaBoost. Random Forest model had the best overall performance across all metrics with the highest accuracy (0.94), F1-score (0.92) and AUC-ROC (0.98) compared to the other models. SVM also performed well, scoring second-best in accuracy (0.91) and AUC-ROC (0.95). However, KNN exhibited the poorest performance among all models with the lowest scores in accuracy (0.79), F1-score (0.70) and AUC-ROC (0.83)."
976,"caption: Model performance based on multiple evaluation metrics.table: Model,Precision,Recall,F1-score,Accuracy, SVM,0.84,0.85,0.84,0.82, RF,0.79,0.87,0.82,0.79, KNN,0.67,0.79,0.72,0.64, MLP,0.85,0.84,0.84,0.83, DT,0.75,0.72,0.74,0.73","The table above shows the performance of five different models (SVM, RF, KNN, MLP, and DT) based on multiple evaluation metrics, including Precision, Recall, F1-score, and Accuracy. The table indicates that SVM outperforms the other models in terms of Precision while MLP shows the best performance in Recall and F1-score. The RF model has the highest Recall score of 0.87, but it falls behind in terms of Precision and F1-score. The DT model achieved the lowest Precision score of 0.75. The results suggest that SVM might be suitable for applications where Precision is critical, while MLP might be preferred if Recall or F1-score is the priority."
977,"caption: Performance comparison of different models based on accuracy, F1-score, ROC-AUC and PR-AUC evaluation metrics.table: **Models**,**Accuracy**,**F1-Score**,**ROC-AUC**,**PR-AUC**, Model 1,0.85,0.87,0.81,0.78, Model 2,0.80,0.83,0.76,0.72, Model 3,0.88,0.90,0.85,0.82, Model 4,0.79,0.81,0.73,0.68, Model 5,0.90,0.92,0.87,0.84","The table compares the performance of five different models based on four evaluation metrics: accuracy, F1-score, ROC-AUC and PR-AUC. Model 5 shows the highest performance in all evaluation metrics compared to all other models, with an accuracy of 0.9, F1-Score of 0.92, ROC-AUC score of 0.87 and PR-AUC score of 0.84. This indicates that Model 5 is the most effective model amongst these five models. Model 3 also shows impressive results, securing the second position with scores of accuracy 0.88, F1-Score 0.90, ROC-AUC 0.85 and PR-AUC 0.82. However, Model 4 appears to be the least effective out of all models in all evaluation metrics."
978,"caption: Comparison of different classification models based on multiple evaluation metrics.table: Model,Precision,Recall,F1-Score,Accuracy,MCC, Logistic Regression,0.84,0.72,0.77,0.86,0.67, Decision Tree,0.82,0.76,0.79,0.84,0.62, Random Forest,0.85,0.78,0.81,0.87,0.70, Support Vector Machine,0.88,0.82,0.85,0.89,0.75, Multi-Layer Perceptron,0.85,0.76,0.80,0.86,0.66","Table presents multiple classification models' performance based on different evaluation metrics, including Precision, Recall, F1-Score, Accuracy, and Matthews Correlation Coefficient (MCC). The table includes Logistic Regression, Decision Tree, Random Forest, Support Vector Machine, and Multi-Layer Perceptron models' performance results. Notably, it can be observed that the Support Vector Machine model shows the highest Precision, Recall, F1-score, Accuracy, and MCC among the other models. Conversely, the Decision Tree model shows the lowest scores based on all evaluation metrics. Additionally, all models exhibit similar performance based on different evaluation metrics, except for the SVM model, which performs exceptionally well in all aspects."
979,"caption: Model performances based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score,AUC, Model A,0.91,0.85,0.92,0.88,0.95, Model B,0.88,0.82,0.89,0.85,0.90, Model C,0.92,0.88,0.83,0.85,0.93, Model D,0.95,0.93,0.95,0.94,0.97, Model E,0.83,0.76,0.81,0.78,0.85","The table presents the performance results of five different models based on multiple evaluation metrics. The evaluation metrics include Accuracy, Precision, Recall, F1-Score, and AUC. All models were trained and tested on the same dataset. Model D achieved the highest accuracy score of 0.95, while Model C achieved the highest precision score of 0.88, and Model A exhibited the highest recall score of 0.92. On the other hand, Model D achieved the highest F1-Score of 0.94, and Model A achieved the highest AUC score of 0.95. Interestingly, Model E had the lowest performance results across all the evaluation metrics."
980,"caption: Evaluation results of different machine learning modelstable: Model,Precision,Recall,F1-Score,Accuracy, SVM,0.84,0.76,0.80,0.81, KNN,0.81,0.77,0.79,0.78, Naive Bayes,0.76,0.83,0.79,0.79, Decision Tree,0.78,0.70,0.74,0.77, Random Forest,0.89,0.88,0.88,0.88, Gradient Boosting,0.91,0.86,0.88,0.90",
981,"caption: Performance comparison of different models on multiple evaluation metrics.table: Metric,Model 1,Model 2,Model 3,Model 4, Accuracy,0.76,0.58,0.68,0.72, F1 Score,0.8,0.6,0.7,0.73, AUC Score,0.85,0.62,0.75,0.8, Precision,0.74,0.56,0.67,0.71, Recall,0.87,0.64,0.72,0.77","Table presents a comparison of four models based on multiple evaluation metrics. The evaluation metrics considered in this table include accuracy, F1 score, AUC Score, precision, and recall. The models' performance has been evaluated and calculated for each metric using the same dataset. Model 1 performs the best in terms of accuracy, F1 Score and AUC Score, with values of 0.76, 0.8, and 0.85, respectively. Model 4 appears to perform the best for precision and recall, with values of 0.71 and 0.77, respectively. The performance of Model 2 is the worst for all metrics, with accuracy, F1-score, AUC Score, precision, and recall scores of 0.58, 0.6, 0.62, 0.56, and 0.64, respectively."
982,"caption: Performance comparison of different models using accuracy, F1 score, and recall measures.table: Model,Accuracy,F1 Score,Recall, SVC,0.86,0.86,0.86, KNN,0.89,0.88,0.91, RF,0.92,0.92,0.92, LR,0.90,0.90,0.90","This table compares different classification models based on their accuracy, F1 score, and recall measures. The evaluated models include Support Vector Classifier (SVC), K-Nearest Neighbor (KNN), Random Forest (RF), and Logistic Regression (LR). From the table, we observe that all models achieved a high performance level with accuracy of at least 0.86. The Random Forest model demonstrates the best accuracy, F1 score, and recall measures, with all scores around 0.92. Furthermore, we can notice that KNN more accurately identifies true positive results with a recall score of 0.91, whereas SVC, KNN, and LR models demonstrated slightly lower recall scores of 0.86-0.90."
983,"caption: Performance comparison of different models using various evaluation metrics.table: Model Name,Accuracy,Precision,Recall,F1 score, Logistic Regression,0.89,0.91,0.85,0.88, Random Forest,0.93,0.93,0.91,0.92, Gradient Boosting,0.91,0.92,0.88,0.90, SVM,0.87,0.88,0.81,0.84, K-Nearest Neighbor,0.81,0.85,0.74,0.79","The table presents a comparison of different machine learning models' performance based on various evaluation metrics. The evaluation metrics included Accuracy, Precision, Recall, and F1 score to measure each model's performance. The Logistic Regression model achieved an accuracy of 0.89 and a precision score of 0.91, with the highest Recall score of 0.85. Random Forest model achieved the highest accuracy of 0.93 with a precision score of 0.93 and Recall score of 0.91. On the other hand, K-Nearest Neighbor model has the lowest Accuracy of 0.81 with precision, recall and F1 Score of 0.85, 0.74, and 0.79, respectively."
984,"caption: Table 4: Model performance using different evaluation metrics.table: Models,Accuracy,Recall,Precision,F1-score, SVM,0.87,0.86,0.89,0.87, Logistic Regression,0.82,0.81,0.84,0.83, K-Nearest Neighbors,0.80,0.78,0.81,0.79, Random Forest,0.90,0.88,0.92,0.90, XGBoost,0.89,0.87,0.90,0.88","The table above shows the model performance using different evaluation metrics such as accuracy, recall, precision, and F1-score. The table includes different machine learning models such as SVM, Logistic Regression, K-Nearest Neighbors, Random Forest, and XGBoost. Among all the models, Random Forest achieved the highest accuracy of 0.90. On the other hand, Logistic Regression achieved the lowest accuracy of 0.82. SVM outperformed other models in both recall and precision with scores of 0.86 and 0.89, respectively. Finally, among all the models, Random Forest achieved the highest F1-score of 0.90, followed closely by XGBoost with a score of 0.88."
985,"caption: Comparison of performance metrics across different models.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.95,0.91,0.78,0.84, KNN,0.92,0.87,0.71,0.78, RF,0.96,0.94,0.80,0.86, NN,0.89,0.81,0.67,0.73, LR,0.94,0.90,0.75,0.80","The table showcases a comparison of five different models' evaluation metrics, namely SVM, KNN, RF, NN, and LR. The performance metrics used in the comparison are Accuracy, Precision, Recall, and F1-score. The RF model has the best accuracy score of 0.96, followed by SVM and LR models with accuracy scores of 0.95 and 0.94, respectively. The NN model had the lowest accuracy score of 0.89, but the KNN model's F1-score was the lowest among all models at 0.78. The RF model had the highest F1-score of 0.86, with a corresponding high precision of 0.94. Overall, the RF model outperformed the other models in all metrics except Recall, where SVM model scored the highest."
986,"caption: Model performance based on various evaluation metricstable: Model,Accuracy,F1-score,Precision,Recall, Logistic Reg,0.85,0.82,0.84,0.81, Decision Tree,0.77,0.74,0.75,0.73, SVM,0.87,0.84,0.86,0.82, KNN,0.72,0.69,0.71,0.67, Random Forest,0.92,0.91,0.93,0.90","The table shows the model performances based on accuracy, F1-score, Precision, and Recall. The models evaluated and compared are Logistic Regression, Decision Tree, Support Vector Machine (SVM), K-Nearest Neighbor (KNN), and Random Forest. The highest accuracy was achieved by the Random Forest model with an impressive score of 0.92. Additionally, the Random Forest model achieved the highest score across all evaluation metrics. Logistic Regression and SVM models provided competitive results as well, with the Logistic Regression model achieving the highest precision score of 0.84. In contrast, the Decision Tree model achieved the lowest performance across all evaluation metrics. Overall, the table represents a comparative view of different model performances using multiple evaluation metrics."
987,"caption: Performance comparison of different models based on different evaluation metrics.table: Model,Accuracy,Recall (positive),Precision (positive),F1-score (positive), Logistic Regression,0.85,0.89,0.82,0.86, Random Forest,0.90,0.91,0.91,0.91, Naive Bayes,0.78,0.84,0.76,0.80, Support Vector Machine,0.88,0.91,0.86,0.88","The table above shows the performance comparison of four models including Logistic Regression, Random Forest, Naive Bayes, and Support Vector Machine based on different evaluation metrics. The evaluation metrics include Accuracy, Recall (positive), Precision (positive), and F1-score (positive). The Random Forest model performed the best with the highest scores for all the evaluation metrics. The Naive Bayes model exhibited the lowest performance with the lowest scores for all the evaluation metrics. It is important to note the Logistic Regression model showed the lowest Recall score despite having a high Accuracy score. This suggests a problem with the model's ability to correctly identify positive instances, which is further highlighted by the low Precision (positive) and F1-score (positive) scores."
988,"caption: A comparison of different machine learning models based on their evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score,AUC-ROC, Logistic Regression,0.85,0.84,0.74,0.79,0.91, Decision Tree,0.78,0.72,0.76,0.72,0.84, Random Forest,0.91,0.87,0.87,0.87,0.96, K-Nearest Neighbor,0.80,0.74,0.71,0.66,0.82, Support Vector Machine,0.83,0.80,0.71,0.73,0.89","Table presents the performance of five different machine learning models which are Logistic Regression, Decision Tree, Random Forest, K-Nearest Neighbor, and Support Vector Machine. Each model is evaluated based on Accuracy, Precision, Recall, F1-Score, and Area Under the Receiver Operating Characteristic (AUC-ROC) metrics. The Random Forest model exhibited the best performance with Accuracy, Precision, Recall, and F1-Score scores of 0.91, 0.87, 0.87, and 0.87, respectively. Moreover, it had the highest AUC-ROC of 0.96. The Decision Tree model had the lowest Accuracy and AUC-ROC scores, while the K-Nearest Neighbor model had the lowest scores for Precision, Recall, and F1-Score."
989,"caption: Model performance using different evaluation metrics.table: Model,Precision,Recall,F1 Score,AUC,Accuracy, SVM,0.78,0.84,0.81,0.87,0.78, Decision tree,0.64,0.63,0.63,0.67,0.64, Random forest,0.86,0.87,0.86,0.89,0.86, Gradient,0.71,0.72,0.71,0.75,0.71, Boosting,0.81,0.81,0.81,0.84,0.81","The table compares the performance of five models for the classification task using different evaluation metrics. The models are SVM, Decision tree, Random forest, Gradient, and Boosting. The evaluation metrics used in the comparison are Precision, Recall, F1 Score, AUC, and Accuracy. The best-performing model depends on the evaluation metric used. For instance, the Random forest model outperforms the other models with the highest AUC of 0.89. Similarly, the SVM model achieves the highest Precision of 0.78. However, it is worth noting that the Gradient and Boosting models closely follow the Random forest and SVM models in performance, depending on the evaluation metric used."
990,"caption: Performance metrics of different machine learning classifiers for sentiment analysis.table: Model,Accuracy,Precision,Recall,F1-Score,AUC, Logistic Regression,0.88,0.92,0.85,0.88,0.92, Decision Tree,0.81,0.73,0.83,0.77,0.79, Random Forest,0.93,0.94,0.92,0.93,0.98, XGBoost,0.91,0.93,0.90,0.91,0.96, Support Vector Machine,0.87,0.89,0.86,0.87,0.91","The table above showcases the performance metrics - accuracy, precision, recall, F1-score, and AUC - of five different machine learning classifiers for sentiment analysis: Logistic Regression, Decision Tree, Random Forest, XGBoost, and Support Vector Machine. Random Forest had the highest accuracy of 0.93 and the highest area under the curve (AUC) of 0.98, making it the best model in terms of overall performance. However, Logistic Regression achieved the highest precision of 0.92, while Decision Tree had the highest recall of 0.83. It's noteworthy that all models achieved high precision and recall scores over 0.73 and 0.85, respectively, indicating that each model could be suitable for sentiment analysis tasks."
991,"caption: Performance of Different Classification Models on the Test Datatable: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.82,0.80,0.81,0.80, Decision Tree,0.78,0.75,0.67,0.71, Random Forest,0.86,0.85,0.74,0.79, Support Vector Machine,0.83,0.82,0.76,0.78","This table provides a comparison of the performance results of different classification models using multiple evaluation metrics including accuracy, precision, recall, and F1 score. The models used are Logistic Regression, Decision Tree, Random Forest, and Support Vector Machine. The highest accuracy score of 0.86 is achieved by Random Forest model, followed closely by the Support Vector Machine model at 0.83. Interestingly, the highest precision score of 0.85 is also achieved by the Random Forest model, while the highest recall score achieved is 0.81 by the Logistic Regression model. Upon further analysis, it can be observed that the Decision Tree model had the lowest performance across all the evaluation metrics."
992,"caption: Table 4: Model performance based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score,AUC-ROC, Logistic Regression,0.88,0.89,0.81,0.85,0.93, K-Nearest Neighbors,0.83,0.85,0.78,0.81,0.88, Decision Tree,0.82,0.83,0.76,0.79,0.86, Random Forest,0.91,0.92,0.87,0.89,0.96, XGBoost,0.93,0.94,0.91,0.92,0.98","Table 4 compares the performance of five different models (Logistic Regression, K-Nearest Neighbors, Decision Tree, Random Forest, and XGBoost) based on five evaluation metrics (Accuracy, Precision, Recall, F1-Score, and AUC-ROC). The Random Forest model shows the highest accuracy score of 0.91, followed by XGBoost with 0.93. For all other metrics, XGBoost achieves the highest scores, e.g., with F1-Score of 0.92 and AUC-ROC of 0.98. Logistic Regression, K-Nearest Neighbors, and Decision Tree demonstrate moderate to low performance compared to Random Forest and XGBoost."
993,"caption: Table 4: Comparison of model performance based on multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.80,0.75,0.82,0.78, Decision Tree,0.73,0.69,0.70,0.69, Random Forest,0.85,0.80,0.86,0.83, Support Vector Machines,0.72,0.65,0.75,0.69","Table 4 presents the performance evaluation of four different models, including Logistic Regression, Decision Tree, Random Forest, and Support Vector Machines, based on different evaluation metrics. The metrics used for evaluation are Accuracy, Precision, Recall, and F1-Score, with higher values indicating better performance. Notably, the Random Forest model outperformed other models in achieving the highest Accuracy score of 0.85 and Recall of 0.86. Interestingly, Logistic Regression showed the highest Precision score of 0.75, while the Decision Tree model showed the lowest performance across all metrics."
994,"caption: Model Performance Comparison using Different Evaluation Metricstable: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.89,0.9,0.85,0.95, k-NN,0.87,0.83,0.89,0.78, Naive Bayes,0.93,0.85,0.97,0.75, Random Forest,0.95,0.91,0.92,0.89, XGBoost,0.94,0.9,0.91,0.89","Table presents a comparison of five different models based on their Accuracy, F1-Score, Precision, and Recall metrics. SVM shows the highest accuracy score of 0.89, while Random Forest showed the highest score in F1-Score of 0.91 and accuracy of 0.95. Interestingly, Naive Bayes scored the highest in Precision with 0.97, while k-NN scored the highest in Recall with 0.78. The XGBoost model performed consistently across all metrics with notable scores in Accuracy, F1-Score, Precision, and Recall with 0.94, 0.9, 0.91, and 0.89, respectively. Thus, the table shows that every model has different strengths and weaknesses based on the evaluation metrics employed."
995,"caption: Model Performance Comparison using Different Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.89,0.92,0.85,0.88, KNN,0.85,0.86,0.81,0.83, Naive Bayes,0.78,0.79,0.73,0.76, Decision Trees,0.87,0.88,0.85,0.86, Random Forest,0.91,0.92,0.90,0.91","This table presents a model performance comparison of different machine learning algorithms using accuracy, precision, recall, and F1-Score. The models SVM, KNN, Naive Bayes, Decision Trees, and Random Forest show their respective performance results. Interestingly, the Random Forest model achieved the best overall performance with an accuracy of 0.91, a precision of 0.92, a recall of 0.90, and an F1-Score of 0.91. SVM has the highest precision and KNN has the lowest overall performance. The results suggest Random Forest is the most reliable algorithm among the studied models for the given task."
996,"caption: Table 4: Model performance based on different evaluation metricstable: Model,Precision,Recall,F1-score,ROC-AUC,PR-AUC, Random Forest,0.94,0.92,0.93,0.86,0.78, XGBoost,0.93,0.89,0.91,0.85,0.77, Support Vector,0.91,0.89,0.90,0.82,0.76, Logistic,0.88,0.87,0.87,0.80,0.71","Table 4 presents the performance results of four different models based on several evaluation metrics, including Precision, Recall, F1-score, ROC-AUC, and PR-AUC. The Random Forest model performed the best in terms of Precision and Recall, achieving a score of 0.94 and 0.92, respectively. The XGBoost model follows closely with a Precision score of 0.93 and Recall of 0.89. The Support Vector model earned the highest F1-score with a score of 0.9. However, the Logistic model had the lowest performance scores in all evaluation metrics. Interestingly, despite the differences among the models' evaluation metrics, they all had similar performance results in terms of ROC-AUC and PR-AUC, achieving scores ranging from 0.71 to 0.78."
997,"caption: Results from different machine learning models using five evaluation metrics.table: Model,Accuracy,F1-Score,Sensitivity,Specificity, RF,0.874,0.889,0.853,0.898, SVM,0.766,0.664,0.826,0.706, LR,0.819,0.846,0.764,0.865, MLP,0.847,0.828,0.851,0.843, KNN,0.783,0.786,0.717,0.856","The table presents results from five different machine learning models' performances evaluated using accuracy, F1-score, sensitivity, and specificity metrics. Random Forest (RF) model achieved the highest accuracy, F1-score, and specificity scores, with 0.874, 0.889, and 0.898, respectively. Support Vector Machine (SVM) model performed poorly with the lowest accuracy and specificity scores, while K-Nearest Neighbor's (KNN) model had the lowest sensitivity. Interestingly, the Multi-layer Perceptron (MLP) model displayed high sensitivity in the classification, but not as high as the RF model. These results may assist in selecting the right algorithm for the specific task and dataset while highlighting the importance of using multiple performance metrics in evaluating machine learning models."
998,"caption: Performance metrics of different modelstable: Model,Accuracy,Recall,Precision,F1-Score,AUC,PR-AUC, LogReg,0.83,0.79,0.84,0.81,0.88,0.76, SVM,0.81,0.72,0.86,0.78,0.85,0.66, RandomForest,0.85,0.75,0.89,0.81,0.90,0.75, XGBoost,0.86,0.76,0.90,0.83,0.91,0.78, MLP,0.84,0.75,0.89,0.81,0.90,0.76",
999,"caption: Model performances based on various evaluation metrics on a binary classification task.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.94,0.93,0.94,0.93, Logistic Regression,0.89,0.88,0.89,0.88, Random Forest,0.96,0.96,0.96,0.96, XGBoost,0.95,0.94,0.95,0.94, MLP,0.92,0.91,0.92,0.91","The presented table shows the performances of five different models on a binary classification task. The models evaluated include SVM, Logistic Regression, Random Forest, XGBoost, and MLP. Four common evaluation metrics, accuracy, F1-score, Precision, and Recall, are used to compare the performances. The Random Forest model has the highest accuracy, F1-score, Precision, and Recall at 0.96, while the Logistic Regression model shows the lowest accuracy, F1-score, Precision, and Recall at 0.89. The table suggests that the Random Forest model performed the best in the binary classification task based on the evaluation metrics used."
1000,"caption: Model performance based on multiple evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall,AUC, Logistic Regression,0.82,0.81,0.78,0.85,0.89, Random Forest,0.85,0.84,0.83,0.84,0.91, Support Vector Machine,0.80,0.79,0.75,0.85,0.88, Gradient Boosting,0.86,0.85,0.84,0.86,0.92","Table presents model performance based on multiple evaluation metrics, including Accuracy, F1-Score, Precision, Recall, and AUC. The table compares the performance of four different models, namely Logistic Regression, Random Forest, Support Vector Machine, and Gradient Boosting. It is interesting to note that the Gradient Boosting model shows the best overall performance with the highest scores for Accuracy (0.86), F1-Score (0.85), Precision (0.84), Recall (0.86), and AUC (0.92). Meanwhile, Logistic Regression exhibits the lowest AUC score despite achieving a decent performance in other metrics, while Random Forest and Support Vector Machine models show competitive results across all metrics."
1001,"caption: Table 4. Model performance based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.92,0.91,0.93,0.92, Random Forest,0.89,0.87,0.9,0.88, K-Nearest Neighbors,0.83,0.79,0.87,0.82, Naive Bayes,0.91,0.88,0.94,0.91","Table 4 presents the performance of four different classification models, where each model's accuracy, precision, recall, and F1-score are reported. The SVM model exhibits the best accuracy of 0.92, while the K-Nearest Neighbors model shows the lowest accuracy of 0.83. The Naive Bayes model exhibits the highest precision, recall, and F1-score of 0.88, 0.94, and 0.91, respectively. Interestingly, the Random Forest model shows a good balance in performance across all metrics with accuracy, precision, recall, and F1-score of 0.89, 0.87, 0.9, and 0.88, respectively. Overall, the Naive Bayes and SVM models demonstrate great performance in terms of individual metrics while the Random Forest model shows consistent results across all performance metrics."
1002,"caption: Performance of different models on the classification task.table: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.85,0.81,0.87,0.76, Decision Tree,0.78,0.70,0.73,0.67, Random Forest,0.90,0.86,0.88,0.84, k-Nearest Neighbors,0.76,0.71,0.70,0.72","The table above summarizes the performance of four different models, including Logistic Regression, Decision Tree, Random Forest, and k-Nearest Neighbors, on a classification task. The table presents four different evaluation metrics, including Accuracy, F1-score, Precision, and Recall. Notably, the table shows that the Random Forest model performs the best among all models on all evaluation metrics with an accuracy score of 0.90, an F1-score of 0.86, a precision score of 0.88, and a recall score of 0.84. Logistic Regression and Decision Tree models have a lower accuracy and F1-score compared to Random Forest. The k-Nearest Neighbors model shows good precision but has lower accuracy and F1-score than other models."
1003,"caption: Table 4: Comparison of multiple models' performance using different evaluation metrics.table: Model,F1-Score,Precision,Recall,Accuracy, Model A,0.89,0.92,0.86,0.92, Model B,0.87,0.85,0.90,0.88, Model C,0.91,0.94,0.88,0.93, Model D,0.85,0.87,0.82,0.87, Model E,0.88,0.91,0.84,0.90","Table 4 presents a comparison of five different models' performance using four evaluation metrics: F1-Score, Precision, Recall, and Accuracy. The table exhibits Model A, Model B, Model C, Model D, and Model E F1-Score, Precision, Recall, and Accuracy scores. Interestingly, Model C is the best performing model regarding all evaluation metrics. Model C has the highest F1-Score of 0.91, Precision of 0.94, Recall of 0.88, and Accuracy of 0.93 which demonstrates better performance overall. It is also worth noting that Model D has the lowest F1-Score and Recall, and that Precision metric also reflects Model B's lower performance than the rest of the models."
1004,"caption: Model evaluation metricstable: Model,Accuracy,Recall,Precision,F1 Score, Logistic Regression,0.93,0.90,0.96,0.93, Decision Tree,0.88,0.80,0.83,0.82, Random Forest,0.96,0.94,0.98,0.96, SVM,0.89,0.82,0.88,0.85","The table above presents the performance results of different models on a particular dataset. The accuracy, recall, precision, and F1 score metrics were used to evaluate the model's performances. Logistic regression achieved the highest accuracy of 0.93 and precision of 0.96, while Random Forest recorded the highest recall of 0.94. However, Random Forest and Logistic Regression both outperformed Decision Tree and SVM in all the evaluation metrics. Overall, Random Forest had the highest F1 score of 0.96, indicating that its overall performance was the best of all the models."
1005,"caption: Table 4: Evaluation metrics of various classification models.table: Model,Accuracy,F1-Score,Precision,Recall, Logistic Reg.,0.90,0.89,0.87,0.92, SVM,0.87,0.86,0.89,0.83, Decision Tree,0.82,0.80,0.78,0.83, Random Forest,0.93,0.92,0.91,0.94, Adaboost,0.89,0.88,0.86,0.92","Table 4 presents the evaluation metrics of different classification models, including Logistic Regression, SVM, Decision Tree, Random Forest, and Adaboost. The table demonstrates the accuracy, F1-score, precision, and recall of each model. Notably, the Random Forest model achieved the highest accuracy of 0.93, while Decision Tree performed the lowest, scoring 0.82. Random Forest also had the highest F1-score of 0.92, and Logistic Regression had the highest precision of 0.87. In contrast, SVM had the highest recall of 0.83. These results suggest that Random Forest could be the best performing approach for the given dataset."
1006,"caption: Model comparison based on different evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.84,0.83,0.76,0.78, Decision Tree,0.84,0.80,0.82,0.81, Random Forest,0.86,0.84,0.82,0.83, Support Vector Machine,0.83,0.81,0.73,0.74, K-Nearest Neighbors,0.81,0.77,0.72,0.73",
1007,"caption: Model Performance Using Multiple Metricstable: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.869,0.868,0.876,0.874, LR,0.872,0.870,0.885,0.857, NB,0.807,0.778,0.809,0.747, KNN,0.850,0.848,0.851,0.852, RF,0.887,0.886,0.888,0.886, DNN,0.874,0.872,0.878,0.866","The table illustrates the performance scores of six models, including SVM, LR, NB, KNN, RF, and DNN. The models were evaluated based on four different metrics: Accuracy, F1-Score, Precision, and Recall. From the table, it is evident that the RF model performed the best with a relatively high score across all metrics. The SVM and LR models also achieved high performance scores in terms of these metrics. However, the NB model achieved comparably lower performance compared to other models, with an accuracy of only 80.7%. These results suggest that some models might perform better than others, depending on the evaluation metrics used."
1008,"caption: Performance comparison of different models based on multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.75,0.68,0.81,0.74, SVM,0.74,0.67,0.77,0.71, Random Forest,0.81,0.75,0.84,0.79, XGBoost,0.82,0.76,0.86,0.81","Table exhibits a comparative analysis of different machine learning models' performances utilizing multiple evaluation metrics. The models presented in the table include Logistic Regression, SVM, Random Forest, and XGBoost. Evaluation metrics include Accuracy, Precision, Recall, and F1-score. The Random Forest and XGBoost models demonstrate a better performance than the Logistic Regression and SVM models in all evaluation metrics. The XGBoost model has obtained the highest Accuracy of 0.82, Precision of 0.76, Recall of 0.86 and F1-Score of 0.81 among all the models presented."
1009,"caption: Table 4: Model evaluation metrics based on accuracy, F1-score, precision, and recall from different models.table: Model,Accuracy,F1-score,Precision,Recall, Model 1,0.89,0.88,0.90,0.86, Model 2,0.93,0.91,0.92,0.90, Model 3,0.85,0.83,0.87,0.81, Model 4,0.91,0.89,0.93,0.85, Model 5,0.78,0.77,0.80,0.74","Table 4 demonstrates different evaluation metrics of five models namely Model 1, Model 2, Model 3, Model 4, and Model 5. The metrics reported in the table are accuracy, F1-score, precision, and recall. Model 2 appears to be the best among all models based on all evaluation metrics. It has the highest accuracy of 0.93, F1-score of 0.91, precision of 0.92, and recall of 0.90. Despite having low metrics scores, Model 5 has the highest precision of 0.80. In contrast, Model 3 has the smallest precision (0.87), while Model 5 has the smallest recall (0.74). These findings suggest that Model 2 generally outperforms other models in all evaluation metrics."
1010,"caption: Comparison of Different Models' Performance Based on Multiple Evaluation Metricstable: Model Name,Precision,Recall,F1-Score,Accuracy, Random Forest,0.90,0.91,0.90,0.91, Logistics Reg,0.86,0.89,0.87,0.88, Decision Tree,0.79,0.80,0.77,0.81, SVM,0.91,0.86,0.87,0.88","The table compares four models' performance using multiple evaluation metrics, including Precision, Recall, F1-Score, and Accuracy. The models evaluated are Random Forest, Logistics Regression, Decision Tree, and SVM. The table exhibits that the Random Forest model shows the best Precision of 0.90, SVM with the highest Accuracy of 0.88, and Logistics Regression with the highest Recall of 0.89. Interestingly, the Decision Tree model had the lowest performance among the evaluated models, with the lowest F1 Score of 0.77. The table provides insight into choosing the best model based on different evaluation metrics and can be useful for decision-making in similar settings."
1011,"caption: Table 4: Model performance based on multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Model 1,0.85,0.82,0.84,0.83, Model 2,0.87,0.83,0.91,0.87, Model 3,0.91,0.92,0.89,0.90, Model 4,0.80,0.79,0.77,0.78","Table 4 shows the performance evaluation of multiple models using different evaluation metrics. The metrics used in the table are accuracy, precision, recall, and F1-score. Model 3 achieved the best overall performance with an accuracy of 0.91, precision of 0.92, recall of 0.89, and F1-score of 0.90. Model 4 had the lowest overall performance with an accuracy of 0.80, precision of 0.79, recall of 0.77, and F1-score of 0.78. Interestingly, model 2 had the highest precision score of 0.83 and recall score of 0.91. In contrast, model 3 had the highest accuracy and F1-score among other models."
1012,"caption: Performance comparison of different models based on multiple evaluation metrics.table: Model,Precision,Recall,F1-score,Accuracy, SVM,0.75,0.82,0.78,0.89, RF,0.82,0.75,0.78,0.89, LR,0.88,0.78,0.83,0.90, MLP,0.81,0.81,0.80,0.88","Table X presents the performance comparison of four different models based on multiple evaluation metrics, including Precision, Recall, F1-score, and Accuracy. The evaluated models include Support Vector Machine (SVM), Random Forest (RF), Logistic Regression (LR), and Multi-Layer Perceptron (MLP) algorithms. Notably, all models were evaluated using the same dataset, and the results show that each model has its strengths and weaknesses. SVM and RF models demonstrate similar F1-score with 0.78, while LR has the highest F1-score of 0.83, indicating the model's superior performance in both Precision and Recall. In contrast, MLP exhibits a moderate performance in all metrics, suggesting its limitation in handling complex datasets. The accuracy scores of all models are relatively comparable, with SVM achieving the lowest score of 0.89, while LR has the highest score of 0.90, indicating high classification accuracy."
1013,"caption: Model evaluation results for different models on multiple evaluation metrics.table: Model,Precision,Recall,F1-score,ROC-AUC,PR-AUC, A,0.89,0.83,0.86,0.77,0.83, B,0.85,0.84,0.84,0.81,0.70, C,0.82,0.86,0.84,0.79,0.68, D,0.91,0.79,0.83,0.82,0.76","The table presents the evaluation results for Model A, Model B, Model C, and Model D on multiple evaluation metrics such as precision, recall, F1-score, ROC-AUC, and PR-AUC. The highest precision score of 0.91 was achieved by Model D, while the highest recall score of 0.86 was obtained by Model C. Model A showed the highest F1-score of 0.86, whereas Model B, Model C, and Model A had an F1 of 0.84. When it comes to the area under the curve, Model B obtained the highest ROC-AUC of 0.81 and Model A had the highest PR-AUC of 0.83. The table indicates that different models perform better on different evaluation metrics."
1014,"caption: Table 4: Model performance on classification task using different evaluation metrics.table: Model,F1-score,Precision,Recall, SVM,0.825,0.801,0.851, KNN,0.745,0.681,0.825, LR,0.839,0.802,0.878, RF,0.853,0.836,0.872, XGB,0.855,0.839,0.871","Table 4 displays the classification task's model performance using different evaluation metrics, namely F1-score, Precision, and Recall. The SVM, KNN, LR, RF, and XGB machine learning models' performance scores are presented. The F1-score metric is the harmonic mean of precision and recall. Notably, XGB and RF models perform better than the other models, with XGB's F1-score of 0.855 being the highest. Precision measures how accurately the model predicts the positive class, while recall determines how many of the actual positive samples, the model predicted. The LR model achieved the highest precision score of 0.802. Additionally, the SVM model had the highest recall score of 0.851."
1015,"caption: Table 4: Performance measures across different machine learning modelstable: Model,Accuracy,F1-Score,Precision,Recall, Model 1,0.86,0.87,0.89,0.85, Model 2,0.92,0.93,0.94,0.93, Model 3,0.85,0.86,0.88,0.84, Model 4,0.91,0.92,0.92,0.93, Model 5,0.83,0.82,0.84,0.81","Table 4 presents performance measures across five different machine learning models. The table shows models' accuracy, F1-Score, Precision, and Recall. Model 2 performs the best among all with the highest accuracy, F1-Score, and Recall values of 0.92, 0.93, and 0.93, respectively. Similarly, Model 4 shows good performance with an accuracy, F1-Score, Precision, and Recall of 0.91, 0.92, 0.92, and 0.93, respectively. Interestingly, the worst-performing model is Model 5, with an accuracy of 0.83, F1-Score of 0.82, Precision of 0.84, and Recall of 0.81."
1016,"caption: Table 4: Evaluation metrics (accuracy, F1 score, precision, and recall) of different models.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.85,0.83,0.87,0.80, LR,0.82,0.80,0.85,0.76, NB,0.81,0.76,0.82,0.72, RF,0.89,0.88,0.91,0.87, XGB,0.87,0.86,0.88,0.85","Table 4 shows the performance of different models using various evaluation metrics, including accuracy, F1 score, precision, and recall. The table includes SVM, LR, NB, RF, and XGB models. The RF model shows the highest accuracy of 0.89 and F1 score of 0.88. Similarly, RF had the highest precision of 0.91, while SVM had the highest recall of 0.80. Interestingly, SVM had the highest precision of 0.87 while XGB had the highest recall of 0.85. These results demonstrate the trade-off between precision and recall, and the importance of selecting the appropriate performance metric based on the problem domain."
1017,"caption: Performance comparison of different classification models using multiple evaluation metrics.table: Model,Precision Score,Recall Score,F1 Score,Accuracy, Logistic Regression,0.85,0.78,0.81,0.90, Decision Tree,0.75,0.86,0.80,0.80, K-Nearest Neighbors,0.90,0.75,0.82,0.85, Random Forest,0.81,0.94,0.87,0.92, Support Vector Machine,0.87,0.80,0.83,0.88","The table compares the performance of different classification models, which are Logistic Regression, Decision Tree, K-Nearest Neighbors, Random Forest, and Support Vector Machine. The models' evaluation metrics include Precision Score, Recall Score, F1 Score, and Accuracy. The results demonstrate that Random Forest model achieved the highest Precision Score of 0.81, Recall Score of 0.94, and F1 Score of 0.87. Notably, the Logistic Regression model scored the highest Accuracy, achieving 0.90. The K-Nearest Neighbors model achieved the highest Precision Score of 0.90, while the Support Vector Machine model achieved the highest Recall Score of 0.80. These results demonstrate that models' different performances based on the evaluation metric that is being assessed."
1018,"caption: Performance comparison of different classifiers using multiple evaluation metrics on the test dataset.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.92,0.91,0.93,0.90, KNN,0.83,0.81,0.93,0.73, LR,0.84,0.82,0.87,0.78, DT,0.81,0.78,0.84,0.75, RF,0.89,0.88,0.91,0.85","This table demonstrates the performance results of several classifiers including, SVM, KNN, LR, DT, and RF, based on different evaluation metrics like accuracy, F1-score, precision, and recall, on the test dataset. The results indicate that SVM and RF models outperform the rest of the models in terms of overall accuracy, achieving 92% and 89%, respectively. Similarly, RF demonstrates the best F1-score of 0.88 followed by SVM with 0.91. In contrast, the DT model performs consistently worse among all classifiers with an accuracy of 81% and an F1-score of 0.78. Overall, the results suggest that SVM and RF models can be trusted to provide reliable predictions for this dataset."
1019,"caption: Table 4: The evaluation of different machine learning models using multiple evaluation metricstable: Model,Accuracy,F1-score,Precision,Recall,AUC, SVM,0.74,0.65,0.68,0.63,0.81, Random Forest,0.78,0.74,0.77,0.71,0.85, XGBoost,0.83,0.79,0.81,0.77,0.88, Logistic Regression,0.72,0.60,0.63,0.57,0.78, Neural Network,0.80,0.76,0.75,0.78,0.86","Table 4 compares the performance of five different machine learning models based on multiple evaluation metrics. The table shows the evaluation results of SVM, Random Forest, XGBoost, Logistic Regression, and Neural Network models based on Accuracy, F1-score, Precision, Recall, and AUC metrics. Notably, the XGBoost model achieved the highest Accuracy score of 0.83, while the SVM model achieved the lowest Accuracy score of 0.74. Interestingly, the Random Forest model performed better in terms of AUC with a score of 0.85. However, the Neural Network model achieved the highest F1-score with a score of 0.76, which is a more balanced measure than Accuracy in an imbalanced dataset. Overall, the table highlights that different models perform differently based on different evaluation metrics."
1020,"caption: Table 4: Model evaluation metrics for multiple modelstable: Model,Accuracy,PR-AUC,F1-Score, Model A,0.88,0.76,0.87, Model B,0.92,0.83,0.90, Model C,0.90,0.78,0.88, Model D,0.85,0.72,0.85, Model E,0.93,0.84,0.91","Table 4 displays the performance evaluation metrics for multiple models. The table shows the accuracy, PR-AUC, and F1-score for each model in the dataset. The models were evaluated using the same validation and testing sets. Interestingly, Model E outperformed the other models with the highest accuracy score of 0.93, PR-AUC of 0.84, and F1-score of 0.91. Notably, Model B achieved the second-best performance with an accuracy score of 0.92, PR-AUC of 0.83, and F1-score of 0.90. The table's results indicate that Model E is the best-performing model with an overall higher evaluation score."
1021,"caption: Comparison of different models' performance based on multiple evaluation metrics.table: Model name,Accuracy,Precision,Recall,F1 score, Model A,0.821,0.783,0.648,0.709, Model B,0.799,0.654,0.671,0.658, Model C,0.835,0.797,0.720,0.758, Model D,0.813,0.729,0.765,0.741, Model E,0.842,0.805,0.805,0.805","The table presents the evaluation metrics results of different models, including Accuracy, Precision, Recall, and F-1 scores. The table shows that Model E achieves the highest Accuracy with a score of 0.842, while Model B has the lowest accuracy score of 0.799. Model C had the highest Precision of 0.797, while Model B had the lowest of 0.654. Model D had the highest recall score of 0.765, while Model A had the lowest recall score of 0.648. Model E also has the highest F1-Score, where all metrics are equal. Overall, Model E appears to be the best-performing model, while Model B appears to perform the worst based on these evaluation metrics."
1022,"caption: Table 4: The performance of five machine learning models in predicting credit default risk.table: Model,F1-Score,Precision,Recall,Accuracy, Logistic Regression,0.702,0.811,0.621,0.815, SVM,0.734,0.709,0.761,0.718, Random Forest,0.823,0.827,0.820,0.825, XGBoost,0.837,0.820,0.855,0.828, Multilayer Perceptron,0.816,0.838,0.796,0.822","Table 4 presents the performance of five machine learning models in predicting credit default risk. Four evaluation metrics- F1-Score, Precision, Recall, and Accuracy are used to evaluate model performance. The models included in the table are Logistic Regression, SVM, Random Forest, XGBoost, and Multilayer Perceptron (MLP). The table displays the evaluated metrics and performance results for each model. Notably, XGBoost has the highest F1-Score and Recall score, while MLP has the highest Precision score. Overall, Random Forest and XGBoost models have a comparable performance evaluation with an F1-Score above 0.82 and Accuracy above 0.82."
1023,"caption: Model performances based on accuracy, precision, recall, and F1-score.table: Model,Accuracy,Precision,Recall,F1-Score, Random Forest,0.92,0.93,0.89,0.91, XGBoost,0.91,0.91,0.92,0.91, Neural Network,0.93,0.93,0.93,0.93, Decision Tree,0.87,0.83,0.89,0.86","The table presents a comparison of multiple models' performances based on different evaluation metrics such as accuracy, precision, recall, and F1-score. The models include Random Forest, XGBoost, Neural Network, and Decision Tree. The accuracy performance of these models ranges from 0.87 to 0.93. Interestingly, the Neural Network model performs best in all evaluation metrics with a score of 0.93. This model achieved balanced accuracy in terms of precision and recall, which leads to a higher F1-score. On the other hand, the Decision Tree model has the lowest performance on all metrics. This table provides a clear comparison of model performance based on different evaluation metrics, which is valuable information for future model selection."
1024,"caption: Performance metrics of different classification models.table: Model,Accuracy (%),F1 Score,AUC Score, SVM,88.4,0.865,0.911, Logistic Regression,87.9,0.856,0.905, Random Forest,89.2,0.875,0.917, KNN,84.3,0.821,0.883","The presented table compares the performance of different classification models, including SVM, Logistic Regression, Random Forest, and KNN. The evaluation metrics include accuracy, F1 score, and AUC score. The Random Forest model reported the highest performance in terms of accuracy and AUC, with an accuracy of 89.2% and an AUC score of 0.917. The F1 score also indicates that Random Forest achieved better results with a score of 0.875. SVM and Logistic Regression show similar performance with an accuracy of 88.4% and 87.9% respectively, while KNN trails with an accuracy of 84.3% and an AUC score of 0.883."
1025,"caption: Performance metrics for different modelstable: Model Name,Accuracy,F1 Score,Precision,Recall,AUC Score, Logistic Regression,0.82,0.75,0.78,0.74,0.84, Support Vector Machine,0.84,0.77,0.79,0.76,0.87, Random Forest,0.89,0.85,0.83,0.87,0.92, Multi-Layer Perceptron,0.83,0.76,0.80,0.74,0.86, Naive Bayes,0.73,0.62,0.67,0.59,0.78","The table highlights the performance metrics of five machine learning models. The models are Logistic Regression, Support Vector Machine, Random Forest, Multi-Layer Perceptron, and Naive Bayes. The performance metrics evaluated are Accuracy, F1 Score, Precision, Recall, and AUC Score. Notably, the Random Forest model shows the highest Accuracy score of 0.89, while the Support Vector Machine model achieves the highest F1 Score score of 0.77. Additionally, the AUC Score metric indicates the Random Forest model is the most consistent in predicting the target variable with a score of 0.92. On the other hand, the Naive Bayes model shows the weakest performance across the evaluated metrics with an Accuracy score of 0.73 and the lowest F1 score of 0.62."
1026,"caption: Comparison of model performances using different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, SVM,0.80,0.81,0.76,0.78, RF,0.76,0.87,0.67,0.73, LR,0.78,0.74,0.84,0.79, NB,0.70,0.63,0.89,0.74, KNN,0.72,0.73,0.70,0.69","Table compares the model performance of SVM, RF, LR, NB, and KNN using different evaluation metrics such as Accuracy, Precision, Recall, and F1 Score. The highest value for each performance metric is highlighted for emphasis. Overall, the SVM model shows the best accuracy score at 0.80, while the RF model has the highest precision score of 0.87. On the other hand, the NB model had the highest recall score of 0.89, and the LR model got the best F1 Score of 0.79. This table indicates a nuanced difference in model performance metrics and highlights the importance of selecting appropriate metrics in machine-learning model evaluation."
1027,"caption: Performance comparison of different classification models on the binary classification task.table: Model,Precision,Recall,F1-score,ROC-AUC,PR-AUC, SVM,0.89,0.91,0.90,0.95,0.88, KNN,0.87,0.93,0.90,0.94,0.85, RF,0.92,0.93,0.93,0.96,0.94, LR,0.88,0.92,0.90,0.94,0.87, ANN,0.94,0.90,0.92,0.96,0.93","The table above presents a comparison of five different classification models' performances on a binary classification task. The models are evaluated using precision, recall, F1-score, ROC-AUC, and PR-AUC metrics. The highest performing model regarding precision, recall, and F1-score is ANN with scores of 0.94, 0.90, and 0.92, respectively. However, the best performing model with the highest ROC-AUC and PR-AUC is RF with scores of 0.96 and 0.94, respectively. It is interesting to note that the SVM model shows relatively high performance in precision, recall, F1-score, and ROC-AUC."
1028,"caption: Model performances using different evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, LR,0.85,0.70,0.78,0.64, SVM,0.87,0.75,0.85,0.67, KNN,0.79,0.63,0.72,0.58, RF,0.90,0.82,0.87,0.81, XGB,0.92,0.86,0.89,0.84","This table compares the models based on their accuracy, F1 score, precision, and recall. The five models presented in the table are Logistic Regression (LR), Support Vector Machine (SVM), K-Nearest Neighbours (KNN), Random Forest (RF), and XGBoost (XGB). The Random Forest and XGBoost have high values in all the evaluation metrics, indicating their excellent overall performance. The SVM model has relatively high accuracy and precision and a moderate F1 score, while the KNN model has the lowest performance based on these metrics. The table's results indicate the Random Forest and XGBoost models' suitability over other models for classification tasks."
1029,"caption: Performance metrics of different models on the test dataset.table: Model,Accuracy,Precision,Recall,F1-score,MCC, Model A,0.845,0.856,0.817,0.836,0.702, Model B,0.857,0.846,0.876,0.861,0.725, Model C,0.828,0.839,0.796,0.817,0.691, Model D,0.864,0.892,0.831,0.860,0.741","Table presents the evaluation metrics of different classification models trained and tested on the same test dataset. The evaluation metrics include Accuracy, Precision, Recall, F1-score, and MCC. Model D achieved the highest accuracy of 0.864, followed by Model B with 0.857. Model D also achieved the highest Precision of 0.892, while Model A has the lowest precision of 0.856. Model B has the best recall score of 0.876, and Model A exhibits the worst recall score of 0.817. F1-score is used to compare the overall performance of models, and Model B has the highest F1-score of 0.861. Finally, Model D shows the best performance in MCC with a score of 0.741."
1030,"caption: Performance comparison of various models using different evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score, Model 1,0.85,0.87,0.82,0.84, Model 2,0.83,0.82,0.85,0.83, Model 3,0.87,0.89,0.86,0.87, Model 4,0.80,0.78,0.82,0.80, Model 5,0.89,0.90,0.88,0.89","The table summarizes the performances of different models based on multiple evaluation metrics such as accuracy, precision, recall, and F1-score. Model 5 performed the best with the highest accuracy of 0.89 while Model 4 had the lowest accuracy of 0.80. Interestingly, although Model 2 and Model 3 had the same accuracy score of 0.83, their precision and recall scores are opposite. Model 2 has a high precision score of 0.82 but a low recall score of 0.85 while Model 3 has a high recall score of 0.86 but a low precision score of 0.89. Overall, Model 5 outperformed the other models in all metrics except for recall where Model 3 had a slightly higher score."
1031,"caption: Table 4: Model Performances with Multiple Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1-score, LogReg,0.875,0.876,0.876,0.875, SVM,0.890,0.893,0.893,0.891, Decision Tree,0.811,0.805,0.827,0.808, Random Forest,0.927,0.929,0.928,0.927, LightGBM,0.920,0.923,0.922,0.920","Table 4 presents an overview of model performances based on diverse evaluation metrics. The models include Logistic Regression (LogReg), Support Vector Machine (SVM), Decision Tree, Random Forest, and LightGBM. The evaluation metrics involved in this table include accuracy, precision, recall, and F1-score. The Random Forest model outperforms other models with the highest accuracy, precision, recall, and F1-score of 0.927, 0.929, 0.928, and 0.927, respectively. SVM follows a close second with accuracy, precision, recall, and F1-score of 0.890, 0.893, 0.893, and 0.891, respectively. On the other hand, Decision Tree showed the lowest performance, with an accuracy of 0.811, precision of 0.805, recall of 0.827, and F1-score of 0.808."
1032,"caption: Model performances based on Accuracy, F1 Score, Precision, and Recall.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.85,0.82,0.85,0.79, Random Forest,0.88,0.84,0.88,0.80, Naive Bayes,0.77,0.71,0.77,0.68, XGBoost,0.90,0.86,0.90,0.83","Table 4 exhibits model performances based on Accuracy, F1 Score, Precision, and Recall. The table presents four models: SVM, Random Forest, Naive Bayes, XGBoost. The accuracy ranges from 0.77 to 0.90, with XGBoost having the highest Accuracy score. The F1 Score score ranges from 0.71 to 0.86, where XGBoost had the highest score. The highest Precision score in this table belongs to Random Forest, while Naive Bayes had the lowest Precision score. Finally, for Recall, XGBoost achieved the highest score, whereas SVM had the lowest Recall score. Overall, considering all evaluation metrics, XGBoost performed the best, with the highest scores across all metrics."
1033,"caption: Table 4. Model performance on Precision, Recall, and F1 Score metrics.table: Model Name,Metric,Performance, Random Forest,Precision,0.85, Recall,0.79, F1 Score,0.82, Support Vector Machine,Precision,0.76, Recall,0.81, F1 Score,0.78, Naive Bayes,Precision,0.79, Recall,0.73, F1 Score,0.76, K-Nearest Neighbors,Precision,0.72, Recall,0.78, F1 Score,0.75","Table 4 presents the model performance on Precision, Recall, and F1 Score metrics. The table includes Random Forest, Support Vector Machine (SVM), Naive Bayes, and K-Nearest Neighbors models. The Random Forest model achieved the highest precision score of 0.85, while the Naive Bayes model achieved the highest recall score of 0.73. Furthermore, SVM achieved the highest F1 score of 0.78, followed by the Naive Bayes model at 0.76. It is important to note that each model's performance varied significantly based on the metric used for evaluation."
1034,"caption: Model evaluation metrics for different classification models.table: Model,Accuracy,Precision,Recall,F1-Score, Decision Tree,0.84,0.85,0.87,0.86, Random Forest,0.91,0.91,0.95,0.93, k-NN,0.78,0.85,0.80,0.82, Logistic,0.87,0.89,0.90,0.89","The presented table showcases multiple classification models - Decision Tree, Random Forest, k-NN, and Logistic - and their accuracy, precision, recall, and F1-score results. The best-performing model in terms of accuracy, Random Forest, has an accuracy of 0.91, precision of 0.91, recall of 0.95, and an F1-score of 0.93. On the other hand, k-NN attained the lowest scores of 0.78 for accuracy and 0.82 for F1-score. Interestingly, Decision Tree scored well in all metrics except recall, with an accuracy of 0.84, precision of 0.85, recall of 0.87, and an F1-score of 0.86. Logistic showed an overall good performance with an accuracy of 0.87, precision of 0.89, recall of 0.90, and an F1-score of 0.89."
1035,"caption: Table 4: Performance metrics of various models on the test dataset.table: Model,Accuracy,F1-score,Precision,Recall, Model A,0.82,0.74,0.81,0.69, Model B,0.84,0.76,0.84,0.70, Model C,0.80,0.71,0.80,0.63, Model D,0.85,0.78,0.85,0.72, Model E,0.81,0.72,0.82,0.63","Table 4 displays the performance results of five different models based on multiple evaluation metrics on the test dataset. The models' accuracy, F1-score, precision, and recall are presented in the table. Model D achieved the highest accuracy of 0.85, followed closely by Model B with 0.84. For the F1-score metric, Model D again had the highest score of 0.78, and Model B had the second-highest F1-score of 0.76. In terms of precision, Model B and Model D both had the best performance with precision scores of 0.84 and 0.85, respectively. Finally, for recall, Model D had the best score of 0.72, while the lowest score was achieved by Model C with a recall score of 0.63. Overall, Model D appears to have achieved the best performance on all metrics."
1036,"caption: Model comparison based on different evaluation metrics.table: Model Name,Accuracy,Precision,Recall,F1-Score, Model 1,88.92%,0.93,0.89,0.91, Model 2,90.11%,0.942,0.919,0.930, Model 3,94.53%,0.965,0.955,0.960, Model 4,84.22%,0.88,0.844,0.858","Table 1 presents the comparison of different models based on different evaluation metrics. The metrics used to evaluate the models are accuracy, precision, recall, and F1-score. Four different models, referred to as Model 1-4, were evaluated, and their performance results were recorded. Model 3 achieved the best overall performance results across all metrics, with an accuracy of 94.53%, precision of 0.965, recall of 0.955, and F1-score of 0.960. Model 2 had the second-best overall performance with all the metrics exceeding 90%. On the other hand, Model 4 had the worst overall performance with a precision and recall of less than 90%."
1037,"caption: Comparison of different machine learning algorithms based on multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.84,0.87,0.82,0.84, KNN,0.92,0.93,0.91,0.92, Decision Tree,0.79,0.78,0.82,0.80, Random Forest,0.95,0.95,0.95,0.95, XGBoost,0.93,0.94,0.92,0.93","The table presents the results of multiple machine learning algorithms concerning accuracy, precision, recall, and F1-score. The SVM model achieved the highest precision score of 0.87, while the KNN model achieved the highest accuracy score of 0.92. Interestingly, the Random Forest model outperformed the rest, achieving the best result concerning all evaluation metrics. The Decision Tree model achieved the lowest accuracy, precision, and F1-score, making it the least effective model in this comparison. Overall, the table presents different models' performances concerning multiple evaluation metrics, providing a comprehensive view of how well each model performed."
1038,"caption: Comparison of different models based on multiple evaluation metrics.table: Model,Precision,Recall,F1-score,Accuracy, Logistic Regression,0.89,0.87,0.88,0.87, Support Vector Machine,0.91,0.90,0.90,0.88, Decision Tree,0.83,0.84,0.83,0.81, Random Forest,0.95,0.94,0.94,0.93, Gradient Boosting,0.92,0.92,0.91,0.90, Neural Network,0.93,0.93,0.92,0.91","The table presents a comparison of different models based on precision, recall, F1-score, and accuracy metrics. The table includes Logistic Regression, Support Vector Machine, Decision Tree, Random Forest, Gradient Boosting, and Neural Network models. The Random Forest model shows the highest precision (0.95), recall (0.94), F1-score (0.94), and accuracy (0.93), demonstrating it is the best-performing model overall. Interestingly, the Neural Network model performed well with a precision of 0.93, recall of 0.93, F1-score of 0.92, and accuracy of 0.91, suggesting it might also be a good model for prediction. The Decision Tree model had the lowest performance, particularly in accuracy (0.81). Nonetheless, all models show competitive performance scores, which indicates that the tested models have potential for future applications."
1039,"caption: Performance comparison of different classifiers on the test set.table: Model,Accuracy,Precision,Recall,F1-Score, Decision Tree Classifier,0.786,0.793,0.778,0.779, Random Forest Classifier,0.879,0.878,0.876,0.876, Gradient Boosting Classifier,0.899,0.899,0.898,0.898, Support Vector Machine,0.789,0.788,0.787,0.787, K-Nearest Neighbor,0.739,0.695,0.758,0.681","The table displays the performance metric scores of five different models: Decision Tree Classifier, Random Forest Classifier, Gradient Boosting Classifier, Support Vector Machine, and K-Nearest Neighbor. The evaluation metrics include accuracy, precision, recall, and F1-score. Notably, Gradient Boosting Classifier has the highest scores with an accuracy of 0.899, precision of 0.899, recall of 0.898, and F1-score of 0.898. On the other hand, K-Nearest Neighbor yielded the lowest performance results, with an accuracy of 0.739 and F1-Score of 0.681."
1040,"caption: Table 4: Model comparison based on different evaluation metrics.table: Model Name,F1,Accuracy,Precision,Recall,AUC, Model 1,0.86,0.93,0.89,0.83,0.78, Model 2,0.71,0.80,0.77,0.65,0.68, Model 3,0.92,0.94,0.94,0.90,0.85, Model 4,0.69,0.78,0.72,0.67,0.57, Model 5,0.83,0.90,0.87,0.79,0.75","Table 4 presents a comparison of different models based on multiple evaluation metrics such as F1 score, Accuracy, Precision, Recall, and AUC. Model 3 has the highest F1 score (0.92), with a high accuracy (0.94), precision (0.94), and recall (0.90) scores. However, Model 5 has the highest AUC of 0.75, followed by Model 1 with an AUC score of 0.78. Model 1 has the highest precision score of 0.89, while Model 5 has the highest recall score of 0.79. Models 2 and 4 have lower performance scores in all the evaluation metrics. Overall, Model 3 seems to outperform others in this comparison."
1041,"caption: Comparison of model performance based on different evaluation metricstable: Model,Accuracy,Precision,Recall,F1 Score, Decision Tree,0.83,0.69,0.82,0.75, Logistic Regression,0.89,0.85,0.71,0.77, Random Forest,0.92,0.92,0.78,0.84, Support Vector Machine,0.87,0.80,0.68,0.73, Naive Bayes,0.78,0.57,0.83,0.68","This table presents a comparison of model performance based on different evaluation metrics, including accuracy, precision, recall, and F1 score. The table includes five models: Decision Tree, Logistic Regression, Random Forest, Support Vector Machine, and Naive Bayes. The Random Forest model shows the highest accuracy of 0.92, while Logistic Regression model exhibits the highest precision of 0.85 and the Naive Bayes model has the highest recall rate of 0.83. Interestingly, the Random Forest model also demonstrates the highest F1 score of 0.84, indicating an optimal balance between precision and recall in this dataset."
1042,"caption: Model evaluation results based on multiple classification metrics.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.75,0.79,0.76,0.82, KNN,0.68,0.65,0.56,0.77, RF,0.85,0.84,0.83,0.83, MLP,0.79,0.81,0.77,0.86, NB,0.62,0.67,0.53,0.86","The table presents the evaluation performances of five models for a specific classification task. The evaluation results are based on different metrics like Accuracy, F1-Score, Precision, and Recall. The Random forest (RF) model outperforms other models in terms of accuracy with a score of 0.85. In contrast, the K-Nearest Neighbors (KNN) model has the lowest Accuracy and F1-score, with 0.68 and 0.65, respectively. Interestingly, the Naive Bayes (NB) model had the highest recall score of 0.86, while the Multilayer Perceptron (MLP) model had the highest precision score of 0.77. Overall, the evaluation results suggest that the Random forest model has better performance than the other models based on the metrics considered."
1043,"caption: Evaluation metrics comparison of different models in a classification task.table: Model,F1 Score,Precision,Recall,Specificity,AUC ROC, Logistic Regression,0.84,0.87,0.82,0.92,0.89, Random Forest,0.85,0.86,0.84,0.91,0.94, Naive Bayes,0.74,0.72,0.76,0.82,0.84, XGBoost,0.83,0.81,0.86,0.92,0.94","Table illustrated above displays the performances of different models in a classification task based on multiple evaluation metrics, including F1 score, precision, recall, specificity, and area under ROC curve (AUC ROC). The table presents four models' performance results, namely Logistic Regression, Random Forest, Naive Bayes, and XGBoost. Compared to other models in the table, Random Forest and XGBoost exhibit a better performance overall by achieving higher F1 scores, precision, recall, and higher-specificity values. Additionally, both Random Forest and XGBoost achieve higher AUC ROC scores, suggesting a better model's ability to distinguish between positive and negative classes."
1044,"caption: Evaluation metrics of various classification models on a particular dataset.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Reg.,0.87,0.78,0.87,0.82, Naive Bayes,0.79,0.64,0.48,0.55, SVM,0.91,0.85,0.90,0.88, K-NN,0.81,0.60,0.72,0.66, Decision Tree,0.83,0.68,0.85,0.76","Table presents the performance of different machine learning models on the same dataset. The metrics used for evaluating each model include Accuracy, Precision, Recall, and F1 Score. The table shows that the SVM model has the best overall performance with an accuracy of 0.91 and an F1 score of 0.88. However, the decision tree model outperforms all other models concerning the recall metric with a score of 0.85. The logistic regression model achieved the highest precision score of 0.78, while the K-NN model shows the lowest performance results in all evaluation metrics. This table demonstrates the importance of evaluating models using various metrics as it helps to provide a comprehensive assessment of the model's overall performance."
1045,"caption: Comparison of Model performance based on Accuracy, Precision, Recall and F1 Score.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.90,0.85,0.91,0.88, Decision Tree,0.89,0.83,0.86,0.84, Random Forest,0.94,0.91,0.93,0.92, Support Vector Machine,0.92,0.88,0.90,0.89","The table shows the comparison of four different models based on the Accuracy, Precision, Recall, and F1 Score performance metrics. The Logistic Regression model achieved the highest accuracy score of 0.90, while the Random Forest model showed the highest precision and recall with scores of 0.91 and 0.93, respectively. In contrast, the Decision Tree model had a lower performance in all the evaluation metrics, with the lowest F1 Score of 0.84. Overall, the Random Forest and Support Vector Machine models showed promise with strong performances in all the evaluation metrics."
1046,"caption: Model performance comparison of different classifiers based on Accuracy, Precision, Recall, and F1-Score.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.856,0.695,0.782,0.735, Decision Tree,0.830,0.640,0.718,0.677, Random Forest,0.896,0.771,0.831,0.800, XGBoost,0.904,0.794,0.846,0.819, Multilayer Perceptron,0.902,0.798,0.831,0.814","The table above presents a comparison of various classifiers' performance based on different evaluation metrics, including Accuracy, Precision, Recall, and F1-Score. The models include Logistic Regression, Decision Tree, Random Forest, XGBoost, and Multilayer Perceptron. Notably, the Random Forest and XGBoost models exhibited superior performance in all performance measures, with the highest Accuracy, Precision, Recall, and F1-Score. The Random Forest model, in particular, achieved the highest Accuracy score of 0.896, while the XGBoost model obtained the highest Precision, Recall, and F1-Score of 0.794, 0.846, and 0.819, respectively. Overall, the table provides informative insights into the performance of various classifiers based on different performance measures."
1047,"caption: Table 4: Performance comparison of different models based on various evaluation metrics.table: Model 1,Model 2,Model 3,Model 4, Metric 1,0.75,0.85,0.64,0.91, Metric 2,0.80,0.72,0.93,0.65, Metric 3,0.95,0.43,0.82,0.75, Metric 4,0.58,0.76,0.99,0.61","Table 4 compares the model performance based on different evaluation metrics. The table presents four different models and four different performance metrics. Metric 1 and Metric 4 show contrasting results, suggesting that each model's strengths and weaknesses vary across the evaluation metrics. Notably, Model 4 shows the highest performance in Metric 1 and Metric 3, while Model 2 performs well in Metric 2 but poorly in Metric 3. Overall, the comparison provides a comprehensive view of the models' performances across multiple evaluation metrics."
1048,"caption: Comparison of multiple models based on accuracy, precision, recall, and F1 score.table: Model,Accuracy,Precision,Recall,F1 Score, LogReg,0.87,0.87,0.86,0.86, Decision Tree,0.76,0.77,0.76,0.76, Random Forest,0.90,0.91,0.89,0.89, Naive Bayes,0.83,0.87,0.82,0.82, SVM,0.88,0.89,0.88,0.87","The table presents a comparison of five different models based on their accuracy, precision, recall, and F1 Score. The models are LogReg, Decision Tree, Random Forest, Naive Bayes, and SVM, and they were evaluated on the same dataset. The evaluation metrics provide insights into how each model performs in regards to correct predictions, identifying the positive class, and recalling the actual positive instances. It is evident that the Random Forest model outperforms the other models in terms of accuracy (0.90), while the SVM model has the highest precision (0.89). On the other hand, the Decision Tree model records the lowest results in all evaluation metrics."
1049,"caption: Performance comparison of different machine learning models based on multiple evaluation metrics.table: Metric,Model 1,Model 2,Model 3,Model 4,Model 5, Accuracy,0.89,0.83,0.91,0.93,0.89, F1-Score,0.89,0.80,0.91,0.94,0.87, AUC-ROC,0.95,0.78,0.94,0.97,0.89, Precision,0.91,0.75,0.92,0.93,0.88","The presented table compares the performance of five different models based on four different evaluation metrics. The models were evaluated on a specific dataset, and the results show variation in performance across different evaluation metrics. Notably, Model 4 performed the best across all of the evaluation metrics. It had the highest accuracy score of 0.93, the highest F1-Score of 0.94, the highest AUC-ROC of 0.97, and a high precision score of 0.93. Model 2 demonstrates the weakest performance, having a below-average score across all metrics. Additionally, we can observe some interesting differences in model performance across different evaluation metrics, indicating variations in the models' strengths and weaknesses."
1050,"caption: Table 4: Performance Metrics of Different Modelstable: Model,Accuracy,F1-score,Precision,Recall, SVM,0.9032,0.9025,0.8980,0.9087, KNN,0.8632,0.8598,0.8534,0.8667, RF,0.9166,0.9161,0.9133,0.9190, DT,0.8913,0.8910,0.8869,0.8954, NN,0.9281,0.9276,0.9267,0.9291","Table 4 summarizes the performance metrics of SVM, KNN, RF, DT, and NN models based on the accuracy, F1-score, precision, and recall obtained from the same dataset. The RF model outperformed the others with an accuracy of 0.9166 and an F1-score of 0.9161. The worst-performing model was KNN with an accuracy of 0.8632 and an F1-score of 0.8598. Furthermore, SVM, KNN, and DT scores had a minimal difference in performance, while the NN model exhibited a high accuracy of 0.9281 and an F1-score of 0.9276. Based on these evaluation metrics, the RF model provides better classification performance for the given dataset."
1051,"caption: Table showing the performance evaluation metrics of six different classification models.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.89,0.91,0.83,0.86, Decision Tree,0.83,0.81,0.89,0.85, Random Forest,0.91,0.94,0.86,0.90, AdaBoost Classifier,0.87,0.88,0.84,0.86, Gradient Boosting,0.92,0.95,0.89,0.92, Support Vector Machine,0.90,0.92,0.88,0.90","This table presents a comparison of six different classification models. Accuracy, precision, recall, and F1 score are used to evaluate the models. The results indicate that Gradient Boosting achieved the highest accuracy of 0.92 and the highest F1 score of 0.92. Random Forest had the highest precision of 0.94 while Logistic Regression had the highest recall with a score of 0.83. Interestingly, Decision Tree had the highest precision, but it was outperformed by other models in terms of accuracy and F1 score. In summary, the table demonstrates the strengths and weaknesses of each classification model in performing the task at hand."
1052,"caption: Performance of different models on the given dataset.table: Model,Accuracy (%),F1-score,Precision,Recall,AUC, Logistic,89.5,0.89,0.90,0.88,0.91, Random Forest,94.3,0.94,0.95,0.93,0.96, SVM,85.6,0.86,0.88,0.85,0.90, Naive Bayes,76.2,0.75,0.74,0.77,0.80, K-Nearest,91.2,0.91,0.92,0.90,0.94","The provided table shows the performance of different models on a given dataset. The table comprises five models, including Logistic, Random Forest, SVM, Naive Bayes, and K-Nearest. Moreover, the table tabulates multiple evaluation metrics such as accuracy(%), F1-score, Precision, Recall, and AUC. The Random Forest model demonstrates the best performance among other models in all evaluation metrics. It achieves accuracy, F1-score, Precision, Recall, and AUC score of 94.3%, 0.94, 0.95, 0.93, and 0.96, respectively. Conversely, the Naive Bayes model performs the poorest, with an accuracy score of 76.2%, which is around 18% lower than the Random Forest model."
1053,"caption: Model comparison based on Precision, Recall, F1-score, and AUCtable: Model,Precision,Recall,F1-score,AUC, Random Forest,0.92,0.87,0.89,0.81, SVM,0.87,0.99,0.93,0.92, K-Nearest-Neigh,0.88,0.83,0.85,0.76, Decision Tree,0.95,0.90,0.92,0.82","The table above presents a model comparison based on four different evaluation metrics, Precision, Recall, F1-score, and AUC. The models presented are Random Forest, SVM, K-Nearest-Neighbors and Decision Tree. Notably, Random Forest had the highest precision of 0.92 and decision tree had the highest F1-score of 0.92. Meanwhile, SVM had the highest Recall of 0.99 and the highest AUC of 0.92 indicating better performance. However, it is important to note that different classification tasks may have different requirements and thus variable metrics should be considered while selecting the best model."
1054,"caption: Table 4: Performance evaluation of different models using multiple metrics.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.92,0.85,0.94,0.89, Random Forest,0.93,0.87,0.93,0.9, Neural Network,0.91,0.84,0.91,0.87, Logistic Regression,0.89,0.83,0.88,0.85, Naïve Bayes,0.87,0.79,0.84,0.81","Table 4 presents the evaluation of multiple models' performance based on several metrics. The models evaluated include SVM, Random Forest, Neural Network, Logistic Regression, and Naïve Bayes. The presented metrics include Accuracy, Precision, Recall, and F1-Score. The table exhibits the highest and lowest values for each metric obtained by each model, with Random Forest achieving the highest Accuracy, Precision, and F1-Score values of 0.93, 0.87, and 0.9, respectively. SVM yields the highest Recall score of 0.94, whereas Naive Bayes achieves the lowest scores for all the metrics. Additionally, Logistic Regression shows one of the lowest Accuracy scores of 0.89."
1055,"caption: Table 1: Performance of various classifiers on the datasettable: Model,F1-score,Precision,Recall,Accuracy, Logistic Regression,0.75,0.78,0.73,0.82, Decision Tree,0.72,0.76,0.70,0.80, Random Forest,0.78,0.80,0.74,0.85, Support Vector Machine,0.73,0.77,0.71,0.84, Multilayer Perceptron,0.76,0.79,0.75,0.83","Table 1 provides a comparison of the performance of various classifiers on the dataset, based on F1-score, Precision, Recall, and Accuracy. The classifiers compared are Logistic Regression, Decision Tree, Random Forest, Support Vector Machine, and Multilayer Perceptron. Among the models, Random Forest demonstrated the highest F1-score of 0.78, while Logistic regression recorded the highest precision of 0.78. In terms of recall, Multilayer Perceptron showed the highest value of 0.75, while Random Forest had the highest accuracy of 0.85. The comparison provides an insightful understanding to choose the appropriate model that aligns with the evaluation metric that is critical to the problem under consideration."
1056,"caption: Table 4: Model performance comparison using multiple metrics.table: Model,F1-Score,Accuracy,AUC-ROC,PR-AUC, A,0.85,0.85,0.91,0.75, B,0.87,0.84,0.92,0.77, C,0.92,0.92,0.95,0.80, D,0.89,0.88,0.94,0.83, E,0.88,0.87,0.92,0.76",
1057,"caption: Model evaluation for different machine learning modelstable: Model Name,Accuracy,F1-Score,Precision,Recall, Model A,0.92,0.94,0.89,1.0, Model B,0.93,0.94,0.91,0.98, Model C,0.91,0.93,0.88,0.97, Model D,0.95,0.96,0.95,0.97, Model E,0.92,0.94,0.9,0.96","The table presents an evaluation of the performance of five different machine learning models on the given dataset. The evaluation metrics used are Accuracy, F1-Score, Precision and Recall. The highest accuracy score was observed in Model D with a score of 0.95. However, Model B showed the highest F1-Score and Precision with 0.94 and 0.91 respectively. Interestingly, Model A and E had the highest and lowest Recall score of 1.0 and 0.96 respectively. The results indicate that different machine learning models have different strengths in terms of evaluation metrics, with no single model outperforming the others in all aspects."
1058,"caption: Comparison of models based on different evaluation metricstable: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.83,0.81,0.83,0.80, SVM,0.87,0.86,0.88,0.84, Decision Tree,0.78,0.77,0.75,0.83, Random Forest,0.92,0.91,0.90,0.92","The above table shows the comparison of various classification models based on different evaluation metrics, Accuracy, F1-score, Precision, and Recall. The Logistic Regression and SVM models have obtained higher accuracy with 0.83 and 0.87, respectively. The Random Forest model performed best, with an accuracy of 0.92. The SVM model also shows a promising F1-score of 0.86, although Random Forest has better Precision and Recall scores. Interestingly, the Decision Tree model showed the lowest accuracy and F1-score since it could not handle complex data patterns. Overall, the Random Forest model outperforms other models, followed by SVM and Logistic Regression."
1059,"caption: Table 4: Model performance comparison based on Accuracy, F1-Score, and AUC evaluation metrics.table: Model Name,Accuracy,F1-Score,AUC, Logistic Regression,0.856,0.863,0.928, Decision Tree,0.817,0.802,0.856, Random Forest,0.904,0.908,0.973, Gradient Boosting,0.898,0.898,0.972, Multilayer Perceptron,0.894,0.896,0.971","Table 4 presents the performance comparison of different models based on three evaluation metrics - Accuracy, F1-Score, and AUC. The models included in this table are Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Multilayer Perceptron. The Random Forest model achieved the highest accuracy score of 0.904, as well as the highest F1-Score and AUC of 0.908 and 0.973, respectively. The Gradient Boosting and Multilayer Perceptron models performed closely with slightly lower scores than the Random Forest model. Interestingly, the Logistic Regression model achieved an accuracy score of 0.856, which is relatively lower compared to the other models in the table."
1060,"caption: Model performance comparison of different algorithms based on multiple evaluation metricstable: Model,F1-Score,Accuracy,Precision,Recall, Logistic Regression,0.87,0.88,0.85,0.90, Decision Tree,0.83,0.87,0.81,0.85, SVM,0.90,0.91,0.88,0.92, Random Forest,0.92,0.93,0.90,0.95, XGBoost,0.93,0.95,0.92,0.94","The table above compares the model performances from different algorithms based on multiple evaluation metrics. Five different algorithms were considered – Logistic Regression, Decision Tree, SVM, Random Forest, and XGBoost. The models' performance was evaluated based on four metrics - F1-score, Accuracy, Precision, and Recall. The Random Forest and XGBoost classifiers outperformed other algorithms in all the metrics and registered the best scores across all categories. While XGBoost recorded the highest accuracy and F1-score metric scores, the Random Forest algorithm had the highest precision and recall scores."
1061,"caption: Comparison of Model Performances Using Different Metricstable: Metric,Model 1,Model 2,Model 3,Model 4,Model 5, Precision,0.74,0.78,0.84,0.81,0.72, Recall,0.61,0.77,0.66,0.81,0.68, F1-Score,0.67,0.77,0.74,0.81,0.70, Accuracy,0.75,0.79,0.71,0.80,0.72, Specificity,0.78,0.81,0.69,0.79,0.68, ROC-AUC,0.80,0.84,0.80,0.86,0.75","The table presents a comparison of the performances of five different models (Model 1-5) across multiple evaluation metrics. Precision, Recall, F1-Score, Accuracy, Specificity, and ROC-AUC of each model are recorded. Model 4 outperforms all other models in terms of the precision score with a value of 0.81. Model 2 shows excellent performances based on all metrics but stands out in terms of Recall score, with a value of 0.77. Also, Model 4 achieved the highest ROC-AUC score of 0.86. Overall, the table compares different models based on various metrics, providing unique insights into the strengths, weaknesses, and suitability of each model for specific applications."
1062,"caption: Model Evaluation Metricstable: Model,Accuracy,F1 Score,Precision,Recall, Model A,0.85,0.86,0.87,0.85, Model B,0.81,0.82,0.85,0.79, Model C,0.89,0.87,0.88,0.86, Model D,0.88,0.83,0.84,0.83","The results of the model performance evaluation are presented in the table. The table shows the accuracy, F1 score, precision, and recall results of four different models, A, B, C, and D. The performance results are based on the same dataset and are evaluated with different metrics. Model C exhibits the highest accuracy and F1 score of 0.89 and 0.87, respectively. Model A shows the best precision of 0.87, and Model B demonstrates the lowest performance metric values. Interestingly, Model D has the same accuracy score as Model C, even though it has lower scores in all other metrics."
1063,"caption: Table 4: Model performance based on different Multiple Metricstable: Model 1,Model 2,Model 3,Model 4, Metric 1,0.82,0.85,0.89,0.93, Metric 2,0.68,0.75,0.82,0.90, Metric 3,0.69,0.73,0.82,0.87","Table 4 compares the performance of four different models based on multiple evaluation metrics. The table exhibits metric 1, metric 2, and metric 3 scores for each of the models listed as Model 1, Model 2, Model 3, and Model 4. The results show that Model 4 performed the best across all metrics with the highest scores of 0.93, 0.9, and 0.87 for metric 1, metric 2, and metric 3, respectively. Additionally, Model 2 also performed well with consistently high scores in all metrics. Interestingly, Model 3 had the highest score for metric 1 but did not perform well in other metrics as compared to the other models."
1064,"caption: Table 4: Model performances based on different evaluation metricstable: Model,Accuracy,F1 score,AUC-ROC, Logistic,0.864,0.759,0.917, SVM,0.842,0.723,0.905, Random forest,0.897,0.809,0.937, XGBoost,0.913,0.829,0.953, MLP,0.899,0.815,0.945","Table 4 compares different models using multiple evaluation metrics. The table shows the accuracy, F1 score, and AUC-ROC performance results of five models: Logistic, SVM, Random forest, XGBoost, and MLP. It is evident from the table that XGBoost model outperformed all other models with the highest accuracy of 0.913 and F1 score of 0.829. The Random forest model shows the second-highest performance result, with an accuracy of 0.897 and an F1 score of 0.809. Interestingly, the MLP model also provided a strong performance result with an accuracy of 0.899 and an F1 score of 0.815."
1065,"caption: Table 4: Model comparison based on multiple evaluation metricstable: Model Name,Metric 1,Metric 2,Metric 3, Model A,0.8,0.6,0.9, Model B,0.7,0.4,0.8, Model C,0.9,0.5,1.0, Model D,0.6,0.3,0.7, Model E,1.0,0.8,0.8","Table 4 presents the performance evaluation of five different models based on multiple metrics. The metrics used in this table include Metric 1, Metric 2, and Metric 3. The values in the table indicate each model's performance in each metric. Model E achieved the best Metric 1 and 3 scores with 1.0 and 0.8, respectively. In contrast, Model D had the lowest scores in all three metrics. It is worth noting that Model A had the highest Metric 3 score of 0.9, while Model C had the highest Metric 1 score of 0.9. However, Model C's Metric 2 score is relatively low compared to other models with a score of 0.5."
1066,"caption: Table 4: Performance comparison of different machine learning algorithms using multiple evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.85,0.83,0.84,0.88, Random Forest,0.91,0.89,0.91,0.90, SVM,0.87,0.86,0.86,0.87, Decision Tree,0.81,0.79,0.81,0.79, kNN,0.78,0.75,0.80,0.71, Naive Bayes,0.76,0.75,0.73,0.78, MLP,0.88,0.86,0.87,0.88","Table 4 compares the performance of several machine learning algorithms such as Logistic Regression, Random Forest, SVM, Decision Tree, k-Nearest-Neighbors (kNN), Naive Bayes, and Multi-layer Perceptron (MLP) based on multiple evaluation metrics. The evaluation metrics used in this table are Accuracy, F1 Score, Precision, and Recall. The table shows that the Random Forest algorithm achieves the best results in terms of accuracy, F1 Score and balanced Precision and Recall scores. On the other hand, the kNN algorithm achieved the lowest scores among all the algorithms. Overall, this table provides valuable information for selecting the appropriate machine learning algorithm based on the evaluation metric requirements."
1067,"caption: Table 4: Model Evaluation Metrics for classification tasktable: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.945,0.945,0.962,0.929, Decision Tree,0.909,0.908,0.928,0.888, Random Forest,0.962,0.962,0.968,0.957, K-Nearest Neighbors,0.919,0.917,0.957,0.880, Support Vector Machine (SVM),0.956,0.956,0.964,0.948","Table 4 presents the evaluation metrics for five different models used in a classification task. The models include Logistic Regression, Decision Tree, Random Forest, K-Nearest Neighbors, and Support Vector Machine (SVM). The evaluation metrics included in the table are Accuracy, F1-Score, Precision, and Recall. Notably, the Random Forest model outperforms other models in all the evaluation metrics with an accuracy of 0.962, F1-Score of 0.962, Precision of 0.968, and Recall of 0.957. Interestingly, the SVM model achieved high scores in all evaluation metrics, nearly equal to the Random Forest model. Nevertheless, the Logistic Regression model achieved high scores, proving to be a robust model for the classification task."
1068,"caption: Table 4: Model evaluation metrics results for different models.table: Model,Accuracy,F1-score,Precision,Recall, Model A,0.85,0.83,0.86,0.81, Model B,0.81,0.79,0.83,0.76, Model C,0.89,0.88,0.90,0.87, Model D,0.90,0.89,0.91,0.88, Model E,0.86,0.85,0.87,0.84","Table 4 presents the results of model evaluation metrics for five different models. The table exhibits accuracy, F1-score, precision, and recall scores for each model. Notably, all models were trained and tested using the same dataset. Model D shows the best accuracy score of 0.90, while Model C has the highest F1-score, precision, and recall scores of 0.88, 0.90, and 0.87, respectively. Interestingly, Model B has the lowest performance results across all the evaluation metrics, and the rest of the models had similar performance results."
1069,"caption: Table 4: Model Performance Evaluation Metricstable: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.84,0.80,0.83,0.77, KNN,0.79,0.71,0.79,0.65, RF,0.92,0.89,0.90,0.88, NB,0.68,0.55,0.67,0.47, LR,0.88,0.83,0.88,0.80","Table 4 shows the performance of five different models categorized based on their different evaluation metrics including Accuracy, F1 Score, Precision, and Recall. The models compared are SVM, KNN, RF, NB, and LR. The RF model outperformed all other models in terms of accuracy with a score of 0.92. The LR model had the second-best accuracy score with 0.88. Looking at F1 Score, the RF model showed the best score with 0.89, followed by the SVM and LR models with 0.80 and 0.83, respectively. The Precision measure shows how many reported positive results are relevant, and the RF model had the highest score of 0.90 compared to other models. Meanwhile, the Recall measure emphasizes the number of true positive outcomes which were identified. The SVM model outperformed the other models with the highest Recall score of 0.77. Overall, the table exhibits the varying performance results of different models across an array of metrics, thus signaling the need to tune specific models for best results."
1070,"caption: Table 4: Model performance based on different evaluation metricstable: Model,Accuracy,F1 score,Precision,Recall, SVM,0.89,0.87,0.87,0.91, Naive Bayes,0.76,0.73,0.78,0.68, Random Forest,0.91,0.89,0.91,0.87, KNN,0.82,0.77,0.79,0.75, Decision tree,0.87,0.84,0.88,0.81","Table 4 presents a comparison of different models based on their performance evaluated using various evaluation metrics. The models included in this table are SVM, Naive Bayes, Random Forest, KNN, and Decision tree. The evaluation metrics include accuracy, F1 score, precision, and recall. The Random Forest model appears to show the best overall performance with an accuracy score of 0.91, F1 score of 0.89, precision score of 0.91, and recall score of 0.87. Conversely, Naive Bayes model shows the worst performance across all metrics with an accuracy score of 0.76, F1 score of 0.73, precision score of 0.78, and recall score of 0.68. Overall, these results suggest that the Random Forest model outperforms other models in this study."
1071,"caption: Table 4: Performance of different models using multiple evaluation metricstable: Models,Accuracy,Precision,Recall,F1 Score, Decision Tree,0.82,0.85,0.74,0.78, Random Forest,0.87,0.88,0.81,0.84, K-Nearest Neighbor,0.76,0.79,0.69,0.73, Support Vector Machine,0.82,0.85,0.76,0.80, Naive Bayes,0.68,0.70,0.60,0.64","Table 4 compares the performance of five different models: Decision Tree, Random Forest, K-Nearest Neighbor, Support Vector Machine, and Naive Bayes using multiple evaluation metrics, including Accuracy, Precision, Recall, and F1 Score. The Random Forest model achieved the highest accuracy score of 0.87, followed by Support Vector Machine with 0.82, Decision tree with 0.82, K-Nearest Neighbor with 0.76, and Naive Bayes with 0.68. The Random Forest model also had the highest Precision score of 0.88 and Recall score of 0.81, while the Decision tree model achieved the highest F1 Score of 0.78. Overall, the Random Forest model demonstrates the best performance out of all models across all evaluation metrics."
1072,"caption: Table 4: Model comparison based on accuracy, F-1 score, precision, and recall.table: Model,Accuracy,F-1 Score,Precision,Recall, Model 1,0.85,0.83,0.82,0.86, Model 2,0.79,0.77,0.81,0.74, Model 3,0.92,0.88,0.94,0.82, Model 4,0.91,0.90,0.85,0.95","Table 4 presents a comparison of different models based on evaluation metrics such as accuracy, F-1 score, precision, and recall. Model 3 has the highest accuracy of 0.92, while Model 2 has the lowest with 0.79. Model 4 has the highest F-1 score with 0.90, indicating its precision and recall are nearly balanced. Model 1 has a higher recall than precision, indicated by its F-1 score of 0.83, while Model 3 has a higher precision. Notably, Model 4 has the highest precision of 0.85, and Model 3 has the highest recall of 0.82. Overall, Model 3 and Model 4 appear to have the best performance in different evaluation metrics."
1073,"caption: Table 4. Model Evaluation Metrics for Various Models.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.912,0.895,0.928,0.911, Support Vector machine,0.894,0.876,0.912,0.894, Random Forest,0.946,0.944,0.950,0.946, XGBoost,0.932,0.920,0.943,0.931, Multilayer perceptron,0.919,0.898,0.932,0.919","The table above (Table 4) shows the model evaluation metrics using various models for a dataset. The models evaluated in this study include Logistic Regression, Support Vector Machine (SVM), Random Forest, XGBoost, and Multilayer Perceptron (MLP). Evaluation metrics include accuracy, precision, recall, and F1 Score. With an accuracy score of 0.946, the Random Forest model outperformed the other models, while Logistic Regression was the second-best with an accuracy of 0.912. Additionally, Random Forest and XGBoost models had the highest precision score of 0.944 and 0.920, respectively. In contrast, the SVM model achieved the highest recall score of 0.912, while the MLP model achieved the highest F1 Score of 0.919."
1074,"caption: Performance comparison of different machine learning models on the classification of cancer types.table: Model,F1 Score,Accuracy,Precision,Recall, Logistic Regression,0.87,0.81,0.85,0.89, Support Vector Machine,0.89,0.84,0.91,0.87, Random Forest,0.93,0.89,0.91,0.95, Multilayer Perceptron,0.91,0.87,0.89,0.94, XGBoost,0.94,0.91,0.92,0.96","The table presents the performance comparison among various machine learning models on the classification of cancer types based on multiple evaluation metrics - F1 Score, Accuracy, Precision, and Recall. The models include Logistic Regression, Support Vector Machine (SVM), Random Forest, Multilayer Perceptron (MLP), and XGBoost. The Random Forest model achieved the highest F1 Score (0.93) and Recall (0.95) scores among all models. The XGBoost model had the highest Precision score of 0.92 and had an F1 Score of 0.94 and a Recall score of 0.96. SVM model achieved an F1-Score of 0.89 and attained the second-highest Accuracy score of 0.84 following the XGBoost model with the highest score of 0.91."
1075,"caption: Model evaluation metricstable: Model,Accuracy (%),Precision (%),Recall (%),F1-score, Model A,92.03,89.21,94.12,0.911, Model B,80.67,83.58,75.84,0.790, Model C,87.45,81.54,93.23,0.869, Model D,94.23,91.12,96.45,0.939, Model E,78.34,75.67,84.21,0.784","Table X presents the performance evaluation metrics of five different models (Model A-E) based on their accuracy, precision, recall, and F1-score. The table reveals that Model D outperforms all other models with the highest accuracy of 94.23%. Model A has the highest precision of 89.21% and recall of 94.12%, resulting in a high F1-score of 0.911. Conversely, Model E has the lowest accuracy of 78.34% and the lowest F1-score of 0.784. It is interesting to note that Model C achieved relatively high recall of 93.23% but has a much lower precision of 81.54%, yielding an F1-score of 0.869. Overall, this table showcases the significance of multiple evaluation metrics in assessing a model's performance."
1076,"caption: Table 4: Model performance based on different evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.93,0.89,0.72,0.79, LR,0.92,0.87,0.67,0.76, RF,0.94,0.89,0.68,0.77, MLP,0.93,0.88,0.72,0.79, KNN,0.90,0.83,0.66,0.73","Table 4 summarizes the performance of five different models based on different evaluation metrics, including Accuracy, Precision, Recall, and F1-Score. SVM, LR, RF, MLP, and KNN models are evaluated with the same dataset. From the table, RF achieved the highest accuracy of 0.94, followed by SVM, MLP, LR, and KNN, respectively. KNN exhibits the lowest accuracy of 0.90, although it performed equally well in terms of precision when compared to LR. Regarding the F1-score, SVM and MLP have the highest scores of 0.79, followed by RF with 0.77, LR with 0.76, and KNN with 0.73. Overall, the table indicates that model performance varies based on different evaluation metrics, and the choice of model depends on the specific task at hand."
1077,"caption: Performance comparison of different models using multiple evaluation metrics.table: Model,Precision,Recall,F1-Score,AUC, Model 1,0.85,0.82,0.83,0.91, Model 2,0.92,0.88,0.89,0.93, Model 3,0.80,0.90,0.85,0.92, Model 4,0.95,0.97,0.96,0.89, Model 5,0.87,0.95,0.91,0.94","Table 1 illustrates the performance of five different models based on Precision, Recall, F1-Score, and AUC (Area Under Curve) metrics. Notably, all the models were trained using the same dataset. It is apparent from the table that Model 4 achieves the highest Precision score of 0.95, whereas Model 3 attains the highest Recall score of 0.90. Model 5 demonstrates the best F1-Score of 0.91, while Model 2 shows the highest AUC score of 0.93. Interestingly, Model 1 has the lowest F1-Score but the highest Precision compared to the remaining models. The performance of all models varied with different evaluation metrics, suggesting that it is crucial to analyze multiple metrics when comparing model performances."
1078,"caption: Performance results of three different models based on multiple evaluation metrics.table: Metric,Model 1,Model 2,Model 3, Accuracy,0.83,0.90,0.86, F1 Score,0.81,0.93,0.84, Precision,0.86,0.84,0.91, Recall,0.79,0.96,0.78","Table 4 presents a performance comparison of three different models based on multiple evaluation metrics. The table exhibits the accuracy, F1 score, precision, and recall metrics for Model 1, Model 2, and Model 3. Notably, Model 2 shows the best overall performance, achieving the highest accuracy of 0.90 and F1 score of 0.93, as well as the highest precision of 0.84. Interestingly, Model 2 also has the highest recall score of 0.96, while Model 1 has the best balance between recall and precision, achieving the highest recall of 0.79 and precision of 0.86. Overall, this table highlights the strengths and weaknesses of different models across various evaluation metrics and can assist in selecting the most appropriate model for a specific task."
1079,"caption: Performance of six machine learning models on a binary classification task.table: Model,Accuracy,Precision,Recall,F1 score, Logistic Regression,0.82,0.75,0.83,0.79, Decision Tree,0.85,0.82,0.75,0.78, Random forest,0.89,0.89,0.87,0.88, XGBoost,0.88,0.85,0.89,0.87, Support Vector Machine,0.79,0.78,0.80,0.79, Multilayer Perceptron,0.86,0.81,0.84,0.82","The table above exhibits a comparison of six popular machine learning models' performances on a binary classification task using four standard evaluation metrics: Accuracy, Precision, Recall, and F1 Score. The models include Logistic Regression, Decision Tree, Random Forest, XGBoost, Support Vector Machine, and Multilayer Perceptron. Interestingly, the Random Forest model outperformed the other models, with the highest accuracy (0.89) and F1-score (0.88), while the Logistic Regression model provided the lowest F1-score (0.79). The Decision Tree and Multilayer Perceptron models provided similar F1-score results, while the Support Vector Machine model exhibited the lowest overall performance based on all the evaluation metrics."
1080,"caption: Model performance based on different evaluation metrics.table: Model,Accuracy,F1 Score,Recall,Precision, SVM,0.72,0.71,0.68,0.75, KNN,0.62,0.61,0.56,0.66, RF,0.78,0.77,0.75,0.80, NB,0.58,0.60,0.70,0.52, DNN,0.81,0.80,0.78,0.83","Table presents model performance based on different evaluation metrics, including Accuracy, F1 Score, Recall, and Precision. The table includes SVM, KNN, RF, NB, and DNN models. Interestingly, DNN showed the highest Accuracy, F1 Score, and Precision performance results with 0.81, 0.80, and 0.83 scores, respectively. However, SVM showed the highest Recall score of 0.68, while RF showed the best performance in terms of Accuracy, F1 Score, and Precision with 0.78, 0.77, and 0.80 scores, respectively. Notably, NB showed the lowest Accuracy score of 0.58, indicating it's the least performing model based on the evaluation metrics presented in the table."
1081,"caption: Classification performance metrics of multiple modelstable: Models,Accuracy,F1-Score,AUC, Model A,0.85,0.82,0.78, Model B,0.87,0.83,0.82, Model C,0.83,0.81,0.77, Model D,0.89,0.85,0.84, Model E,0.76,0.75,0.70","The table illustrates the classification performances of five different models based on three evaluation metrics. The metrics measured are Accuracy, F1-score, and AUC. Model D performed the best in all the evaluation metrics, achieving the highest accuracy of 0.89, F1-score of 0.85, and AUC of 0.84. Meanwhile, Model A and Model C showed lower performance metrics across all metrics. Model E, on the other hand, denotes the lowest accuracy with the value of 0.76. The table shows that Model B had the highest F1-score value of 0.83 and AUC value of 0.82. The results illustrate that Model D is the best-performing model as it had the best performance across all three metrics."
1082,"caption: Model evaluation metrics for different approaches of a classification problem.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.89,0.92,0.77,0.84, Logistic Regression,0.82,0.87,0.64,0.73, Random Forests,0.93,0.94,0.84,0.89, Naive Bayes,0.70,0.58,0.99,0.73, Decision Tree,0.91,0.90,0.83,0.85","The table above illustrates the accuracy, precision, recall, and F1-score of five distinct classification models- SVM, Logistic Regression, Random Forests, Naive Bayes, and Decision Trees. The table presents the models' performance results on the same dataset. Notably, Random Forests outperformed all other models with an impressive accuracy score of 0.93, precision of 0.94, recall of 0.84, and F1-score of 0.89. Although Naive Bayes recorded a high recall result of 0.99, it achieved a poor accuracy of 0.70. Interestingly, the Logistic Regression approach recorded the second-lowest accuracy of 0.82 despite its relatively high precision metric of 0.87."
1083,"caption: Table 4: Evaluation metrics for different models.table: Model,Accuracy,Recall,Precision,F1 Score, Model A,0.84,0.89,0.86,0.87, Model B,0.80,0.83,0.90,0.86, Model C,0.77,0.92,0.81,0.86, Model D,0.83,0.87,0.84,0.85, Model E,0.81,0.85,0.83,0.84","Table 4 presents the evaluation metrics of different models. The accuracy, recall, precision, and F1 score are calculated for each model. Model A achieves the highest accuracy score of 0.84, with a recall score of 0.89. Model C achieved the highest recall score of 0.92, while Model B achieved the highest precision score of 0.90. Interestingly, the F1 score shows that Model A has the best performance, scoring 0.87, while Model C and Model B both score 0.86. Overall, this table highlights the comparative performance of different models, revealing their strengths and weaknesses in terms of the evaluation metrics."
1084,"caption: Comparison of Different Models Based on Various Evaluation Metricstable: Models,F1-Score,Accuracy,Precision,Recall, Model 1,0.82,0.85,0.87,0.78, Model 2,0.87,0.88,0.89,0.85, Model 3,0.91,0.89,0.88,0.94, Model 4,0.75,0.83,0.81,0.7","Table above presents a comparison of different models based on multiple evaluation metrics, including F1-score, accuracy, precision, and recall. Model 1, Model 2, Model 3, and Model 4 were evaluated based on their performance on the task. Notably, Model 3 showed the best overall performance, achieving the highest F1-score of 0.91, but it had the lowest accuracy score of 0.89. In contrast, Model 2 had the highest accuracy of 0.88 and outperformed other models on precision with the score of 0.89. However, Model 4 had the lowest performance among other models with the lowest F1-Score of 0.75 and recall of 0.7."
1085,"caption: Model comparison by different evaluation metricstable: Model,Accuracy,Precision,Recall,F1 Score,AUC Score, Logistic Regression,93.75%,0.88,0.92,0.90,0.95, Random Forest,95.87%,0.90,0.94,0.92,0.91, XGBoost,96.12%,0.91,0.94,0.93,0.94, Multilayer Perceptron,94.25%,0.89,0.93,0.91,0.92, Support Vector Machine,94.12%,0.89,0.91,0.90,0.93","The table compares five different models' performance using different evaluation metrics - Accuracy, Precision, Recall, F1 Score, and AUC Score. The models compared are Logistic Regression, Random Forest, XGBoost, Multilayer Perceptron, and Support Vector Machine. From the table, XGBoost shows the highest accuracy of 96.12%. The Random Forest and XGBoost also show good performance in precision, recall, F1 score, and AUC score. The Logistic Regression and Multilayer Perceptron models show slightly lower performance. However, it is important to note that depending on the specific project's objectives, different evaluation metrics may have varying levels of importance, which may influence the model selection process."
1086,"caption: Performance comparison of different models using various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.831,0.846,0.787,0.815, Logistic Regression,0.834,0.855,0.772,0.811, Random Forest,0.851,0.864,0.816,0.839, Naïve Bayes,0.790,0.889,0.649,0.752, Neural Network,0.846,0.831,0.826,0.827","The table presents a performance comparison of different models based on multiple evaluation metrics. The models include SVM, Logistic Regression, Random Forest, Naïve Bayes, and Neural Network. The evaluation metrics comprise of Accuracy, Precision, Recall, and F1-Score. Notably, Random Forest outperformed all other models in Accuracy, Precision, and F1-Score, with scores of 0.851, 0.864, and 0.839, respectively. Although Naïve Bayes had the highest Precision score of 0.889, its Recall score was significantly lower than the other models. The Neural Network model achieved balanced scores in all the evaluation metrics with the highest Recall of 0.826."
1087,"caption: Comparison of five different models' performances based on various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Model A,0.76,0.81,0.72,0.76, Model B,0.81,0.85,0.80,0.82, Model C,0.73,0.78,0.69,0.73, Model D,0.85,0.88,0.84,0.86, Model E,0.79,0.82,0.77,0.79","Table above displays an evaluation comparison of five different models using four evaluation metrics; accuracy, precision, recall and, F1 score. Model D presents the best performance in the dataset with an accuracy score of 0.85. Similarly, Model D achieved the highest precision score of 0.88, and recall of 0.84. On the other hand, Model C had the worst performance with scores of 0.73, 0.78, 0.69, and 0.73 of accuracy, precision, recall and F1-score, respectively. This table provides key performance insights to help identify the best-performing models in the dataset, making it easier to evaluate models based on specific criteria."
1088,"caption: Performance comparison of CNN, Random Forest, and Logistic Regression models for sentiment analysis using accuracy, precision, recall, f1 score, and AUC metrics.table: Model,Accuracy,Precision,Recall,F1 Score,AUC, CNN,0.842,0.852,0.813,0.832,0.907, Random Forest,0.869,0.861,0.882,0.871,0.935, Logistic Regression,0.798,0.775,0.812,0.785,0.870","The table shows the performance comparison of CNN, Random Forest, and Logistic Regression models for sentiment analysis based on different metrics, including accuracy, precision, recall, f1 score, and AUC. As shown in the table, the Random Forest outperformed the other models in all metrics except for accuracy, in which CNN performed better. Notably, the AUC metrics were consistently higher than other metrics across all models, with the Random Forest having the highest AUC score of 0.935. The results suggest that the Random Forest model may be the most suitable for sentiment analysis tasks due to its overall high performance across multiple evaluation metrics."
1089,"caption: Performance of different classification models on the given dataset.table: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.75,0.76,0.77,0.75, Decision Tree,0.85,0.87,0.88,0.86, Random Forest,0.88,0.90,0.90,0.91, SVM,0.78,0.80,0.79,0.81, KNN,0.81,0.82,0.83,0.82","The presented table shows the performance comparison of five different classification models on the given dataset based on different evaluation metrics, including accuracy, F1-score, precision, and recall. Notably, the Random Forest model achieved the highest accuracy of 0.88 and F1-score of 0.90, while also delivering a relatively high precision and recall of 0.90 and 0.91, respectively. Meanwhile, the Decision Tree model achieved the second-best performance with an accuracy of 0.85 and F1-score of 0.87. The KNN model achieved moderate performance, while the SVM model achieved the lowest accuracy of 0.78. Overall, the Random Forest model outperformed the other models, while the Decision Tree model achieved the second-best performance."
1090,"caption: Performance results of various machine learning models used in the classification of bank loan approval dataset.table: Model Name,Precision Score,Recall Score,F1-score,Accuracy, Logistic Regression,0.74,0.81,0.73,0.85, Decision Tree Classifier,0.67,0.64,0.62,0.67, Random Forest Classifier,0.82,0.70,0.75,0.83, Support Vector Machines,0.78,0.84,0.81,0.87, Naive Bayes Classifier,0.62,0.93,0.72,0.78","The table presents multiple machine learning model performances based on the classification of a bank loan approval dataset. The models' evaluation metrics include precision score, recall score, F1-score, and accuracy. The Random Forest Classifier model achieved the highest precision score of 0.82, followed by SVM model with a score of 0.78. While Naive Bayes Classifier had the highest recall score of 0.93, Logistic Regression had the highest F1-score of 0.73. Additionally, the accuracy scores were the highest for Support Vector Machines (0.87), followed by Logistic Regression (0.85)."
1091,"caption: Model evaluation metrics for different classification modelstable: Model,Accuracy,F1-Score,Precision,Recall,AUC, Random Forest,0.75,0.74,0.76,0.74,0.80, Gaussian Naive Bayes,0.65,0.60,0.57,0.72,0.70, K-Nearest Neighbors,0.70,0.67,0.71,0.66,0.75, Neural Network,0.80,0.79,0.81,0.78,0.85","The table presents the evaluation metrics (accuracy, F1-score, precision, recall, and AUC) for four different classification models (Random Forest, Gaussian Naive Bayes, K-Nearest Neighbors, and Neural Network). Each model was trained and tested on a specific dataset, and the table displays the final performance results. The best-performing model in terms of overall accuracy and AUC is the Neural Network model, with the highest accuracy score of 0.80 and AUC of 0.85. However, the Random Forest model exhibits the highest precision score of 0.76, while the Neural Network model obtains the greatest F1-score of 0.79. The Gaussian Naive Bayes model achieved the highest recall score of 0.72, indicating that it was better at correctly identifying positive cases."
1092,"caption: Model performance based on different classification metricstable: Model,Accuracy,F1 Score,Recall, KNN,0.82,0.82,0.82, Decision Tree,0.75,0.65,0.72, Random Forest,0.86,0.86,0.86, SVM,0.90,0.90,0.89, Logistic Reg.,0.87,0.86,0.85","Table presents the model performance evaluation results based on multiple classification metrics, including Accuracy, F1 Score, and Recall. The models used for the evaluation were KNN, Decision Tree, Random Forest, SVM, and Logistic Regression, with accuracy between 0.75 and 0.90. SVM had the best overall accuracy of 0.90, while the KNN model demonstrates consistent results across all metric measures. Conversely, Decision Tree had the lowest accuracy of 0.75 and F1 Score of 0.65, while Random Forest model demonstrate uniform performance across all metric measures. In conclusion, the table highlights important observations of the model's classification accuracy based on different evaluation metrics; hence the choice of evaluation metrics used could influence the model selection process."
1093,"caption: Evaluation metrics for classification modelstable: Model,Precision,Recall,F1-Score,Accuracy, Logistic Regression,0.85,0.74,0.79,0.86, Decision Tree,0.82,0.68,0.72,0.83, K-Nearest Neighbors,0.78,0.58,0.65,0.80, Random Forest,0.89,0.82,0.85,0.90, Gradient Boosting,0.91,0.85,0.88,0.92","The table above compares the performance of five different classification models on different evaluation metrics, including precision, recall, F1-score, and accuracy. The models evaluated include Logistic Regression, Decision Tree, K-Nearest Neighbors, Random Forest, and Gradient Boosting. The results show that the Gradient Boosting model outperformed other models on all metrics, achieving the highest precision (0.91), recall (0.85), F1-Score (0.88), and accuracy (0.92). The Random Forest also achieved relatively high precision, recall, and F1-score, but with a slightly lower accuracy (0.90) than the Gradient Boosting. The Decision Tree and K-Nearest Neighbors models achieved lower performance on all four metrics. Overall, the Gradient Boosting model had the best performance across all evaluation metrics."
1094,"caption: Table 4: Model performance comparison on different evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.89,0.86,0.88,0.88, Logistic Regression,0.87,0.83,0.84,0.86, Random Forest,0.92,0.91,0.90,0.92, Neural Network,0.91,0.88,0.87,0.91","Table 4 shows the comparison of multiple models based on different evaluation metrics, including Accuracy, F1-Score, Precision, and Recall. SVM, logistic regression, random forest, and neural network models are evaluated using the same dataset, and their results are presented in the table. The Random Forest model shows the highest accuracy of 0.92, while the SVM model achieves the highest F1-Score of 0.86. Interestingly, the Neural Network model has the highest precision and recall scores of 0.87 and 0.91, respectively. Overall, the table helps compare and choose the best model based on different evaluation metrics."
1095,"caption: Table 4. Performance comparison of various models for binary classification.table: Model,Accuracy,F1 Score,Precision,Recall, Random Forest,0.92,0.91,0.93,0.89, SVM (linear),0.87,0.85,0.88,0.82, SVM (RBF),0.85,0.84,0.87,0.81, Decision Tree,0.86,0.83,0.86,0.81, KNN,0.80,0.79,0.81,0.77","Table 4 provides a comprehensive performance comparison of different models in binary classification. The table presents the accuracy, F1 score, precision, and recall of Random Forest, Support Vector Machine (SVM) with a linear kernel, SVM with the Radial Basis Function (RBF) kernel, Decision Tree, and K-Nearest Neighbors (KNN) models. The Random Forest model performs the best in all evaluation metrics with an accuracy of 0.92, F1 score of 0.91, precision of 0.93, and recall of 0.89. Meanwhile, the KNN model has the lowest performance with an accuracy of 0.80, F1 score of 0.79, precision of 0.81, and recall of 0.77. Overall, the table suggests that the Random Forest model may be the best choice for binary classification tasks in this domain."
1096,"caption: Performance comparison of different models with multiple evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.87,0.85,0.81,0.90, MLP,0.89,0.87,0.84,0.91, RF,0.90,0.89,0.85,0.93, KNN,0.83,0.81,0.79,0.83","The table compares different models' performance using multiple evaluation metrics such as Accuracy, F1 score, Precision, and Recall. The table includes SVM, MLP, RF, and KNN models and presents their respective Accuracy, F1 score, Precision, and Recall values. The RF (Random Forest) model illustrates the best performance in all four evaluation metrics with an Accuracy of 0.90, F1 score of 0.89, Precision of 0.85, and Recall of 0.93. The MLP (Multilayer Perceptron) model performed well with an Accuracy of 0.89, F1 score of 0.87, Precision of 0.84, and Recall of 0.91. However, the KNN (K-nearest neighbor) model shows relatively low performance compared to other models with an Accuracy of 0.83, F1 score of 0.81, Precision of 0.79, and Recall of 0.83."
1097,"caption: Performance of different models on evaluation metrics.table: Model,F1-Score,Precision,Recall,ROC-AUC,PR-AUC, Model 1,0.55,0.65,0.48,0.75,0.63, Model 2,0.60,0.73,0.52,0.78,0.65, Model 3,0.65,0.78,0.55,0.82,0.71, Model 4,0.56,0.71,0.45,0.79,0.59, Model 5,0.62,0.75,0.52,0.81,0.67",
1098,"caption: Table 4: Model Performance using Different Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1-Score, Model A,0.85,0.81,0.75,0.78, Model B,0.78,0.80,0.50,0.60, Model C,0.90,0.88,0.95,0.91, Model D,0.95,0.94,0.97,0.95","Table 4 shows the performance of four different models, identified as Models A, B, C, and D, measured against an Accuracy, Precision, Recall, and F1-Score metrics. Model A demonstrates the highest accuracy score of 0.85, whereas Model D has the highest scores for Precision, Recall, and F1-Score, with 0.94, 0.97, and 0.95, respectively. It can be observed that the best overall model performance can be determined by evaluating the different evaluation metrics used. Overall, the models show promising results, but Model D can be considered the best performer based on the evaluation metrics' score."
1099,"caption: Model Performance Metricstable: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.87,0.89,0.83,0.86, Random Forest,0.91,0.91,0.92,0.91, KNN,0.83,0.88,0.79,0.83, Decision Tree,0.81,0.78,0.80,0.79, SVM,0.89,0.87,0.91,0.89, Naive Bayes,0.84,0.82,0.86,0.84","Table presents the performance metrics of six different models for the classification task. The evaluation metrics include accuracy, precision, recall and F1 score. The results show that the performance of all the models are generally high. The Random Forest model had the highest accuracy of 0.91, followed by SVM with an accuracy of 0.89. However, Naive Bayes has the lowest accuracy of 0.84. Interestingly, the highest precision score is obtained by Logistic regression at 0.89 with KNN having the highest recall score of 0.79. Lastly, the F1 score shows Random Forest and SVM models perform similarly with the highest score of 0.91 and Naive Bayes having the lowest score of 0.84."
1100,"caption: Table 4: Model Evaluation Metrics of Different Classification Modelstable: Model Name,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.80,0.75,0.80,0.75, Decision Tree,0.75,0.70,0.75,0.65, Random Forest,0.87,0.83,0.90,0.85, Gradient Boosting,0.88,0.85,0.88,0.86, Support Vector Machine,0.78,0.72,0.78,0.72","Table 4 depicts the performance index of various classification models. Five models, Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Support Vector Machine, are evaluated based on the evaluation metrics: Accuracy, Precision, Recall, and F1-Score.  The highest accuracy score of 0.88 was shown by the Gradient Boosting model, while the Random Forest model exhibited the highest precision (0.83). On the other hand, the Random Forest attained the highest recall and F1-Score of 0.90 and 0.85, respectively. In contrast, the Decision Tree model had the lowest performance record across all indices."
1101,"caption: Comparison of Model Performance Using Different Evaluation Metricstable: Model,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.86,0.86,0.89,0.83, Decision Tree,0.81,0.78,0.76,0.81, Random Forest,0.90,0.90,0.91,0.91, Support Vector Machine,0.87,0.87,0.88,0.86, Gradient Boosting,0.91,0.91,0.94,0.88","Table presents a comparison of the accuracy, F1-score, precision, and recall values for five different classification models, namely Logistic Regression, Decision Tree, Random Forest, Support Vector Machine, and Gradient Boosting. The table indicates that Gradient Boosting performed the best, achieving an accuracy of 0.91, F1-score of 0.91, precision of 0.94, and recall of 0.88. Random Forest was the second-best model in terms of accuracy (0.90) and F1-score (0.90) but had the highest precision (0.91) and recall (0.91). On the other hand, Decision Tree was the worst-performing model, with accuracy and F1-score of 0.81 and 0.78, respectively."
1102,"caption: Performance of different models on classification task using multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, RandomForest,0.89,0.91,0.84,0.87, SVM,0.85,0.87,0.80,0.83, Naive Bayes,0.77,0.82,0.69,0.75, ANN,0.92,0.94,0.90,0.92, XGBoost,0.91,0.93,0.88,0.90","Table presents the results of five different models' accuracy, precision, recall, and F1-score on a classification task. The RandomForest model performed the best in terms of accuracy with 0.89, followed by XGBoost (0.91), ANN (0.92), SVM (0.85), and Naive Bayes (0.77). On the other hand, the ANN model achieved the highest precision with a score of 0.94, while SVM had the highest recall with a score of 0.80. Additionally, the RandomForest and XGBoost models had the highest F1-score of 0.87 and 0.90, respectively."
1103,"caption: Performance metrics of various classification models on the test dataset.table: Model,Accuracy,Precision,Recall,F1-Score,Cohen's Kappa, SVM,0.92,0.93,0.86,0.89,0.83, KNN,0.88,0.90,0.80,0.83,0.78, Decision Tree,0.79,0.81,0.69,0.70,0.56, Random Forest,0.94,0.94,0.91,0.92,0.89, Gradient Boosted,0.93,0.95,0.88,0.90,0.85","The table summarizes the performance metrics of five classification models on the test dataset. The models evaluated were SVM, KNN, Decision Tree, Random Forest, and Gradient Boosted. The performance of these classifiers was measured using five evaluation metrics: Accuracy, Precision, Recall, F1-Score, and Cohen's Kappa. The Random Forest and Gradient Boosted models displayed the highest Accuracy, Precision, Recall, F1-Score, and Cohen's Kappa scores. The Decision Tree model had the lowest performance scores among all models evaluated. Interestingly, the SVM model displayed the highest Precision score, and the KNN model exhibited the highest Cohen's Kappa score."
1104,"caption: Performance comparison of different models based on various evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.83,0.82,0.84,0.80, Decision Trees,0.72,0.68,0.64,0.72, Random Forest,0.85,0.84,0.86,0.82, Neural Network (NN1),0.79,0.76,0.75,0.77, Neural Network (NN2),0.86,0.84,0.84,0.85",
1105,"caption: Table 4: Model performance comparison based on evaluation metrics MAE, MSE, and R-squared.table: Model,MAE,MSE,R2, Linear reg,10.2,175.1,0.77, Poly reg,10.0,166.0,0.80, Ridge reg,9.9,162.6,0.81, Lasso reg,10.6,187.2,0.74, Elastic net,10.4,182.0,0.76","Table 4 compares the model performances of Linear regression, Polynomial regression, Ridge regression, Lasso regression, and Elastic net based on the evaluation metrics MAE (Mean Absolute Error), MSE (Mean Squared Error), and R2 (R-squared). These models were trained and tested on the same dataset. The table shows that Ridge regression achieved the lowest MAE and MSE with the values of 9.9 and 162.6, respectively, and the highest R-squared value of 0.81. On the other hand, Lasso regression had the highest MAE and Elastic net had the highest MSE."
1106,"caption: Model Performance Metrics Tabletable: Model,Accuracy,F1-score,Precision,Recall, SVM,0.79,0.78,0.81,0.79, Random Forest,0.85,0.84,0.86,0.85, KNN,0.75,0.74,0.77,0.75, Naive Bayes,0.81,0.80,0.82,0.81, DNN,0.87,0.86,0.88,0.87","The table shows the performance of different models based on evaluation metrics such as accuracy, F1-score, precision, and recall. The models compared in the table are SVM, Random Forest, KNN, Naive Bayes, and DNN. It is seen that the DNN model outperformed other models in all metrics, achieving an accuracy of 0.87 and F1-score of 0.86. The Random Forest model showed the second-best performance in all metrics. Interestingly, Naive Bayes model displayed comparable performance to other models in terms of accuracy and F1-score, but it had relatively lower precision and recall scores compared to other models."
1107,"caption: Table 1: Model evaluation metrics with different classification algorithms.table: Model,Accuracy,F1-score,Precision,Recall,AUC, SVM,0.91,0.91,0.87,0.95,0.97, KNN,0.83,0.82,0.78,0.87,0.91, LR,0.90,0.90,0.86,0.94,0.95, RF,0.94,0.93,0.90,0.97,0.98, DT,0.87,0.88,0.85,0.92,0.93","Table 1 compares the evaluation metrics of five different classification algorithms, including support vector machine (SVM), k-nearest neighbor (KNN), logistic regression (LR), random forest (RF), and decision tree (DT). The table presents the accuracy, F1-score, precision, recall, and AUC metrics for each algorithm on a common dataset. RF outperformed other models with the highest accuracy of 0.94, F1-score of 0.93, precision of 0.90, recall of 0.97, and AUC of 0.98. SVM had the highest AUC of 0.97, while LR and DT had the second highest accuracy and F1-score, respectively. KNN had the lowest accuracy, F1-score, and AUC among all models."
1108,"caption: Performance evaluation of various models using different metrics.table: Model,Accuracy,Precision,Recall,F1-Score,AUC-ROC, Baseline Model,0.80,0.63,0.70,0.66,0.79, Random Forest,0.85,0.73,0.78,0.76,0.83, XGBoost,0.84,0.72,0.76,0.74,0.81, Support Vector Machines (Linear),0.82,0.67,0.75,0.70,0.80, Naïve Bayes,0.79,0.56,0.78,0.65,0.76","The above table presents the performance evaluation results of different machine learning models, consisting of the baseline model, Random Forest, XGBoost, SVM (Linear), and Naïve Bayes, using multiple evaluation metrics. The evaluation metrics include accuracy, precision, recall, F1-Score, and AUC-ROC. The Random Forest model achieved the highest accuracy of 0.85 among all the models, while the Naïve Bayes model achieved the lowest accuracy of 0.79. However, the Naïve Bayes model achieved the highest recall of 0.78, while the baseline model had the highest precision of 0.63. XGBoost had the highest AUC-ROC score of 0.81, which indicates a good balance between true positive and false positive rates. Overall, these results demonstrate how different performance metrics can give different but complementary perspectives on the model's performance."
1109,"caption: Table 4: Model performance comparison based on multiple evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score,AUC, Model 1,0.85,0.78,0.79,0.77,0.91, Model 2,0.84,0.81,0.76,0.74,0.86, Model 3,0.87,0.85,0.86,0.84,0.93, Model 4,0.83,0.76,0.85,0.75,0.89, Model 5,0.88,0.89,0.83,0.85,0.92","Table 4 presents a comparison of different models based on multiple evaluation metrics, including Accuracy, Precision, Recall, F1-Score, and AUC. The table exhibits five models with varying performance results across all metrics. Model 5 achieved the highest accuracy score of 0.88, while also achieving the highest precision score of 0.89 and F1-score of 0.85. On the other hand, Model 1 achieved the highest AUC score of 0.91. Interestingly, Model 3 achieved the highest Precision, Recall, and F1-Score scores of 0.85, 0.86, and 0.84, respectively, with a close AUC score of 0.93. These results suggest that Model 3 is the best performing model among the five models based on the chosen evaluation metrics."
1110,"caption: Table 4: Evaluation Metrics Results for Different Modelstable: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.85,0.74,0.58,0.65, SVM,0.83,0.69,0.66,0.67, Random Forest,0.88,0.79,0.71,0.74, XGBoost,0.89,0.82,0.73,0.76",
1111,"caption: Table 4: Model performances based on different evaluation metricstable: Model,Accuracy,F1,Recall,Precision, Logistic Regression,0.84,0.79,0.82,0.78, Random Forest,0.87,0.84,0.85,0.88, Gradient Boosting,0.86,0.83,0.84,0.84, Support Vector Machine,0.82,0.77,0.76,0.81","Table 4 exhibits the accuracy, F1, recall, and precision scores for various models, including Logistic Regression, Random Forest, Gradient Boosting, and Support Vector Machine. All the models were evaluated using different metrics on the same dataset. The Random Forest model stands out as the best-performing model, achieving an accuracy of 0.87, F1 score of 0.84, recall score of 0.85, and precision of 0.88. The other models have slightly lower but competitive accuracy scores, with the lowest accuracy score is 0.82 achieved by Support Vector Machine. It is also interesting to note that the Logistic Regression model has the highest precision score of 0.78, while the Random Forest has the highest recall score of 0.85."
1112,"caption: Model performances based on different evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.85,0.88,0.76,0.81, Logistic Regression,0.8,0.74,0.92,0.81, Random Forest,0.79,0.81,0.75,0.78, K-NN,0.83,0.77,0.88,0.82, Naïve Bayes,0.77,0.67,0.98,0.8, Decision Tree,0.75,0.68,0.72,0.69","The table presents the model performances of six different models. The models' performance is evaluated based on the accuracy, precision, recall, and F1-Score metrics. The table shows that the SVM model performed the best in terms of accuracy, achieving an accuracy score of 0.85. The K-NN model had the highest precision with a score of 0.77, whereas Naïve Bayes had the highest recall score of 0.98. The Logistic Regression model achieved the highest F1-Score of 0.81. Furthermore, we observe that the Random Forest model shows a balance performance across different metrics."
1113,"caption: Model evaluation metrics for SVM, KNN, Bayes, DT, and MLP classifiers.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.89,0.90,0.82,0.85, KNN,0.82,0.80,0.86,0.81, Bayes,0.75,0.70,0.88,0.78, DT,0.80,0.83,0.74,0.78, MLP,0.92,0.92,0.91,0.91","Table presents the accuracy, precision, recall, and F1-Score of five different classifiers. Each classifier uses the same data set, and their performance is evaluated using the same evaluation metrics. The MLP classifier performed best overall, achieving an accuracy of 0.92, precision of 0.92, and recall of 0.91, and F1-Score of 0.91. The SVM classifier performs the best in accuracy with 0.89, while the KNN performs the best recall performance with 0.86. Interestingly, the Bayes classifier achieves the highest precision among all models, with a score of 0.70. Results show that the classifiers exhibit unique behaviour, with some models performing better in certain metrics than others."
1114,"caption: Performance results of different models using multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Model A,0.85,0.87,0.83,0.85, Model B,0.83,0.85,0.80,0.82, Model C,0.90,0.89,0.92,0.90, Model D,0.87,0.88,0.85,0.87","The table displays the performance results of four different models using multiple evaluation metrics, which include Accuracy, Precision, Recall, and F1 Score. Model A attained the highest Accuracy score of 0.85, with high Precision and Recall scores of 0.87 and 0.83, respectively. Model C achieved the highest score for Precision (0.89) and Recall (0.92) and the second-highest Accuracy (0.90). Overall, Model C has the highest F1 score of 0.90, with a balanced combination of Precision and Recall scores. Conversely, Model B has the lowest Accuracy (0.83) and F1 score (0.82), whereas Model D is relatively similar to Model A in terms of performance."
1115,"caption: Comparison of performance metrics for different models on a binary classification task.table: Model,Accuracy,Precision,Recall,F1-score, RF,0.927,0.937,0.891,0.913, SVC,0.889,0.867,0.844,0.856, LogReg,0.900,0.881,0.870,0.856, KNN,0.875,0.865,0.818,0.820","The table presents results for different models on a binary classification task. The models compared include Random Forest (RF), Support Vector Classifier (SVC), Logistic Regression (LogReg), and K-Nearest Neighbors (KNN). Four evaluation metrics were used to assess model performances, these include Accuracy, Precision, Recall, and F1-score. Results show that the RF model performs overall better with the highest accuracy of 0.927, highest precision of 0.937, and highest F1-score of 0.913. However, the LogReg model has the highest recall value of 0.870. The KNN model, on the other hand, has the lowest accuracy, precision, and F1-score."
1116,"caption: Table 4: Model performance evaluation using different evaluation metrics.table: Model Name,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.825,0.75,0.74,0.77, Decision Tree,0.780,0.69,0.72,0.68, Random Forest,0.867,0.80,0.87,0.76, XGBoost,0.893,0.85,0.86,0.87, Neural Network,0.912,0.88,0.87,0.96","Table 4 presents the accuracy, F1-Score, Precision, and Recall of different models trained on a single dataset. The models evaluated are Logistic Regression, Decision Tree, Random Forest, XGBoost, and Neural Network. Among all models, the Neural Network model performed the best with an impressive accuracy score of 0.912. The XGBoost and Random forest models also performed well, achieving high accuracy scores of 0.893 and 0.867, respectively. Although the Logistic Regression and Decision Tree models' accuracy scores are lower than the other models, they achieved competitive results while still being computationally inexpensive. The F1-Score, Precision, and Recall benchmarks show that the Neural Network model achieved the highest scores consistently across all three evaluation metrics. Overall, Table 4 highlights the usefulness of utilizing diversified evaluation metrics beyond instance accuracy in evaluating machine learning model performance."
1117,"caption: Table 4: Comparison of different classification models based on F1-Score, Precision, Recall, and Accuracy.table: Model Name,F1-Score,Precision,Recall,Accuracy, Logistic Regression,0.78,0.80,0.76,0.82, Random Forest,0.81,0.84,0.79,0.84, Decision Tree,0.74,0.80,0.70,0.78, Gradient Boosting,0.84,0.87,0.82,0.85, K-NN,0.76,0.78,0.74,0.77","In Table 4, we compare the performance of different classification models based on evaluation metrics: F1-Score, Precision, Recall, and Accuracy. The table shows the performance results of Logistic Regression, Random Forest, Decision Tree, Gradient Boosting, and K-NN models. Interestingly, Gradient Boosting achieves the best F1-score, Precision, and Recall scores of 0.84, 0.87, and 0.82, respectively. In contrast, the Random Forest model has the best accuracy score of 0.84. The Decision Tree model appears to be the weakest model based on all the evaluation metrics."
1118,"caption: Model performance based on multiple evaluation metricstable: Model,Accuracy,F1-Score,Precision,Recall, A,0.92,0.89,0.92,0.87, B,0.86,0.81,0.85,0.83, C,0.94,0.91,0.93,0.89, D,0.90,0.87,0.88,0.86, E,0.88,0.83,0.84,0.82, F,0.95,0.92,0.94,0.90","The table above presents the accuracy, F1-Score, precision, and recall scores for six different models (A-F). Model C achieves the highest performance in all evaluation metrics with an accuracy score of 0.94, F1-Score of 0.91, precision score of 0.93, and recall score of 0.89. Model F follows as the second-best performer, with an accuracy score of 0.95, F1-Score of 0.92, precision score of 0.94, and recall score of 0.90. Interestingly, model A achieves the highest accuracy score of 0.92, while model C achieved the best scores for F1-Score, precision, and recall. Overall, the table provides insight into the relative performance of different models based on an array of evaluation metrics."
1119,"caption: Comparison of different models' performance based on accuracy, precision, recall, and F1-score.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.92,0.92,0.91,0.91, Logistic Regression,0.88,0.89,0.87,0.87, K-Nearest Neighbors,0.85,0.88,0.84,0.83, Random Forest,0.95,0.95,0.96,0.95, XGBoost,0.97,0.97,0.97,0.97","The table presents an overview of various models' performance based on accuracy, precision, recall, and F1-score. The models include SVM, Logistic Regression, K-Nearest Neighbors, Random Forest, and XGBoost. The results showcase that the Random Forest and XGBoost models demonstrate the best overall performance across all evaluation metrics. Notably, the XGBoost model achieves the highest accuracy, precision, recall and F1-score with a score of 0.97 for each metric, while the SVM model offers competitive performance with 0.92 accuracy, precision, recall and F1-score. Meanwhile, the K-Nearest Neighbors model shows the weakest performance with an accuracy score of 0.85 and an F1 score of 0.83."
1120,"caption: Performance Metrics of Different Classification Models on Test Settable: Model,Accuracy,F1 Score,Precision,Recall,AUC Score, Logistic Regression,0.80,0.78,0.82,0.75,0.87, Random Forest,0.82,0.80,0.83,0.78,0.90, Support Vector Machine,0.78,0.76,0.80,0.72,0.85, Neural Network,0.85,0.83,0.87,0.80,0.91, Decision Tree,0.79,0.76,0.81,0.73,0.86","The table presents the performance of different classification models on the test set evaluated using various metrics. The metrics used are Accuracy, F1 Score, Precision, Recall, and AUC Score. The highest accuracy is achieved by the Neural Network with a score of 0.85, and the Random Forest model achieves the highest AUC score of 0.90. Notably, the Logistic Regression and Random Forest models outperform other models in various metrics. Overall, the table suggests that the Random Forest and Neural Network models could be a good choice for classification tasks based on the evaluation metrics."
1121,"caption: Table 4: Model performance based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.83,0.84,0.73,0.77, KNN,0.78,0.80,0.67,0.71, DT,0.82,0.80,0.78,0.79, RF,0.88,0.91,0.81,0.85, MLP,0.91,0.92,0.88,0.90","Table 4 compares five different models' performance based on various evaluation metrics such as Accuracy, Precision, Recall, and F1-score. SVM, KNN, DT, RF, and MLP are the models evaluated in this table. The MLP model performs the best across all the metrics with an accuracy score of 0.91, precision score of 0.92, recall score of 0.88, and F1-score of 0.90. RF was also observed to perform well, with an accuracy of 0.88 and a precision score of 0.91. However, for recall and F1-score, MLP clearly outperformed all other models."
1122,"caption: Performance results of Model 1, Model 2, and Model 3 based on multiple evaluation metrics.table: Metric,Model 1,Model 2,Model 3, Accuracy,0.745,0.812,0.826, F1 Score,0.62,0.78,0.83, Precision,0.75,0.72,0.89, Recall,0.54,0.89,0.76, AUC,0.77,0.81,0.86","Table presents the performance results of Model 1, Model 2, and Model 3 based on different evaluation metrics. The models were trained and tested on the same dataset. The metrics included Accuracy, F1 Score, Precision, Recall, and AUC. Model 3 shows the highest accuracy of 0.826, and Model 2 has the highest F1 score of 0.78. Interestingly, Model 1 has the highest precision of 0.75, and Model 2 has the highest recall of 0.89. Finally, Model 3 has the highest AUC score of 0.86. Overall, the table provides a comprehensive view of the performance of the different models based on the multiple evaluation metrics."
1123,"caption: Table 4: A comparison of model performance using different evaluation metrics.table: Models,Precision,Recall,F1 score,AUC,Accuracy, ModelA,0.89,0.92,0.90,0.87,0.83, ModelB,0.92,0.95,0.93,0.91,0.87, ModelC,0.89,0.93,0.91,0.88,0.84, ModelD,0.93,0.98,0.95,0.92,0.89, ModelE,0.87,0.90,0.88,0.86,0.84","Table 4 presents a comparison of the performance of multiple models. The evaluation metrics used in the table include; Precision, Recall, F1 score, AUC, and Accuracy. The table compares the performance of ModelA, ModelB, ModelC, ModelD, and ModelE. Notably, ModelD shows the best performance across the metrics, with the highest Precision score of 0.93, Recall score of 0.98, F1 score of 0.95, AUC of 0.92, and Accuracy of 0.89. ModelB also shows relatively good performance results across the metrics, with Precision, Recall, F1 scores, AUC, and Accuracy scores close to ModelD. Alternatively, ModelE shows the weakest performance of the models in the table."
1124,"caption: Comparison of different Machine Learning Models in terms of accuracy, F1 score, Precision and Recall.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.874,0.832,0.827,0.839, Random Forest,0.909,0.892,0.893,0.891, Support Vector Machine,0.888,0.864,0.857,0.872, K-Nearest Neighbor,0.846,0.781,0.774,0.789, Gradient Boosting,0.907,0.885,0.883,0.890","The table presents the comparison of five machine learning models' performance based on accuracy, F1-score, precision, and recall evaluation metrics. The table shows that the Random Forest model outperforms all other models with an accuracy score of 0.909, F1-Score of 0.892, Precision of 0.893, and Recall of 0.891. Gradient Boosting is the second-best model with an accuracy score of 0.907, making it a strong competitor to the Random Forest model. Meanwhile, K-Nearest Neighbor's model shows the weakest performance, scoring last based on the four evaluation metrics."
1125,"caption: Comparison of model performances based on accuracy, F1 score, precision, recall, and AUC.table: Model,Accuracy,F1 Score,Precision,Recall,AUC, Logistic Regression,0.89,0.77,0.82,0.74,0.95, Random Forest,0.93,0.83,0.86,0.81,0.97, Support Vector Machine,0.91,0.79,0.84,0.76,0.96, Neural Network,0.92,0.80,0.86,0.75,0.95, Naive Bayes,0.87,0.70,0.76,0.65,0.93","The table compares the model performances based on different evaluation metrics such as accuracy, F1 score, precision, recall, and AUC. The table includes Logistic Regression, Random Forest, SVM, Neural Network, and Naive Bayes models. Interestingly, the Random Forest model exhibited the highest accuracy of 0.93, followed closely by the Neural Network model, which had an accuracy of 0.92. The Naive Bayes model showed the lowest accuracy of 0.87. In terms of the F1 score, the Random Forest model showed the highest score of 0.83, while the Naive Bayes model recorded the lowest F1 score of 0.70. The Random Forest model also had the highest precision and recall score at 0.86 and 0.81, respectively. The highest AUC score was observed from the Random Forest model at 0.97. Overall, the Random Forest model demonstrates the best performance across all evaluation metrics."
1126,"caption: Model performance comparison on the test dataset based on different metrics.table: Model Name,Accuracy,Precision,Recall,F1-Score,AUC, Logistic Regression,0.69,0.80,0.56,0.66,0.75, Support Vector Classifier,0.70,0.75,0.64,0.69,0.72, Random Forest,0.76,0.83,0.70,0.76,0.82, XGBoost,0.78,0.84,0.73,0.78,0.83, Multi-layer Perceptron (MLP),0.68,0.79,0.56,0.66,0.71","The table highlights the performance of different models, including Logistic Regression, Support Vector Classifier (SVC), Random Forest, XGBoost, and Multi-layer Perceptron (MLP). The evaluation metrics, such as Accuracy, Precision, Recall, F1-Score, and AUC, were used to assess the models' performances on the test dataset. Notably, Random Forest and XGBoost achieved the highest accuracy scores of 0.76 and 0.78, respectively, while MLP obtained the lowest score of 0.68. Furthermore, XGBoost and Random Forest achieved the highest Precision scores of 0.84 and 0.83, respectively, whereas Logistic Regression obtained the lowest score of 0.80. Interestingly, SVC and XGBoost obtained the highest Recall scores of 0.64 and 0.73, respectively, while MLP achieved the lowest score of 0.56. Additionally, XGBoost and Random Forest obtained the highest F1-Score scores of 0.78 and 0.76, respectively, while MLP showed the lowest score of 0.66. Finally, the AUC scores of the models ranged from 0.71 (MLP) to 0.83 (XGBoost)."
1127,"caption: Table 4: Comparison of various models based on accuracy, recall, F1-score, and precisiontable: Model name,Accuracy,Recall,F1-score,Precision, Logistic Reg.,0.905,0.843,0.872,0.904, SVM,0.895,0.844,0.860,0.884, Random Forest,0.912,0.863,0.886,0.909, KNN,0.881,0.834,0.844,0.871, XGBoost,0.910,0.869,0.884,0.907","Table 4 demonstrates a comparison of various machine learning models based on four evaluation metrics: accuracy, recall, F1-score, and precision. The models are Logistic Regression, SVM, Random Forest, KNN, and XGBoost. Notably, the Random Forest model shows the highest accuracy (0.912), while XGBoost achieved the highest recall (0.869) and precision (0.907). However, the F1-score of Random Forest outperformed all the models with a score of 0.886. Interestingly, Logistic Regression surprisingly achieved competitive scores in all four evaluation metrics."
1128,"caption: Performance comparison of different models on the classification task.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.92,0.93,0.94,0.93, Random Forest,0.86,0.86,0.83,0.84, XGBoost,0.89,0.87,0.87,0.87, K-NN,0.82,0.84,0.79,0.79, Naive Bayes,0.77,0.75,0.80,0.76","The above table illustrates the performance metrics such as accuracy, precision, recall, and F1-score of various models in a classification task. Five models, namely SVM, Random Forest, XGBoost, K-NN, and Naive Bayes, were evaluated on the same dataset. The best accuracy score of 0.92 is achieved by the SVM model, while the Naive Bayes model has the lowest accuracy score of 0.77. The Random Forest model shows the highest precision of 0.86, and the highest recall of 0.94 is achieved by the SVM model. Overall, the results indicate that SVM and Random Forest models perform well in this classification task."
1129,"caption: Table 4: Various models' performance in classification of sentiment analysis.table: Model,Accuracy,F1-Score,Precision,Recall, CNN,0.81,0.78,0.77,0.80, DNN-1,0.76,0.67,0.68,0.67, DNN-2,0.77,0.71,0.69,0.73, SVM,0.79,0.73,0.72,0.74, LogReg,0.75,0.65,0.67,0.62","Table 4 showcases models' classification performance in sentiment analysis using various evaluation metrics. The table presents the Accuracy, F1-Score, Precision, and Recall results of five different models - CNN, DNN-1, DNN-2, SVM, and LogReg. Among these models, the CNN and SVM models tend to perform better than other models in terms of accuracy, having achieved 0.81 and 0.79 respectively. The DNN-2 model achieved the highest F1-Score of 0.71. Interestingly, the LogReg model was the weakest in all of the evaluation metrics, recording the lowest accuracy, F1-Score, Precision, and Recall scores of 0.75, 0.65, 0.67, and 0.62, respectively. Nonetheless, it is important to note that these models were trained and tested on the same dataset."
1130,"caption: Table 4: Model performance based on different evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.87,0.85,0.88,0.86, Random Forest,0.91,0.92,0.89,0.91, Logistic Regression,0.88,0.84,0.89,0.86, Decision Tree,0.83,0.79,0.83,0.81, Gradient Boosting,0.93,0.94,0.92,0.93","The table displays the model performances of five machine learning algorithms based on different evaluation metrics. The algorithms include SVM, Random Forest, Logistic Regression, Decision Tree, and Gradient Boosting. The evaluation metrics used are Accuracy, Precision, Recall, and F1-Score. Interestingly, Gradient Boosting has the highest performance across all evaluation metrics, where it had the highest accuracy of 0.93, precision of 0.94, recall of 0.92, and F1-Score of 0.93. On the other hand, Decision Tree had the lowest performance scores across all evaluation metrics, whereas the other models' scores were relatively close."
1131,"caption: Model Performance Metrics using Various Classification Algorithmstable: Model,F1-score,Accuracy,Precision Score,Recall Score, SVM,0.89,0.90,0.91,0.87, KNN,0.84,0.86,0.80,0.89, Random Forest,0.91,0.92,0.94,0.88, Naive Bayes,0.79,0.82,0.82,0.77, AdaBoost,0.88,0.89,0.88,0.90","Table presents a comparison of the classification model's performance using different evaluation metrics. The table contains performance results of different classification algorithms, including SVM, KNN, Random Forest, Naive Bayes, and AdaBoost. The model performances are evaluated based on the F1-score, Accuracy, Precision Score, and Recall Score. Notably, the Random Forest model produced the highest F1-score and Accuracy at 0.91 and 0.92, respectively. However, AdaBoost outperformed all models in terms of Recall Score with a score of 0.90. Interestingly, the Naive Bayes model achieved the lowest F1-score at 0.79. Overall, the table provides a comprehensive view of several classification models' performance using different evaluation metrics."
1132,"caption: Table 4: Comparison of classification models' performance using various evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.76,0.71,0.81,0.63, KNN,0.69,0.64,0.67,0.62, DT,0.72,0.67,0.71,0.63, RF,0.81,0.77,0.82,0.72","Table 4 exhibits the performance of four classification models: Support Vector Machine (SVM), k-Nearest Neighbor (KNN), Decision Tree (DT), and Random Forest (RF), evaluated using different metrics. The metrics presented in the table are Accuracy, F1-score, Precision, and Recall. The table highlights that the RF model exhibits the highest Accuracy, F1-Score, and Precision, with a score of 0.81, 0.77, and 0.82, respectively. However, the SVM model shows the highest Recall score of 0.63. The KNN model exhibits the lowest Accuracy, F1-Score, and Precision, with a score of 0.69, 0.64, and 0.67, respectively. In conclusion, among the four models compared, the RF model performs the best on all metrics except Recall, where SVM outperforms."
1133,"caption: Table 4: Model evaluation using different evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.87,0.88,0.85,0.86, Random Forest,0.83,0.85,0.78,0.81, Naive Bayes,0.72,0.62,0.90,0.73, ANN,0.90,0.93,0.87,0.89","Table 4 presents the performance evaluation results of various models using different evaluation metrics. The table shows accuracy, precision, recall, and F1-score results for SVM, Random Forest, Naive Bayes, and ANN models. Notably, ANN achieved the highest accuracy of 0.90, precision of 0.93, and F1-score of 0.89. On the other hand, Naive Bayes model shows the highest recall of 0.90. Overall, the results demonstrate the ANN model's superior performance against other models, although the Naive Bayes model achieved the highest recall among all models."
1134,"caption: Table 4: Performance comparison of different classification models based on multiple evaluation metrics.table: ```, Model,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.86,0.87,0.84,0.91, Random Forest,0.89,0.91,0.87,0.94, Gradient Boosting,0.89,0.91,0.88,0.94, Naive Bayes,0.82,0.83,0.84,0.83, Support Vector Machine,0.88,0.90,0.86,0.94","Table 4 presents a performance comparison of different classification models based on multiple evaluation metrics, which include Accuracy, F1-Score, Precision, and Recall. The table displays the results of the Logistic Regression, Random Forest, Gradient Boosting, Naive Bayes, and Support Vector Machine (SVM) models. SVM achieved the highest Recall score of 0.94, while Random forest and Gradient boosting models had the highest F1-Score and Precision scores of 0.91 and 0.87, respectively. Nonetheless, based on the overall performance, the Random Forest model got the highest accuracy score of 0.89."
1135,"caption: Table 4: Evaluation metrics of different models based on accuracy, recall, precision, and F1-scoretable: Model,Accuracy,Recall,Precision,F1 Score, Model 1,0.81,0.70,0.82,0.75, Model 2,0.85,0.80,0.78,0.79, Model 3,0.89,0.85,0.90,0.87, Model 4,0.83,0.76,0.84,0.79, Model 5,0.92,0.92,0.90,0.91","Table 4 illustrates the performance comparison of 5 different models. The table presents evaluation metrics based on accuracy, recall, precision, and F1-score. Model 5 demonstrates the best accuracy result of 0.92, while Model 3 shows the best recall and precision results of 0.85 and 0.90, respectively. Interestingly, Model 2 presents a slightly better precision result than recall, which makes it stand out from others. Model 1 and Model 4 follow similar trends in all evaluation metrics with the lowest performance among all models. Overall, Model 5 seems to have the most stable performance across all evaluation metrics."
1136,"caption: Table 4: Classification results for multiple models based on different evaluation metricstable: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.92,0.89,0.92,0.86, KNN,0.86,0.78,0.82,0.75, RF,0.95,0.92,0.95,0.89, GNB,0.78,0.65,0.72,0.61, MLP,0.94,0.91,0.94,0.89","Table 4 shows the classification results of multiple models using different evaluation metrics. The table shows the accuracy, F1 score, precision, and recall of five different models, namely Support Vector Machine (SVM), k-Nearest Neighbor (KNN), Random Forest (RF), Gaussian Naive Bayes (GNB), and Multi-layer Perceptron (MLP). It is apparent from the results that the RF model performs the best across all evaluation metrics with an accuracy of 0.95, F1 score of 0.92, precision of 0.95, and recall of 0.89. The SVM model comes next with an accuracy of 0.92, F1 score of 0.89, precision of 0.92, and recall of 0.86. The MLP model also performed well with an accuracy of 0.94, F1 score of 0.91, precision of 0.94, and recall of 0.89. The KNN and GNB models performed significantly worse than the other models, with accuracies of 0.86 and 0.78, respectively."
1137,"caption: Table 4. Performance metrics of different machine learning models on the classification task.table: Model,Precision,Recall,F1-Score,Accuracy, SVM,0.82,0.86,0.84,0.85, Random Forest,0.88,0.89,0.88,0.89, Neural Network,0.85,0.87,0.86,0.86, Decision Tree,0.79,0.80,0.80,0.80, Logistic Regression,0.87,0.89,0.88,0.88","Table 4 presents the performance metrics of five different machine learning models, including Support Vector Machine (SVM), Random Forest, Neural Network, Decision Tree, and Logistic Regression, on a classification task. The evaluation metrics include Precision, Recall, F1-Score, and Accuracy computed using the same dataset. The Random Forest model shows the best performance in all the metrics except Precision, achieving the best Accuracy of 0.89, Recall of 0.89, and F1-Score of 0.88. However, Logistic Regression achieved the best Precision of 0.87.  Overall, the results suggest that Random Forest may be a better model for this classification problem."
1138,"caption: Model performances based on different evaluation metricstable: Model Name,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.87,0.68,0.71,0.68, Decision Tree,0.78,0.60,0.58,0.59, Random Forest,0.93,0.80,0.87,0.83, Support Vector Machine,0.88,0.70,0.75,0.73, Gradient Boosting,0.91,0.75,0.82,0.76","The table presents the model performances of Logistic Regression, Decision Tree, Random Forest, Support Vector Machine, and Gradient Boosting based on different evaluation metrics, including Accuracy, Precision, Recall, and F1-Score. The table shows the superiority of the Random Forest model concerning all evaluation matrices, achieving the highest accuracy, precision, recall, and F1-Score of 0.93, 0.80, 0.87, and 0.83, respectively. Interestingly, the Gradient Boosting model performs the second-best with an accuracy of 0.91 and F1-Score of 0.76, although it has a lower precision and recall compared to the Support Vector Machine and Logistic Regression models."
1139,"caption: Performance evaluation of different models based on precision, recall, F1-score and AUC.table: Models,Precision,Recall,F1-score,AUC, A,0.92,0.87,0.89,0.68, B,0.85,0.90,0.87,0.75, C,0.91,0.79,0.84,0.71, D,0.77,0.95,0.85,0.81, E,0.83,0.85,0.81,0.69, F,0.68,0.62,0.65,0.52","The above table provides the performance of six models, labelled A to F, based on four evaluation metrics; Precision, Recall, F1-score, and AUC. The models were tested on the same dataset. Notably, Model A achieved the highest Precision score of 0.92 and the second-highest Recall score of 0.87. Model D showed the highest Recall score of 0.95, while Model B demonstrated the highest F1-score of 0.87. Model B also had the highest AUC score of 0.75, followed by Model D with an AUC score of 0.81. Interestingly, Model F demonstrated the lowest performance scores across all evaluation metrics."
1140,"caption: Model performance for different classification models using multiple evaluation metrics.table: Model,Accuracy,F1-score,AUC-score, SVM,0.875,0.852,0.923, KNN,0.891,0.873,0.908, RF,0.917,0.907,0.943, XGB,0.912,0.902,0.939","This table presents the performance of different classification models, including SVM, KNN, Random Forest (RF), and XGBoost (XGB), using multiple evaluation metrics. The evaluation metrics involved are accuracy, F1-score, and AUC-score. The classification models were tested on the same dataset. The results show that the RF model performed the best with an accuracy of 0.917, F1-score of 0.907, and AUC-score of 0.943. XGB also demonstrated good performance with an accuracy of 0.912 and F1-score of 0.902. The SVM and KNN models both had reasonable results, scoring over 85% for all evaluation metrics."
1141,"caption: Table 4 - Model performance based on multiple evaluation metrics.table: Model,Accuracy,PR-AUC,F1-Score, SVM,0.89,0.86,0.75, RF,0.91,0.87,0.78, LG,0.88,0.82,0.70, MLP,0.90,0.88,0.80","Table 4 presents the model performances based on multiple evaluation metrics. The table shows four different models, namely Support Vector Machine (SVM), Random Forest (RF), Logistic Regression (LG), and Multi-Layer Perceptron (MLP). The evaluation metrics used are Accuracy, PR-AUC, and F1-Score. The best performance is achieved by the RF model in all metrics with an accuracy of 0.91, PR-AUC of 0.87, and F1-Score of 0.78. MLP also performed well and achieved the highest PR-AUC of 0.88. Thus, the table suggests that RF and MLP are the best models for the given dataset based on multiple evaluation metrics."
1142,"caption: Comparison of different models using MAE, RMSE, and R-squared.table: Model,MAE,RMSE,R-squared, Linear Regression,3.42,5.21,0.78, Decision Tree,3.13,4.78,0.82, Random Forest,2.70,4.01,0.89, Gradient Boosting,2.83,4.36,0.87","The table above compares different models' performance based on different evaluation metrics, including MAE, RMSE, and R-squared. The four models evaluated are Linear Regression, Decision Tree, Random Forest, and Gradient Boosting. Notably, Random Forest achieves the best performance in all metrics, obtaining the least MAE score of 2.70, the least RMSE score of 4.01, and the highest R-squared score of 0.89. In contrast, Linear Regression model gives the highest MAE of 3.42 and RMSE of 5.21 and the lowest R-squared of 0.78. However, Decision Tree model shows a slightly better performance than the Linear Regression, while Gradient Boosting lies between Decision Tree and Random forest with respect to performance."
1143,"caption: Table 4: Model performance comparison based on accuracy, F1 score, and AUC.table: Model,Accuracy,F1 Score,AUC, A,0.80,0.79,0.89, B,0.82,0.85,0.86, C,0.85,0.81,0.92, D,0.79,0.77,0.88, E,0.78,0.84,0.90","Table 4 compares the performance of five different models based on accuracy, F1 score, and AUC evaluation metrics. Notably, Model C exhibits the highest accuracy of 0.85, which is closely followed by Model B with an accuracy of 0.82. The highest F1 score is acquired by Model B with 0.85, followed by Model E with a score of 0.84. The model with the highest AUC in the table is Model C with a score of 0.92, while the remaining models have AUC scores ranging between 0.86 to 0.90. Overall, this table demonstrates that each model performs differently based on different evaluation metrics."
1144,"caption: Performance of Different Models on Evaluation Metricstable: Model,Accuracy,F1-Score,Precision,Recall, Random Forest,0.95,0.95,0.96,0.94, Naive Bayes,0.89,0.85,0.92,0.79, Support Vector Machine,0.93,0.92,0.93,0.91, Multilayer Perceptron,0.91,0.90,0.91,0.89","The table presents the performance of four different models based on multiple evaluation metrics. The evaluation metrics include Accuracy, F1-Score, Precision, and Recall. The Random Forest model performed the best with an Accuracy score of 0.95, F1-Score of 0.95, Precision of 0.96, and Recall of 0.94. Interestingly, although the Naive Bayes model had the lowest Accuracy score of 0.89, it achieved the second-best Precision score of 0.92, implying that it performed relatively better at identifying True Positives. Overall, the Random Forest model outperformed the other models on all evaluation metrics, followed by Support Vector Machine and Multilayer Perceptron models."
1145,"caption: Table 4: Model evaluation metrics and results for different classification methodstable: Model,Accuracy,Recall,Precision,F1 Score, Logistic Regression,0.85,0.82,0.89,0.85, Decision Tree,0.77,0.72,0.78,0.75, K-NN,0.73,0.68,0.76,0.71, Naïve Bayes,0.81,0.76,0.85,0.79, Random Forest,0.91,0.88,0.93,0.90, Gradient Boosting,0.90,0.86,0.92,0.89","Table 4 compares multiple classification models’ performances based on various evaluation metrics. The models in the table are Logistic Regression, Decision Tree, K-NN, Naïve Bayes, Random Forest, and Gradient Boosting. The models are evaluated based on their accuracy, recall, precision, and F1 score. Notably, the Random Forest classification method achieved the highest accuracy and precision score of 0.91 and 0.93, respectively. On the other hand, the Decision Tree classification method achieved the lowest accuracy and F1 Score of 0.77 and 0.75, respectively. Finally, the Logistic Regression performed relatively well, with an accuracy score of 0.85 and a recall score of 0.82."
1146,"caption: The table presents the performance of different models with multiple evaluation metrics. The evaluation metrics include precision, recall, F1 score, and ROC-AUC. All models were trained and tested using the same dataset.table: Model,Precision,Recall,F1 Score,ROC-AUC, Logistic Regression,0.864,0.828,0.846,0.761, Decision Tree,0.877,0.82,0.846,0.735, Random Forest,0.942,0.935,0.938,0.89, SVM,0.926,0.85,0.879,0.761, MLP,0.928,0.93,0.929,0.868","Table presents the performance of five different models: Logistic Regression, Decision Tree, Random Forest, SVM, and MLP. The table demonstrates four evaluation metrics for each model: precision, recall, F1 score, and ROC-AUC. Notably, the Random Forest model achieved the highest precision, recall, F1 score of 0.942, 0.935, and 0.938, respectively. The MLP model also achieved high performance results, with a precision of 0.928 and recall of 0.93. Interestingly, the Logistic Regression model had the fewest F1 score and ROC-AUC values of the five models, while the SVM model had the lowest recall."
1147,"caption: Comparison of Model Performances Using Different Evaluation Metricstable: Model,Precision,Recall,F1-Score,Accuracy, SVM,0.87,0.90,0.88,0.89, KNN,0.80,0.85,0.82,0.83, LR,0.84,0.92,0.87,0.87, RF,0.89,0.86,0.88,0.90, DT,0.79,0.81,0.80,0.84","The table presents a comparison of different models' performances based on multiple evaluation metrics such as precision, recall, F1-score, and accuracy. The SVM model achieved the highest precision of 0.87 and recall of 0.90, followed closely by the RF model with precision of 0.89 and accuracy of 0.90. Meanwhile, the logistic regression (LR) model achieved the highest accuracy of 0.87 and F1-score of 0.87, showing relatively competitive performance compared to other models. Interestingly, the decision tree (DT) model had the lowest precision of 0.79 but reasonable accuracy of 0.84 and F1-score of 0.80."
1148,"caption: Table 4: Classifier performances based on precision, recall, f1-score, and accuracy.table: Model,Precision,Recall,F1 Score,Accuracy, Random Forest,0.82,0.84,0.83,0.82, Support Vector,0.78,0.84,0.81,0.79, Logistic Regression,0.77,0.75,0.76,0.76, Decision Tree,0.79,0.77,0.78,0.77","Table 4 presents the evaluation results of four different machine learning classifiers based on four different evaluation metrics, namely precision, recall, f1-score, and accuracy. The table shows that the Random Forest model achieved the highest precision and recall scores of 0.82 and 0.84, respectively. On the other hand, the Decision Tree model resulted in the highest F1-Score and accuracy of 0.78 and 0.77. Interestingly, the Support Vector model had a high precision score but a relatively low accuracy score, while Logistic Regression showed a relatively even performance across all metrics. Overall, it is vital to select an appropriate evaluation metric to choose the most accurate classifier for a specific application."
1149,"caption: Model performance comparison based on F1 score, Matthews correlation coefficient (MCC), and AUC-ROC.table: Models,F1-score,Matthews correlation coefficient (MCC),AUC-ROC, Logistic regression,0.65,0.294,0.742, Linear SVM,0.69,0.335,0.759, Decision tree,0.64,0.288,0.715, Random forest,0.73,0.377,0.788, XGBoost,0.68,0.324,0.769","The table presents a comparison of different machine learning models, Logistic regression, Linear SVM, Decision tree, Random forest, and XGBoost, evaluated on three different performance metrics, F1-score, Matthews correlation coefficient, and AUC-ROC. The Random forest model outperformed the other models, achieving the highest F1-score of 0.73, MCC score of 0.377 and AUC-ROC score of 0.788. The Linear SVM model also showed a higher F1-score of 0.69 and AUC-ROC score of 0.759. However, the Random forest model still demonstrated better MCC score of 0.377. The Logistic regression, Decision tree, and XGBoost models had F1-scores within the range of 0.64-0.68, MCC scores within the range of 0.288-0.335, and AUC-ROC scores within the range of 0.715-0.769."
1150,"caption: Table 4: Comparison of different models' F1 score, MAE, and RMSEtable: Model,F1 Score,MAE,RMSE, Model 1,0.80,0.13,1.25, Model 2,0.76,0.25,1.32, Model 3,0.72,0.21,1.12, Model 4,0.78,0.23,1.18, Model 5,0.85,0.18,1.29","The table presents a comparison of multiple models based on their F1 score, Mean Absolute Error (MAE), and Root Mean Square Error (RMSE). The F1 score represents the harmonic mean of the Precision and Recall metrics. Model 5 achieved the highest F1 score among the models with a score of 0.85. Model 1 achieved the highest MAE with a score of 0.13, while Model 3 had the lowest one with a score of 0.21. Regarding RMSE, Model 3 performed the best with the lowest score of 1.12, while Model 2 had the highest score of 1.32. The table shows that different metrics produce different results, which further emphasizes the importance of selecting multiple metrics when evaluating models."
1151,"caption: Model Performance Evaluation Metrics for different Classification Modelstable: Model,Accuracy,F1 Score,Precision,Recall,AUC, Logistic Regress.,0.78,0.71,0.68,0.74,0.808, Naive Bayes,0.74,0.61,0.65,0.58,0.789, SVM,0.80,0.74,0.70,0.78,0.825, Random Forest,0.83,0.79,0.76,0.83,0.881, XGBoost,0.85,0.81,0.79,0.84,0.891","The table shows the results of five different classification models (Logistic Regression, Naive Bayes, SVM, Random Forest, and XGBoost) based on various evaluation metrics (Accuracy, F1 Score, Precision, Recall, and AUC). The Random Forest model performs the best regarding all the metrics, boasting an accuracy of 0.83, F1 Score of 0.79, Precision of 0.76, Recall of 0.83, and AUC of 0.881. The XGBoost model also achieves commendable results, obtaining the second-best scores for all measures. Interestingly, SVM performs better than all other models except Random Forest and XGBoost. Naive Bayes has underperformed in all metrics compared to other classification models."
1152,"caption: Comparison of model performance using various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, SVM,0.83,0.76,0.82,0.79, RF,0.85,0.82,0.80,0.81, XGB,0.84,0.80,0.82,0.81, MLP,0.81,0.75,0.75,0.75, DT,0.78,0.71,0.68,0.69","This table presents a comparison of the performance of five machine learning models - SVM, RF, XGB, MLP, and DT - using various evaluation metrics. The models were evaluated based on their accuracy, precision, recall, and F1 score. Results showed that the RF model had the highest accuracy score of 0.85, and MLP had the lowest of 0.81. The RF model also displayed the highest precision score of 0.82, while the SVM model had the lowest precision of 0.76. On recall, SVM displayed the highest score of 0.82, while DT had the lowest of 0.68. The F1 score shows RF to be the best-performing model with a score of 0.81, while DT had the lowest F1 score of 0.69."
1153,"caption: Comparison of accuracy, F1 Score, precision, and recall among different models.table: Model,Accuracy,F1 Score,Precision,Recall, Model A,0.87,0.91,0.86,0.96, Model B,0.84,0.88,0.90,0.86, Model C,0.91,0.93,0.87,0.99, Model D,0.87,0.89,0.84,0.96, Model E,0.90,0.92,0.91,0.93","The table compares the performance of five models based on different evaluation metrics. Model A has the highest F1 Score of 0.91, while Model C has the highest accuracy of 0.91. Surprisingly, Model E had the highest precision score of 0.91, and its recall score of 0.93 is only surpassed by Model C with a recall score of 0.99. Model B has the lowest accuracy score of 0.84 but makes it up with a high precision score of 0.9. Model D maintains a good balance of all the metrics but still ranks fourth in the overall performance. Overall, the table provides a comprehensive picture that captures the performance profile of the various models."
1154,"caption: Table 4: Evaluation metrics of different models based on accuracy, F1-score, precision, and recall.table: Model,Accuracy,F1-score,Precision,Recall, Random Forest,0.84,0.83,0.85,0.82, Decision Tree,0.76,0.74,0.76,0.72, Gradient Boosting,0.89,0.89,0.88,0.90, Logistic Regression,0.83,0.82,0.82,0.82, K-Nearest Neighbors,0.72,0.70,0.75,0.66","Table 4 presents the evaluation metrics of multiple different models based on four different performance measures: accuracy, F1-score, precision, and recall. The table shows Random Forest, Decision Tree, Gradient Boosting, Logistic Regression, and K-Nearest Neighbors models' scores. The Gradient Boosting model has the highest accuracy (0.89) and the highest F1-score (0.89). The Random Forest model achieves the highest precision (0.85), while the K-Nearest Neighbors model has the lowest precision (0.75) but has the highest recall score (0.66). Overall, the Gradient Boosting model outperforms the others in terms of accuracy and F1-score."
1155,"caption: Comparison of model evaluation metricstable: Model,Accuracy,F1 Score,Precision,Recall,Specificity, Log Regression,0.85,0.84,0.87,0.81,0.93, Naive Bayes,0.79,0.74,0.84,0.66,0.92, Decision Tree,0.81,0.79,0.78,0.81,0.83, Random Forest,0.89,0.89,0.90,0.89,0.89, SVM,0.86,0.85,0.87,0.84,0.89","Table presents a comparison of model evaluation metrics for five different models: Logistic Regression, Naive Bayes, Decision Tree, Random Forest, and SVM. The metrics assessed include Accuracy, F1 Score, Precision, Recall, and Specificity. It can be observed that Random Forest has outperformed all other models with the highest Accuracy of 0.89 and F1 Score of 0.89. Additionally, Random Forest also has the highest scores for Precision, Recall, and Specificity, all with a score of 0.90. However, Logistic Regression also performed well, with an Accuracy of 0.85 and F1 Score of 0.84, while Naive Bayes had the lowest scores across all the evaluation metrics, indicating a need for improvement."
1156,"caption: Comparison of Model Performance on Classification Tasktable: Model,Accuracy,Precision,Recall,F1-Score, Logistic,0.78,0.79,0.81,0.80, SVM,0.81,0.81,0.85,0.83, Random Forest,0.83,0.83,0.86,0.84, XGBoost,0.84,0.85,0.87,0.86, Neural Network,0.82,0.83,0.85,0.84","The table provides a comparison of different models in terms of their performance metrics on a classification task. The models evaluated include Logistic, SVM, Random Forest, XGBoost, and Neural Network. The evaluation metrics used are Accuracy, Precision, Recall, and F1-Score. Of the five models, XGBoost achieved the highest accuracy with a score of 0.84. In contrast, Logistic had the lowest score of accuracy with 0.78. The Precision measurements of all models are nearly identical ranging from 0.79 to 0.85. SVM achieved the highest recall of 0.85, while the Neural Network achieved the highest F1-Score of 0.84. Random Forest and XGBoost showed similar levels of performance across the four metrics evaluated."
1157,"caption: Table 4: Performance comparison of different models over various evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.89 ± 0.02,0.88,0.91,0.86, Random Forest,0.94 ± 0.01,0.93,0.96,0.90, XGBoost,0.93 ± 0.01,0.92,0.95,0.89, MLP,0.92 ± 0.02,0.91,0.93,0.90, Decision Tree,0.85 ± 0.03,0.83,0.86,0.81","Table 4 presents the performance comparison of different models over various evaluation metrics, including Accuracy, F1 Score, Precision, and Recall. The table includes SVM, Random Forest, XGBoost, MLP, and Decision Tree models. Notably, Random Forest performed the best with an overall Accuracy score of 0.94 ± 0.01, followed closely by XGBoost with an Accuracy score of 0.93 ± 0.01. Both models also have the highest scores for F1 score, Precision, and Recall. Interestingly, SVM shows the best Precision score of 0.91, while MLP has the highest Recall score of 0.9. The Decision Tree model exhibits the lowest overall performance in all the evaluation metrics."
1158,"caption: Comparison of multiple models based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Model 1,0.87,0.92,0.88,0.90, Model 2,0.85,0.91,0.83,0.87, Model 3,0.81,0.86,0.80,0.83, Model 4,0.90,0.93,0.91,0.92","This table presents a comparison of multiple models based on different evaluation metrics, including accuracy, precision, recall, and F1-score. Model 1 exhibits the highest accuracy of 0.87, while Model 4 demonstrates the best precision, recall, and F1-score with 0.93, 0.91, and 0.92, respectively. Interestingly, Model 2's performance result is the second-best in all evaluation metrics, although slightly lower than the best-performing models. Additionally, Model 3 has the lowest performance results in all evaluation metrics. The table highlights that Model 4 is the most effective model for the given task, scoring high in all evaluation metrics."
1159,"caption: Results of different models for binary classification task using multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Random Forest,0.95,0.94,0.95,0.94, Logistic Regression,0.89,0.88,0.85,0.86, Naive Bayes,0.78,0.81,0.68,0.73, Decision Tree,0.94,0.93,0.94,0.93, Support Vector Machine,0.90,0.86,0.87,0.86","Table presents the results of various models for a binary classification task evaluated based on different metrics, including accuracy, precision, recall, and F1 score. Among the models, Random Forest had the highest accuracy of 0.95, followed closely by Decision Tree with 0.94 accuracy. In terms of precision, the Naive Bayes algorithm outperformed other models with 0.81 precision; however, it had the lowest recall and F1 scores, indicating more false negatives. Overall, the results suggest that Random Forest and Decision Tree should be prioritized due to their higher accuracy scores."
1160,"caption: Table 4: Comparison of different classification models based on various performance metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.85,0.84,0.88,0.80, Random Forest,0.92,0.91,0.94,0.88, Gradient Boosting,0.91,0.90,0.92,0.88, Support Vector Machine,0.83,0.82,0.85,0.80, K-Nearest Neighbor,0.80,0.79,0.81,0.77","Table 4 provides a comparison of five different classification models (Logistic Regression, Random Forest, Gradient Boosting, Support Vector Machine, and K-Nearest Neighbor) based on their accuracy, F1 score, precision, and recall metrics. The Random Forest model has shown the best performance among all the models in terms of achieving the highest accuracy (0.92), F1 Score (0.91), precision (0.94), and recall (0.88). In contrast, the K-Nearest Neighbor model has demonstrated the lowest accuracy (0.80), F1 Score (0.79), precision (0.81), and recall (0.77). Nonetheless, all models achieved an accuracy of greater than 0.80, showing potential applicability of all the models in the classification task."
1161,"caption: Evaluation metrics table for different models.table: Model Name,Accuracy,F1 Score,Precision,Recall, Model A,0.85,0.80,0.82,0.78, Model B,0.79,0.75,0.76,0.75, Model C,0.88,0.83,0.85,0.82, Model D,0.71,0.62,0.71,0.58","The table above compares the performance of four different models, Model A through D, based on multiple evaluation metrics including accuracy, F1 score, precision, and recall. Model C outperformed other models with the highest accuracy of 0.88. Also, Model A has the best F1 score of 0.80. On the other hand, Model D fared poorly with the lowest scores in all metrics. Interestingly, Model B has a relatively lower accuracy score but a higher F1 score, indicating it had a few false negatives but a higher positive predicted value."
1162,"caption: Model performance comparison based on evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.91,0.87,0.83,0.85, Logistic regression,0.88,0.81,0.78,0.79, Decision tree,0.84,0.65,0.70,0.67, Random forest,0.93,0.88,0.90,0.87, Gradient boosting,0.92,0.86,0.87,0.84",
1163,"caption: Table 4: Model performances based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score,ROC-AUC,PR-AUC, Model A,0.85,0.87,0.82,0.84,0.89,0.92, Model B,0.82,0.84,0.81,0.82,0.86,0.88, Model C,0.87,0.84,0.89,0.86,0.90,0.91, Model D,0.80,0.83,0.79,0.81,0.85,0.87","Table 4 displays the performances of four different models across multiple evaluation metrics. The models were assessed for their accuracy, precision, recall, F1-score, ROC-AUC, and PR-AUC. Model A achieved the highest PR-AUC score of 0.92 and ROC-AUC score of 0.89. Model C scored the highest accuracy (0.87), recall (0.89), and F1-score (0.86), whereas Model B achieved the highest precision (0.84). Model D achieved the lowest scores across all assessments. This table highlights the strengths and weaknesses of the models based on different metrics and provides insights on which model performs better under certain evaluation metrics."
1164,"caption: Table 4: Performance Comparison of Different Models.table: Model,Accuracy,Precision,Recall,F1-Score, Model A,0.82,0.81,0.82,0.79, Model B,0.83,0.82,0.83,0.81, Model C,0.85,0.84,0.85,0.83, Model D,0.82,0.81,0.82,0.80, Model E,0.84,0.83,0.84,0.82","Table 4 presents a comparison of the performance of different models based on various evaluation metrics. The evaluated metrics are accuracy, precision, recall, and F1-score. Model A, B, C, D, and E depict the models' names, while their corresponding performance results are presented in the following columns. Notably, Model C achieved the highest performance scores in all the metrics evaluated. Specifically, Model C had an accuracy of 0.85, precision of 0.84, recall of 0.85, and F1-score of 0.83. Meanwhile, Model A, Model B, and Model D had comparable performances with slightly lower metrics scores. Model E had a relatively high performance score but slightly lower than Model C."
1165,"caption: Performance comparison of different machine learning algorithms on a classification task.table: Model Name,F1-Score,Accuracy,Precision,Recall, Logistic Regression,0.79,0.81,0.72,0.88, Decision Tree,0.80,0.78,0.75,0.87, Random Forest,0.84,0.85,0.80,0.89, Gradient Boosting,0.84,0.85,0.81,0.87, Support Vector Machine,0.83,0.84,0.80,0.87","The table presents a performance comparison of various machine learning algorithms on a classification task. The models are evaluated based on multiple metrics, including F1-Score, Accuracy, Precision, and Recall. The table indicates that the Random Forest and Gradient Boosting models show the best performance based on F1-Score, both having the same score of 0.84. Additionally, Random Forest has the highest Accuracy of 0.85. However, the Support Vector Machine (SVM) model has the highest Precision score of 0.80. Interestingly, Logistic Regression has the highest Recall of 0.88, but its performance is weaker than other models regarding other metrics. Overall, the results suggest that all models perform well, and the performance of each model varies for different metrics."
1166,"caption: Table 4: Performance comparison of different classifiers using various evaluation metrics.table: Model,F1-Score,Precision,Recall,Accuracy, Logistic Regression,0.84,0.86,0.82,0.85, Decision Tree,0.78,0.81,0.76,0.79, Support Vector Machines,0.81,0.84,0.80,0.82, Random Forest,0.88,0.89,0.86,0.88, Multilayer Perceptron,0.80,0.81,0.80,0.81","Table 4 portrays a comparison of different classifiers' performance using distinct evaluation metrics. The table illustrates the models' F1-score, precision, recall, and accuracy values. The presented models include Logistic Regression, Decision Tree, Support Vector Machines, Random Forest, and Multilayer Perceptron. Notably, the Random Forest model showed the highest F1-Score of 0.88, Precision of 0.89, and Recall of 0.86, that indicates a virtually perfect balance between precision and recall measures. Conversely, Multilayer Perceptron model shows the lowest F1-score, precision, and recall metrics. The models could be further tuned based on these performances."
1167,"caption: Table 4: Evaluation metrics of models A, B, C, D, and E.table: Model,Accuracy,Precision,Recall,F1-score, Model A,0.89,0.83,0.91,0.87, Model B,0.92,0.91,0.87,0.89, Model C,0.85,0.87,0.91,0.89, Model D,0.87,0.91,0.88,0.89, Model E,0.91,0.89,0.93,0.91","Table 4 displays the evaluation metrics of five different models, Model A, B, C, D, and E. The models' performance was evaluated using four different metrics: accuracy, precision, recall, and F1-score. Model B achieved the highest accuracy score (0.92), while Models A, D, and E achieved scores above 0.87. The precision score of Model D was the highest at 0.91, while Models B and E had scores above 0.89. Recall scores varied across the models, with Model A having the highest score of 0.91 and Model B the lowest score of 0.87. Model E displayed the highest F1-score at 0.91, while Models A, B, C, and D had F1-scores ranging from 0.87 to 0.89. Overall, Model B showed the most consistent performance across all metrics, while Model E had the best overall performance for accuracy and F1-score."
1168,"caption: Performance of different models based on various evaluation metrics.table: Model name,Accuracy,F1 score,Precision,Recall, Model A,0.89,0.87,0.90,0.84, Model B,0.92,0.91,0.93,0.89, Model C,0.85,0.83,0.86,0.81, Model D,0.91,0.90,0.92,0.88, Model E,0.88,0.86,0.87,0.85","The table displays the performance evaluation of five different models based on various evaluation metrics. The evaluation metrics used in the table are Accuracy, F1 score, Precision, and Recall. Model B achieved the highest Accuracy, F1 score, Precision, and Recall with 0.92, 0.91, 0.93, and 0.89, respectively. In contrast, Model C performed the worst with an Accuracy of 0.85, F1 score of 0.83, Precision of 0.86, and Recall of 0.81. However, the models' performance trends were consistent across all the evaluation metrics."
1169,"caption: Model performance of different classifiers using evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.89,0.73,0.92,0.81, Decision Tree,0.86,0.72,0.85,0.78, Random Forest,0.92,0.78,0.96,0.86, XGBoost,0.91,0.76,0.94,0.84, Convolutional Neural Network,0.95,0.85,0.97,0.91","Table 1 reveals the performance of multiple classifiers using evaluation metrics like accuracy, precision, recall, and F1-score. The Logistic Regression classifier performs well in terms of accuracy (0.89) and recall (0.92), while the Convolutional Neural Network yields the highest accuracy of 0.95 and F1-score of 0.91. Notably, the Random Forest classifier reports significant improvement in terms of precision and recall with values of 0.78 and 0.96, respectively. Meanwhile, XGBoost contributed to higher precision and recall than Logistic Regression and Decision Tree classifiers, but lower performance than Random Forest. Therefore, careful evaluation of evaluation metrics is critical when choosing the best model for a dataset."
1170,"caption: Performance comparison of different models using various evaluation metrics.table: Model,F1-Score,Accuracy,Precision,Recall, SVM,0.85,0.87,0.89,0.82, RF,0.83,0.85,0.85,0.81, DT,0.77,0.79,0.79,0.77, KNN,0.79,0.82,0.82,0.78, NB,0.71,0.73,0.76,0.67","The table compares the performance of five different models using four evaluation metrics, i.e., F1-Score, Accuracy, Precision, and Recall. The SVM model achieved the best results among all the models in terms of F1-Score (0.85) and Precision (0.89), while the RF model performed slightly better in terms of Accuracy (0.85). The DT, KNN, and NB models had lower scores in all evaluation metrics compared to the other models. Thus, the SVM and RF models seem to be the most effective models in this particular scenario."
1171,"caption: Model performance using different evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.82,0.77,0.81,0.74, Decision Tree,0.78,0.63,0.67,0.60, Random Forest,0.91,0.88,0.91,0.85, Gradient Boosting,0.86,0.81,0.84,0.79, Support Vector Machine,0.80,0.70,0.78,0.63","The table compares the performance of five different models, namely Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Support Vector Machine, using various evaluation metrics. The metrics considered included Accuracy, F1-Score, Precision, and Recall, which are commonly used to evaluate classification models. Notably, the Random Forest model outperformed the other models across all the considered metrics with a remarkable Accuracy score of 0.91, F1-Score of 0.88, Precision of 0.91, and Recall of 0.85. The Gradient Boosting model also performed well, albeit not as good as Random Forest, whereas Decision Tree and Support Vector Machine models recorded lower scores. However, Logistic Regression model registered relatively high scores in all the evaluated metrics, which indicates its potential effectiveness in performing well in other classification tasks."
1172,"caption: Table 4: Model performance based on different evaluation metrics.table: Model,Precision,Recall,F1,Accuracy,AUC, SVM,0.68,0.71,0.64,0.78,0.81, KNN,0.78,0.62,0.69,0.77,0.80, Decision Tree,0.60,0.61,0.56,0.72,0.75, Random Forest,0.77,0.75,0.71,0.78,0.81, AdaBoost,0.76,0.70,0.72,0.78,0.80","Table 4 features a comparison of different models based on multiple evaluation metrics. The models included are SVM, KNN, Random Forest, Decision Tree, and AdaBoost. The evaluation metrics used to rank each of the models are precision, recall, F1 score, accuracy, and AUC. Interestingly, the best performing model according to AUC and accuracy is Random Forest with an AUC of 0.81 and an accuracy of 0.78. On the other hand, KNN has the highest precision of 0.78 with a recall score of 0.62. Therefore, the choice of the best performing model depends on the evaluation metric used to make the comparison."
1173,"caption: Comparison of different models based on the evaluation metrics.table: Model,Accuracy,F1-Score,Recall,Precision,AUC, SVM,0.89,0.87,0.88,0.86,0.92, KNN,0.85,0.82,0.95,0.72,0.88, RF,0.93,0.92,0.95,0.90,0.96, XGB,0.92,0.90,0.94,0.85,0.95, ANN,0.94,0.91,0.94,0.90,0.97","The table exhibits a comparison of different models based on evaluation metrics such as accuracy, F1-score, recall, precision, and AUC. The table includes SVM, KNN, RF, XGB, and ANN models and their respective performance scores for each evaluation metric. The ANN model has the highest accuracy of 0.94, followed closely by RF and XGB, both with an accuracy of 0.93 and 0.92, respectively. The ANN model also has the highest AUC of 0.97, followed by RF and XGB at 0.96 and 0.95, respectively. Conversely, the KNN model's recall score of 0.95 is the highest among the models, followed by RF and XGB with a recall score of 0.95 and 0.94, respectively. In summary, the ANN model appears to be the best-performing model based on the majority of the evaluation metrics."
1174,"caption: Table 4: Performance metrics of multiple modelstable: Model,Accuracy,Sensitivity,Specificity, Model 1,0.85,0.95,0.75, Model 2,0.75,0.85,0.65, Model 3,0.79,0.90,0.70, Model 4,0.89,0.92,0.86, Model 5,0.92,0.95,0.89","Table 4 showcases the performance metrics of multiple models based on accuracy, sensitivity, and specificity. The table provides a comparison of the five different models, where Model 5 achieved the highest accuracy with a score of 0.92. Meanwhile, Model 1 achieves the highest sensitivity of 0.95, and Model 4 exhibits the highest specificity with a score of 0.86. These findings indicate that each model has its strengths and weaknesses, and choosing a model solely based on one metric may not yield accurate results. Therefore, the selection of a model should depend on the research problem requirements and use case scenarios."
1175,"caption: Performance metrics for different models.table: Model,Accuracy,Precision,Recall,F1-score, Model A,0.8,0.85,0.7,0.75, Model B,0.7,0.8,0.6,0.67, Model C,0.9,0.87,0.95,0.91, Model D,0.75,0.7,0.85,0.77, Model E,0.82,0.75,0.9,0.82","The table presents the performance metrics for five different models evaluated based on accuracy, precision, recall, and F1-score. Among the presented models, Model C achieved the highest accuracy of 0.9, while Model B had the lowest accuracy of 0.7. For precision, Model A had the highest score of 0.85, followed by Model C with 0.87, while Model D got the lowest precision score of 0.7. Model C outperformed the other models in terms of recall with 0.95, while Model B had the lowest recall score of 0.6. Finally, Model C had the best F1-score of 0.91, while Model B still had the lowest F1-score of 0.67. Therefore, based on these results, Model C can be considered the best performing model across all metrics evaluated."
1176,"caption: Table 4: Performance results of different models based on F1-score, Matthews Correlation Coefficient (MCC), and Balanced Accuracy.table: Model,F1-score,Matthews Correlation Coefficient (MCC),Balanced Accuracy, Logistic Regression,0.85,0.7,0.82, Decision Tree,0.80,0.63,0.75, Random Forest,0.89,0.77,0.84, Support Vector Machine,0.86,0.73,0.82, XGBoost,0.91,0.82,0.88","Table 4 presents performance results of five different models based on F1-score, Matthews Correlation Coefficient (MCC), and Balanced Accuracy. The table exhibits Logistic Regression, Decision Tree, Random Forest, Support Vector Machine, and XGBoost models' performance scores. Notably, the Random Forest model shows the highest F1-score and MCC of 0.89 and 0.77, respectively. The XGBoost model achieved the highest score of 0.91 in F1-score, while also showing the highest MCC score (0.82), and Balanced Accuracy score (0.88). Interestingly, Decision Tree showed the lowest scores in all three metrics among the models listed in the table."
1177,"caption: Comparison of different models' performance based on multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.81,0.76,0.72,0.74, Decision Tree,0.75,0.70,0.69,0.64, Random Forest,0.89,0.88,0.85,0.86, KNN,0.78,0.74,0.70,0.71, SVM,0.84,0.79,0.80,0.79","The above table compares different models' performance based on multiple evaluation metrics such as accuracy, precision, recall, and F1-score. The table presents performance results of Logistic Regression, Decision Tree, Random Forest, KNN, and SVM models. The Random Forest model achieved the highest accuracy score of 0.89, followed by SVM with an accuracy score of 0.84. The Random Forest model also achieved the highest precision score of 0.88 and highest recall score of 0.85, leading to the highest F1-score of 0.86. However, the Logistic Regression model performed comparably well, with an accuracy score of 0.81 and an F1-score of 0.74. The Decision Tree and KNN models had the lowest performance results in this comparison."
1178,"caption: Table 4: Model performance evaluation based on precision, recall, F1-score, and accuracy.table: Model,Precision,Recall,F1-Score,Accuracy, SVM,0.87,0.89,0.88,0.91, KNN,0.84,0.90,0.87,0.89, Naive Bayes,0.82,0.83,0.83,0.86, Decision Tree,0.91,0.88,0.89,0.91, Random Forest,0.94,0.95,0.94,0.95, XGBoost,0.92,0.94,0.93,0.94",
1179,"caption: Table 4: Model performance comparison across different metrics.table: Model,Accuracy,F1-score,Precision,Recall, Logistic regression,0.85,0.84,0.87,0.82, Random forest,0.87,0.86,0.88,0.85, Decision tree,0.70,0.67,0.68,0.67, Naive Bayes,0.76,0.75,0.81,0.70, K-nearest neighbours,0.81,0.79,0.83,0.75","Table 4 compares the performance metrics of the models used: Logistic regression, Random forest, Decision tree, Naive Bayes, and K-nearest neighbours. The evaluation metrics used were Accuracy, F1-score, Precision, and Recall. The Random forest model outperforms all other models in accuracy with a score of 0.87. Comparatively, the Decision tree model had a low accuracy of 0.70. On the other hand, Naive Bayes had the highest Precision score with 0.81, while Logistic regression and K-nearest neighbours had similar and fairly balanced performance across all metrics."
1180,"caption: Comparison of Model Performance using Various Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.85,0.89,0.77,0.82, Decision Tree,0.79,0.84,0.73,0.78, Random Forest,0.90,0.93,0.85,0.89, Naive Bayes,0.82,0.74,0.90,0.81, Support Vector Machine,0.87,0.91,0.81,0.85","The table above compares the performance of five models- Logistic Regression, Decision Tree, Random Forest, Naive Bayes, and Support Vector Machine using four evaluation metrics- Accuracy, Precision, Recall, and F1-score. The highest accuracy is obtained by the Random Forest model, which also has the highest precision and F1-scores. The Support Vector Machine model had the best recall score. The Decision Tree model had the lowest accuracy score but obtained a reasonably decent precision, recall and F1-score. The Naive Bayes model got a relatively lower precision score but the highest recall score. The table provides a comprehensive comparison of model performance using different evaluation metrics to assist in selecting the best model for the task."
1181,"caption: Performance metrics of various models.table: Model,Accuracy,Precision,Recall,F1-Score, Model A,0.85,0.90,0.83,0.86, Model B,0.82,0.88,0.87,0.87, Model C,0.89,0.85,0.92,0.88, Model D,0.81,0.90,0.77,0.83, Model E,0.86,0.82,0.90,0.86","The table compares different models' performances based on accuracy, precision, recall, and F1-score metrics. Model A shows the highest accuracy of 0.85, while model C has the highest precision of 0.85, and model A has the highest recall of 0.83. The F1-score is the harmonic mean of precision and recall. According to the F1-score, the best-performing model is model C with a score of 0.88, while model B and model E are in second place with an F1-score of 0.87. The results suggest that, depending on the evaluation metric selected, different models could be suitable for different situations."
1182,"caption: Table 4: Model performance comparison using different evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.86,0.89,0.92,0.86, KNN,0.79,0.83,0.86,0.88, RF,0.91,0.93,0.92,0.94, XGB,0.89,0.92,0.93,0.90","Table 4 presents a comparison of model performances using different evaluation metrics: Accuracy, F1-Score, Precision, and Recall. SVM, KNN, RF, and XGB models are compared based on the mentioned evaluation metrics. The table shows that the Random Forest model outperformed all the other models, achieving the highest accuracy rate of 0.91 and F1-Score of 0.93. On the other hand, the SVM model performed well in Precision with a score of 0.92, while XGB had the best Recall rate of 0.90. It is essential to report different evaluation metrics, such as Accuracy, F1-Score, Precision, and Recall, as each metric serves a specific purpose in assessing model performances."
1183,"caption: Comparison of different model performances based on multiple metrics.table: Model,Metric 1,Metric 2,Metric 3, Model 1,0.85,0.75,0.9, Model 2,0.92,0.67,0.78, Model 3,0.88,0.82,0.84, Model 4,0.79,0.6,0.92, Model 5,0.91,0.8,0.68","The table presents a comparison of different models based on three evaluation metrics. The table exhibits a total of five models, where each model's performance is evaluated using Metric 1, Metric 2, and Metric 3. Model 2 shows the best performance with Metric 1 of 0.92, while Model 1 achieved the highest score with Metric 3 of 0.9. Metric 2's results indicate that Model 3 had the highest score of 0.82, which is followed by Model 5 that achieved a score of 0.8. Interestingly, Model 4 had the lowest scores among all models with Metric 1 of 0.79 and Metric 2 of 0.6."
1184,"caption: Table 4: Model performance based on Accuracy, Recall, Precision, and F1-Scoretable: Model Name,Accuracy,Recall,Precision,F1-Score, SVM,0.868,0.869,0.873,0.871, Logistic Reg.,0.860,0.857,0.875,0.866, Decision Tree,0.811,0.818,0.828,0.823, Random Forest,0.905,0.906,0.912,0.909, XGBoost,0.894,0.895,0.897,0.896","Table 4 demonstrates model performance from SVM, Logistic Regression, Decision Tree, Random Forest, and XGBoost classification algorithms. Each model's performance scores were evaluated based on Accuracy, Recall, Precision, and F1-Score. Notably, Random Forest obtained the highest scores for each metric, with a top score of 0.912 for Precision. Additionally, XGBoost achieved the second-best scores across all evaluation metrics, while the decision tree model had the lowest performance results in comparison to the other models. Overall, the table exhibits the efficacy of random forest and XGBoost classifiers in classification tasks based on the evaluated metrics."
1185,"caption: Model performance for binary classificationtable: Model,Accuracy,Recall,F1 Score,AUC, Decision Tree,0.75,0.83,0.78,0.62, Logistic,0.86,0.90,0.88,0.76, KNeighbors,0.80,0.82,0.81,0.69, SVM,0.74,0.85,0.78,0.58, Naive Bayes,0.64,0.60,0.62,0.52, Random Forest,0.92,0.95,0.94,0.85","The table presents the evaluation results of six different models implementing binary classification: Decision Tree, Logistic Regression, KNeighbors Classifier, SVM, Naive Bayes, and Random Forest. Four evaluation metrics were used- Accuracy, Recall, F1 Score, and AUC. The Random Forest model outperformed all models across all metrics with a high accuracy score of 0.92, recall of 0.95, F1 Score of 0.94, and AUC of 0.85. The Logistic Regression model showed the second-best performance with accuracy, recall, F1 Score, and AUC of 0.86, 0.9, 0.88, and 0.76, respectively. It is notable that the Naive Bayes model achieved low scores across all metrics."
1186,"caption: Comparison of various models based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score,Specificity, Model 1,0.89,0.87,0.91,0.89,0.92, Model 2,0.92,0.94,0.90,0.92,0.95, Model 3,0.87,0.84,0.91,0.87,0.88, Model 4,0.91,0.90,0.92,0.91,0.93","Table above compares the performance of four distinct models on various evaluation metrics, including Accuracy, Precision, Recall, F1-Score, and Specificity. The models were evaluated on a similar dataset, and the models' specific evaluation metrics' results are reported above. The table highlights that Model 2 seems to perform the best, with the highest Accuracy (0.92) and Specificity (0.95) scores. In contrast, Model 3 appears to have the lowest Accuracy (0.87) and Precision (0.84) scores. Overall, the table provides a detailed comparison of each model's performance, indicating Model 2 as the best performing model in this evaluation."
1187,"caption: Table 4: Model evaluation results based on accuracy, F1-score, precision, and recall.table: Model,Accuracy,F1-score,Precision,Recall, Model A,0.82,0.76,0.88,0.68, Model B,0.87,0.81,0.87,0.76, Model C,0.76,0.68,0.81,0.58, Model D,0.91,0.86,0.93,0.81, Model E,0.89,0.83,0.85,0.82","Table 4 compares the performance of different models such as model A, model B, model C, model D, and model E based on accuracy, F1-score, precision, and recall. The accuracy metric evaluates how well a model correctly predicts the target labels, whereas F1-score is the weighted average of precision and recall. Precision is a metric that assesses the number of true positive predictions over the total number of positive predictions, and recall refers to the ratio of true positive instances to the total number of actual positive instances in the data. Interestingly, Model D had the highest accuracy score of 0.91 while Model B achieved the highest F1-score of 0.81. Model D also attained the highest precision of 0.93, while Model B had the highest recall of 0.76. Additionally, Model E had high performance on all evaluation metrics with an accuracy score of 0.89, F1-score of 0.83, precision of 0.85, and recall of 0.82."
1188,"caption: Performance comparison of different machine learning models on predicting heart diseasetable: Model,Precision,Recall,F1-Score,Accuracy, Logistic Regression,80%,67%,73%,75%, Random Forest,68%,89%,77%,71%, Decision Tree,56%,87%,68%,63%, Support Vector Machine,75%,74%,74%,76%, K-Nearest Neighbors,70%,80%,74%,72%","Table 4 displays a performance comparison of five machine learning models, i.e., Logistic Regression, Random Forest, Decision Tree, Support Vector Machine, and K-Nearest Neighbors, in predicting heart disease. The evaluation measures precision, recall, F1-score, and accuracy were used to compare the models. The results show that Random Forest had the highest recall value of 89%, while Logistic Regression had the highest precision value of 80%. However, the overall best model could be determined based on a combination of all four evaluation metrics."
1189,"caption: Comparison of model performance based on multiple metrics.table: Model,Precision,Recall,F1-score,Accuracy, Model 1,0.85,0.83,0.84,0.87, Model 2,0.82,0.81,0.81,0.86, Model 3,0.83,0.84,0.83,0.88, Model 4,0.86,0.82,0.84,0.87, Model 5,0.88,0.86,0.87,0.89","The table presents a comparison of five different models based on multiple evaluation metrics- Precision, Recall, F1-Score, and Accuracy. Model 1 achieved the highest precision score of 0.85 while Model 5 has the highest precision score of 0.88. However, Model 5 showed better recall scores across all models with a value of 0.86. In terms of F1-score, Model 5 also had the highest value of 0.87. Model 3 had the best accuracy score of 0.88 compared to other models. The table's presentation provides a useful overview of the models performances and can be helpful in selecting the best model based on the appropriate evaluation metric."
1190,"caption: Performance evaluation of different machine learning modelstable: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.82 +/- 0.03,0.85 +/- 0.05,0.81 +/- 0.12,0.83 +/- 0.05, Random Forest,0.85 +/- 0.02,0.87 +/- 0.05,0.87 +/- 0.09,0.87 +/- 0.04, SVM,0.89 +/- 0.01,0.91 +/- 0.03,0.89 +/- 0.06,0.90 +/- 0.02, Naïve Bayes,0.78 +/- 0.02,0.82 +/- 0.06,0.79 +/- 0.11,0.80 +/- 0.03, Neural Network,0.90 +/- 0.01,0.93 +/- 0.03,0.91 +/- 0.06,0.92 +/- 0.02","The table compares the accuracy, precision, recall, and F1 score performance metrics for several machine learning models. Logistic Regression, Random Forest, SVM, Naïve Bayes, and Neural Network models are evaluated on the given dataset. The table shows that the Neural Network model had the highest accuracy score of 0.90 +/- 0.01. Also, the SVM model had the highest precision score of 0.91 +/- 0.03. On the other hand, the Random Forest model had the highest recall and F1 score of 0.87 +/- 0.09 and 0.87 +/- 0.04, respectively. These results demonstrate the different strengths of each model and provide insights into further model selection."
1191,"caption: Performance evaluation of five different models based on accuracy, precision, recall, and F1-score.table: Model,Accuracy,Precision,Recall,F1-Score, Model A,0.82,0.85,0.75,0.79, Model B,0.76,0.78,0.86,0.80, Model C,0.87,0.82,0.94,0.87, Model D,0.90,0.88,0.92,0.90, Model E,0.93,0.95,0.90,0.92","The presented table shows five different models' performance evaluation based on multiple evaluation metrics such as accuracy, precision, recall, and F1-score. These models were trained and tested with the same dataset. Model E shows the highest accuracy score of 0.93, while Model D scored the highest precision and F1-score of 0.88 and 0.90, respectively. However, Model C achieved the highest recall score, which indicates that it correctly identified most of the positive samples, while Model A had the lowest recall score. This information could help in selecting the best-performing model based on the evaluation metric that holds more weight."
1192,"caption: Model Performance Metrics for Different Algorithmstable: Model,Accuracy,F1 score,Precision,Recall, Logistic Regression,0.85,0.84,0.86,0.85, Random Forest,0.89,0.88,0.91,0.89, K-Nearest Neighbors,0.82,0.81,0.82,0.80, Gradient Boosting,0.91,0.90,0.92,0.91, Naive Bayes,0.77,0.76,0.79,0.77","The table exhibits the accuracy, F1 score, precision, and recall performance metrics for five different models. The models used in this experiment are Logistic Regression, Random Forest, K-Nearest Neighbors, Gradient Boosting, and Naive Bayes. The table highlights that the Gradient Boosting model achieved the best performance across all metrics with accuracy, F1 score, precision, and recall scores of 0.91, 0.90, 0.92, and 0.91, respectively. Random Forest also provided strong performance, with accuracy and F1 scores of 0.89 and 0.88, respectively. Naive Bayes had the lowest accuracy and F1 scores, demonstrating that it was the least effective model for this experiment."
1193,"caption: Model performance using different evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.83,0.85,0.86,0.84, Decision Tree,0.78,0.75,0.77,0.70, Random Forest,0.91,0.93,0.93,0.92, Gradient Boosting,0.89,0.91,0.89,0.89, Naive Bayes,0.76,0.78,0.80,0.77","This table presents the model performance of five different models using different evaluation metrics, including accuracy, precision, recall, and F1-score. The models evaluated are Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Naive Bayes. Each model was trained and tested on the same dataset. Interesting observations from the table are that Random Forest achieves the highest accuracy of 0.91 and the highest precision and recall of 0.93. The Logistic Regression model achieved the highest precision score of 0.85, while Naive Bayes model has the least accuracy score of 0.76."
1194,"caption: Model Performance Summarytable: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.85,0.86,0.85,0.85, Support Vector Machine,0.87,0.88,0.86,0.87, Decision Tree,0.82,0.82,0.81,0.82, Random Forest,0.89,0.89,0.89,0.89","The above table shows the performance results of four different models used to model a classification task. The models' metrics include accuracy, precision, recall, and F1-score. The highest accuracy of 0.89 was obtained with the Random Forest model, while the lowest accuracy was 0.82, produced by the Decision Tree model. The models' precision scores ranged from 0.82 for the Decision Tree model to 0.89 for the Random Forest model. Additionally, the recall scores ranged from 0.81 for the Decision Tree model to 0.89 for the Random Forest model, while the F1-scores ranged from 0.82 for the Decision Tree model to 0.89 for the Random Forest model. These results suggest that the Random Forest model would be the best choice for this classification task based on the metrics evaluated."
1195,"caption: Performance comparison of different models evaluated using multiple metrics.table: Models,Accuracy,Precision,Recall,F1-Score,AUC, Model A,0.89,0.91,0.87,0.89,0.95, Model B,0.88,0.89,0.91,0.88,0.92, Model C,0.82,0.85,0.81,0.83,0.85, Model D,0.92,0.93,0.94,0.93,0.95, Model E,0.94,0.92,0.97,0.94,0.99","The table compares five different models' performance, including Model A to E, evaluated using multiple metrics, namely Accuracy, Precision, Recall, F1-score, and AUC. As depicted, Model E is the best model having the highest Accuracy of 0.94 and AUC of 0.99. Also, it has a higher Recall score of 0.97 than other models. Model A yields relatively good results, having an Accuracy and AUC of 0.89 and 0.95, respectively. Model D also provides good performance with 0.92 Accuracy and 0.95 AUC compared to other models. Model B and Model C provide lower results than other models, although having decent scores in Precision and Recall. Overall, Model E produces the highest performance among other models evaluated using multiple metrics in the table."
1196,"caption: Model performances using different metricstable: Model,Accuracy,Precision,Recall,F1-Score,AUC, SVM,0.91,0.89,0.91,0.90,0.77, KNN,0.86,0.85,0.86,0.85,0.75, GaussianNB,0.76,0.72,0.76,0.73,0.65, Decision Tree,0.81,0.79,0.81,0.80,0.71","The table presents the performances of four different models, SVM, KNN, GaussianNB, and Decision Tree. The evaluation metrics used to measure the model's performance are Accuracy, Precision, Recall, F1-Score, and AUC. SVM and KNN models achieved comparable accuracy scores of 0.91 and 0.86, respectively. The SVM outperforms other models in terms of precision and recall. On the other hand, KNN has the highest precision score of 0.85. Among the four models, the Decision Tree shows the lowest performance in all metrics. Interestingly, the SVM model shows the highest AUC score, indicating a better overall performance in comparison to other models."
1197,"caption: Table 4: Model performance using multiple different evaluation metrics.table: Model,Precision,Recall,F1-Score,Accuracy,AUC, SVM,0.89,0.84,0.86,0.91,0.93, MLP,0.92,0.79,0.83,0.89,0.91, Ensemble,0.88,0.87,0.87,0.90,0.92, Random Forest,0.93,0.91,0.92,0.94,0.95, XGBoost,0.91,0.89,0.90,0.92,0.94","Table 4 summarizes the performance of various models using multiple evaluation metrics, including Precision, Recall, F1-Score, Accuracy, and AUC. The SVM model shows the highest AUC score of 0.93, while the Random Forest model exhibits the best Precision and AUC scores of 0.93 and 0.95, respectively. The MLP model gives the highest Precision score of 0.92, but its Recall score is lower than those of the SVM, Random Forest, and XGBoost models. On the other hand, the Ensemble model obtained competitive scores in all metrics but shows lower performance compared to the Random Forest and XGBoost models. Overall, the table suggests that the Random Forest and XGBoost models outperform the other models in terms of multiple evaluation metrics."
1198,"caption: Comparison of various models based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score,AUC-ROC, Logistic Reg.,0.820,0.798,0.800,0.798,0.890, Decision Tree,0.775,0.735,0.750,0.739,0.800, Random Forest,0.852,0.835,0.840,0.837,0.909, Gradient Boosting,0.839,0.817,0.820,0.818,0.899, XGBoost,0.861,0.845,0.855,0.848,0.925","The above table captures the results of various models trained and tested with a common dataset across different evaluation metrics. The evaluation metrics include accuracy, precision, recall, F1 score, and AUC-ROC. Notably, the XGBoost model outperformed all other models with the highest AUC-ROC score of 0.925 and an accuracy of 0.861 compared to other models. On the other hand, the Random Forest model obtained a close score of 0.909 for the AUC-ROC. The Logistic Reg and Gradient Boosting models result in nearly similar scores for accuracy and AUC-ROC metrics, while the Decision Tree model shows relatively poorer performance in all metrics compared to other models."
1199,"caption: Table 4. Model performance of different machine learning algorithms tested on the dataset with multiple metrics.table: Model Name,Accuracy,Precision (0),Precision (1),Recall (0),Recall (1),F1-Score (0),F1-Score (1), Logistic Regression,0.77,0.80,0.52,0.81,0.48,0.81,0.49, Naive Bayes,0.65,0.58,0.75,0.92,0.25,0.70,0.36, Decision Tree,0.70,0.68,0.53,0.71,0.50,0.69,0.51, Random Forest,0.85,0.84,0.78,0.87,0.74,0.85,0.76, Gradient Boosting,0.82,0.82,0.72,0.83,0.71,0.82,0.72, Support Vector Machines,0.79,0.80,0.59,0.82,0.56,0.81,0.57","Table 4 compares the performance of different classification models using multiple evaluation metrics. The evaluated models are Logistic Regression, Naive Bayes, Decision Tree, Random Forest, Gradient Boosting, and Support Vector Machines. The performance of these models is measured based on accuracy, precision for both positive and negative classes, recall for both classes, and F1-score for both classes. The table reveals that the Random Forest model achieved the highest accuracy of 0.85 and F1-Score for the negative class (0.84). The Gradient Boosting model performed well in all metrics except precision for the positive class. While the Naive Bayes model performed poorly in most metrics, it had a high precision of 0.75 for the positive class. The Logistic Regression model achieved the highest precision for the negative class (0.80)."
1200,"caption: Table 4: Model Performance based on Multiple Evaluation Metricstable: Model,Accuracy,F1-Score,Precision,Recall,AUC, SVM with RBF kernel,0.86,0.89,0.84,0.95,0.92, Naïve Bayes,0.78,0.83,0.90,0.76,0.80, Random Forest,0.91,0.94,0.91,0.96,0.97, K-Nearest Neighbors,0.82,0.87,0.83,0.91,0.89","Table 4 shows the model performance of four different models based on multiple evaluation metrics. The models used are SVM with RBF Kernel, Naive Bayes, Random Forest, and K-Nearest Neighbors, whereas the evaluation metrics used are Accuracy, F1-Score, Precision, Recall, and AUC. The Random Forest model achieves the highest scores in all five evaluation metrics, where it obtains an accuracy of 0.91, an F1-Score of 0.94, precision of 0.91, recall of 0.96, and an AUC of 0.97. It is also interesting to note that all models perform well, with no model performing poorly in all the evaluation metrics used."
1201,"caption: Model performance based on different evaluation metricstable: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.87,0.86,0.84,0.88, KNN,0.81,0.74,0.69,0.80, RF,0.93,0.93,0.93,0.93, XGB,0.91,0.90,0.88,0.92, LR,0.84,0.83,0.80,0.85","The table illustrates the performance results of multiple machine learning models based on different evaluation metrics. The models include SVM, KNN, RF, XGB, and LR. The evaluation metrics used in the table include accuracy, F1-Score, precision, and recall. Performance results show that RF outperforms other models in terms of accuracy, F1-Score, precision, and recall. XGB also shows excellent performance results based on all the metrics used in the table. The KNN model, on the other hand, has the lowest accuracy, F1-Score, precision, and recall scores. Based on these results, it is evident that RF and XGB are highly effective models for this dataset."
1202,"caption: Model's performance based on different evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.91,0.85,0.83,0.87, Random Forest,0.93,0.90,0.91,0.88, K-Nearest Neighbors,0.89,0.82,0.79,0.86, Naive Bayes,0.86,0.80,0.76,0.84","The table represents the performance of different models based on multiple evaluation metrics. The metrics include Accuracy, F1 Score, Precision, and Recall. The Logistic Regression and Random Forest models show the highest Accuracy with 0.91 and 0.93, respectively. The Random Forest model also shows the highest F1 Score of 0.90. However, the Precision and Recall of the Logistic Regression model are higher with 0.83 and 0.87 compared to the Random Forest's Precision and Recall of 0.91 and 0.88, respectively. The K-Nearest Neighbors model shows the lowest Accuracy, F1 Score, Precision, and Recall among the models. Naive Bayes performs better than K-Nearest Neighbors but is still outperformed by Logistic Regression and Random Forest."
1203,"caption: Performance Comparison of Different Modelstable: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.93,0.84,0.89,0.80, KNN,0.89,0.77,0.81,0.77, Logistic Regression,0.94,0.85,0.87,0.84, Decision Tree,0.91,0.79,0.80,0.79, Random Forest,0.95,0.88,0.91,0.87","The table presents the performance evaluation of five models computed for classification tasks. The evaluation metrics include Accuracy, F1-Score, Precision, and Recall. The results depict that the Random Forest model is the best performing model in terms of accuracy with a score of 0.95 whilst achieving an F1-Score of 0.88. Logistic regression and SVM had comparable results, both attaining high accuracy and F1-Score. Interestingly, the Support Vector Machine model has the highest recall score; Decision tree, KNN models also achieved decent scores with respect to these evaluation metrics."
1204,"caption: Table 4: Performance of different models based on multiple evaluation metrics.table: Model Name,Precision,Recall,F1-Score,AUC-ROC,Accuracy, Model A,0.82,0.75,0.78,0.87,0.80, Model B,0.84,0.81,0.82,0.88,0.82, Model C,0.86,0.85,0.85,0.90,0.84, Model D,0.85,0.78,0.80,0.85,0.79, Model E,0.82,0.84,0.83,0.86,0.81","Table 4 presents the performance of different models based on multiple evaluation metrics, including Precision, Recall, F1-Score, AUC-ROC, and Accuracy. The models are labeled as Model A, B, C, D, and E. The overall best performing model is Model C with the highest Precision of 0.86, Recall of 0.85, F1-Score of 0.85, AUC-ROC of 0.90, and Accuracy of 0.84. Model B performs the second best among all models with scores of 0.84, 0.81, 0.82, 0.88, and 0.82, respectively. Interestingly, Model E has the highest Recall of 0.84, while Model A has the lowest Precision but the highest Accuracy among all models."
1205,"caption: Comparison of Model Performance on Classification Tasktable: Model,Accuracy,Recall,F1-score,AUC, Logistic Regression,0.89,0.91,0.87,0.94, Decision Tree,0.84,0.88,0.82,0.87, SVM,0.92,0.94,0.92,0.97, Random Forest,0.95,0.96,0.95,0.98, XGBoost,0.96,0.97,0.96,0.99",
1206,"caption: Performance results of different models based on multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, SVM,0.84,0.846,0.785,0.814, KNN,0.80,0.803,0.732,0.748, RF,0.91,0.917,0.896,0.906, XGB,0.88,0.887,0.865,0.873, MLP,0.85,0.855,0.805,0.824","The table above compares the performance of five different classification models based on four different evaluation metrics: Accuracy, Precision, Recall, and F1 Score. The SVM model achieved the highest accuracy of 0.84 while the RF model had the highest accuracy of 0.91. The RF model outperformed all other models in terms of precision, recall, and F1 score with 0.917, 0.896, and 0.906, respectively. On the other hand, KNN and MLP models yielded lower performance results in all metrics than the other models in the table. Overall, the table shows that the RF model performed the best among all the models considered while the KNN and MLP models had lower performance results than the other models."
1207,"caption: Table 4: Performance Results of Different Machine Learning Models based on Multiple Evaluation Metrics.table: Model,Accuracy,F1 Score,Precision,AUC, Logistic Regression,0.82,0.84,0.81,0.90, Decision Tree,0.75,0.74,0.75,0.76, Random Forest,0.87,0.88,0.87,0.91, Gradient Boosting,0.89,0.90,0.89,0.93, CNN,0.82,0.83,0.83,0.87, RNN,0.79,0.81,0.79,0.85",
1208,"caption: Table 4: Performance of different models based on different evaluation metricstable: Model,F1-score,Recall,Precision,Accuracy, Random Forest,0.91,0.92,0.90,0.91, SVM (RBF),0.85,0.86,0.84,0.85, SVM (Linear),0.84,0.85,0.83,0.84, Logistic Regression,0.82,0.78,0.89,0.81, Decision Tree,0.68,0.67,0.70,0.68","Table 4 presents a comparison of different models' performances based on various evaluation metrics such as F1-score, Recall, Precision, and Accuracy. The table includes Random Forest, SVM (RBF), SVM (Linear), Logistic Regression, and Decision Tree models. It is evident from the table that Random Forest achieved the best results in all evaluation metrics with an F1-score of 0.91, Recall of 0.92, Precision of 0.90, and Accuracy of 0.91. The SVM models had the second-best performance, with SVM (RBF) outperforming SVM (Linear) in all metrics. Logistic Regression produced an F1-score of 0.82, Recall of 0.78, Precision of 0.89, and Accuracy of 0.81. Finally, the Decision Tree model had the lowest performance among all models, with an F1-score of 0.68, Recall of 0.67, Precision of 0.70, and Accuracy of 0.68."
1209,"caption: Table 1: Performance comparison of different models using various evaluation metrics.table: Model_1,Model_2,Model_3,Model_4, Metric_1,0.72,0.68,0.65,0.74, Metric_2,0.61,0.53,0.72,0.50, Metric_3,0.93,0.95,0.79,0.66, Metric_4,0.45,0.75,0.88,0.91","Table 1 presents the performance comparison of four different models using multiple evaluation metrics. The models are denoted as Model_1, Model_2, Model_3, and Model_4. The table reveals the model performance on four evaluation metrics, denoted as Metric_1, Metric_2, Metric_3, and Metric_4. Interestingly, Model_1 achieved the highest score for Metric_3 (0.93), while Model_2 performed best in Metric_4 (0.75). Model_3 scored the lowest in Metric_2 (0.72), and Model_4 performed poorly in Metric_1 (0.74). Overall, the table provides a holistic overview of model comparison using various evaluation metrics."
1210,"caption: Table comparing different classification models using various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Decision Tree,0.89,0.91,0.85,0.88, Random Forest,0.94,0.96,0.91,0.93, Gradient Boost,0.91,0.93,0.88,0.90, KNN,0.85,0.87,0.80,0.83, SVM,0.93,0.95,0.89,0.92","The table shows the model performances of Decision Tree, Random Forest, Gradient Boost, KNN, and SVM based on different evaluation metrics such as accuracy, precision, recall, and F1-score. The Random Forest model outperforms all other models in terms of accuracy, with a score of 0.94, while Decision Tree performed with an accuracy score of 0.89. Interestingly, SVM and Random Forest have similar precision and F1 Score values, with SVM slightly outperforming Random Forest in terms of recall score. KNN model recorded the lowest scores in all evaluation metrics, with the lowest accuracy score of 0.85. Overall, the table suggests that Random Forest might be the best fit for this classification problem based on consistent and high-performance scores across various metrics."
1211,"caption: Table 4: Performance evaluation of different models on the classification tasktable: Models,Precision,Recall,F1-score,AUC, Logistic,0.87,0.89,0.88,0.91, Decision Tree,0.83,0.80,0.81,0.84, Random Forest,0.94,0.92,0.93,0.97, Support Vector,0.91,0.88,0.89,0.93","Table 4 provides an overview of model performance in a classification task. The table includes precision, recall, F1-score, and AUC metrics for four different models: Logistic Regression, Decision Tree, Random Forest, and Support Vector Machine. Notably, the Random Forest model outperformed the other models, achieving the highest scores across all metrics, including precision (0.94), recall (0.92), F1-score (0.93), and AUC (0.97). Support Vector Machine had the second-best results with a precision score of 0.91, recall score of 0.88, F1-score of 0.89, and AUC score of 0.93. Logistic Regression and Decision Tree models performed comparatively less effective than other models."
1212,"caption: Table 4: Comparison of the performance metrics of different models.table: Model,F1-Score,Precision,Recall,Accuracy, LR,0.788,0.857,0.728,0.821, SVM,0.847,0.790,0.916,0.865, Random forest,0.849,0.890,0.811,0.865, XGBoost,0.872,0.861,0.884,0.879, Gradient Boosting,0.878,0.881,0.875,0.882","Table 4 compares the F1-score, Precision, Recall, and Accuracy of different models. The models include Logistic Regression (LR), Support Vector Machine (SVM), Random Forest, XGBoost, and Gradient Boosting. All models were trained, validated, and tested on the same dataset. Notably, Gradient Boosting performed the best across all metrics, scoring the highest F1-score of 0.878 and the highest accuracy of 0.882. XGBoost also performed well across all metrics, scoring the highest Precision of 0.861 and the second-highest F1-score, Recall, and Accuracy. Random Forest performed comparably well but had lower Recall than other models. SVM gave the highest Recall but comparatively lower Precision, while the LR model had the lowest F1-score and Recall among all models."
1213,"caption: Table 4: Model performance of different classification algorithmstable: Model,Accuracy,Precision,Recall,F1-Score,AUC, SVM,75%,0.56,0.80,0.65,0.82, Logistic Regression,80%,0.64,0.78,0.70,0.84, Decision Tree,70%,0.60,0.70,0.64,0.75, Random Forest,85%,0.80,0.88,0.82,0.90, XGBoost,82%,0.76,0.84,0.80,0.88","The presented table demonstrates the comparison of different classification algorithms based on different key performance metrics such as accuracy, precision, recall, F1-score, and AUC. SVM, Logistic Regression, Decision Tree, Random Forest and XGBoost are used as model approaches in this experiment. According to the results, the Random Forest algorithm demonstrated the highest accuracy (85%) and AUC (0.90), followed by XGBoost with 82% accuracy and 0.88 AUC respectively. Logistic Regression was relatively effective in precision with 0.64, while Random Forest showed the best results in terms of precision (0.80), recall (0.88), and F1-score (0.82). The Decision Tree model had the lowest performance among all approaches, with 70% accuracy, 0.60 precision, 0.70 recall, 0.64 F1-score, and 0.75 AUC."
1214,"caption: Performance metrics of multiple models.table: Model,Accuracy,Precision,Recall,F1 Score, Model 1,0.85,0.87,0.84,0.85, Model 2,0.75,0.77,0.74,0.75, Model 3,0.89,0.90,0.88,0.89, Model 4,0.92,0.93,0.92,0.92, Model 5,0.78,0.80,0.77,0.78","Table shows the performance metrics of five different models evaluated using multiple classification evaluation metrics, including Accuracy, Precision, Recall, and F1 score. Model 4 exhibits the highest performance among all models across all evaluation metrics with an Accuracy of 0.92, Precision of 0.93, Recall of 0.92, and F1 score of 0.92. Model 3 also performs very well with an Accuracy of 0.89, and high Precision, Recall, and F1 score of 0.90, 0.88, and 0.89, respectively. Model 5 shows the poorest performance across all evaluation metrics with an Accuracy of 0.78 and the lowest Precision of 0.80."
1215,"caption: Table 4: Model performance comparison based on different evaluation metrics.table: Model,PR-AUC,ROC-AUC,F1 Score,Accuracy, Random Forest,0.901,0.710,0.813,0.795, Naive Bayes,0.784,0.645,0.696,0.619, Logistic Regression,0.810,0.652,0.726,0.750, K-Nearest Neighbors,0.799,0.621,0.721,0.676, Neural Network,0.901,0.712,0.817,0.813","Table 4 shows the comparison of different models using various evaluation metrics. The models analyzed are Random Forest, Naive Bayes, Logistic Regression, K-Nearest Neighbors, and Neural Network. The evaluation metrics used for the comparison are PR-AUC, ROC-AUC, F1-Score, and Accuracy. Interestingly, the Random Forest and Neural Network models perform the best across all evaluation metrics. The Random Forest model had the highest PR-AUC and F1-Score of 0.901 and 0.813, respectively. In contrast, the Neural Network model had the highest accuracy and ROC-AUC of 0.813 and 0.712, respectively. The Naive Bayes model achieved the lowest overall performance of all models."
1216,"caption: Model performances on the test dataset using different evaluation metrics.table: Models,F1 Score,Accuracy,AUC_ROC,Sensitivity,Specificity, Random Forest,0.897,0.902,0.945,0.917,0.896, XGBoost,0.896,0.901,0.940,0.912,0.897, Multi-layer Perceptron,0.893,0.900,0.942,0.912,0.889, Support Vector Machine,0.881,0.891,0.925,0.903,0.879, Logistic Regression,0.854,0.865,0.881,0.888,0.857","The table compares the performance of Random Forest, XGBoost, Multi-layer Perceptron (MLP), Support Vector Machine (SVM), and Logistic Regression (LR) models on a test dataset using five evaluation metrics: F1 Score, Accuracy, AUC_ROC, Sensitivity, and Specificity. The Random Forest model shows the best F1 Score, Accuracy, and AUC_ROC with a score of 0.897, 0.902, and 0.945, respectively. The MLP model achieves the second-best F1 Score and Accuracy scores with a close score of 0.893 and 0.900, respectively. However, the SVM has the highest Sensitivity score of 0.903. The Logistic Regression model yields the lowest F1 Score, Accuracy, and AUC_ROC compared to other models. Interestingly, all models have achieved relatively higher Specificity scores (>0.85), indicating that the models perform well in predicting negative cases."
1217,"caption: Model Performance Metrics for Various Models in Binary Classificationtable: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.92,0.93,0.92,0.94, KNN,0.89,0.90,0.89,0.91, DT,0.85,0.86,0.84,0.87, MLP,0.91,0.92,0.91,0.93",
1218,"caption: Model performance evaluation for four models on a classification task.table: Model,Precision,Recall,F1 Score,Accuracy, Logistic Regression,0.76,0.86,0.81,0.84, Decision Tree,0.81,0.76,0.78,0.79, Random Forest,0.84,0.83,0.83,0.84, Gradient Boosting,0.85,0.84,0.84,0.85","Table presents the performance of four different models, namely Logistic Regression, Decision Tree, Random Forest, and Gradient Boosting, on a classification task. The models' performance was evaluated using four different evaluation metrics: Precision, Recall, F1 score, and Accuracy. The Random Forest model exhibited the highest Precision, Recall, and F1 Score with scores of 0.84, 0.83, and 0.83, respectively. Similarly, Gradient Boosting showed the highest Accuracy of 0.85. Interesting to note that Logistic Regression showed a relatively high Recall of 0.86, while Decision Tree exhibited a relatively high Precision of 0.81. Furthermore, all the models had an Accuracy score above 0.79, indicating good overall performance."
1219,"caption: Table 4 presents the performance of different machine learning algorithms for a classification problem. The F1 Score, Precision, Recall, and Accuracy metrics are utilized to evaluate the models. The table includes Decision Tree, Random Forest, Naive Bayes, Support Vector Machine, and K-Nearest Neighbors models.table: Model,F1 Score,Precision,Recall,Accuracy, Decision Tree,0.85,0.83,0.87,0.89, Random Forest,0.89,0.88,0.91,0.91, Naive Bayes,0.76,0.81,0.72,0.82, Support Vector Machine,0.91,0.92,0.90,0.93, K-Nearest Neighbors,0.75,0.72,0.80,0.78","Table 4 shows the performance of five different machine learning algorithms for a classification problem. The table presents F1 Score, Precision, Recall, and Accuracy metrics for each model. Notably, the Support Vector Machine model performed the best with the highest F1 Score, Precision, and Recall of 0.91, 0.92, and 0.90, respectively. The model achieved the highest accuracy score of 0.93. Additionally, the Random Forest model outperformed all models on the F1 Score metric with a score of 0.89. It is interesting to observe that the Naive Bayes and K-Nearest Neighbors models both have lower accuracy scores compared to the other models despite having similar performance in the other metrics."
1220,"caption: Model performances based on evaluation metricstable: Model,Accuracy (%),Precision (%),Recall (%),F1-Score (%), SVM,85.4,87.2,79.3,82.9, KNN,76.2,78.4,70.1,72.8, LR,91.1,92.5,89.7,90.9, RF,89.9,91.3,88.2,89.6, NB,71.5,69.8,79.9,70.4","The table shows the accuracy, precision, recall, and F1-Score percentages of different machine learning models. SVM has the highest precision percentage at 87.2%, while LR achieved the highest accuracy of 91.1% and highest F1-Score of 90.9%. NB had the lowest accuracy score of 71.5%, while KNN had the lowest precision percentage of 78.4%. RF achieved the highest recall of 88.2%. The results indicate that LR and RF are better options if we want models with high accuracy and robust F1-Score. However, model selection ultimately depends on goals and priorities."
1221,"caption: Table 4: Evaluation of different classification models based on multiple metricstable: Model,Accuracy,F1-score,Precision,Recall, SVM,0.88,0.82,0.79,0.85, MLP,0.92,0.87,0.84,0.90, RF,0.91,0.86,0.83,0.89, KNN,0.87,0.80,0.76,0.85, NB,0.79,0.70,0.67,0.73","Table 4 presents the evaluation of five different classification models based on various metrics, including accuracy, F1-score, precision, and recall. The models evaluated in the table include Support Vector Machine (SVM), Multilayer Perceptron (MLP), Random Forest (RF), K-Nearest Neighbors (KNN), and Naive Bayes (NB). The MLP model performed the best in terms of accuracy, achieving a score of 0.92, while the NB model had the lowest accuracy score of 0.79. Similarly, the MLP model achieved the best F1-score of 0.87, while the NB model again had the lowest F1-score of 0.70. These results suggest that the MLP model may be the best choice for this specific classification task."
1222,"caption: Model performances based on different evaluation metricstable: Model,Accuracy,Precision,Recall,F1 Score, SVM,0.907,0.928,0.883,0.905, Logistic Regression,0.895,0.908,0.869,0.887, Random Forest,0.918,0.936,0.903,0.918, Gradient Boosting,0.921,0.938,0.908,0.922, Deep Learning,0.923,0.940,0.910,0.924, Ensemble (SVM, Random Forest, Gradient Boosting),0.931,0.946,0.922,0.933",
1223,"caption: Table 4: Model Comparison using Multiple Evaluation Metricstable: Model,F1 Score,Precision,Recall,Accuracy, Logistic Regression,0.89,0.91,0.87,0.90, Random Forest,0.92,0.93,0.96,0.91, XGBoost,0.95,0.94,0.96,0.94, SVM,0.87,0.89,0.85,0.88, Multilayer Perceptron,0.91,0.92,0.93,0.88","Table 4 presents a comparison of different models based on multiple evaluation metrics, including F1 Score, Precision, Recall, and Accuracy. The table consists of Logistic Regression, Random Forest, XGBoost, SVM, and Multilayer Perceptron models. The Random Forest model showcases the highest F1 Score and Recall of 0.92 and 0.96, respectively. The XGBoost model exhibits the highest Precision of 0.94, while the Multilayer Perceptron model had the lowest but acceptable performance regarding Accuracy. Overall, the Random Forest model appears to be the best model based on the highest F1 Score, Precision, and Recall values."
1224,"caption: Classification Model Performances on Test Datatable: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.82,0.82,0.84,0.81, Decision Tree,0.73,0.72,0.70,0.76, Random Forest,0.86,0.85,0.87,0.83, SVM,0.76,0.75,0.74,0.77","The table above presents a comparison of different classification models based on multiple evaluation metrics, including accuracy, F1-score, precision, and recall. The Logistic Regression model achieved the highest accuracy score of 0.82, followed by the Random Forest model at 0.86. The Random Forest model had the best overall performance in terms of F1-score, precision, and recall, with scores of 0.85, 0.87, and 0.83, respectively. Notably, the Decision Tree model shows the least performance among the models, with an accuracy score of 0.73, an F1-score of 0.72, a precision score of 0.70, and a recall score of 0.76. Overall, this table provides an insight into how different models perform on classification tasks."
1225,"caption: Model Evaluation Metrics and Resultstable: Model,F1-Score,Recall,Precision,AUC-PR,Accuracy, Random Forest,0.93,0.87,0.98,0.95,0.93, Logistic Regression,0.85,0.92,0.79,0.87,0.84, SVM,0.81,0.77,0.86,0.77,0.80, KNN,0.62,0.46,0.96,0.48,0.60","Table present a comparison of different models based on F1-score, recall, precision, AUC-PR, and accuracy evaluation metrics. Four classifiers, namely Random Forest, Logistic Regression, SVM, and KNN, were used to classify the same dataset. Interestingly, the Random Forest model exhibits the best performance on most metrics, having the highest F1-score of 0.93, precision of 0.98, recall of 0.87, and AUC-PR of 0.95. Additionally, the model achieved an accuracy of 0.93, making it the most reliable model. On the other hand, KNN had the lowest scores on all metrics, with an F1-score of 0.62, recall of 0.46, precision of 0.96, AUC-PR of 0.48, and accuracy of 0.60."
1226,"caption: Classification Model Performancestable: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.95,0.94,0.98,0.91, Random Forest,0.93,0.92,0.96,0.88, Logistic Regression,0.91,0.89,0.94,0.85, K-Nearest Neighbor,0.89,0.87,0.92,0.83, Decision Tree,0.85,0.83,0.88,0.78","Table 4 displays different classification models' performances measured using multiple evaluation metrics: accuracy, F1 score, precision, and recall. The SVM model achieves the best performance with accuracy of 0.95, F1 score of 0.94, precision of 0.98, and recall of 0.91. The Random Forest model comes in second, performing relatively well with an accuracy of 0.93, F1 score of 0.92, precision of 0.96, and recall of 0.88. The Logistic Regression and K-Nearest Neighbor models show almost equal performances, while the Decision Tree model displays the weakest predictive power among the models."
1227,"caption: Performance of different models using multiple evaluation metrics on the dataset.table: Model,F1-Score,Accuracy,Precision,Recall, SVM,0.82,0.85,0.82,0.85, Decision Tree,0.74,0.77,0.72,0.77, Naive Bayes,0.68,0.72,0.72,0.51, Random Forest,0.88,0.91,0.89,0.87, Logistic Regression,0.80,0.83,0.81,0.78","Table presents the performance of five different models using multiple evaluation metrics such as F1-score, accuracy, precision, and recall on the dataset. The top-performing model based on all the chosen metrics is Random Forest model. It has the highest F1-score of 0.88 and accuracy of 0.91. On the other hand, Naive Bayes model shows relatively poorer performance compared to other models, attaining an F1-Score of 0.68 and accuracy of 0.72. Both SVM and Logistic Regression models demonstrate similar performance with F1-Scores of 0.82 and 0.80, respectively. In stark contrast, the Decision Tree model shows a lower F1-score of 0.74. Overall, the Random Forest model demonstrates the best performance in all the metrics."
1228,"caption: Performance Measures of Different Classification Models.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.86,0.88,0.84,0.86, Decision Tree,0.76,0.79,0.75,0.76, Random Forest,0.91,0.92,0.90,0.91, Support Vector Machine,0.84,0.85,0.83,0.84, K-Nearest Neighbors,0.79,0.81,0.79,0.79, Naive Bayes,0.75,0.70,0.78,0.74","Table presents a comparison of different classification models' performance based on multiple evaluation metrics. The evaluation metrics used here are Accuracy, Precision, Recall, and F1-Score. The table compares six models, namely Logistic Regression, Decision Tree, Random Forest, Support Vector Machine, K-Nearest Neighbors, and Naive Bayes. The Random Forest model performs the best in terms of accuracy, achieving 0.91, while the Naive Bayes model achieved the least accuracy of 0.75. However, Naive Bayes obtained the highest recall score of 0.78, and Logistic Regression recorded the highest precision score of 0.88 among all the models. Overall, the Random Forest model seems to perform better than the rest of the models under evaluation."
1229,"caption: Table 4: Model performances based on multiple evaluation metrics.table: Model,Accuracy,F1 score,Precision,Recall,ROC AUC, SVM,0.83,0.82,0.78,0.87,0.88, KNN,0.79,0.75,0.77,0.74,0.82, MLP,0.86,0.85,0.82,0.89,0.89, Naive Bayes,0.77,0.76,0.80,0.72,0.81, Random Forest,0.87,0.86,0.84,0.89,0.92","In Table 4, we present the performance of five different models, namely SVM, KNN, MLP, Naive Bayes, and Random Forest, based on multiple evaluation metrics. The evaluation metrics include accuracy, F1 score, precision, recall, and ROC AUC score. The MLP model achieved the highest accuracy and F1 score of 0.86 and 0.85, respectively. The Random Forest model outperformed other models with the highest ROC AUC score of 0.92 and precision score of 0.84. The SVM model showed the highest recall score of 0.87, and the Naive Bayes model demonstrated the lowest accuracy and recall score among all other models, with scores of 0.77 and 0.72, respectively. Overall, the Random Forest model exhibited the best performance, whereas the Naive Bayes model performed the worst among all models."
1230,"caption: Table 4: Model performance based on accuracy, F1 score, precision, and recall.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.85,0.80,0.80,0.82, Logistic Regression,0.81,0.76,0.78,0.74, Decision Tree,0.79,0.74,0.73,0.76, Random Forest,0.89,0.84,0.87,0.81, XGBoost,0.91,0.86,0.88,0.85","The table compares multiple models based on accuracy, F1 score, precision, and recall. The SVM model has a top accuracy of 0.85 and recall of 0.82. The Random Forest model has the highest accuracy of 0.89 and F1 score of 0.84, but its recall is 0.81, which is lower than those of the SVM and Logistic Regression models. The XGBoost model outperforms all the other models in terms of accuracy and F1 score, with 0.91 and 0.86, respectively, but its precision and recall are slightly lower than those of the Random Forest model. It is worth noting that the performance of the models varies significantly for different evaluation metrics."
1231,"caption: Comparison of Machine Learning models' performance on the given problem.table: Model,Accuracy,Precision,Recall,F1,AUC, SVM,0.89,0.90,0.86,0.88,0.92, Logistic Regression,0.87,0.85,0.92,0.88,0.90, Random Forest,0.94,0.93,0.96,0.94,0.97, XGBoost,0.96,0.95,0.97,0.96,0.98, Neural Network,0.93,0.91,0.95,0.93,0.96","The table presents a comparison of the machine learning models' performance in terms of accuracy, precision, recall, F1-score, and AUC. The SVM model achieved an accuracy of 0.89 followed by Logistic Regression and Random Forest with accuracy scores of 0.87 and 0.94, respectively. XGBoost scored the highest accuracy value of 0.96, outperforming all other models. In terms of precision, Random Forest and XGBoost had the highest precision scores of 0.93 and 0.95, respectively. Random Forest also outperformed the other models in terms of recall and F1-score, with a score of 0.96 and 0.94, respectively. Finally, XGBoost achieved the highest AUC score of 0.98, indicating its superiority over the other models."
1232,"caption: Performance metrics of different models on the test dataset.table: Model Name,Precision,Recall,F1-Score,Accuracy, LR,0.78,0.85,0.81,0.75, Tree,0.70,0.72,0.71,0.72, RF,0.81,0.89,0.85,0.81, XGB,0.84,0.90,0.87,0.84","The table above illustrates the model performances on precision, recall, F1-score, and accuracy metrics. The LR model achieved the highest precision with a score of 0.78, while the XGB model resulted in the highest precision of 0.84. The RF model produced the best recall score of 0.89, whereas the XGB model resulted in the highest recall of 0.90. Finally, the XGB model resulted in the best F1-score and accuracy, with scores of 0.87 and 0.84, respectively. Overall, the XGB model appears to achieve the best performance on all metrics in this experiment."
1233,"caption: Table 4: Model performance comparison based on Accuracy, F1 Score, Precision, and Recall.table: Model,Accuracy,F1 Score,Precision,Recall, Model 1,0.87,0.85,0.89,0.82, Model 2,0.84,0.81,0.86,0.78, Model 3,0.90,0.87,0.91,0.84, Model 4,0.82,0.78,0.84,0.77, Model 5,0.88,0.86,0.87,0.85","Table 4 provides the performance comparison of five different models based on various evaluation metrics, including Accuracy, F1 Score, Precision, and Recall. Each model's evaluation metrics scores are presented in a separate column. Model 3 achieved the highest Accuracy score of 0.90, followed by Model 5 with 0.88. Additionally, Model 1 achieved the highest F1 Score of 0.85, while Model 3 recorded the highest Precision score of 0.91. Finally, Model 1 recorded the highest Recall score of 0.82, followed closely by Model 5 at 0.85. Interestingly, there is a considerable difference in performance scores among the models, with Model 4 displaying the worst performance."
1234,"caption: Comparison of model performances based on Accuracy, F1 Score, Precision, and Recall.table: Models,Accuracy,F1 Score,Precision,Recall, Model A,0.82,0.81,0.83,0.80, Model B,0.87,0.86,0.89,0.83, Model C,0.80,0.79,0.81,0.77, Model D,0.89,0.88,0.90,0.87, Model E,0.76,0.75,0.76,0.74","Table 4 presents the comparison of different models based on Accuracy, F1 Score, Precision, and Recall metrics. Model A shows the lowest performance with an accuracy score of 0.82 and F1 score of 0.81, while Model D stands out with the highest performance by achieving an accuracy score of 0.89 and F1 score of 0.88. Model B demonstrated the best precision and recall score with 0.89 and 0.83, respectively, while Model E showed the lowest performance across all metrics. The findings from this table can help researchers to identify the best performing model for their particular case based on the maximization of these specific evaluation metrics."
1235,"caption: Performance results of different models evaluated based on accuracy, precision, recall, and F1-score.table: Model,Accuracy,Precision,Recall,F1-Score, LR,0.89,0.87,0.91,0.89, SVM,0.92,0.91,0.93,0.92, RF,0.95,0.95,0.94,0.94, XGB,0.93,0.92,0.94,0.93","The table presents the performance results of different models based on accuracy, precision, recall, and F1-score. The models include Logistic Regression (LR), Support Vector Machine (SVM), Random Forest (RF), and XGBoost (XGB), and all models were evaluated using the same dataset. It is observed that the Random Forest model performed best in terms of accuracy with a score of 0.95, while the Logistic Regression model had the lowest accuracy with a score of 0.89. In terms of precision, the Random Forest model had the highest score of 0.95, followed by SVM with a score of 0.91. The SVM model had the highest recall score of 0.93, while the Logistic Regression model had the lowest recall score of 0.91. Finally, the Logistic Regression model had the lowest F1-score with a score of 0.89, while all other models had an F1-score of 0.92 or higher."
1236,"caption: Table 4: Model Performance Metrics.table: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.89,0.93,0.89,0.91, Random Forest,0.91,0.93,0.91,0.92, Support Vector Machine,0.87,0.92,0.87,0.89, Naive Bayes,0.85,0.90,0.85,0.87, K-Nearest Neighbors,0.88,0.91,0.88,0.89","Table 4 presents the performance metrics of different machine learning models on a given dataset. The models' evaluation is based on the accuracy, precision, recall, and F1-score. The models used in this study include Logistic Regression, Random Forest, Support Vector Machine, Naive Bayes, and K-Nearest Neighbors. The best overall performer is the Random Forest model, achieving an accuracy score of 0.91 and an F1 score of 0.92. However, the Logistic Regression model showed a slightly higher precision score of 0.93, while the K-Nearest Neighbors achieved a higher recall score of 0.88."
1237,"caption: Model performances based on various evaluation metricstable: Model,Accuracy,F1 score,Precision,Recall, LR,0.872,0.824,0.819,0.829, DT,0.818,0.795,0.774,0.818, NB,0.801,0.742,0.781,0.707, SVM,0.887,0.855,0.853,0.859, RF,0.923,0.917,0.911,0.924","Table above reports the performances of multiple models based on Accuracy, F1 score, Precision, and Recall. Models include Logistic Regression (LR), Decision Tree (DT), Naive Bayes (NB), Support Vector Machine (SVM), and Random Forest (RF). Best performing model for different metrics include RF with highest Accuracy (0.923), highest F1 score (0.917), highest Precision (0.911), and second-highest Recall (0.924) scores. SVM performs the best in Recall score with a score of 0.859. Interestingly, LR performs well in all evaluation metrics, except Recall (0.829). The NB model shows the lowest performances in all scores except Precision where it performs better than DT."
1238,"caption: Table 4: Model performances based on different evaluation metrics using the same dataset.table: Model,Accuracy,F1-score,Recall,Precision, SVM,0.78,0.76,0.64,0.94, KNN,0.72,0.68,0.58,0.88, RF,0.85,0.83,0.78,0.88, MLP,0.89,0.87,0.84,0.9, CNN,0.92,0.91,0.89,0.92","Table 4 displays the performances of the SVM, KNN, RF, MLP, and CNN models regarding accuracy, F1-score, recall, and precision using the same dataset. The table highlights that the CNN model has the highest accuracy score of 0.92, while the MLP model has the highest F1-score of 0.87. Additionally, the SVM model has the highest precision score of 0.94, while the RF model has the highest recall score of 0.78. The table provides insight into each model's performance regarding different evaluation metrics, highlighting their strengths and weaknesses."
1239,"caption: Table 4: Model performances based on multiple evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall,AUC, Logistic Reg.,0.853,0.846,0.859,0.833,0.923, Random Forest,0.882,0.877,0.892,0.863,0.936, Support Vector,0.849,0.844,0.855,0.834,0.927, Neural Network,0.891,0.885,0.899,0.871,0.944","Table 4 demonstrates the performances of different models using multiple evaluation metrics, including Accuracy, F1-score, Precision, Recall, and AUC. The table exhibits four models: Logistic Regression, Random Forest, Support Vector, and Neural Network. The Random Forest model performed the best with an accuracy of 0.882, closely followed by the Neural Network model with an accuracy of 0.891. The Neural Network model excelled in multiple evaluation metrics, including F1-score (0.885) and AUC (0.944). However, the Logistic Regression model had the highest Recall score of 0.833, while the Random Forest model had the highest Precision score of 0.892."
1240,"caption: Table 4: Performance comparison of five models based on various evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Model 1,0.85,0.82,0.90,0.76, Model 2,0.82,0.79,0.88,0.72, Model 3,0.88,0.85,0.91,0.81, Model 4,0.79,0.76,0.85,0.68, Model 5,0.90,0.87,0.92,0.83","Table 4 shows a performance comparison of five different models based on various evaluation metrics, such as Accuracy, F1 Score, Precision, and Recall. All models were tested using the same dataset and are listed in the table with their corresponding evaluation scores. Interestingly, Model 5 has the best overall performance, achieving the highest accuracy (0.90), F1 score (0.87), precision (0.92), and recall (0.83) among all the models. On the other hand, Model 4 has the lowest overall performance, achieving the least on all the evaluation metrics."
1241,"caption: Model Evaluation Metricstable: Model,F1-Score,Accuracy,Precision,Recall, SVM,0.89,0.91,0.93,0.85, KNN,0.82,0.84,0.76,0.89, Decision Tree,0.75,0.79,0.80,0.71, Random Forest,0.91,0.92,0.94,0.88","The table presents the performance of four different models: SVM, KNN, Decision Tree, and Random Forest, on a particular dataset. Four evaluation metrics, namely F1-Score, Accuracy, Precision, and Recall, were used to compute the performance of the models. Notably, Random Forest achieved the best F1-Score of 0.91, while SVM had the highest Accuracy, Precision, and Recall with the values of 0.91, 0.93, and 0.85, respectively. KNN had a lower F1-score of 0.82 compared to the other models but had a high recall of 0.89. Decision Tree achieved the lowest F1-Score of 0.75. Overall, the Random Forest model outperformed the other models, except SVM, in most of the evaluated metrics."
1242,"caption: Comparison of Model performances based on different evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, Model 1,0.92,0.95,0.92,0.98, Model 2,0.87,0.90,0.88,0.93, Model 3,0.89,0.92,0.90,0.96, Model 4,0.91,0.94,0.93,0.95, Model 5,0.90,0.93,0.91,0.95","The table above shows the performance comparison of five different models based on different evaluation metrics. The metrics used for performance comparison are Accuracy, F1-score, Precision, and Recall. From the table, it can be observed that Model 1 has the highest Accuracy score of 0.92, while Model 2 has the lowest Accuracy score of 0.87. Also, Model 1 has the highest F1-score of 0.95, and Model 2 has the lowest F1-score of 0.90. Model 4 has the highest Precision score of 0.93, while Model 2 has the lowest Precision score of 0.88. On the other hand, Model 1 and Model 3 have the highest Recall score of 0.98 and 0.96, respectively, while Model 2 has the lowest Recall score of 0.93."
1243,"caption: Model Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.82,0.85,0.64,0.73, Decision Tree,0.73,0.68,0.64,0.66, Random Forest,0.85,0.88,0.74,0.80, Gradient Boosting,0.87,0.88,0.80,0.84, Neural Network,0.84,0.86,0.76,0.80","The table presents the evaluation metrics of five different models. The models include Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Neural Network. The evaluation metrics measured are Accuracy, Precision, Recall, and F1 Score. The best-performing model demonstrated by the table is the Gradient Boosting model, which achieved the highest Accuracy of 0.87, Precision of 0.88, Recall of 0.80, and F1 Score of 0.84. Remarkably, overall, the table's models performed moderately well, with Logistic Regression maintaining the lowest performance metrics, and Gradient Boosting the highest."
1244,"caption: Performance metrics of different machine learning modelstable: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.89,0.91,0.87,0.89, KNN,0.76,0.81,0.72,0.76, SVM,0.93,0.95,0.91,0.93, Decision Tree,0.81,0.83,0.78,0.80, Random Forest,0.86,0.88,0.84,0.86","The table above shows the performance metrics of different machine learning models evaluated based on multiple metrics, including accuracy, precision, recall, and F1 score. The table includes Logistic Regression, KNN, SVM, Decision Tree, and Random Forest models. Interestingly, the table highlights that SVM achieved the highest overall performance with an accuracy of 0.93, precision of 0.95, recall of 0.91 and F1 score of 0.93. In contrast, KNN model underperformed in all metrics with an accuracy of 0.76, precision of 0.81, recall of 0.72, and F1 score of 0.76."
1245,"caption: Table 4: Performance of different models based on multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,Cohen's kappa, SVM,0.85,0.85,0.90,0.70, Random Forest,0.89,0.91,0.86,0.78, Naive Bayes,0.78,0.77,0.81,0.56, Decision Trees,0.81,0.85,0.75,0.60","Table 4 presents the performance comparison of four different models based on multiple evaluation metrics: accuracy, precision, recall, and Cohen's kappa. The table exhibits SVM, Random Forest, Naive Bayes, and Decision Trees models' performance in terms of the aforementioned metrics. Interestingly, the Random Forest model performed the best in terms of accuracy (0.89), precision (0.91), and Cohen's kappa (0.78), while SVM achieved the highest recall (0.9). Naive Bayes performed the least in all metrics, except for recall where it achieved the second-best score of 0.81. The table provides valuable insights into the models' performance and allows for a comparison of their strengths and weaknesses."
1246,"caption: Model Performance Comparisonstable: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.82,0.86,0.71,0.77, MLP,0.84,0.83,0.86,0.84, LR,0.81,0.81,0.86,0.83, KNN,0.72,0.79,0.56,0.65","The presented table shows the evaluation results for four different machine learning models. The models, SVM, MLP, LR, and KNN, were tested on the same dataset, and multiple performance metrics were calculated. These metrics include accuracy, precision, recall, and F1-score. From the table, it shows that MLP performed the best with an accuracy of 0.84 and F1-score of 0.84. SVM had the highest precision of 0.86, while LR had the highest recall of 0.86. Interestingly, the KNN model had the lowest overall performance, achieving the lowest accuracy and F1-score values."
1247,"caption: Comparison of model performances based on different evaluation metricstable: Model,Accuracy,F1-Score,Precision,Recall, Model A,0.85,0.84,0.86,0.83, Model B,0.87,0.86,0.88,0.85, Model C,0.90,0.89,0.91,0.88, Model D,0.86,0.85,0.86,0.85, Model E,0.89,0.88,0.91,0.86",
1248,"caption: Comparison of Different Models' Performance Using Multiple Evaluation Metricstable: Model,Precision,Recall,F1-Score,AUC, Logistic Regression,0.75,0.95,0.84,0.90, Naive Bayes,0.68,0.81,0.74,0.83, Random Forest,0.82,0.92,0.87,0.92, XGBoost,0.87,0.88,0.87,0.93, Neural Network,0.89,0.91,0.90,0.94","Table 4 above displays a comparison of different models' performances based on various evaluation metrics. The evaluation metrics include Precision, Recall, F1-Score, and AUC. The models included are Logistic Regression, Naive Bayes, Random Forest, XGBoost, and Neural Network. The table exhibits that the Neural Network model outperforms the other models in most of the evaluation metrics, achieving the highest Precision, Recall, F1-score, and AUC of 0.89, 0.91, 0.90, and 0.94, respectively. Interestingly, XGBoost also performed well, with an F1-score and a higher AUC score of 0.87 and 0.93, respectively. In contrast, the Naive Bayes model achieved the lowest scores for all evaluation metrics."
1249,"caption: Comparison of accuracy, F1 Score, recall, and precision for different classification models.table: Model,Accuracy,F1 Score,Recall,Precision, SVM,0.89,0.90,0.91,0.90, Logistic Reg.,0.87,0.88,0.89,0.88, Random Forest,0.90,0.91,0.92,0.91, XGBoost,0.91,0.92,0.93,0.92, Neural Network,0.92,0.93,0.94,0.93","The table presents a comparison of different classification models based on accuracy, F1 Score, recall, and precision metrics. SVM, Logistic Regression, Random Forest, XGBoost, and Neural Network models are evaluated using the same dataset. The table illustrates that Neural Network outperforms all models with an accuracy of 0.92, F1 Score of 0.93, recall of 0.94, and precision of 0.93. Notably, XGBoost also demonstrates significantly improved performance compared to other models. It achieves an accuracy of 0.91, F1 Score of 0.92, recall of 0.93, and precision of 0.92, showing the second-best performance across all models. Conversely, Logistic regression, despite being a popular classification model, underperforms with the lowest accuracy, F1 Score, recall, and precision scores amongst the models."
1250,"caption: Performance results of different models evaluated on various metrics.table: Model,Accuracy,F1-Score,Recall,Precision, SVM,0.82,0.83,0.78,0.89, KNN,0.74,0.75,0.68,0.84, Random Forest,0.89,0.89,0.83,0.96, Multinomial Naive Bayes,0.78,0.79,0.76,0.83, XGBoost,0.91,0.91,0.88,0.94","The table displays the performances of five different models, namely SVM, KNN, Random Forest, Multinomial Naive Bayes, and XGBoost. All models were evaluated based on four distinct metrics - Accuracy, F1-Score, Recall, and Precision. From the table, XGBoost achieved the best Accuracy, F1-Score, and Precision with 0.91, 0.91, and 0.94, respectively. Conversely, SVM had the best Recall score of 0.78. Additionally, Random Forest achieved a slightly better Accuracy result than SVM with 0.89. The table indicates that XGBoost is the most efficient model among the listed models."
1251,"caption: Model performance based on different evaluation metrics.table: Model,Accuracy,F1-Score,AUC, LR,0.85,0.84,0.90, RF,0.87,0.86,0.92, SVM,0.82,0.81,0.87, KNN,0.80,0.78,0.85, DT,0.82,0.81,0.87, MLP,0.90,0.89,0.94","The table above presents a comparison of multiple model performances based on different evaluation metrics: accuracy, F1-score, and AUC. Six models are presented in the table: Logistic Regression (LR), Random Forest (RF), Support Vector Machine (SVM), K Nearest Neighbors (KNN), Decision Tree (DT), and Multi-Layer Perceptron (MLP). Among all the models, MLP has achieved the highest performance in all the evaluation metrics. It has an accuracy of 0.9, F1-score of 0.89, and AUC of 0.94. RF and LR models also exhibited excellent performances with AUC scores of 0.92 and 0.9, respectively. SVM and DT models showed similar performance with AUC scores of 0.87. KNN model has shown relatively weaker performance among the presented models in all the evaluation metrics."
1252,"caption: Model performances based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, SVM,0.79,0.85,0.74,0.79, Decision Trees,0.76,0.78,0.70,0.74, Random Forest,0.84,0.88,0.81,0.84, KNN,0.72,0.75,0.63,0.68, Logistic,0.81,0.84,0.78,0.81","The table compares different models' performances based on multiple evaluation metrics. The models include SVM, Decision Trees, Random Forest, KNN, and Logistic Regression. The evaluation metrics include Accuracy, Precision, Recall, and F1 Score. The Random Forest model performs best in terms of accuracy, scoring 0.84, while the SVM model has the highest precision of 0.85. On the other hand, the Logistic Regression model is outperformed by some models, but it ranks consistently higher across all metrics. The table shows that each model has its strength, with the Random Forest model being the overall best performer, considering all metrics."
1253,"caption: Model comparison of Precision, Accuracy, Recall, and F1 Score.table: Model,Precision,Accuracy,Recall,F1 Score, SVM,0.92,0.89,0.86,0.89, KNN,0.83,0.82,0.76,0.80, Logistic Regression,0.95,0.91,0.88,0.92, Decision Tree,0.80,0.81,0.75,0.78, Random Forest,0.93,0.92,0.87,0.90","This table compares different machine learning models' performance metrics using Precision, Accuracy, Recall, and F1 Score. The models evaluated in the table are SVM, KNN, Logistic Regression, Decision Tree, and Random Forest. The table highlights that the Logistic Regression model showed the highest performance in all four metrics, attaining Precision of 0.95, Accuracy of 0.91, Recall of 0.88, and F1 Score of 0.92. On the other hand, the Decision Tree model gained the lowest scores in all four metrics, obtaining Precision of 0.80, Accuracy of 0.81, Recall of 0.75, and F1 Score of 0.78. The table indicates that Logistic Regression and Random Forest models are the best models to use based on the computed metrics."
1254,"caption: Model performance comparison based on different evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, Model A,0.85,0.78,0.82,0.75, Model B,0.80,0.77,0.76,0.78, Model C,0.89,0.82,0.88,0.77, Model D,0.91,0.87,0.89,0.86, Model E,0.79,0.66,0.72,0.62","The table summarizes the performance comparison of five different models based on various evaluation metrics. The models were evaluated based on their accuracy, F1-score, precision, and recall. Model D achieved the highest accuracy of 0.91, followed by Model C with 0.89. In terms of F1-score, Model D also achieved the highest score with 0.87. Interestingly, even though Model A's overall accuracy was not the highest, it had the highest precision score of 0.82. On the other hand, Model E had the lowest performance scores across all evaluation metrics. Overall, the table provides a comprehensive overview of the different models' performance, highlighting their respective strengths."
1255,"caption: Model performances based on different evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.975,0.865,0.892,0.843, Logistic Regression,0.958,0.804,0.789,0.819, Decision Tree,0.929,0.777,0.776,0.779, Random Forest,0.971,0.845,0.873,0.819, KNN,0.937,0.758,0.777,0.740","The table presents the performances of different machine learning models based on various evaluation metrics. The models include SVM, Logistic Regression, Decision Tree, Random Forest, and KNN. The table exhibits the accuracy, F1-score, precision, and recall metrics for each of the models. Notably, the Random Forest model shows the highest accuracy of 0.971, while the SVM model produced the best F1-score of 0.865. In contrast, Logistic Regression achieved the highest precision score of 0.789, while recall turned out to be the highest for SVM with a score of 0.843. Overall, the Random Forest model seems to perform the best across all metrics, but the choice of model will depend on which evaluation metric is most important for a specific use case."
1256,"caption: Model performances based on multiple metrics.table: Model,Accuracy,Precision,Recall,F1-Score,AUC, Model 1,0.85,0.79,0.89,0.83,0.92, Model 2,0.84,0.80,0.87,0.83,0.91, Model 3,0.86,0.77,0.91,0.82,0.92, Model 4,0.82,0.78,0.82,0.80,0.89, Model 5,0.87,0.82,0.86,0.84,0.93","Table presents the performance evaluation of five different models based on five evaluation metrics: Accuracy, Precision, Recall, F1-Score, and AUC. Among the five models, Model 5 achieved the highest overall performance score with a 0.87 accuracy and 0.93 AUC score. Interestingly, Model 1 produced the second-highest AUC with a score of 0.92, while Model 3 achieved the highest Recall score of 0.91. It is also noticeable that Model 2 produced the highest Precision score of 0.80 in the group. Overall, the table shows that different models may excel in different metrics, and it is essential to evaluate models carefully, considering all the different metrics to choose the best one."
1257,"caption: Model performance using different evaluation metrics.table: Model,F1-Score,Accuracy,Precision,Recall,AUC, Logistic Regression,0.76,0.69,0.76,0.75,0.787, Random Forest,0.82,0.74,0.80,0.84,0.856, Gradient Boosting,0.85,0.81,0.86,0.85,0.889, Support Vector Machine,0.74,0.66,0.73,0.75,0.756, Multi-layer Perceptron,0.78,0.75,0.77,0.80,0.742","The table reports performance comparison of different models using multiple evaluation metrics, including F1-Score, Accuracy, Precision, Recall, and AUC. The models included in the table are Logistic regression, Random Forest, Gradient Boosting, Support Vector Machine and Multi-layer Perceptron. Notably, the Gradient Boosting model reports the highest performance for all metrics, including F1-Score (0.85), Accuracy (0.81), Precision (0.86), Recall (0.85), and AUC (0.889). Random Forest is the second-best performer overall, achieving F1-Score of 0.82, Accuracy of 0.74, Precision of 0.80, Recall of 0.84, and AUC of 0.856. Support Vector Machine exhibits the lowest overall performance and reports an F1-Score of 0.74, Accuracy of 0.66, Precision of 0.73, Recall of 0.75 and AUC of 0.756."
1258,"caption: Model performance based on accuracy, precision, recall, and F1-scoretable: Model,Accuracy,Precision,Recall,F1-score, Random Forest,0.84,0.89,0.78,0.83, SVM,0.82,0.87,0.77,0.81, Naive Bayes,0.78,0.84,0.75,0.79, Logistic Regression,0.81,0.86,0.76,0.80","The table presents the performance of four distinct models, namely Random Forest, SVM, Naive Bayes, and Logistic Regression. The models' performance has been evaluated based on several metrics such as Accuracy, Precision, Recall, and F1-score. Notably, random forest achieved the highest accuracy (0.84) and Precision (0.89), while SVM had the highest recall (0.77), but its F1-score (0.81) was closely followed by LSTM (bi-directional) at 0.83. Naive Bayes achieved the lowest accuracy (0.78), Precision (0.84), but its recall (0.75) matched that of the Logistic Regression with an accuracy of 0.81 and Precision of 0.86. The table indicates that each model has different strengths and weaknesses based on each metric evaluated."
1259,"caption: Comparison of model performances based on accuracy, F1 score, precision and recall metricstable: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.75,0.72,0.8,0.66, Random Forest,0.81,0.80,0.81,0.79, Gradient Boosting,0.80,0.79,0.8,0.78, Support Vector Machine,0.77,0.75,0.79,0.71, Decision Tree,0.71,0.70,0.69,0.71, Naive Bayes,0.78,0.76,0.78,0.75, K-Nearest Neighbors,0.70,0.68,0.67,0.70",
1260,"caption: Table 4: Model evaluation results using multiple evaluation metricstable: Models,Accuracy,F1-score,Precision,Recall, Decision Tree,0.81,0.78,0.70,0.89, Random Forest,0.91,0.89,0.87,0.92, Logistic Regression,0.87,0.85,0.78,0.92, Support Vector Machine,0.83,0.78,0.71,0.88, K-Nearest Neighbors,0.80,0.70,0.65,0.76","Table 4 presents the accuracy, F1-score, precision, and recall metrics of five different models, namely Decision Tree, Random Forest, Logistic Regression, Support Vector Machine, and K-Nearest Neighbors. The models were evaluated using the same dataset with different evaluation metrics. Notably, Random Forest obtained the highest accuracy score of 0.91, whereas K-Nearest Neighbors achieved the lowest accuracy among others, with a score of 0.80. However, when it comes to F1-score, as the most common evaluation metric, the Random Forest outperforms all the models with 0.89, while K-Nearest Neighbors has the lowest score of 0.70. Logistic Regression achieved the highest precision score with 0.78, outperforming all other models in this metric. Finally, it is interesting to note that Random Forest and Support Vector Machine models have the highest recall score with 0.92, whereas Decision Tree has the lowest score with 0.89."
1261,"caption: Table 4: Model performance comparison based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.88,0.84,0.81,0.83, Decision Tree,0.92,0.92,0.90,0.91, Random Forest,0.95,0.95,0.94,0.94, Gradient Boosting,0.94,0.93,0.93,0.93, Support Vector Classifier,0.89,0.84,0.82,0.83","Table 4 presents a comparison of different models' performance in classification tasks based on various evaluation metrics such as Accuracy, Precision, Recall, and F1 Score. The table contains results for five models, namely Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Support Vector Classifier. Notably, the Random Forest model achieved the highest performance in all the metrics, having Accuracy, Precision, Recall, and F1-Score of 0.95, 0.95, 0.94, and 0.94, respectively. It is also noteworthy that the Decision Tree model's performance is very close to that of Random Forest, with Accuracy, Precision, Recall, and F1-Score of 0.92, 0.92, 0.90, and 0.91, respectively. The table's results may be used to select the best-fit classification model for a given set of evaluation metrics."
1262,"caption: Table 4: Performance of different classification models based on different evaluation metrics.table: Model,Accuracy,F1-score,Precision, LogReg,0.85,0.88,0.84, SVM,0.78,0.82,0.88, KNN,0.62,0.58,0.45, RF,0.91,0.90,0.92, XGBoost,0.95,0.95,0.96","Table 4 displays the performance of five different classification models based on different evaluation metrics. The models are LogReg, SVM, KNN, RF, and XGBoost, and the evaluation metrics are accuracy, F1-score, and precision. The highest accuracy score is achieved by XGBoost with a value of 0.95, while the lowest accuracy score is obtained by KNN with a value of 0.62. Among all models, XGBoost also exhibits the highest F1-score (0.95) and precision (0.96) values. On the other hand, RF has the highest precision score of 0.92, whereas LogReg achieves the highest F1-score of 0.88. It is evident that the performance of the models is variable across the different metrics, hence it is important to evaluate models based on multiple metrics rather than relying on a single metric."
1263,"caption: Table 4 - Performance of Multiple Models on Various Evaluation Metricstable: Model,Precision Score,Recall Score,F1 Score,AUC Score, Decision Tree,0.84,0.79,0.81,0.88, Random Forest,0.92,0.88,0.89,0.95, XGBoost,0.90,0.90,0.90,0.94, SVM,0.87,0.82,0.83,0.91, Naive Bayes,0.78,0.85,0.80,0.87","The table above illustrates the comparison of different models on various evaluation metrics, including Precision Score, Recall Score, F1 Score, and AUC Score. We can observe that among all the models, Random Forest proves to be the best performing model with the highest Precision Score of 0.92, Recall Score of 0.88, F1 Score of 0.89, and AUC Score of 0.95. The SVM comes second-best with a Precision Score of 0.87 and an AUC Score of 0.91. However, Naive Bayes achieved the highest Recall Score of 0.85 and the lowest Precision Score of 0.78. Therefore, these models' result can help researchers to select the best model based on their specific requirements."
1264,"caption: Comparison of model performance using multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, SVM,0.75,0.74,0.76,0.75, Random Forest,0.82,0.81,0.82,0.82, Logistic Regression,0.80,0.78,0.82,0.80, MLP,0.83,0.82,0.83,0.83, XGBoost,0.84,0.82,0.85,0.84","The table above illustrates the comparison of multiple models' performances for a given task using various evaluation metrics. The models in the table include SVM, Random Forest, Logistic Regression, MLP, and XGBoost. The metrics compared are accuracy, precision, recall, and F1 score. The results demonstrate that XGBoost has the highest accuracy, precision, recall, and F1 score values, with an accuracy score of 0.84. Interestingly, MLP also performed well in all the metrics conducted, with an accuracy score of 0.83 and an F1 score of 0.83. On the other hand, SVM had the lowest scores in all four metrics conducted."
1265,"caption: Model performance based on multiple metricstable: Model,Precision,Recall,F1-Score,Accuracy, Logistic Regression with L1 Penalty,0.74,0.49,0.59,0.82, Logistic Regression with L2 Penalty,0.78,0.53,0.64,0.83, Random Forest,0.85,0.67,0.75,0.89, Decision Tree,0.79,0.61,0.68,0.81, Support Vector,0.76,0.52,0.62,0.84, Naive Bayes,0.66,0.75,0.65,0.72","Table displays model performance based on multiple metrics such as Precision, Recall, F1-Score, and Accuracy. Models compared in the table include Logistic Regression with L1 Penalty, Logistic Regression with L2 Penalty, Random Forest, Decision Tree, Support Vector, and Naive Bayes. The table shows that all models have different performance results depending on the evaluation metric used. Random Forest achieved the highest overall performance across all evaluation metrics, with an accuracy score of 0.89, followed by Logistic Regression with L2 Penalty having an accuracy score of 0.83. Naive Bayes had the lowest Precision score but achieved the highest Recall score."
1266,"caption: Comparison of model performance  based on various evaluation metrics.table: Model Name,Metric 1,Metric 2,Metric 3, Model 1,85.3%,65.4%,90.5%, Model 2,80.2%,67.8%,88.9%, Model 3,82.5%,69.2%,91.1%, Model 4,83.1%,64.3%,89.7%, Model 5,78.9%,66.7%,89.5%","The above table provides a comparison of model performance based on various evaluation metrics. The table comprises five different models, where each model's performance is assessed based on Metric 1, Metric 2, and Metric 3. Model 1 exhibits the best performance with a score of 85.3% for Metric 1, while Model 3 performed the best concerning Metric 3 with a score of 91.1%. On the other hand, Model 2 has a decent performance based on all three evaluation metrics, with the second-highest scores in the table. Finally, Model 5's scores range in the lower mid-range in comparison to the other models. Overall, the table's results provide a clear comparison of how different models can perform in conjunction with multiple evaluation metrics."
1267,"caption: Table 4: Performance evaluation results of different models using accuracy, F1-score, recall, and precision as evaluation metricstable: Model,Accuracy,F1-score,Recall,Precision, Model A,0.92,0.93,0.91,0.95, Model B,0.88,0.89,0.85,0.93, Model C,0.95,0.94,0.96,0.92, Model D,0.89,0.84,0.86,0.83, Model E,0.91,0.92,0.89,0.94",
1268,"caption: Table 4: Evaluation metrics (F1 score, AUC score, Precision, and Recall) comparison across different modelstable: Model,F1 Score,AUC Score,Precision,Recall, RF (n=100),0.832,0.899,0.799,0.867, XGBoost (n=200),0.843,0.904,0.819,0.869, SVM (rbf, C=1),0.824,0.801,0.821,0.828, SVM (linear, C=1),0.837,0.883,0.813,0.863, Logistic (C=0.5),0.831,0.888,0.804,0.861","Table 4 presents the evaluation metrics of five different models, where the models' performances are measured based on F1 score, AUC score, Precision, and Recall. The table shows the Random Forest (RF), XGBoost, support vector machine (SVM) with rbf kernel and C=1, SVM with linear kernel and C=1, and the logistic regression (Logistic) models. Interestingly, the RF model achieves the highest AUC score of 0.899 and F1 score of 0.832, while the XGBoost model attains the highest Precision of 0.819 and the Recall of 0.869. Further, SVM with a linear kernel and C=1 shows substantial F1 score and AUC score performance of 0.837 and 0.883, respectively. In contrast, the SVM with rbf kernel and C=1 experiences the lowest AUC score of 0.801."
1269,"caption: Model performances based on different evaluation metricstable: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.85,0.84,0.83,0.85, Random Forest,0.89,0.88,0.87,0.89, SVM,0.86,0.83,0.85,0.81, Naïve Bayes,0.81,0.74,0.75,0.74, MLP,0.90,0.89,0.88,0.90",
1270,"caption: Table 4. Model Evaluations using Different Metricstable: Model,Accuracy,F1 Score,Precision,Recall, Model A,0.86,0.80,0.85,0.75, Model B,0.81,0.76,0.80,0.73, Model C,0.90,0.85,0.89,0.81, Model D,0.79,0.75,0.78,0.72","Table 4 presents the evaluation metrics for four different models. The evaluation metrics include accuracy, F1 score, precision, and recall. The Model C showed the best overall performance with an accuracy of 0.90 and F1 score of 0.85. The model C also achieved the highest precision of 0.89 and recall of 0.81. Model A also had good overall performance with the second-highest accuracy of 0.86 and F1 score of 0.80. Meanwhile, Model B and D showed lower overall performance, with an accuracy ranging from 0.79 to 0.81 and F1 score ranging from 0.75 to 0.76."
1271,"caption: Performance Comparison of Different Classification Modelstable: Model,Accuracy,Precision,Recall,F1-Score, Random Forest,0.93,0.94,0.93,0.93, Logistic Regression,0.88,0.89,0.88,0.88, Decision Tree,0.87,0.86,0.87,0.87, Naive Bayes,0.82,0.84,0.82,0.82","Table presents the performance comparison of four different classification models. The evaluation metrics used in this table are Accuracy, Precision, Recall, and F1-Score. The Random Forest model shows the best results in all the metrics with 0.93 accuracy, 0.94 precision, 0.93 recall, and 0.93 F1-Score. Logistic Regression and Decision Tree models also demonstrate acceptable results with Accuracy 0.88 and 0.87, respectively. However, the Naive Bayes model has poor performance compared to the other models, demonstrating the lowest accuracy, precision, recall, and F1-Score values of 0.82."
1272,"caption: Table 4: Model performances based on multiple evaluation metricstable: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.76,0.73,0.78,0.75, Support Vector Machine,0.79,0.75,0.81,0.72, Random Forest,0.84,0.81,0.87,0.78, XGBoost,0.85,0.82,0.88,0.79","The table above presents a comparison of four models based on multiple performance metrics. The models are Logistic Regression, Support Vector Machine (SVM), Random Forest, and XGBoost. The evaluation metrics included are Accuracy, F1-score, Precision, and Recall. The table shows that all the models have relatively moderate to high accuracy ranging from 0.76 to 0.85, with XGBoost having the highest accuracy score. Random Forest and XGBoost appear to perform better in terms of F1-score, Precision, and Recall compared to Logistic Regression and SVM. Nevertheless, Random Forest and XGBoost show a slight increase in accuracy score, indicating their better suitability for data classification tasks."
1273,"caption: Model performance metrics for different classifierstable: Model,Accuracy,F1-score,Precision,Recall, SVM,0.8,0.786,0.774,0.801, KNN,0.75,0.732,0.701,0.766, NB,0.73,0.695,0.786,0.621, RF,0.85,0.839,0.828,0.851, LR,0.81,0.802,0.788,0.818","The presented table describes the performance metrics of different machine learning classifiers, namely SVM, KNN, NB, RF, and LR. The performance evaluation metrics include Accuracy, F1-score, Precision, and Recall. The SVM model performed best in terms of accuracy, achieving a score of 0.8. The RF model demonstrated the highest F1-score, with a performance score of 0.839. Both LR and SVM models had comparable precision and recall scores, while the NB model showed significantly higher precision than recall. Therefore, this table demonstrates that different models could have better performance on specific performance evaluation metrics, thus necessitating the selection of machine learning algorithms appropriate to the specific use case requirements."
1274,"caption: Model performance comparison based on different evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Model A,0.87,0.89,0.92,0.87, Model B,0.81,0.83,0.90,0.79, Model C,0.90,0.91,0.93,0.91, Model D,0.84,0.88,0.86,0.91, Model E,0.89,0.90,0.89,0.93","The table above presents the performance comparison of five different models based on different evaluation metrics- Accuracy, F1 Score, Precision, and Recall. Model A performed the best in terms of Accuracy with a score of 0.87, while Model C performed the best in terms of F1 Score with a score of 0.91. Model C also performed the best in terms of Precision with a score of 0.93, and Model E performed the best in terms of Recall with a score of 0.93. It is interesting to note that despite Model A having the highest accuracy score, it had a relatively low Recall score of 0.87. The table results suggest that based on the evaluation metric of interest, a different model would be considered the best performer."
1275,"caption: Performance evaluation of different models on the dataset.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.75,0.77,0.61,0.68, KNN,0.80,0.78,0.73,0.75, Naive Bayes,0.67,0.70,0.51,0.59, Decision Tree,0.72,0.66,0.71,0.68, Random Forest,0.82,0.84,0.75,0.78, Gradient Boosting,0.84,0.86,0.78,0.81","The table presents a comparison of multiple models' performance based on various evaluation metrics, including Accuracy, Precision, Recall, and F1-score. SVM, KNN, Naive Bayes, Decision Tree, Random Forest, and Gradient Boosting models were evaluated on the dataset. Overall, Random Forest and Gradient Boosting models perform the best, achieving an accuracy of 0.82 and 0.84, respectively. Naive Bayes achieved the lowest accuracy of 0.67. Interestingly, the Precision score of Naive Bayes is the second-highest, implying that the model misclassifies fewer positive predictions as false. The KNN model achieves the highest recall score of 0.73, and the Gradient Boosting model obtains the highest F1-score of 0.81."
1276,"caption: A comparison of different models using various evaluation metrics.table: Model Name,Accuracy,Precision,Recall,F1-Score, Support Vector Machine,0.93,0.94,0.93,0.93, Logistic Regression,0.86,0.83,0.79,0.81, Decision Tree,0.83,0.84,0.80,0.82, Random Forest,0.91,0.90,0.88,0.89, XGBoost,0.92,0.91,0.89,0.90","The table presents a comparison of different machine learning models' performance, evaluated based on different metrics. The models' accuracy, precision, recall, and F1-Score are shown in the table. The Support Vector Machine model performed the best based on all the metrics, achieving an accuracy of 0.93, precision of 0.94, recall of 0.93, and F1-Score of 0.93. However, the Random Forest and XGBoost models' performances are not far behind, with accuracy values of 0.91 and 0.92, respectively. Interestingly, the Logistic Regression model's performance is not as good as the other models, achieving an accuracy of 0.86, precision of 0.83, recall of 0.79, and F1-Score of 0.81."
1277,"caption: Model performances based on different evaluation metrics.table: Model,Accuracy,F1-Score,Recall,Precision, SVM-SMOTE,0.74,0.71,0.63,0.81, AdaBoost,0.68,0.63,0.49,0.85, Random Forest,0.76,0.70,0.62,0.82, Gradient Boosting,0.72,0.68,0.57,0.84","The table presents a comparison of different classification models' performances using four evaluation metrics: Accuracy, F1-Score, Recall, and Precision. The models are SVM-SMOTE, AdaBoost, Random Forest, and Gradient Boosting. Notably, all models were trained and tested on the same dataset. Random Forest demonstrated the highest accuracy score of 0.76, while AdaBoost yielded the lowest accuracy score of 0.68. Similarly, the Random Forest algorithm was the top-performing model based on the F1-Score, Recall, and Precision. Gradient Boosting model gave the lowest Recall score of 0.57, indicating that this technique may not be ideal for a few classification problems."
1278,"caption: Table 4: Model performance comparison based on different evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.89,0.91,0.87,0.89, Logistic Regression,0.85,0.88,0.81,0.84, Random Forest,0.92,0.93,0.91,0.92, Naive Bayes,0.78,0.81,0.75,0.77, K-Nearest Neighbors,0.81,0.82,0.79,0.80","Table 4 provides a comparison of multiple classification models' performance based on various evaluation metrics. The table includes SVM, Logistic Regression, Random Forest, Naive Bayes, and K-Nearest Neighbors models. The table presents evaluation metrics such as accuracy, precision, recall, and F1-score. The results show that the Random Forest model outperformed the other models in all the evaluation metrics with an accuracy of 0.92, precision of 0.93, recall of 0.91, and F1-score of 0.92. The SVM model also performed well with an accuracy of 0.89 and an F1-score of 0.89. On the other hand, the Naive Bayes model appeared to have the lowest performance with an accuracy of 0.78 and an F1-score of 0.77."
1279,"caption: Table 4: Performance metrics of different models in the classification task.table: Model,Accuracy,Precision,Recall,F1 Score, Model A,0.91,0.88,0.91,0.89, Model B,0.93,0.92,0.94,0.93, Model C,0.88,0.86,0.89,0.87, Model D,0.94,0.93,0.95,0.94, Model E,0.90,0.85,0.91,0.88","Table 4 shows the performance metrics of five different models in a classification task. The models are evaluated based on accuracy, precision, recall and F1 Score, which are important evaluation metrics for a classification problem. The highest accuracy of 0.94 was achieved by model D. Similarly, model D also achieved the highest precision and recall scores of 0.93 and 0.95, respectively. However, model B had the highest F1 score of 0.93, which is a combined metric and considers both precision and recall. Interestingly, models C and E had lower accuracy than the other models but had competitive precision, recall, and F1 scores. Hence, other evaluation metrics besides accuracy should also be considered while evaluating a classification model."
1280,"caption: Performance comparison of different models based on multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score,AUC, Model A,0.75,0.60,0.80,0.67,0.79, Model B,0.90,0.72,0.82,0.77,0.86, Model C,0.80,0.85,0.71,0.76,0.82, Model D,0.85,0.70,0.90,0.79,0.84",
1281,"caption: Evaluation metrics of various modelstable: Model,Accuracy,Precision,Recall,F1-score, Model A,0.82,0.85,0.76,0.80, Model B,0.87,0.89,0.82,0.85, Model C,0.88,0.92,0.79,0.85, Model D,0.91,0.89,0.94,0.92, Model E,0.85,0.86,0.83,0.85","The presented table compares the performance of five different models based on various evaluation metrics. The models' accuracy, precision, recall, and F1-score are shown along with their corresponding results. Model D showed the highest accuracy of 0.91, whereas Model C had the highest precision result of 0.92. Interestingly, Model D had the highest recall score of 0.94, while Model A had the lowest recall of 0.76. The F1-score shows Model D had the best performance at 0.92, whereas Model A and E had the lowest of 0.80 and 0.85, respectively. Overall, Model D seems to be the best-performing model in this comparison."
1282,"caption: Performance of Multiple Models based on Accuracy, Precision, Recall, F1-Score, and Specificitytable: Model,Accuracy,Precision,Recall,F1-Score,Specificity, SVM,0.86,0.88,0.82,0.85,0.89, KNN,0.74,0.80,0.68,0.71,0.77, DT,0.81,0.77,0.85,0.80,0.72, RF,0.89,0.87,0.92,0.89,0.84, NB,0.90,0.85,0.91,0.88,0.86","The presented table summarizes the performance of SVM, KNN, DT, RF, and NB models based on different evaluation metrics. The evaluation metrics include Accuracy, Precision, Recall, F1-Score, and Specificity. Notably, the NB model achieved the highest accuracy with a score of 0.9, while the KNN model shows the lowest accuracy of 0.74. Out of the Precision and Recall scores, the KNN model had the highest precision score of 0.8, and the RF model achieved the highest recall score of 0.92. Additionally, the F1 score indicates the overall model performance, and the RF model had the highest score of 0.89. Finally, the Specificity metric shows how well the model can identify negative samples, and the NB model achieved the highest score of 0.86."
1283,"caption: Table 4: Evaluation metrics for different models.table: Model,Accuracy,Precision,Recall,F1-Score, Model A,0.75,0.80,0.68,0.74, Model B,0.82,0.79,0.83,0.81, Model C,0.78,0.82,0.76,0.79, Model D,0.85,0.88,0.82,0.85, Model E,0.80,0.76,0.84,0.80, Model F,0.87,0.91,0.85,0.87","Table 4 illustrates the evaluation metrics for six different models. The models were evaluated based on various metrics such as accuracy, precision, recall, and F1-score. The results showed that the best overall performer was Model F, with an accuracy of 0.87 and precision of 0.91. Model D and Model B follow closely with an accuracy of 0.85 and 0.82, respectively. However, Model D achieved the highest precision score of 0.88, which indicates that it had the smallest number of false positives. Model B obtained the highest recall score of 0.83, indicating that it had the lowest number of false negatives. These observations suggest that model selection should depend on the specific performance metric of interest."
1284,"caption: Table 4: Classification model performances based on different evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.86,0.85,0.87,0.85, Random Forest,0.89,0.88,0.90,0.88, Naive Bayes,0.83,0.83,0.82,0.86, Support Vector Machine,0.90,0.89,0.91,0.89","Table 4 presents the classification model performances based on various evaluation metrics, including accuracy, F1-score, precision, and recall. Four different models are considered in this comparison: Logistic Regression, Random Forest, Naive Bayes, and Support Vector Machine (SVM). Each model's performance is evaluated based on its ability to predict the binary classes accurately. The SVM model outperforms the other models with an accuracy score of 0.90 and F1-score of 0.89. Nonetheless, all models perform reasonably well and achieve an accuracy score of at least 0.83."
1285,"caption: Performances of different models based on accuracy, F1 Score, precision, and recall.table: Model,Accuracy,F1 Score,Precision,Recall, Model A,0.80,0.82,0.84,0.80, Model B,0.82,0.85,0.81,0.90, Model C,0.78,0.84,0.78,0.90, Model D,0.84,0.87,0.86,0.88","The table presents the evaluation metrics (accuracy, F1 Score, precision, and recall) for four different models (Model A, Model B, Model C, and Model D). Model B recorded the best accuracy and recall, with a value of 0.82 and 0.9, respectively. Model D, on the other hand, shows the best F1 Score and precision, with a score of 0.87 and 0.86, respectively. Interestingly, Model A had the lowest F1 score, even though its accuracy was only slightly worse than Model B. The results suggest that depending on the evaluation metric, different models may perform significantly better than others."
1286,"caption: Performance results of different machine learning classification modelstable: Model Name,Accuracy,Precision,Recall,F1-Score, Logistics Regression,0.88,0.90,0.89,0.89, Decision Tree,0.82,0.79,0.81,0.80, Random Forest,0.91,0.93,0.91,0.92, K-Nearest Neighbor,0.75,0.68,0.76,0.72, Support Vector Machine,0.89,0.91,0.90,0.91","The presented table compares the performance results of five different machine learning classification models, including Logistics Regression, Decision Tree, Random Forest, K-Nearest Neighbor, and Support Vector Machine. The models' performance is measured using four evaluation metrics, including Accuracy, Precision, Recall, and F1-Score. The table demonstrates that the Random Forest model has the highest accuracy of 0.91, while the Decision Tree model has the lowest accuracy of 0.82. Moreover, the metrics further prove the superior performance of the Random Forest model as it has the best Precision, Recall, and F1-Score among other models. The K-Nearest Neighbor model shows the lowest performance level with the lowest accuracy, precision, and F1-Score."
1287,"caption: Comparison of model performance using different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, SVM,0.92,0.89,0.93,0.91, KNN,0.89,0.86,0.89,0.87, RF,0.93,0.90,0.95,0.92, NB,0.85,0.82,0.87,0.84, LR,0.92,0.89,0.94,0.91","The above table provides a comparison of different models' performances using various evaluation metrics. The models include Support Vector Machine (SVM), K-Nearest Neighbors (KNN), Random Forest Classifier (RF), Naive Bayes (NB), and Logistic Regression (LR). The evaluation metrics used are Accuracy, Precision, Recall, and F1 Score. According to the table, RF model achieved the highest accuracy score of 0.93, while NB model had the lowest accuracy score with 0.85. On the other hand, RF model outperformed all other models in Precision, Recall, and F1 Score. Meanwhile, the SVM model demonstrated the second-best performance in most of the evaluation metrics. The findings suggest that the RF model could be the best choice for the given task, with the SVM model being a close second."
1288,"caption: Performance of different models on binary classificationtable: Models,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.85,0.73,0.70,0.76, Naive Bayes,0.80,0.62,0.65,0.65, Support Vector Machine,0.89,0.77,0.73,0.83, K-Nearest Neighbors,0.84,0.71,0.75,0.67, Random Forest,0.92,0.82,0.85,0.79","The table compares the performance of different models on binary classification using evaluation metrics such as Accuracy, F1 Score, Precision, and Recall. The models examined here include Logistic Regression, Naive Bayes, Support Vector Machine, K-Nearest Neighbors, and Random Forest. The Random Forest model outperforms all other models, achieving the highest Accuracy, F1 Score, and Recall while having a relatively high Precision score. Interestingly, the Support Vector Machine model also performed fairly well, having the second-highest scores for all evaluation metrics. The table provides a useful summary of the potential options for different models for classification tasks."
1289,"caption: Table 4: Model Evaluations with Multiple Metrics.table: Model,Accuracy,F1 score,Precision,Recall, Logistic Regression,0.75,0.71,0.75,0.72, Naïve Bayes,0.53,0.42,0.61,0.53, SVM,0.72,0.69,0.71,0.70, Random Forest,0.81,0.78,0.81,0.79, XGBoost,0.83,0.82,0.84,0.81","Table 4 highlights multiple model evaluations using different metrics. The table exhibits five models: Logistic Regression, Naïve Bayes, SVM, Random Forest, and XGBoost. The evaluation metrics are Accuracy, F1-score, Precision, and Recall. Among all models, Random Forest and XGBoost achieved the highest accuracy scores of 0.81 and 0.83 and the highest F1-scores of 0.78 and 0.82, respectively. Precisely, XGBoost had the highest Precision and Random Forest had the highest Recall amongst all models evaluated. However, Logistic Regression showed decent performance on all metrics with an accuracy of 0.75, F1-score of 0.71, Precision of 0.75, and Recall of 0.72."
1290,"caption: Performance Comparison of Different Modelstable: Model Name,Accuracy,F1 Score,Precision,Recall, Model 1,91.2%,0.91,0.89,0.93, Model 2,89.6%,0.88,0.84,0.92, Model 3,90.8%,0.90,0.89,0.91, Model 4,92.3%,0.92,0.91,0.93","The presented table compares four different models based on four evaluation metrics. The metrics included Accuracy, F1 Score, Precision, and Recall. Model 4 demonstrated the highest Accuracy of 92.3% and F1 Score of 0.92. Model 1 achieved the second-best performance with an Accuracy of 91.2% and an F1 Score of 0.91. Model 3 and Model 2 showed relatively closer results with Accuracy of 90.8% and 89.6% respectively. Interestingly, Model 4 also performed the best in terms of Precision and Recall. The table reveals Model 4 as the best out of the presented models based on these selected evaluation metrics."
1291,"caption: Model performance comparison based on multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.71,0.68,0.72,0.69, Decision Tree,0.67,0.63,0.68,0.66, Random Forest,0.74,0.72,0.73,0.72, XGBoost,0.76,0.75,0.76,0.75, Neural Network,0.78,0.76,0.78,0.77","The table above presents a comparison of five different models' performance based on their evaluation metrics. These models include Logistic Regression, Decision Tree, Random Forest, XGBoost, and Neural Network. The evaluation metrics incorporated for comparison are Accuracy, Precision, Recall, and F1 Score. The model with the best overall performance is the Neural Network with an Accuracy score of 0.78, a Precision score of 0.76, a Recall score of 0.78, and an F1 score of 0.77. On the other hand, the Random Forest model scored the highest Accuracy, Precision, and Recall scores of 0.74, 0.72, and 0.73, respectively."
1292,"caption: Model Performance Comparision based on different evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.75,0.68,0.7,0.67, SVM,0.77,0.72,0.69,0.76, Random Forest,0.82,0.78,0.9,0.72, XGBoost,0.85,0.81,0.88,0.76","In this table, the model performances are compared based on different evaluation metrics, including Accuracy, F1-Score, Precision, and Recall. The table consists of four models - Logistic Regression, SVM, Random Forest, and XGBoost. Interestingly, Random Forest achieved the highest accuracy score of 0.82 and F1-Score of 0.78, while XGBoost achieved the highest Precision score of 0.88. Additionally, the SVM model acquired the highest Recall of 0.76. This table's results reveal that multiple evaluation metrics must be considered while evaluating a model's performance as the model with the highest performance based on one metric may not be the best based on another metric."
1293,"caption: Performance comparison of different machine learning models based on different evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.92,0.93,0.94,0.92, RF,0.89,0.91,0.87,0.95, XGB,0.88,0.89,0.88,0.90, KNN,0.79,0.80,0.81,0.78","The table presents the performance of different machine learning models based on different evaluation metrics, including accuracy, F1 score, precision, and recall. The table reports the results of SVM, RF, XGB, and KNN models. Notably, SVM obtained the highest accuracy with 0.92, followed by RF and XGB with 0.89 and 0.88, respectively. However, RF achieved the highest F1 score with 0.91. In terms of precision, SVM outperformed all other models with 0.94, while KNN had the lowest performance score of 0.81. Similarly, SVM had the highest recall with 0.92, while RF had the highest performance score of 0.95. Overall, the results show that SVM and RF models have better overall performances than the KNN and XGB models."
1294,"caption: Performance results of different machine learning models' evaluation metrics on the datasettable: Model Name,Accuracy,F1 Score,Precision,Recall, Decision Tree,0.81,0.79,0.87,0.72, Random Forest,0.87,0.87,0.89,0.85, AdaBoost,0.81,0.80,0.83,0.77, Gradient Boosting,0.86,0.86,0.88,0.84, Logistic Regression,0.78,0.76,0.81,0.72, Naive Bayes,0.73,0.65,0.81,0.54","The table presents a comparison of the different machine learning models' performance results based on multiple evaluation metrics on a given dataset. The models considered are Decision Tree, Random Forest, AdaBoost, Gradient Boosting, Logistic Regression, and Naive Bayes. The evaluation metrics used for measuring the models' performance are accuracy, F1 Score, precision, and recall. The Random Forest model achieved the best performance results across all the evaluation metrics, with an accuracy score of 0.87 and F1 Score of 0.87, closely followed by the Gradient Boosting model with an accuracy score of 0.86 and F1 Score of 0.86. However, the Logistic Regression model achieved the best precision score of 0.81. On the other hand, the Naive Bayes model scored the lowest across all the evaluation metrics."
1295,"caption: Comparison of Different Model Performancestable: Model,Accuracy,F1 Score,Precision,Recall, Model 1,0.89,0.87,0.91,0.84, Model 2,0.92,0.90,0.93,0.88, Model 3,0.88,0.85,0.90,0.81, Model 4,0.93,0.91,0.94,0.89, Model 5,0.91,0.88,0.92,0.85","Table 1 presents a comparison of five different models' (Model 1-5) performances based on multiple metrics: accuracy, F1 score, precision, and recall. All models were tested using the same dataset, and the table displays the scores they achieved for each metric. Notably, all models show a relatively high accuracy score of at least 88%. Model 4 demonstrates the highest accuracy of 0.93. Moreover, Model 4 and Model 2 exhibit the highest F1 score of 0.91 and 0.90, respectively. However, Model 2 displays the highest precision score of 0.93, while Model 1 achieved the highest recall score of 0.84. Overall, the table demonstrates interesting differences in models' performance based on different evaluation metrics."
1296,"caption: Table 4: Multiple models' performance metrics.table: Model,Accuracy,F1-Score,Specificity,Sensitivity, Model A,0.87,0.85,0.89,0.82, Model B,0.84,0.81,0.86,0.77, Model C,0.89,0.87,0.91,0.83, Model D,0.81,0.78,0.83,0.74, Model E,0.92,0.91,0.93,0.89","Table 4 presents an overview of the evaluation metrics of Model A through E, including Accuracy, F1-Score, Specificity, and Sensitivity. The models were trained and tested on the same dataset. Interestingly, Model E demonstrates the highest performance in terms of Accuracy (0.92) and Sensitivity (0.89). It also exhibits a strong F1-Score of 0.91. Model C has the second-best performance metrics with an Accuracy of 0.89 and F1-Score of 0.87, achieving the highest Specificity of 0.91. In contrast, Model D shows the lowest Accuracy of 0.81 and Sensitivity of 0.74, proving to be the least effective model in this instance."
1297,"caption: A comparison of different models based on accuracy, precision, recall, and F1-score metrics.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.809,0.813,0.576,0.672, Random Forest,0.811,0.738,0.679,0.707, XGBoost,0.824,0.794,0.593,0.682, Logistic Regression,0.829,0.855,0.543,0.663, Decision Tree,0.776,0.611,0.603,0.604","The tabulated results present the accuracy, precision, recall, and F1-score metrics for five different classification models, namely SVM, Random Forest, XGBoost, Logistic Regression, and Decision Tree, all trained and tested on the same dataset. The models' performances were evaluated based on the given metrics, where the Logistic Regression model showed the highest accuracy of 0.829. In contrast, the SVM model has the highest precision of 0.813. Surprisingly, the Random Forest model showed the highest recall of 0.679, while XGBoost had the maximum F1-Score of 0.682. These results suggest that the XGBoost model has well-balanced performance on all metrics."
1298,"caption: Table 4: Comparison of multiple classification models over different evaluation metricstable: Model,Precision,Recall,F1-score,Accuracy, SVM,0.85,0.80,0.82,0.90, Naive Bayes,0.75,0.85,0.80,0.85, Random Forest,0.90,0.75,0.82,0.88, K-Nearest Neighbor,0.80,0.75,0.77,0.83","Table 4 displays a comparison analysis of four different classification models used to classify a dataset with equal number of classes. The models performed with different evaluation metrics, including precision, recall, F1-score, and accuracy. The SVM showed the highest precision and recall scores of 0.85 and 0.80, respectively, while the Naive Bayes model scored the lowest precision of 0.75. On the other hand, Random Forest had the highest accuracy score of 0.88, while the K-Nearest Neighbor had the lowest F1-score of 0.77."
1299,"caption: Comparison of Model performance based on different evaluation metricstable: Model,Accuracy,F1-score,Precision,Recall, SVM,0.825,0.804,0.842,0.768, Logistic Reg,0.814,0.789,0.830,0.753, Random Forest,0.851,0.830,0.856,0.804, Neural Net,0.810,0.780,0.815,0.746",
1300,"caption: Evaluation metrics of Different Modelstable: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.85,0.83,0.91,0.87, Random Forest,0.87,0.86,0.94,0.90, Decision Tree,0.79,0.78,0.87,0.82, Support Vector Machine,0.83,0.82,0.90,0.86, Naive Bayes,0.77,0.74,0.89,0.81","The table above displays the evaluation metrics of five different models- Logistic Regression, Random Forest, Decision Tree, Support Vector Machine, and Naive Bayes. The models were evaluated based on Accuracy, Precision, Recall, and F1-Score. Random Forest obtained the best performance with an accuracy of 0.87, precision of 0.86, recall of 0.94, and F1-score of 0.90. Logistic Regression, Support Vector Machine, and Naive Bayes models show similar accuracy, but Logistic Regression and Support Vector Machine exhibited a better performance in terms of precision, recall, and F1-score than Naive Bayes. Decision Tree showed the least performance among the tested models."
1301,"caption: Model performances using different algorithms based on binary classification of dataset A.table: Model,Accuracy,Precision,Recall,F1-score, Random Forest,0.93,0.93,0.91,0.92, Support Vector Machine,0.91,0.92,0.88,0.89, Logistic Regression,0.89,0.89,0.86,0.87, Naive Bayes,0.84,0.84,0.78,0.80, K-Nearest Neighbors,0.86,0.87,0.84,0.85","The presented table compares the performance of various models using different algorithms based on binary classification of dataset A. The listed algorithms are Random Forest, Support Vector Machine (SVM), Logistic Regression, Naive Bayes, and K-Nearest Neighbors (KNN). The evaluation metrics include Accuracy, Precision, Recall, and F1-score. Notably, Random Forest has the best Accuracy, Precision, and F1-score of 0.93, 0.93, and 0.92, respectively. SVM outperforms other models in Recall with a score of 0.88. Moreover, KNN has the highest Precision of 0.87. Conversely, Naive Bayes has the lowest Accuracy, Precison, and F1-score. The table provides researchers with insights to choose the best-suited model depending on their classification task's requirements."
1302,"caption: Table 4. Performance of Different Models on the Evaluation Metricstable: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.79,0.75,0.82,0.70, Decision Tree,0.72,0.66,0.71,0.63, Random Forest,0.85,0.83,0.86,0.80",
1303,"caption: Model performance on the test datasettable: Model,Precision,Recall,F1-score,Accuracy, Logistic Regression,0.79,0.75,0.77,0.76, Random Forest,0.85,0.88,0.86,0.87, Gradient Boosting,0.82,0.84,0.83,0.83, Artificial Neural Net,0.77,0.79,0.78,0.78","The above table presents the model performance of four different models on the test dataset measured using four evaluation metrics - Precision, Recall, F1-Score, and Accuracy. The Logistic Regression model achieves a Precision score of 0.79 and an Accuracy of 0.76. The Random Forest model, on the other hand, has the highest Recall score of 0.88 and the F1-Score of 0.86. The Gradient Boosting model stands in the middle in terms of performance with a Precision score of 0.82, Recall of 0.84, and the F1-Score of 0.83. The Artificial Neural Network model ranks the lowest among all models with a Precision score of 0.77 and an Accuracy of 0.78. Overall, the Random Forest model appears to be the best performing model, having achieved the top score in two out of the four metrics."
1304,"caption: Performance of different models on the classification tasktable: Model,F1 Score,Precision,Recall,Accuracy, Logistic Regression (LR),0.87,0.86,0.89,0.90, Decision Tree (DT),0.79,0.77,0.82,0.80, Random Forest (RF),0.91,0.90,0.92,0.92, Support Vector Machine (SVM),0.85,0.84,0.86,0.87","The table presents the performance summary of four different models - Logistic Regression (LR), Decision Tree (DT), Random Forest (RF), and Support Vector Machine (SVM) on a classification task. Multiple evaluation metrics like F1 Score, Precision, Recall and Accuracy have been used to evaluate the performance of the models. The table shows that Random Forest performed the best among all models with the highest F1 Score of 0.91 and the best accuracy of 0.92. Logistic Regression also produced good results with an F1 Score of 0.87 and an accuracy of 0.90. Decision Tree performed the worst with an F1 Score of 0.79 among all models. The table provides a quick and easy-to-understand overview of the performance differences among the models on the classification task."
1305,"caption: Table 4: Comparison of multiple models’ performances using different evaluation metricstable: Model,Accuracy,F1-score,Precision,Recall, SVM,0.89,0.89,0.90,0.89, KNN,0.86,0.85,0.85,0.86, Logistic Regression,0.91,0.91,0.92,0.90, Decision Tree,0.82,0.81,0.82,0.81, Random Forest,0.94,0.94,0.95,0.93",
1306,"caption: Table 4: Model Comparison Metricstable: Model,Accuracy,F1 Score,Precision,Recall,AUC, Model A,0.905,0.855,0.879,0.865,0.950, Model B,0.912,0.862,0.887,0.872,0.952, Model C,0.891,0.823,0.837,0.831,0.942, Model D,0.898,0.843,0.862,0.852,0.941, Model E,0.915,0.876,0.889,0.894,0.957","Table 4 presents the performance comparison of five different models measured by multiple evaluation metrics, Accuracy, F1 Score, Precision, Recall, and AUC. Notably, all models were trained and tested using the same dataset, the accuracies ranged from 0.891 to 0.915. Model E achieved the highest accuracy of 0.915, while Model C showed the lowest with 0.891. Model E also achieved the highest F1 score of 0.876. Precision scores for all models ranged from 0.837 to 0.889, and recall scores range from 0.831 to 0.894. Model E also achieved the highest AUC of 0.957, while the rest of the models achieved AUC values between 0.941 and 0.952. Overall, Model E shows the most favourable performance across all metrics evaluated."
1307,"caption: Comparison Table of Model Performance Based on Multiple Evaluation Metricstable: Model,Accuracy,F1-Score,Precision,Recall, Model A,0.92,0.91,0.90,0.92, Model B,0.88,0.87,0.85,0.91, Model C,0.93,0.93,0.93,0.92, Model D,0.85,0.83,0.81,0.89","The table displays a comparison of four different models, Model A through D, based on multiple evaluation metrics, including Accuracy, F1-Score, Precision, and Recall. Model C appears to have the highest Accuracy of 0.93, and it also performs well in other evaluation metrics, with a F1-Score of 0.93 and Precision and Recall of 0.93 and 0.92, respectively. Model B, on the other hand, has a relatively low accuracy of 0.88, but it shows a high Recall score of 0.91. Model D appears to be the worst performer among all with an accuracy of 0.85."
1308,"caption: Table 4: Model performance with different evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall,AUC, Model A,0.90,0.83,0.86,0.81,0.94, Model B,0.91,0.79,0.92,0.71,0.95, Model C,0.92,0.89,0.90,0.88,0.94, Model D,0.81,0.67,0.72,0.62,0.87, Model E,0.87,0.79,0.81,0.78,0.91","Table 4 presents the performance evaluation of five different machine learning models. The table displays each model's accuracy, F1-Score, Precision, Recall, and AUC. Model C achieved the highest accuracy of 0.92, while Model D had the lowest accuracy of 0.81. For the F1-Score, the Model A and Model C both performed well with the scores of 0.83 and 0.89. Interestingly, the Model B recorded the highest precision score of 0.92, but with the lowest recall score of 0.71. Moreover, Model A displayed the highest AUC of 0.94, followed by Model C and E, showing that the models performed well in different metrics depending on the evaluation metric used."
1309,"caption: Table 4: Different models' evaluation results based on accuracy, F1-score, sensitivity, and specificity.table: Model,Accuracy,F1-score,Sensitivity,Specificity, SVM,0.83,0.84,0.81,0.84, KNN,0.79,0.80,0.74,0.80, RF,0.85,0.85,0.84,0.86, XGB,0.88,0.88,0.87,0.90, CNN,0.84,0.83,0.81,0.86","Table 4 shows a comparison of five different models' performances using accuracy, F1-score, sensitivity, and specificity metrics. The table presents SVM, KNN, RF, XGB, and CNN models with their respective evaluation results. Interestingly, the XGB model shows the highest accuracy, F1-score, sensitivity, and specificity scores of 0.88, 0.88, 0.87, and 0.90, respectively. On the other hand, the KNN model yielded the lowest accuracy, F1-score, and sensitivity scores (0.79, 0.80, and 0.74, respectively). Interestingly, the RF model achieved the highest specificity score of 0.86. The results from Table 4 suggest that the XGB model outperforms the other models in all the evaluation metrics."
1310,"caption: Table 4: Model Evaluation Results for Various Evaluation Metricstable: Model Name,Metric1,Metric2,Metric3, Model A,0.90,0.82,0.95, Model B,0.78,0.89,0.87, Model C,0.85,0.77,0.92, Model D,0.79,0.74,0.88, Model E,0.92,0.98,0.97, Model F,0.85,0.91,0.78","Table 4 presents the evaluation results for different models, including Model A, B, C, D, E, and F, across various evaluation metrics. In this table, three different evaluation metrics were used to evaluate each model's performance. From the table, it is clear that Model E outperforms all other models across all evaluation metrics, achieving scores of 0.92, 0.98, and 0.97 for Metric1, Metric2, and Metric3, respectively. Model B falls behind with scores of 0.78, 0.89, and 0.87, while other models achieve mixed results. The evaluation results suggest that Model E is the most promising model for this particular task."
1311,"caption: Evaluation metrics of different models.table: Model,Precision,Recall,F1-Score,Accuracy, Model A,0.85,0.75,0.80,0.89, Model B,0.79,0.81,0.80,0.86, Model C,0.83,0.78,0.80,0.87, Model D,0.81,0.84,0.83,0.85",
1312,"caption: Table 4: Model performance metrics for different Modelstable: Model,Accuracy,F1-Score,Cohen's Kappa, Model1,0.87,0.85,0.74, Model2,0.91,0.89,0.82, Model3,0.89,0.88,0.79, Model4,0.86,0.82,0.70, Model5,0.93,0.92,0.87","Table 4 exhibits the comparison of different Models' performances based on three different evaluation metrics: Accuracy, F1-Score, and Cohen's Kappa. The Models show varying degrees of performance on all metrics. Model5 demonstrates the best performance on all metrics, with an Accuracy of 0.93, F1-Score of 0.92, and Cohen's Kappa of 0.87. On the other hand, Model4 showed the weakest performance with an Accuracy of 0.86, F1-Score of 0.82, and Cohen's Kappa of 0.70. The table highlights the importance of using multiple metrics to evaluate model performance, as the metrics reflect different aspects of the performance."
1313,"caption: Performance comparison of different models based on various evaluation metricstable: Model,Accuracy,F1 Score,Precision,Recall, Model A,0.89,0.88,0.92,0.83, Model B,0.88,0.87,0.89,0.85, Model C,0.92,0.90,0.95,0.86, Model D,0.86,0.85,0.86,0.88","Table 4 compares the performances of Model A, Model B, Model C, and Model D on various evaluation metrics such as Accuracy, F1 Score, Precision, and Recall. Model C showed the best performance regarding Accuracy, achieving 0.92, followed by Model A with 0.89. Model C also showed the highest scores for F1 Score and Precision, achieving 0.90 and 0.95, respectively. However, Model A performed best on recall with a score of 0.83. Conversely, Model D showed relatively lower results on all the evaluation metrics, exhibiting the lowest accuracy of 0.86, F1 Score of 0.85, precision of 0.86, and recall of 0.88 among all the models."
1314,"caption: Comparison of model performance based on multiple evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall,ROC AUC, Model A,0.72,0.67,0.72,0.62,0.81, Model B,0.80,0.74,0.75,0.80,0.86, Model C,0.68,0.61,0.68,0.57,0.75, Model D,0.84,0.78,0.82,0.73,0.90","The above table compares different models' performance based on multiple evaluation metrics. The models are evaluated with traditional metrics such as accuracy, F1 score, precision, recall, and ROC AUC. Model B performs best in most of the metrics with an accuracy of 0.80, F1 score of 0.74, precision of 0.75, recall of 0.80 and an ROC AUC of 0.86, outperforming other models. However, Model D also shows quite good results with an accuracy of 0.84, F1 score of 0.78, precision of 0.82, recall of 0.73, and the highest ROC AUC of 0.90. On the other hand, Model C has the lowest scores for all evaluation metrics."
1315,"caption: The performance of different models on classification task.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.82,0.84,0.77,0.80, Random Forest,0.79,0.80,0.73,0.76, K-Nearest Neighbors,0.72,0.67,0.81,0.73, Decision Tree,0.67,0.65,0.63,0.64","The table presents the performance results of different models on a classification task. We evaluate the models based on multiple metrics, namely Accuracy, Precision, Recall, and F1-score. The table includes Logistic Regression, Random Forest, K-Nearest Neighbors, and Decision Tree models. The Logistic Regression model exhibits the highest Accuracy of 0.82, and Precision of 0.84, while K-Nearest Neighbors has the highest Recall of 0.81. Interestingly, the Decision Tree model shows the lowest accuracy of all models with 0.67."
1316,"caption: Performance evaluation of different models using various metrics.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.846,0.814,0.832,0.798, Random Forest,0.885,0.856,0.873,0.840, Multilayer Perceptron,0.879,0.851,0.867,0.836, Logistic Regression,0.831,0.790,0.811,0.772","The table shows the performance of different models in terms of Accuracy, F1-Score, Precision, and Recall evaluation metrics. The SVM model scored an Accuracy of 0.846, F1-Score of 0.814, Precision of 0.832, and Recall of 0.798. The Random Forest model had the highest accuracy performance of 0.885, while Multilayer Perceptron and Logistic Regression performance were somewhat identical with an accuracy of 0.879 and 0.831, respectively. The F1-Score results indicate the SVM model had the lowest performance, and Random Forest had the highest performance with an F1-Score of 0.856. Random Forest also achieved the highest precision and recall scores, while SVM scored the lowest. The table depicts the difference in performance among these models and identifies which model performed well based on each metric."
1317,"caption: Comparison of different models' performances using multiple evaluation metrics.table: Model,F1-score (class 0),F1-score (class 1),Accuracy,Balanced Accuracy, SVM,0.68,0.82,0.76,0.75, KNN,0.59,0.73,0.68,0.66, LR,0.62,0.80,0.72,0.71, RF,0.71,0.83,0.80,0.79, MLP,0.65,0.81,0.74,0.73","This table showcases the performance of five different models concerning F1-score (class 0 and class 1), accuracy, and balanced accuracy. Notably, the Random Forest (RF) model outperforms all other models in terms of accuracy, F1-score (class 0 and class 1), and balanced accuracy with scores of 0.80, 0.71, 0.83, and 0.79, respectively. The Support Vector Machine (SVM) model was the second-best performing model with an F1-score of 0.68 and 0.82 for class 0 and class 1, respectively. On the other hand, K-Nearest Neighbor (KNN) was the least performing model with the lowest F1-scores for both classes and the lowest accuracy and balanced accuracy scores."
1318,"caption: Model Comparison Table for Accuracy, F1-score, Precision, Recall and AUC.table: Model,Accuracy,F1-score,Precision,Recall,AUC, Logistic,0.89,0.89,0.91,0.86,0.95, SVM,0.86,0.85,0.87,0.83,0.92, Random Forest,0.93,0.93,0.92,0.94,0.98, Decision Tree,0.88,0.87,0.84,0.91,0.93, Neural Network,0.91,0.91,0.92,0.90,0.96","The above 'Model Comparison Table for Accuracy, F1-score, Precision, Recall and AUC,' demonstrates the performance evaluation of different models in a classification task. The table compares the accuracy, F1-score, precision, recall, and AUC scores of five diverse models: Logistic regression, SVM, Random forest, Decision Tree, and Neural Network. The Random forest model stands out with the highest accuracy score of 0.93, while the Neural Network produces the most balanced scores overall. Interestingly, the Logistic Regression model surpasses other models with regards to precision, while the Decision Tree model produces the highest recall score. Finally, the Random Forest model shows the best AUC score of 0.98, which suggests excellent overall model performance."
1319,"caption: Performance comparison of various classification models on the test dataset.table: Model,F1-score,Accuracy,Precision,Recall, SVM,0.95,0.96,0.93,0.97, Logistic Regression,0.91,0.93,0.87,0.96, Random Forest,0.93,0.94,0.90,0.96, Naive Bayes,0.85,0.88,0.82,0.87","The above table compares the performance of different classification models, including SVM, Logistic Regression, Random Forest, and Naive Bayes, on the test dataset using four different evaluation metrics, namely F1-score, Accuracy, Precision, and Recall. The table shows that SVM had the best F1-score of 0.95 and accuracy of 0.96, while Naive Bayes had the lowest F1-score but with the highest precision of 0.82. The Random Forest model had the second-best performance with an F1-score of 0.93 and recall of 0.96. Overall, the table provides a useful comparison of evaluation metrics for different models that would aid in making an informed decision when selecting a model for classification tasks."
1320,"caption: Table 4: Model evaluation metrics for various modelstable: Model,Precision,Recall,F1-Score,Accuracy, Logistic Regression,0.86,0.76,0.80,0.83, Naive Bayes,0.78,0.82,0.80,0.78, SVM,0.87,0.77,0.82,0.85, Random Forest,0.94,0.86,0.89,0.92, XGBoost,0.95,0.87,0.90,0.93","Table 4 presents the evaluation metrics of different models based on their performance on the given dataset. The table consists of five different models, including Logistic Regression, Naive Bayes, SVM, Random Forest, and XGBoost. The evaluation metrics such as Precision, Recall, F1-Score, and Accuracy were used to determine the performance of these models. Notably, the Random Forest and XGBoost models exhibit the highest Precision, Recall, and F1-Score values in comparison to other models in the table, while Logistic Regression and SVM showed the highest accuracy. It should be noted that these evaluations were conducted using the same dataset."
1321,"caption: Evaluation metrics for different models trained on a binary classification task.table: Model,F1 Score,Accuracy,Precision,Recall, SVM,0.94,0.93,0.91,**0.98**, Random Forest,**0.97**,**0.96**,**0.96**,0.97, Logistic Regression,0.89,0.89,0.91,0.87, KNN,0.91,0.90,0.87,0.94","This table presents the evaluation metrics including F1 Score, Accuracy, Precision and Recall for four different classification models trained on a binary classification task. Notably, the Random Forest model indicates the highest F1 Score and Accuracy, indicating strong model performance among others, with scores of 0.97 and 0.96, respectively. The SVM model resulted in the highest Recall score of 0.98, and Logistic Regression yielded the highest precision score of 0.91. KNN has the lowest precision score of 0.87 but still shows strong performance with an F1 score of 0.91."
1322,"caption: Comparison of different models' performances based on accuracy, F1 Score, Matthew Corr, Precision, and Recall.table: Model,Accuracy,F1 Score,Matthew Corr,Precision,Recall, Logistic regression,0.84,0.81,0.68,0.85,0.79, Random Forest,0.86,0.83,0.71,0.87,0.79, Naive Bayes,0.72,0.62,0.38,0.83,0.49, XGBoost,0.87,0.84,0.73,0.86,0.83","Table above lists the comparison of multiple models' performances based on five different evaluation metrics such as Accuracy, F1 Score, Matthew Corr, Precision, and Recall. The table presents four different models: Logistic Regression, Random Forest, Naive Bayes, and XGBoost. Random Forest performed the best, achieving the highest scores for accuracy (0.86), F1 Score (0.83), Matthew Corr (0.71), and precision (0.87). XGBoost performed the best in recall (0.83). Naive Bayes appears to be the weakest model, as it achieved the lowest scores for all the evaluation metrics except for precision."
1323,"caption: Model performance on a classification task using different machine learning algorithms based on accuracy, precision, recall, and F1 score evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, SVM with RBF,0.876,0.913,0.823,0.866, KNN,0.836,0.857,0.774,0.814, Decision Trees,0.841,0.854,0.786,0.818, Random Forest,0.888,0.919,0.842,0.879, Neural Network,0.901,0.928,0.870,0.898","The table illustrates the performance comparison of five different machine learning models on a classification task. The models include SVM with RBF kernel, KNN, Decision Trees, Random Forest, and a Neural Network. The evaluation metrics include accuracy, precision, recall, and F1 score. Notably, the Neural Network model demonstrated the best overall performance across all metrics, scoring highest accuracy (0.901), precision (0.928), recall (0.870), and F1 score (0.898), while the SVM with RBF model had the second-best performance. Interestingly, the Random Forest model showed high performance in all metrics, with its best result achieved in precision (0.919) and F1 score (0.879)."
1324,"caption: Model performance of multiple classifiers based on four evaluation metrics.table: Model,F1 Score,Precision,Recall,Accuracy, Logistic Regression,0.85,0.87,0.83,0.90, Random Forest,0.92,0.93,0.91,0.93, Gradient Boosting,0.87,0.88,0.86,0.88, Support Vector Machine,0.90,0.92,0.88,0.91","Table above displays the model performance comparison of four different classifiers, including Logistic Regression, Random Forest, Gradient Boosting, and Support Vector Machine (SVM). The table shows F1 score, precision, recall, and accuracy for each model. The best performing model based on the F1 score is the Random Forest model, which achieved an F1 score of 0.92, and it also had the highest precision (0.93) and recall (0.91). However, the Support Vector Machine model achieved the highest accuracy (0.91). Therefore, the choice of model might depend on the relative importance of precision, recall, and accuracy in the given problem."
1325,"caption: Model comparison on performance metricstable: Model,Accuracy,F1-Score,Cohens Kappa, Model A,0.91,0.92,0.89, Model B,0.92,0.91,0.90, Model C,0.90,0.88,0.87, Model D,0.93,0.94,0.91, Model E,0.89,0.90,0.86","Table shows the comparison of five models' performances on evaluation metrics - Accuracy, F1-Score, and Cohens Kappa. The table reports that models B and D achieve the highest accuracy score of 0.92 and 0.93, respectively. Model D also shows the highest F1-Score of 0.94, while model A has the best Cohens Kappa of 0.89. Model E provides the lowest performance in the three metrics with an accuracy of 0.89, F1-Score of 0.90, and Cohens Kappa of 0.86. Based on the table metrics, it is recommended to use model D if high F1-score and accuracy are of prime importance."
1326,"caption: Model Performance Comparison using Multiple Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1 Score,AUC, Logistic,0.83,0.86,0.75,0.8,0.916, Decision Tree,0.82,0.81,0.77,0.77,0.844, Random Forest,0.87,0.89,0.8,0.84,0.922, Gradient Boost,0.85,0.88,0.76,0.8,0.911, MLP,0.81,0.78,0.8,0.79,0.889","Table presents the comparison of multiple machine learning models used to predict a binary outcome. The models include Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Multi-Layer Perceptron (MLP). The evaluation of the models is based on five different metrics, accuracy, precision, recall, F1 score, and AUC. The results show that Random Forest has the highest accuracy (0.87), precision (0.89), F1 score (0.84), and AUC (0.922) compared to the other models. Interestingly Gradient Boost and Logistic Regression have high AUC scores (0.911 and 0.916), while MLP and Decision Trees have moderate accuracy, precision and recall scores (between 0.78-0.81). The table provides a quick overview of which models and evaluation metrics to focus on for predicting the binary outcome."
1327,"caption: Model performances comparison using multiple evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, LR,0.897,0.886,0.876,0.898, SVM,0.905,0.896,0.884,0.909, RF,0.922,0.912,0.906,0.918, XGB,0.914,0.904,0.893,0.914, ANN,0.904,0.895,0.885,0.905",
1328,"caption: Evaluation Metrics Results for Different Modelstable: Model,Precision,Recall,F1-Score,Accuracy, Logistic Regression,0.85,0.75,0.80,0.90, Gradient Boosting,0.90,0.77,0.83,0.88, Support Vector Machine,0.88,0.79,0.82,0.87, Random Forest,0.92,0.84,0.87,0.91","Table ""Evaluation Metrics Results for Different Models"" presents Precision, Recall, F1-Score, and Accuracy values of four different models - Logistic Regression, Gradient Boosting, Support Vector Machine, and Random Forest. The evaluation metrics were used to measure the models' classification performance. Notably, the Random Forest model achieved the highest Precision of 0.92 and Accuracy of 0.91. In contrast, Gradient Boosting achieved the highest Recall value of 0.77. The Support Vector Machine model had a high Precision, Recall, and F1-Score, which indicates that the model is overall performing well on the dataset. The Logistic Regression model has the lowest Recall value; however, it has a high Precision and F1-Score."
1329,"caption: Performance Table of Various Models using different evaluation metricstable: Model,Mean Squared Error (MSE),Root Mean Squared Error (RMSE),Mean Absolute Error (MAE), MLP,4.571,2.139,1.702, CNN,4.223,2.052,1.599, Random Forest,3.987,1.996,1.522, XGBoost,3.845,1.961,1.458, Support Vector Machine (SVM),4.922,2.216,1.781","The table presents the performance of different models using three evaluation metrics: Mean Squared Error (MSE), Root Mean Squared Error (RMSE), and Mean Absolute Error (MAE). The models included in the table are Multi-Layer Perceptron (MLP), Convolutional Neural Network (CNN), Random Forest, XGBoost, and Support Vector Machine (SVM). The table highlights that the XGBoost model outperformed other models in all evaluation metrics, exhibiting an MSE of 3.845, RMSE of 1.961, and MAE of 1.458. The Random Forest model closely followed with an MSE of 3.987, RMSE of 1.996, and MAE of 1.522. Interestingly, the SVM model, which exhibited the highest MSE, had a lower RMSE and MAE than MLP and CNN models."
1330,"caption: Table 4: Model Performance on the Evaluation Metricstable: Model,F1-Score,Accuracy,Precision,Recall, Logistic Reg.,0.78,0.89,0.81,0.76, Random Forest,0.87,0.95,0.89,0.85, SVM,0.75,0.88,0.83,0.69, Naive Bayes,0.63,0.76,0.69,0.57, Decision Trees,0.81,0.92,0.84,0.79","Table 4 presents a comparison of different models' performance based on multiple evaluation metrics. The models evaluated are Logistic Regression, Random Forest, SVM, Naive Bayes, and Decision Trees. The metrics used in evaluating their performance are F1-Score, Accuracy, Precision, and Recall. The Random Forest model exhibited the best overall performance with an F1-score of 0.87, an accuracy score of 0.95, a precision score of 0.89, and a recall score of 0.85. Though Logistic Regression performed the worst with an overall F1-score of 0.78, all models exhibited good performance scores on the evaluation metrics."
1331,"caption: Table 4: Model evaluations of 4 different models using multiple evaluation metricstable: Metric,Model 1,Model 2,Model 3,Model 4, Precision,0.755,0.842,0.803,0.906, Recall,0.873,0.724,0.937,0.812, F1-Score,0.810,0.778,0.864,0.857, Accuracy,0.836,0.864,0.830,0.910","Table 4 presents the evaluation results for 4 different models using four different evaluation metrics, namely precision, recall, F1-score, and accuracy. The models are identified as Model 1, Model 2, Model 3, and Model 4, respectively. Interestingly, Model 4 outperforms all other models in all metrics assessed, with a precision of 0.906, recall of 0.812, F1-score of 0.857 and accuracy of 0.910. Model 2 is second-best in most metrics, having a precision of 0.842, F1-score of 0.778 and accuracy of 0.864. Model 3 is the best-performing model in recall, achieving a score of 0.937. These results provide distinct insights into the models' strengths and weaknesses and show Model 4 performs the best overall."
1332,"caption: Model performances based on multiple evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.87,0.86,0.88,0.84, Decision Tree,0.82,0.79,0.84,0.75, Random Forest,0.89,0.88,0.90,0.86, SVM,0.85,0.84,0.85,0.83, MLP,0.88,0.87,0.89,0.86","Table presents the evaluated models' performances based on various evaluation metrics, including Accuracy, F1-score, Precision, and Recall. The models assessed were Logistic Regression, Decision Tree, Random Forest, SVM, and MLP. Notably, all models' accuracy scores range between 0.82 and 0.89, with the Random Forest model having the highest accuracy of 0.89. The F1-score metric ranges between 0.79 and 0.88, with the Random Forest model having the highest F1-score of 0.88. The Precision and Recall scores display a similar trend, with the Random Forest model obtaining the highest scores of 0.90 and 0.86, respectively, for Precision and Recall. Overall, Random Forest model displayed the best overall performance among the other models based on the evaluation metrics considered."
1333,"caption: Performance comparison of different classification models using various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score,AUC, KNN,0.87,0.88,0.85,0.85,0.91, SVM,0.82,0.84,0.80,0.80,0.89, Naive Bayes,0.79,0.74,0.84,0.79,0.87, Random Forest,0.91,0.91,0.89,0.89,0.96, XGBoost,0.89,0.88,0.90,0.89,0.95","The table presents a comparison of five different classification models, including KNN, SVM, Naive Bayes, Random Forest, and XGBoost, using various evaluation metrics. The models' performance is gauged through Accuracy, Precision, Recall, F1-Score, and AUC. The Random Forest model showed the best results across all metrics, with an accuracy of 0.91, and an AUC of 0.96. The KNN model also demonstrated strong performance, achieving an accuracy of 0.87 and an AUC of 0.91. Interestingly, SVM and Naive Bayes yielded comparable results, with SVM achieving a slightly better accuracy of 0.82 and Naive Bayes exhibiting a higher recall of 0.84. Finally, XGBoost had the second-highest accuracy of 0.89 and an AUC of 0.95, indicating strong model performance across the metrics."
1334,"caption: Performance results from different models using multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1, SVM,0.93,0.94,0.94,0.94, KNN,0.89,0.87,0.89,0.88, RF,0.95,0.94,0.96,0.95, NB,0.86,0.89,0.84,0.86","The table above presents the performance results of multiple different models evaluated using multiple evaluation metrics, including Accuracy, Precision, Recall, and F1. The models compared are SVM, KNN, RF, and NB. Notably, the RF model achieved the highest Accuracy score of 0.95 and Recall score of 0.96, while the SVM model had the highest Precision score of 0.94. Additionally, the NB model achieved the lowest Accuracy and Recall scores of 0.86 and 0.84, respectively, but had the second-highest Precision score of 0.89. Overall, the table indicates that the RF model outperformed the other models in this experiment."
1335,"caption: Comparing the performance of different classifiers on a binary classification task.table: Model,Accuracy (A),Precision (P),Recall (R),F1-Score (F1), Random Forest,0.96,0.97,0.96,0.96, XGBoost,0.94,0.94,0.90,0.91, Naïve Bayes,0.89,0.91,0.83,0.85, Logistic Regression,0.96,0.94,0.98,0.96, Decision Tree,0.92,0.88,0.94,0.91","The table compares five different machine learning models' performances on a binary classification task using four evaluation metrics: accuracy (A), precision (P), recall (R), and F1-score (F1). The Random Forest model had the highest accuracy of 0.96, achieving a high level of precision, recall, and F1-score. The Logistic Regression model attained a similarly high accuracy score and had a high precision score and recall score of 0.94 and 0.98, respectively. However, the Naïve Bayes model had the lowest accuracy of 0.89, achieving lower precision, recall, and F1-score than the rest of the models. The XGBoost and Decision Tree models attained an accuracy of 0.94 and 0.92, respectively. The Decision Tree model achieved high recall but had lower precision, while XGBoost had high precision but comparatively lower recall."
1336,"caption: Table 4: Model performance based on multiple evaluation metrics.table: Model,F1-Score,Accuracy,Precision,Recall, SVM,0.83,0.81,0.85,0.81, Logistic Regression,0.84,0.82,0.79,0.90, Decision Tree,0.79,0.76,0.82,0.76, Random Forest,0.87,0.84,0.90,0.83, XGBoost,0.87,0.85,0.87,0.90","Table 4 compares the performance of SVM, Logistic Regression, Decision Tree, Random Forest, and XGBoost models based on four different evaluation metrics including F1-Score, Accuracy, Precision, and Recall. The table shows the best performing model for each metric. The Random Forest model outperforms the other models in terms of F1-Score with a score of 0.87, closely followed by XGBoost with a score of 0.87. For accuracy, XGBoost has the highest score of 0.85, followed by Random Forest with a score of 0.84. For precision, the highest score was achieved by Random Forest with a score of 0.90, while SVM and XGBoost both had the highest recall score of 0.81 and 0.90, respectively."
1337,"caption: Table 4: Performance of different models using multiple evaluation metrics.table: Model,F1-Score,Precision,Recall,Accuracy,Bal. Accuracy, Model 1,0.84,-,-,0.91,-, Model 2,0.81,0.88,0.76,0.89,0.82, Model 3,0.92,0.87,0.98,0.92,-, Model 4,-,0.84,0.79,0.88,-, Model 5,0.73,-,-,0.85,0.73","Table 4 presents the comparison of different models' performances with multiple evaluation metrics, including F1-Score, Precision, Recall, Accuracy, and Balanced Accuracy. The table displays five models with varying combinations of evaluation metrics. Notably, Model 3 performs the best with an F1-Score of 0.92, Precision of 0.87, Recall of 0.98, and Accuracy of 0.92. Model 2 also demonstrated a relatively good performance with an F1-Score of 0.81, Precision of 0.88, Recall of 0.76, and Balanced Accuracy of 0.82. Moreover, Model 4 achieved moderate results in terms of Precision and Recall, with values of 0.84 and 0.79, respectively. Interestingly, some models had missing values for certain metrics."
1338,"caption: Performance comparison of different models using different evaluation metrics.table: Model,Metrics,Accuracy,F1-Score,Precision,Recall, SVM,Train,0.98,0.94,0.96,0.92, Valid,0.89,0.72,0.75,0.70, RF,Train,0.96,0.91,0.94,0.88, Valid,0.94,0.82,0.85,0.80, MLP,Train,0.92,0.85,0.89,0.82, Valid,0.91,0.81,0.83,0.79, KNN,Train,0.93,0.84,0.87,0.82, Valid,0.85,0.67,0.70,0.64","Table above presents a comparison of four different models: Support Vector Machine (SVM), Random Forest (RF), Multilayer Perceptron (MLP), and K-Nearest Neighbors (KNN) based on multiple evaluation metrics - Accuracy, F1-Score, Precision, and Recall. We evaluated and compared the performance of these models based on the training and validation dataset separately. From the table, it is observed that SVM had the best training performance in terms of accuracy, F1-Score, Precision, and Recall. For the validation dataset, RF model has the highest accuracy of 0.94. Overall, the table exhibits that the selected models had varying performances on different evaluation metrics, and therefore, model selection can be dependent on the metrics of interest."
1339,"caption: Comparison of different machine learning models based on their evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Support Vector Machine (SVM),0.91,0.94,0.89,0.91, Random Forest,0.95,0.95,0.94,0.95, Logistic Regression,0.87,0.85,0.93,0.87, K-Nearest Neighbor (KNN),0.82,0.78,0.91,0.83, Neural Network,0.93,0.92,0.94,0.93","The table above presents a comparison of different machine learning models' performances based on the evaluation metrics Accuracy, Precision, Recall, and F1-score. The table shows five models: Support Vector Machine (SVM), Random Forest, Logistic Regression, K-Nearest Neighbor (KNN), and Neural Network. Notably, Random Forest achieved the highest scores in all evaluation metrics, with an Accuracy, Precision, Recall, and F1-Score of 0.95. In contrast, K-Nearest Neighbor (KNN) had the lowest scores in all four metrics, with an Accuracy of 0.82, Precision of 0.78, Recall of 0.91, and F1-Score of 0.83. Overall, the findings suggest that Random Forest performs better than other models in terms of evaluation metrics."
1340,"caption: Model evaluation metrics with their respective scores.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.85,0.83,0.89,0.80, Random Forest,0.89,0.88,0.92,0.85, K-Nearest Neighbors,0.82,0.78,0.84,0.73, Support Vector Machines,0.87,0.86,0.90,0.83, Decision Tree,0.82,0.80,0.84,0.77","The table above evaluates the performance of different models' accuracy, F1-Score, Precision, and Recall using the same dataset. The models were trained and tested on binary classification data, where the goal is to predict the presence or absence of the target class. The Random Forest model had the highest accuracy score of 0.89, the highest Precision score of 0.92, and the second-highest Recall score of 0.85. Logistic Regression had the highest F1 score at 0.83, while Support Vector Machines had the highest Recall score of 0.83. The K-Nearest Neighbors model had the lowest accuracy, F1-Score, Precision, and Recall scores. The results provide insights for selecting models based on specific evaluation metrics."
1341,"caption: Results of different classification modelstable: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.80,0.81,0.56,0.66, Decision Tree,0.76,0.69,0.63,0.66, Random Forest,0.85,0.80,0.72,0.75, Support Vector Machine,0.79,0.76,0.60,0.67, Naive Bayes,0.71,0.57,0.80,0.67","Table X presents the results of different classification models based on multiple evaluation metrics such as accuracy, precision, recall, and F1 score. The table highlights the performance of logistic regression, decision tree, random forest, support vector machine, and naive Bayes models. The best-performing model in terms of accuracy is Random Forest with a score of 0.85, whereas Naive Bayes got the lowest accuracy of 0.71. The Random Forest model's precision and recall scores were the highest, followed by Logistic regression with precision of 0.81 and recall of 0.56. Interestingly, Naive Bayes tops the recall score with 0.80 and Logistic Regression tops the precision score. The F1 score ranks Random Forest first, while Decision tree and Naive Bayes shared the lowest score. It is worth noting that each model used the same dataset for training and testing."
1342,"caption: Performance comparison of multiple models based on various evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Model 1,0.87,0.76,0.85,0.70, Model 2,0.83,0.72,0.87,0.63, Model 3,0.91,0.83,0.93,0.74, Model 4,0.85,0.67,0.77,0.59, Model 5,0.88,0.77,0.83,0.73","The table shows the performance comparison of five models based on different evaluation metrics, including accuracy, F1 score, precision, and recall. Model 3 has the highest accuracy of 0.91, the highest F1 score of 0.83, and the highest precision score of 0.93. Interestingly, Model 2 scores the second-highest F1 score of 0.72, surpassed by Model 3. Model 3 also scored the lowest recall of 0.74 amongst all the models. However, all models have a close accuracy score ranging from 0.83 to 0.91, indicating that the models are relatively competent. Overall, the table highlights Model 3 as the best-performing model based on most of the evaluation metrics."
1343,"caption: Table 4: Comparison of different classifiers evaluation metricstable: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,90.12,0.89,0.91,0.90, Decision Tree,78.32,0.72,0.74,0.73, Random Forest,92.56,0.91,0.95,0.93, XGBoost,91.78,0.92,0.89,0.91, Support Vector Machine,89.96,0.87,0.92,0.88","Table 4 shows a comparative analysis of different machine learning classifiers' performance metrics. The metrics included Accuracy, Precision, Recall, and F1 Score. The results show that Random Forest performed the best with an Accuracy score of 92.56%, Precision of 0.91, Recall of 0.95, and F1 Score of 0.93. XGBoost and Logistic Regression follow with similar but slightly lesser results. On the other hand, Decision Tree struggles to perform, with the lowest Accuracy score of 78.32%, a Precision score of 0.72, Recall of 0.74 and an F1 Score of 0.73. The Support Vector Machine performer moderately, with an Accuracy of 89.96%, a Precision of 0.87, Recall of 0.92, and an F1 Score of 0.88."
1344,"caption: Comparison of Various Machine Learning Model Performancestable: Model,F1-score,Precision,Accuracy,Recall, Multinomial Naive Bayes,0.73,0.68,0.76,0.79, Logistic Regression,0.75,0.79,0.72,0.72, Random Forest,0.77,0.71,0.77,0.85, K-Nearest Neighbors,0.64,0.58,0.68,0.73, Support Vector Machine,0.75,0.72,0.75,0.80",
1345,"caption: Performance comparison of different classification models using various evaluation metrics.table: Model,Accuracy,F1 Score,AUC-ROC,AUC-PR, Logistic Regression,0.8,0.78,0.78,0.64, Decision Tree,0.72,0.68,0.67,0.57, Random Forest,0.84,0.83,0.81,0.69, Support Vector Machine,0.79,0.73,0.79,0.62, K-Nearest Neighbors,0.76,0.71,0.73,0.56",
1346,"caption: Table 4: Performance evaluation of different machine learning modelstable: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.82,0.83,0.81,0.82, RF,0.83,0.85,0.80,0.82, XGBoost,0.84,0.87,0.81,0.84, KNN,0.78,0.80,0.76,0.77, Naive Bayes,0.74,0.81,0.62,0.70","Table 4 presents the performance evaluation results of five different machine learning models. The accuracy, precision, recall, and F1-score metrics are shown for SVM, RF, XGBoost, KNN, and Naive Bayes models. Interestingly, XGBoost achieved the highest accuracy of 0.84, while RF had the highest precision of 0.85. Naive Bayes, on the other hand, had the lowest accuracy of 0.74 but demonstrated the highest precision score of 0.81 among all models. Furthermore, KNN exhibited the lowest performance results, with an accuracy of 0.78, precision of 0.80, recall of 0.76, and F1-score of 0.77."
1347,"caption: Performance comparison of various models on multiple evaluation metrics.table: Models,Precision (P),Recall (R),F1-Score,Accuracy, Model 1,0.83,0.85,0.83,0.84, Model 2,0.82,0.80,0.81,0.81, Model 3,0.79,0.86,0.82,0.83, Model 4,0.88,0.82,0.84,0.87, Model 5,0.81,0.84,0.82,0.83",
1348,"caption: Model performance based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.87,0.86,0.89,0.87, Support Vector Machine,0.91,0.90,0.91,0.91, Random Forest,0.92,0.92,0.90,0.91, Gradient Boost,0.93,0.93,0.92,0.93, Multi-Layer Perceptron,0.94,0.94,0.93,0.93","Table presents the accuracy, precision, recall, and F1-score of five different models: Logistic Regression, Support Vector Machine, Random Forest, Gradient Boost, and Multi-Layer Perceptron. Each model's performance was evaluated using the same dataset, and their results were marked with different evaluation metrics. Interestingly, the Multi-Layer Perceptron model achieves the best accuracy of 0.94 among all models. Similarly, the Gradient Boost and Multi-Layer Perceptron models have the highest precision, recall and F1-score compared to other models. It is worth noticing that the Support Vector Machine, Random Forest, and Gradient Boost models closely perform with only slight variations in different evaluation metrics."
1349,"caption: Comparison of different models based on multiple evaluation metrics.table: Model,F1-score,Precision,Recall,Accuracy, Logistic Regression,0.85,0.87,0.84,0.88, Decision Tree,0.78,0.80,0.76,0.81, Random Forest,0.91,0.92,0.90,0.92, Naive Bayes,0.72,0.65,0.81,0.75, Support Vector,0.83,0.84,0.82,0.85","Table X presents a comparison of different models based on multiple evaluation metrics, including F1-score, Precision, Recall, and Accuracy. The table includes Logistic Regression, Decision Tree, Random Forest, Naive Bayes, and Support Vector models. Results show that the Random Forest model outperforms other models, recording the best F1-score of 0.91, precision of 0.92, recall of 0.90, and accuracy of 0.92. Notably, Naive Bayes recorded the lowest F1-score of 0.72, Precision of 0.65, and Accuracy of 0.75. Overall, the Random Forest outperforms other models in terms of F1-score, Precision, Recall, and Accuracy, while Naive Bayes model renders the lowest performance values in all the evaluation metrics."
1350,"caption: Performance evaluation of different classification modelstable: Model,Precision,Recall,F1-Score,Accuracy, Model A,0.82,0.90,0.86,0.88, Model B,0.78,0.92,0.84,0.83, Model C,0.85,0.82,0.83,0.85, Model D,0.80,0.88,0.84,0.86, Model E,0.87,0.79,0.83,0.85",
1351,"caption: Performance metrics of multiple modelstable: Model,Accuracy,F1-score,Recall,Precision, Model A,0.92,0.91,0.89,0.94, Model B,0.89,0.88,0.90,0.87, Model C,0.94,0.93,0.89,0.98","Table presents the accuracy, F1-score, recall, and precision metrics of multiple models. Model A achieved the highest accuracy and precision with scores of 0.92 and 0.94, respectively. The model also shows reasonable F1-score and recall scores of 0.91 and 0.89, respectively. Contrarily, Model B had the lowest accuracy (0.89) and precision (0.87) scores with a relatively low F1-score and high recall score. Model C had remarkable scores across all metrics with the highest F1-score (0.93) and accuracy (0.94), high precision (0.98), and reasonable recall score (0.89). Model C can be considered the best-performing model based on these metrics."
1352,"caption: Table 4: Comparison of various models based on multiple evaluation metricstable: Model,F1 Score,Precision,Recall,Accuracy, Logistic Regression,0.908,0.912,0.904,0.905, Random Forest,0.943,0.952,0.934,0.940, Gradient Boosting,0.947,0.944,0.951,0.935, Support Vector Machine,0.940,0.932,0.949,0.925","Table 4 presents a comparison of four different models' performances based on four evaluation metrics: F1 score, Precision, Recall, and Accuracy. The table exhibits Logistic Regression, Random Forest, Gradient Boosting, and Support Vector Machine models' performance scores. Notably, the Random Forest model shows the highest F1 score of 0.943, while the Gradient Boosting model shows the highest Precision score of 0.944 and the highest Recall score of 0.951. However, the Logistic Regression model shows the highest accuracy score of 0.905. It should be noted that the SVM model had the lowest scores in all the evaluation metrics compared to the other models. The results suggest that the Random Forest and Gradient Boosting models outperform the other models in terms of the performance measures evaluated."
1353,"caption: Model performances evaluated based on different metrics.table: Model,Accuracy,F1-score,Precision,Recall, Model A,0.82,0.83,0.85,0.84, Model B,0.83,0.82,0.82,0.83, Model C,0.72,0.70,0.68,0.72, Model D,0.88,0.87,0.89,0.87, Model E,0.79,0.81,0.78,0.85","The table above displays the performance of five different models, namely Model A, B, C, D, and E. The models were evaluated using multiple metrics such as Accuracy, F1-score, Precision, and Recall. Interestingly, Model D had the highest score in all metrics evaluating its performance at 0.88, 0.87, 0.89, and 0.87 for accuracy, F1-score, precision, and recall, respectively. Model C had the least score in all metrics, displaying the lowest performance in this study. Notably, the models' performance seems to differ across different evaluation metrics and can be investigated further for better understanding."
1354,"caption: Evaluation metrics comparison for different modelstable: Model,Accuracy,Precision,Recall,F1 Score, Model 1,0.85,0.87,0.89,0.86, Model 2,0.81,0.78,0.84,0.81, Model 3,0.87,0.86,0.88,0.87, Model 4,0.84,0.83,0.85,0.84, Model 5,0.83,0.81,0.83,0.82","Table 1 presents a comparison of different models' performances for multiple evaluation metrics, including accuracy, precision, recall, and F1 score. The table consists of Model 1, Model 2, Model 3, Model 4, and Model 5, and their corresponding evaluation metrics.  It can be observed in the table that Model 3 achieves the highest accuracy of 0.87. On the other hand, Model 2 has the lowest accuracy of 0.81. In terms of precision, Model 1 has the highest precision value of 0.87, while Model 5 has the lowest precision value of 0.81. Model 3 also has the highest recall of 0.88, whereas Model 2 shows the lowest recall of 0.84. Lastly, Model 1 has the highest F1 score of 0.86, while Model 5 has the lowest F1 score of 0.82."
1355,"caption: Performance comparison of different classification models based on accuracy, precision, recall, and F1 score metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.89,0.91,0.87,0.89, Decision Tree,0.80,0.81,0.78,0.79, Random Forest,0.92,0.93,0.91,0.92, Support Vector Machines,0.87,0.89,0.85,0.87, Neural Networks,0.91,0.92,0.90,0.91","This table displays the performance comparison of five different classification models based on four evaluation metrics, namely, Accuracy, Precision, Recall, and F1 score. The models used are Logistic Regression, Decision Tree, Random Forest, Support Vector Machines, and Neural Networks. The highest-performing model based on the listed four metrics is the Random Forest with an Accuracy of 0.92, Precision of 0.93, Recall of 0.91, and F1 score of 0.92. Interestingly, all models performed best in terms of precision, which indicates the low rate of false-positive. On the other hand, the Decision Tree model shows the lowest performance with an accuracy of 0.80 and F1 score of 0.79. Overall, this table is useful in evaluating model performances and selecting the best classification approach for the dataset."
1356,"caption: Table 4: Evaluation metrics of different modelstable: Model,Accuracy (%),F1 Score (%),Recall (%),Precision (%), Model 1,92.3,86.5,87.6,85.4, Model 2,89.7,83.6,81.2,86.9, Model 3,94.1,90.3,92.8,87.9, Model 4,91.2,87.1,89.3,85.2, Model 5,90.8,84.2,85.4,83.1","Table 4 displays the evaluation metrics of five different models- Model 1, Model 2, Model 3, Model 4, and Model 5. Four common evaluation metrics, accuracy, F1 score, recall, and precision, were used to evaluate the models. Model 3 has the best performance across all evaluation metrics, with an accuracy of 94.1%, F1 score of 90.3%, recall of 92.8%, and precision of 87.9%. Model 2 narrowly beats out Model 5 for having the second-best performance across all evaluation metrics. Interestingly, while Model 5 has the lowest metrics scores among all models, it has relatively high accuracy compared to Model 2 and Model 4."
1357,"caption: Performance comparison of different models using various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.85,0.88,0.78,0.83, Logistic Regression,0.78,0.81,0.75,0.76, Decision Tree,0.82,0.84,0.80,0.82, Random Forest,0.88,0.89,0.84,0.86, XGBoost,0.91,0.92,0.89,0.91","The table above compares the performance of different models that were trained and tested using the same dataset. The models include Support Vector Machine (SVM), Logistic Regression, Decision Tree, Random Forest and XGBoost. The evaluation metrics used to test the models are Accuracy, Precision, Recall and F1-score. Random Forest had the highest Accuracy (0.88) and F1-score (0.86) values, while XGBoost had the highest Precision (0.92) and Recall (0.89) values. Interestingly, the XGBoost model shows the highest overall performance with an Accuracy of 0.91 and an F1-score of 0.91."
1358,"caption: Comparison of different models based on different evaluation metricstable: Model,F1-score,AUPRC,AUROC, SVM,0.89,0.86,0.79, RF,0.93,0.92,0.85, NB,0.82,0.79,0.68, MLP,0.94,0.93,0.88, LR,0.88,0.84,0.75, DT,0.91,0.89,0.81","Table presents the performance evaluation of six different models, namely SVM, RF, NB, MLP, LR, and DT. The models were evaluated using three different evaluation metrics, namely F1-score, AUPRC, and AUROC. The RF model shows the best F1-score and AUROC of 0.93 and 0.85, respectively. The MLP model exhibits the highest AUPRC score of 0.93. Interestingly, the SVM model achieved relatively consistent results across all metrics, showing an F1-score of 0.89, AUPRC of 0.86, and AUROC of 0.79. Overall, the table demonstrates that different models may show variations in their performances based on different evaluation metrics."
1359,"caption: Comparison of Different Classification Modelstable: Model,Accuracy,Precision,Recall,F1 Score,AUC Score, Logistic Regression,0.82,0.78,0.77,0.77,0.86, Decision Tree,0.74,0.63,0.66,0.64,0.77, Random Forest,0.88,0.85,0.83,0.84,0.94, k-Nearest Neighbor,0.79,0.73,0.75,0.74,0.87, Support Vector Machines,0.84,0.81,0.80,0.80,0.91","The table shows the performance comparison of five different classification models namely - Logistic Regression, Decision Tree, Random Forest, k-Nearest Neighbor, and Support Vector Machines. The models are evaluated based on five different metrics - Accuracy, Precision, Recall, F1 Score, and AUC Score. The Random Forest model outperformed all other models with an Accuracy score of 0.88, Precision of 0.85, Recall of 0.83, F1 Score of 0.84, and AUC Score of 0.94. It is noteworthy that the Decision Tree and k-Nearest Neighbor models had inferior scores compared to other models. Overall, the table suggests that Random Forest and Support Vector Machines are promising models for classification tasks."
1360,"caption: Table 4: Model Performance Comparison Based on Different Evaluation Metrics and Foldstable: Models,Metric,1st Fold,2nd Fold,3rd Fold, Linear Regression,RMSE,3.2,4.1,2.8, Linear Regression,MAE,2.6,3.8,2.2, Random Forest,RMSE,2.5,3.9,2.4, Random Forest,MAE,2.1,3.4,2.0, XGBoost,RMSE,2.3,3.5,2.3, XGBoost,MAE,1.9,3.0,1.9","Table 4 presents a comparison of models' performance based on multiple different evaluation metrics and three different fold results. The linear regression, random forest, and XGBoost models' RMSE and MAE of the first, second, and third folds are discussed in this table. Interestingly, the XGBoost model shows the best performance overall, having the lowest RMSE and MAE results for all three folds. Moreover, all models' RMSE and MAE values indicate it's a good fit for the data, with errors near the study's minimum level."
1361,"caption: Table 4: Model Performances Based on Different Evaluation Metrics.table: Model,Accuracy,F1 Score,Precision, Model A,0.87,0.88,0.86, Model B,0.82,0.81,0.80, Model C,0.91,0.92,0.91, Model D,0.78,0.79,0.76, Model E,0.93,0.93,0.94","Table 4 presents the comparison of five different models based on accuracy, F1 score, and precision metrics. Model C achieved the highest accuracy score of 0.91, while Model E performed the best in F1 score and precision with the scores of 0.93 and 0.94, respectively. Notably, Model A and Model C had relatively high precision scores while Models D and B showed lower performances in all three metrics. This table demonstrates that various evaluation metrics might result in different best performing models, highlighting the importance of understanding the goal of modeling and selecting the appropriate evaluation metrics accordingly."
1362,"caption: Model performance based on evaluation metricstable: Model,Accuracy,F1 Score,Precision,Recall,AUC, SVM,0.89,0.89,0.91,0.87,0.92, KNN,0.82,0.79,0.81,0.77,0.84, Random Forest,0.96,0.96,0.98,0.94,0.98, Naive Bayes,0.77,0.73,0.82,0.67,0.85, XGBoost,0.95,0.95,0.97,0.93,0.96","The table summarizes the accuracy, F1 score, precision, recall, and AUC for different models. The models include SVM, KNN, Random Forest, Naive Bayes, and XGBoost. Among all the models, Random Forest performs the best, achieving an accuracy score of 0.96, F1 score of 0.96, precision of 0.98, recall of 0.94 and AUC of 0.98. XGBoost also performs well, obtaining an accuracy score of 0.95, F1 score of 0.95, precision of 0.97, recall of 0.93 and AUC of 0.96. SVM and KNN show relatively lower accuracy scores of 0.89 and 0.82, respectively. Naive Bayes has the lowest accuracy score of 0.77 but has the highest precision score of 0.82 among all models."
1363,"caption: Table 4. Model performance using multiple evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.85,0.87,0.84,0.85, Naive Bayes,0.78,0.81,0.76,0.77, Random Forest,0.92,0.93,0.91,0.91, Decision Tree,0.88,0.89,0.87,0.87","Table 4 presents model performance using various evaluation metrics, including Accuracy, Precision, Recall, and F1-Score. Four models, including SVM, Naive Bayes, Random Forest, and Decision Tree, are evaluated using the same dataset. The Random Forest model achieved the highest accuracy score of 0.92, while the SVM model demonstrated the highest precision at 0.87. Furthermore, the Naive Bayes model had the lowest performance in all evaluation metrics. Interestingly, the Decision Tree model performed better than SVM and Naive Bayes models in all evaluation metrics, except precision."
1364,"caption: Model performances based on different evaluation metricstable: Model,Accuracy (%),F1 Score,Precission,Recall, SVM,90.1,0.895,0.903,0.889, KNN,88.9,0.882,0.892,0.873, Naive Bayes,86.7,0.862,0.960,0.785, Decision Tree,87.6,0.875,0.877,0.874, Random Forest,91.3,0.912,0.920,0.903","The presented table demonstrates the models' performances measured by various evaluation metrics. The table includes five models - SVM, KNN, Naive Bayes, Decision tree, and Random Forest. The evaluation metrics are Accuracy(%), F1 Score, Precision, and Recall. Among all models, the Random Forest model outperforms the other models with the highest Accuracy of 91.3%, F1 Score of 0.912, Precision of 0.920, and Recall of 0.903. Naive Bayes shows the lowest accuracy of 86.7%, while it has the highest Precision of 0.960. The SVM model performs well on all the evaluation criteria, such as Accuracy of 90.1%, F1 Score of 0.895, Precision of 0.903, and Recall of 0.889. The Decision tree model has shown competitive performance with 87.6% accuracy and 0.877 Precision."
1365,"caption: Model performance with different evaluation metricstable: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.72,0.65,0.68,0.62, Decision Tree,0.68,0.58,0.60,0.57, Random Forest,0.78,0.74,0.75,0.74, Support Vector Machine,0.73,0.67,0.69,0.66, Gradient Boosting,0.79,0.74,0.76,0.74","The table depicts a comparison of various machine learning models' performance metrics. The models include Logistic Regression, Decision Tree, Random Forest, Support Vector Machine, and Gradient Boosting. The evaluation metrics consist of Accuracy, F1 Score, Precision, and Recall. The best model is Gradient Boosting, exhibiting the highest accuracy score of 0.79, followed closely by Random Forest with an accuracy of 0.78. Moreover, Gradient Boosting also demonstrated the best performance in terms of Precision and Recall, unlike the other models. In contrast, Logistic Regression showed significant worse results than the other models across all performance metrics."
1366,"caption: Comparison of multiple models based on the multiple evaluation metrics.table: Model name,Precision,Recall,F1 Score,Accuracy, Model A,0.85,0.90,0.87,0.89, Model B,0.87,0.84,0.85,0.88, Model C,0.89,0.81,0.85,0.87, Model D,0.82,0.92,0.87,0.88","The presented table provides a comparison of four different models' performance based on precision, recall, F1 score, and accuracy metrics. The results suggest that Model C has the highest precision with a score of 0.89 and Model D shows the highest recall with a score of 0.92. Considering the F1 score, Model A has the highest score of 0.87. In terms of accuracy, Model A has a score of 0.89, which is the highest among the models. Therefore, based on these four different metrics, it seems like Model A provides the best performance among the compared models."
1367,"caption: Performance metrics of different models on the evaluation dataset.table: Model,Accuracy,Precision,Recall,F1-Score, Model A,0.78,0.87,0.74,0.80, Model B,0.84,0.83,0.91,0.87, Model C,0.72,0.75,0.82,0.78, Model D,0.86,0.90,0.82,0.86, Model E,0.81,0.80,0.89,0.84","Table presents the performance metrics of five different models- Model A, Model B, Model C, Model D, and Model E on the evaluation dataset. The table displays the evaluation metrics, Accuracy, Precision, Recall, and F1-Score for each model. Notably, Model D demonstrated the highest Accuracy (0.86) and F1-Score (0.86) among all models. Conversely, Model C had the lowest Accuracy (0.72), Precision (0.75), Recall (0.82), and F1-Score (0.78). Interesting observations made from the table show Model B has high Precision (0.83) and Recall (0.91) but not the highest Accuracy. Model E, on the other hand, has the second-highest F1-Score (0.84) despite an accuracy of 0.81."
1368,"caption: Table 4: Model Performance based on various evaluation metricstable: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.85,0.85,0.86,0.84, Support Vector Machine,0.89,0.89,0.88,0.89, Random Forest,0.92,0.92,0.92,0.92, Naive Bayes,0.78,0.77,0.81,0.73","Table 4 presents the performance of four models on multiple evaluation metrics, including Accuracy, F1-score, Precision, and Recall. The models were Logistic Regression, Support Vector Machine, Random Forest, and Naive Bayes. The results show that the Random Forest model performed the best in all metrics, with an accuracy score of 0.92, an F1-score of 0.92, and both Precision and Recall scores of 0.92. Support Vector Machine had a remarkable performance in terms of F1-score and Recall, with scores of 0.89 each. Interestingly, Naive Bayes had the lowest accuracy score of 0.78, however, it achieved the highest score in Precision with 0.81. These results suggest that different models have their strengths and weaknesses depending on specific evaluation metrics."
1369,"caption: A comparison of different models based on precision, recall, f1-score, and accuracy.table: Model,Precision,Recall,F1-score,Accuracy, Logistic Regression,0.75,0.78,0.72,0.80, Multinomial Naive Bayes,0.65,0.82,0.72,0.75, Support Vector Machine,0.69,0.80,0.74,0.77","Table 4 compares the performance metrics of three different models using precision, recall, f1-score, and accuracy measures. The Logistic Regression model achieved the highest precision at 0.75 and recall at 0.78. The Multinomial Naive Bayes model showed the highest recall at 0.82, albeit with the lowest precision at 0.65. In contrast, the Support Vector Machine model performed averagely, achieving a precision, recall, and f1-score at 0.69, 0.80, and 0.74, respectively. Finally, the Logistic Regression model attained the highest accuracy of 0.80, outperforming both Multinomial Naive Bayes and Support Vector Machine models."
1370,"caption: Performance comparison of different models using various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score,AUC ROC,AUC PRC,Parameters, SVM,0.87,0.88,0.89,0.88,0.92,0.94,C=0.1, kernel=RBF, Random Forest,0.92,0.91,0.95,0.93,0.94,0.93,n_estimators=200, max_depth=100, Gradient Boosting,0.91,0.92,0.94,0.92,0.96,0.94,n_estimators=150, learning_rate=0.1, K-Nearest Neighbors,0.83,0.82,0.91,0.85,0.89,0.86,n_neighbors=5, weights=distance","The table compares the performance of different models in terms of accuracy, precision, recall, F1-score, AUC ROC, AUC PRC, and their respective hyperparameters. The evaluated models include SVM, Random Forest, Gradient Boosting, and K-nearest Neighbors. From the comparison, Random Forest exhibits the highest accuracy (0.92), relatively high precision (0.91), recall (0.95), and F1-score (0.93), making it the best-performing model. Gradient Boosting comes second, with an accuracy of 0.91, higher than SVM (0.87) and K-Nearest Neighbors (0.83). However, Gradient Boosting achieves a high AUC ROC (0.96), indicating that the model has fewer false positives. SVM achieves the highest AUC PRC (0.94), indicating that the model has fewer false negatives."
1371,"caption: Performance of different machine learning models on a binary classification task.table: Model,Accuracy,Precision,F1-score,Time (s), Logistic Regression,0.87,0.85,0.82,2.5, Decision Tree,0.75,0.71,0.68,1.8, Random Forest,0.92,0.93,0.92,4.9, K-Nearest Neighbor,0.81,0.78,0.75,3.2, Support Vector Machine,0.88,0.86,0.84,8.1, AdaBoost,0.89,0.91,0.89,7.4, Gradient Boosting,0.91,0.92,0.91,9.8","The table presents a comparison of seven different machine learning models' performance on a binary classification task. The models' performance is evaluated using multiple metrics: accuracy, precision, F1-score, and time of execution. The Random Forest model attained the highest accuracy score of 0.92, while the Decision Tree model recorded the lowest score of 0.75. The Gradient Boosting algorithm had the highest precision and F1-score of 0.92 and 0.91, respectively. Moreover, the support vector machine took the most significant amount of time to execute, consuming 8.1 seconds, while the decision tree took the shortest time of 1.8 seconds."
1372,"caption: Model performances for different models and evaluation metrics.table: Model,Metric,Result, Logistic Regression,Accuracy,0.87, Random Forest,Accuracy,0.92, Gradient Boosting,Accuracy,0.91, SVM,Accuracy,0.88, KNN,Accuracy,0.82, Naive Bayes,Accuracy,0.84, Logistic Regression,Precision,0.85, Random Forest,Precision,0.91, Gradient Boosting,Precision,0.90, SVM,Precision,0.86, KNN,Precision,0.81, Naive Bayes,Precision,0.83, Logistic Regression,Recall,0.84, Random Forest,Recall,0.93, Gradient Boosting,Recall,0.87, SVM,Recall,0.88, KNN,Recall,0.81, Naive Bayes,Recall,0.81, Logistic Regression,F1-Score,0.84, Random Forest,F1-Score,0.92, Gradient Boosting,F1-Score,0.88, SVM,F1-Score,0.87, KNN,F1-Score,0.81, Naive Bayes,F1-Score,0.82","The table presents the performance of various classification models evaluated using different evaluation metrics, including accuracy, precision, recall, and F1-score. The table shows Logistic Regression, Random Forest, Gradient Boosting, SVM, KNN, and Naive Bayes models' performance using multiple evaluation metrics. Interestingly, the Random Forest model achieved the best performance across all the metrics, obtaining an accuracy of 0.92, precision of 0.91, recall of 0.93, and F1-score of 0.92. Meanwhile, the KNN model obtained the lowest performance scores across all metrics among all models. Furthermore, the Logistic Regression model demonstrated a consistent performance across all metrics, indicating that it could be a useful option in classification tasks that require more balanced accuracy, precision, recall, and F1-scores."
1373,"caption: Table 4: Model performances using different evaluation metrics.table: Model,Accuracy,F1-score,Recall,Precision, Logistic Reg,0.84,0.63,0.89,0.49, Naive Bayes,0.82,0.57,0.86,0.42, SVM,0.87,0.69,0.91,0.57, Random Forest,0.90,0.78,0.93,0.65, XGBoost,0.89,0.76,0.92,0.63","Table 4 shows the performances of five different models in terms of their accuracy, F1-score, recall, and precision on the test set. Logistic Regression model has the lowest F1-score (0.63), recall (0.89) and precision (0.49) compared to other models. Naive Bayes performs slightly better than logistic regression with an F1-score of (0.57), recall of (0.86), and precision of (0.42). SVM produces higher performance compared to Logistic regression and Naive Bayes with an F1-score of (0.69), recall of (0.91), and precision of (0.57). Random Forest achieved the highest accuracy (0.90), F1-score (0.78), recall (0.93), and precision (0.65) among all the models. XGBoost also achieved a high performance with an accuracy of (0.89), F1 score (0.76), recall (0.92), and precision (0.63)."
1374,"caption: Table 4: Comparison of different regression models based on their evaluation metrics.table: Models,MAE,RMSE,R-squared, Linear Regression,2.045,4.112,0.765, KNN Regression,1.876,4.122,0.758, Decision Tree,2.591,4.951,0.657, Random Forest,1.783,3.996,0.786, XGBoost,1.761,3.752,0.804, Support Vector Machine,2.391,4.642,0.698","Table 4 presents a comparison of different regression models based on their evaluation metrics. The table exhibits the MAE, RMSE, and R-squared scores for each model. The models include Linear Regression, KNN Regression, Decision Tree, Random Forest, XGBoost, and Support Vector Machine. Notably, all models were trained and tested using the same dataset. The XGBoost model achieves the best performance among all the models, achieving the lowest MAE and RMSE score and a high R-squared score of 0.804. Interestingly, the Random Forest model achieves the second-best MAE and RMSE, while both Support Vector Machine and Decision Tree models perform poorly with the highest error scores and lowest R-squared score."
1375,"caption: Model performance on a binary classification tasktable: Model,Precision,Recall,F1-score,Accuracy,ROC-AUC, SVM,0.89,0.95,0.92,0.86,0.96, Logistic Regression,0.64,0.76,0.70,0.65,0.74, Random Forest,0.91,0.96,0.93,0.88,0.94, Gradient Boosting,0.92,0.95,0.94,0.90,0.95","The table presents the evaluation results of four different models on a binary classification task using different evaluation metrics such as precision, recall, F1-score, accuracy, and ROC-AUC. SVM shows the highest ROC-AUC of 0.96, while Random Forest and Gradient Boosting models had comparable ROC-AUC scores of 0.94 and 0.95, respectively. The Random Forest model demonstrates the highest precision score of 0.91, whereas Gradient Boosting achieved the highest recall score of 0.95. The table highlights the importance of evaluating models using multiple metrics and comparing their performances to select the optimal one."
1376,"caption: Table 4: Model performance on classification of customer churn prediction based on multiple metrics.table: Model Name,F1 Score,Accuracy,Precision,Recall, Logistic Regression,0.85,0.90,0.86,0.84, Naive Bayes,0.87,0.87,0.81,0.94, K-Nearest Neighbor,0.76,0.88,0.82,0.72, Random Forest,0.91,0.93,0.92,0.90, Support Vector Machine,0.88,0.91,0.87,0.88","Table 4 shows the performance of five different models on the classification of customer churn prediction. The table reports the F1 score, accuracy, precision, and recall for each model. The results indicate that the Random Forest model has the highest F1 score (0.91) and Accuracy (0.93) among all other models. The Naive Bayes model exhibits the highest recall (0.94), but it has lower precision (0.81) than others. The Logistic Regression model displays moderate performance with a balanced score in all metrics. Overall, considering the multiple evaluation metrics, the Random Forest model appears to be the best performer for classification of customer churn prediction."
1377,"caption: Table 4: Comparative analysis of classification model performances using different evaluation metricstable: Model,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.87,0.85,0.89,0.82, Decision Tree,0.76,0.75,0.80,0.72, K-Nearest Neighbors,0.79,0.77,0.82,0.73, Support Vector Machine,0.89,0.88,0.87,0.90, Random Forest,0.92,0.91,0.90,0.93","Table 4 reports the comparative analysis of classification model performances using different metrics, including accuracy, F1-score, precision, and recall. The table displays the results of five models, including Logistic Regression, Decision Tree, K-Nearest Neighbors, Support Vector Machine, and Random Forest. The Random Forest model shows the highest overall performance on all evaluation metrics, with accuracy of 0.92, F1-score of 0.91, precision of 0.90, and recall of 0.93. On the other hand, the Decision Tree model presents the lowest performance on all evaluation metrics, with accuracy of 0.76, F1-score of 0.75, precision of 0.80, and recall of 0.72. It can be observed that the Random Forest model significantly outperforms the other models with the highest overall performance."
1378,"caption: Comparison of model performances on the test set using multiple evaluation metrics.table: Model,Precision,Recall,F1-score,Accuracy, Model A,0.82,0.78,0.80,0.85, Model B,0.90,0.82,0.85,0.87, Model C,0.75,0.83,0.79,0.80, Model D,0.88,0.76,0.81,0.86, Model E,0.92,0.87,0.89,0.90","The table above compares the performance metrics of five different models on the test set. Models A-E were evaluated based on four different metrics: precision, recall, F1-score, and accuracy. Based on the results, Model B had the highest precision of 0.90 and F1-score of 0.85. Model E had the highest recall of 0.87, and accuracy of 0.90. Additionally, Model A had a balance of all metrics, with precision, recall, F1-score, and accuracy scores of 0.82, 0.78, 0.80, and 0.85, respectively. It can be concluded that Model E had the best overall performance, while Model B had the best precision and F1-score."
1379,"caption: Comparison of Different Models' Performance Metricstable: Model,Accuracy,Precision,Recall,F1-Score, Model A,0.85,0.86,0.87,0.86, Model B,0.82,0.81,0.84,0.82, Model C,0.89,0.87,0.92,0.89, Model D,0.87,0.85,0.88,0.86, Model E,0.90,0.91,0.88,0.89","The table above illustrates the comparison of five different models in terms of their classification performance metrics: Accuracy, Precision, Recall, and F1-Score. Model E displays the highest accuracy of 0.90, while Model C shows the highest precision of 0.87 and recall of 0.92. Notably, Model E also produced the highest F1-Score of 0.89, providing overall optimal performance. Conversely, Model B has the lowest accuracy of 0.82, while it is offset by Model A's higher precision and comparable accuracy. In summary, Model E outperformed all of the other models, followed closely by Model C, while Model B had the poorest performance in all metrics."
1380,"caption: Evaluation metrics for different classification models.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.87,0.84,0.91,0.87, Naive Bayes,0.81,0.73,0.93,0.82, Decision Tree,0.93,0.91,0.97,0.94, Random Forest,0.95,0.93,0.98,0.95, XGBoost,0.96,0.94,0.98,0.96","The table shows the performance comparison of different classification models based on the accuracy, precision, recall, and F1-score metrics. SVM, Naive Bayes, Decision Tree, Random Forest and XGBoost models are evaluated using the same dataset, and the results show that the XGBoost model is the best-performing model achieving the highest accuracy, precision, recall, and F1-score of 0.96, 0.94, 0.98, and 0.96, respectively. The Decision Tree and Random Forest models achieved decent performance, with an accuracy of 0.93 and 0.95, respectively. The Naive Bayes model achieved a good recall score of 0.93, while the SVM model achieved a good balance between precision and recall."
1381,"caption: Metrics of various classifiers on classification task.table: Model,Precision,Recall,F1-score,Accuracy,AUC Score, Logistic Regression,0.77,0.63,0.70,0.76,0.79, Naive Bayes,0.67,0.75,0.71,0.68,0.74, Decision Tree,0.60,0.60,0.60,0.60,0.63, Random Forest,0.84,0.77,0.80,0.83,0.89, Gradient Boosting,0.82,0.75,0.78,0.82,0.87","The table presents the performance of five different classification models on a task. Evaluation metrics such as precision, recall, F1-score, accuracy, and AUC score are used to compare the results. The models include Logistic Regression, Naive Bayes, Decision Tree, Random Forest, and Gradient Boosting, all trained and tested on the same task dataset. The results in the table show that Random Forest and Gradient Boosting had the highest precision, recall, F1-score, accuracy, and AUC scores (0.84, 0.77, 0.80, 0.83, 0.89) followed closely by Logistic Regression (0.77, 0.63, 0.7, 0.76, 0.79). Naive Bayes also performed well in terms of accuracy and AUC score (0.68, 0.74), even though its precision, recall, and F1-scores were slightly lower than other models. The Decision Tree model had the lowest performance across all evaluation metrics."
1382,"caption: Table 4: Model comparison based on multiple evaluation metrics.table: Model Name,F1 Score,Precision,Recall,Accuracy,Time Taken(sec), SVM,0.89,0.85,0.94,0.87,32, Random Forest,0.87,0.82,0.93,0.86,25, Naive Bayes,0.82,0.78,0.87,0.79,05, Logistic Regression,0.92,0.89,0.96,0.88,42, MLP Classifier,0.87,0.82,0.92,0.85,96","Table 4 presents a comparison of five different models used in a classification task, evaluated using multiple evaluation metrics. The models compared in the table include Support Vector Machine (SVM), Random Forest, Naive Bayes, Logistic Regression, and Multi-layer Perceptron Classifier (MLP Classifier). The evaluation metrics considered for the comparison are F1 Score, Precision, Recall, Accuracy, and Time Taken (in seconds) per iteration. The Logistic Regression model attains the highest F1 score of 0.92, whereas the SVM model achieves the highest Recall of 0.94. Notably, the Naive Bayes model's training time is comparatively lower than the other models. Overall, this table presents a comprehensive comparison of different models used in a classification task based on various performance metrics."
1383,"caption: Model performances based on multiple evaluation metrics.table: Model,Accuracy,F1-Score,Recall, Logistic Regression,0.78,0.75,0.85, SVM,0.82,0.79,0.89, Random Forest,0.85,0.82,0.91, KNN,0.68,0.65,0.78, Naive Bayes,0.70,0.67,0.81","The table compares the performance of different models based on multiple evaluation metrics, including Accuracy, F1-Score, and Recall. The models used are Logistic Regression, SVM, Random Forest, KNN, and Naive Bayes. The results show that the Random Forest model achieves the highest Accuracy, F1-Score, and Recall, with scores of 0.85, 0.82, and 0.91, respectively. Meanwhile, the KNN and Naive Bayes models presented lower Accuracy, F1-Score, and Recall scores than the other models."
1384,"caption: Model performance on the test data for different classifiers using various evaluation metrics.table: Model,Precision,Recall,F1 Score,AUC ROC,AUC PR, Logistic,0.72,0.86,0.78,0.90,0.87, Decision Tree,0.81,0.76,0.78,0.82,0.80, Random Forest,0.88,0.87,0.87,0.90,0.89, XGBoost,0.89,0.91,0.90,0.94,0.91","The table presents the performance of different classifiers, namely Logistic Regression, Decision Tree, Random Forest, and XGBoost, based on various evaluation metrics. The evaluation metrics include Precision, Recall, F1 Score, AUC ROC, and AUC PR. The models were tested on the same test data, and the table shows that the XGBoost model outperformed the other models in almost all evaluation metrics, followed by the Random Forest model. Notably, the Random Forest model performed well in Precision, Recall, and F1 Score, while the Decision Tree model had the lowest AUC ROC score. Furthermore, the Logistic Regression model had the lowest performance in most evaluation metrics. Overall, the table provides a useful overview of model performance on the test data, indicating that XGBoost and Random Forest are promising classifiers for this dataset."
1385,"caption: Comparison of different models based on various evaluation metrics.table: Model,Accuracy,F1 Score,Recall,Precision, Logistic Regression,0.75,0.80,0.75,0.85, Decision Tree,0.71,0.73,0.68,0.78, K-Nearest Neighbors,0.78,0.80,0.78,0.81, Random Forest,0.82,0.84,0.81,0.87, XGBoost,0.86,0.88,0.85,0.90","The table above presents a comparison of different models using multiple evaluation metrics, including Accuracy, F1 Score, Recall, and Precision. The models included in the table are Logistic Regression, Decision Tree, K-Nearest Neighbors, Random Forest, and XGBoost. Notably, the Random Forest and XGBoost models demonstrated the best performance across all evaluation metrics, achieving Accuracy scores of 0.82 and 0.86, F1 Scores of 0.84 and 0.88, Recall scores of 0.81 and 0.85, and Precision scores of 0.87 and 0.90, respectively. The Logistic Regression model had the lowest scores, while the K-Nearest Neighbors' model had moderate scores for all evaluation metrics."
1386,"caption: Comparing the Classification Performance of Different Modelstable: Model Name,Accuracy,Precision,Recall,F1 Score, Random Forest,0.75,0.72,0.79,0.75, Support Vector Machine,0.68,0.69,0.74,0.66, Naive Bayes,0.69,0.66,0.78,0.71, Artificial Neural Network,0.72,0.71,0.76,0.72, Decision Tree,0.61,0.61,0.62,0.61","The table presents a comparison of multiple classification models based on their accuracy, precision, recall, and F1 score metrics. The models' performance was evaluated with the same dataset, and each model represents a different algorithm. Notably, the Random Forest model has the highest accuracy of 0.75, followed closely by the ANN with an accuracy of 0.72. The Naive Bayes model has the highest recall score of 0.78, while the Random Forest model has the highest precision score of 0.72. Comparing the F1 scores, the Naive Bayes model offered the highest score of 0.71."
1387,"caption: Model performance based on different evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.78 ± 0.02,0.77 ± 0.02,0.80 ± 0.03,0.75 ± 0.03, Decision Tree,0.72 ± 0.01,0.71 ± 0.01,0.68 ± 0.02,0.74 ± 0.01, Random Forest,0.84 ± 0.02,0.84 ± 0.02,0.85 ± 0.03,0.83 ± 0.02, KNN,0.63 ± 0.03,0.60 ± 0.03,0.62 ± 0.04,0.58 ± 0.03, SVM,0.81 ± 0.02,0.80 ± 0.02,0.83 ± 0.04,0.77 ± 0.03","The above table shows the model performances based on various evaluation metrics, including accuracy, F1-Score, precision, and recall. It reveals that the Random Forest model achieved the highest accuracy score of 0.84 +/- 0.02, followed by SVM with a score of 0.81 +/- 0.02. Interestingly, both models have similar precision scores of 0.85 +/- 0.03 and 0.83 +/- 0.04, respectively, which are the highest precision scores among all models. Meanwhile, the Logistic Regression model has the highest precision score of 0.80 +/- 0.03 and the highest recall score of 0.75 +/- 0.03. The Decision Tree model records the lowest accuracy, F1-Score, precision, and recall scores, indicating that the Decision Tree model is the weakest model among the considered models."
1388,"caption: Table 4: Performance comparison of four models based on different evaluation metrics.table: Model,Accuracy(%),F1-score,Precision,Recall, Logistic Regression,87.5,0.87,0.88,0.86, Decision tree,82.1,0.78,0.78,0.8, Random forest,89.6,0.9,0.91,0.89, XGBoost,90.2,0.91,0.92,0.901","The table summarizes the performance comparison of four models, including Logistic Regression, Decision tree, Random forest, and XGBoost, based on different evaluation metrics, such as accuracy, F1-score, precision, and recall. The accuracy of the models varies from 82.1% to 90.2%. The Random forest and XGBoost models demonstrate the best accuracy results of 89.6% and 90.2%, respectively. The F1-score for all models ranges from 0.78 to 0.91, where XGBoost achieved the highest score of 0.91. Similarly, the precision and recall scores range from 0.78 to 0.92 and from 0.86 to 0.901, respectively. Overall, XGBoost performed considerably well in all evaluation metrics, which makes it the best model among the presented models."
1389,"caption: Table 4: Performance comparison of different classifiers based on accuracy, F1-Score, Precision, and Recall.table: Model,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.82,0.83,0.81,0.85, Decision Tree,0.75,0.76,0.73,0.79, Random Forest,0.86,0.87,0.85,0.89, K-Nearest Neighbors,0.79,0.79,0.78,0.81, Support Vector Machine,0.83,0.84,0.82,0.86","Table 4 presents a comparison of five different classifiers in terms of their accuracy, F1-Score, Precision, and Recall performance evaluation metrics. The table contains the performance results of Logistic Regression, Decision Tree, Random Forest, K-Nearest Neighbors, and Support Vector Machine. From the results, it is observed that the Random Forest model has the highest accuracy, F1-Score, Precision, and Recall scores, with 0.86, 0.87, 0.85, and 0.89, respectively. On the other hand, the Decision Tree model shows the lowest performance results with an accuracy, F1-Score, Precision, and Recall scores of 0.75, 0.76, 0.73, and 0.79, respectively. It is interesting to note that the Logistic Regression model shows relatively consistent performance across all metrics with scores of 0.82, 0.83, 0.81, and 0.85 for accuracy, F1-Score, Precision, and Recall, respectively."
1390,"caption: Model performance on classification task across different metrics.table: Model,Accuracy,Precision,Recall,F1 Score, SVM,0.88,0.89,0.81,0.85, Logistic Regression,0.86,0.84,0.87,0.85, Random Forest,0.91,0.94,0.86,0.90, KNN,0.82,0.77,0.84,0.80, Naive Bayes,0.79,0.72,0.79,0.74","Table shows the performance comparison of the classification models - SVM, Logistic regression, Random forest, K-Nearest Neighbors (KNN), and Naive Bayes using Accuracy, Precision, Recall, and F1 Score. The Random Forest model stands out in the comparison, scoring the highest in all the evaluation metrics. The SVM model performed well in Accuracy and Precision but comparatively poorly in Recall. Logistic regression shows a consistent Precision-Recall trade-off. KNN model scored the lowest among all the models, indicating its unsuitability for this data. Overall, the table demonstrates Random Forest to be the best model for the classification task based on the evaluation metrics considered."
1391,"caption: Table 4: Model performances measured by multiple evaluation metricstable: Model,F1-score,Precision,Recall,AUC,Accuracy, Model A,0.85,0.80,0.92,0.91,0.83, Model B,0.84,0.78,0.91,0.86,0.81, Model C,0.82,0.72,0.94,0.87,0.78, Model D,0.83,0.75,0.93,0.89,0.80, Model E,0.87,0.82,0.92,0.93,0.85","Table 4 shows multiple evaluation metrics for five different models (Model A to E). The evaluation metrics include F1-score, precision, recall, AUC, and accuracy. The F1-score, precision, and recall were computed from a binary classification task. Among the models, Model E shows the highest F1-score of 0.87 and AUC of 0.93. On the other hand, Model C shows the highest recall score of 0.94. The precision metric shows Model A has the highest precision of 0.80. Finally, Model E shows the highest accuracy of 0.85. Overall, the table provides a comparison of the models' performances based on different evaluation metrics."
1392,"caption: Table 4: A comparison of four models based on multiple evaluation metrics on test data.table: Model Name,Accuracy,Precision,Recall,F1-Score, Random Forest,92.0,0.93,0.92,0.92, Naive Bayes,75.4,0.80,0.70,0.73, Logistic Regression,85.6,0.86,0.87,0.85, SVM,87.2,0.88,0.87,0.87","Table 4 presents a comparison of four models' performances based on multiple evaluation metrics on the test data. The evaluation metrics used in this table include Accuracy, Precision, Recall, and F1-score. The highest accuracy score is achieved by the Random Forest model (92.0%), while the highest precision score is obtained by the Naive Bayes model (0.80). On the other hand, the Logistic Regression model has the highest recall score (0.87). Interestingly, the SVM model performs consistently well in all evaluation metrics, ranked second after Random Forest in the accuracy score. Overall, it can be concluded that the Random Forest model outperforms the other three models based on the accuracy score, but the best model choice may depend on the business objective of the study."
1393,"caption: Model comparison with multiple evaluation metrics and performance results.table: Model,Precision,Recall,F1-score,Accuracy, SVM,0.845,0.856,0.85,0.853, Random Forest,0.867,0.881,0.874,0.870, Naive Bayes,0.689,0.692,0.682,0.693, Decision Tree,0.821,0.835,0.825,0.832, AdaBoost,0.847,0.854,0.846,0.853","This table presents a comparison of five different models based on multiple evaluation metrics, including precision, recall, F1-score, and accuracy. The models are SVM, Random Forest, Naive Bayes, Decision Tree, and AdaBoost. SVM and Random Forest models exhibit considerably good overall performance, achieving accuracy scores of 0.853 and 0.870, respectively. Furthermore, the Random Forest model shows the highest precision, recall, and F1-score among all models, with scores of 0.867, 0.881, and 0.874, respectively. On the other hand, the Naive Bayes model achieved the lowest performance results on all evaluation metrics. Overall, the Random Forest and SVM models are the standout performers in this comparison."
1394,"caption: Table 4: Model performance on multiple evaluation metrics.table: Model Name,Metric1 Score,Metric2 Score,Metric3 Score, Model 1,0.87,0.64,0.95, Model 2,0.78,0.73,0.77, Model 3,0.92,0.55,0.88, Model 4,0.81,0.62,0.76, Model 5,0.94,0.49,0.92","Table 4 compares the performance of five different models based on multiple evaluation metrics. The table displays the scores for Metric1, Metric 2, and Metric 3 for each model. Notably, different models showcase varying performances across the evaluation metrics. Model 5 demonstrates the best Metric1 score, whereas Model 1 obtains the highest score for Metric3. However, no model stands out as the consistently best-performing, as each model has its unique strengths and weaknesses across the stated evaluation metrics."
1395,"caption: Table 4: Comparison of evaluation metrics for multiple classification modelstable: Model,Accuracy,F1_score,Precision,Recall, Logistic_Regression,0.88,0.86,0.89,0.83, Decision_Tree,0.82,0.78,0.80,0.76, Random_Forest,0.92,0.90,0.91,0.89, Gradient_Boosting,0.90,0.87,0.89,0.85, Support_Vector_Machine,0.82,0.78,0.80,0.77","Table 4 presents a comparison of evaluation metrics for various classification models, which were trained and tested on the same dataset. The models include Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Support Vector Machine. The metrics used for evaluation include Accuracy, F1 score, Precision, and Recall. The results indicate that Random Forest has the highest accuracy of 0.92 and F1 score of 0.90. Meanwhile, Logistic Regression exhibits the best precision and Gradient Boosting performs best in terms of recall. It can be seen that different models excel over various metrics, highlighting the importance of selecting the proper model for the desired evaluation metric."
1396,"caption: Table 4: Performance comparison of different classifiers using evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.853,0.862,0.857,0.870, Random Forest,0.864,0.872,0.866,0.880, K-Nearest-Neigh,0.817,0.830,0.825,0.837, Logistic Regression,0.837,0.846,0.840,0.862, Decision tree,0.761,0.750,0.740,0.776","Table 4 presents a comparison of the performance of five different classifiers. The classifiers are SVM, Random Forest, K-Nearest Neighbour, Logistic Regression, and Decision Tree. The table reports the evaluation metrics of Accuracy, F1 Score, Precision, and Recall. The results indicate that the Random Forest and SVM models achieved the highest Accuracy rates of 0.864 and 0.853, respectively. The Random Forest classifier also exhibited the best F1 Score of 0.872. Overall, the results demonstrate the potential of the Random Forest model in achieving the highest classification accuracy and F1 score."
1397,"caption: Comparison of various models based on different evaluation metricstable: Model,Accuracy,Precision,Recall,ROC-AUC, Random forest,0.89,0.73,0.83,0.92, Logistic regression,0.85,0.68,0.76,0.87, XGBoost,0.92,0.78,0.84,0.93, Decision tree,0.83,0.64,0.71,0.86, SVM,0.87,0.70,0.78,0.90",
1398,"caption: Comparison of different classification models based on multiple evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.79,0.79,0.83,0.78, Decision Tree,0.73,0.73,0.73,0.73, Random Forest,0.85,0.85,0.90,0.84, Support Vector Machine,0.81,0.81,0.84,0.80",
1399,"caption: Model performance in different evaluation metricstable: Model,Precision,Recall,F1 Score,Accuracy,Brier Loss, SVM,0.87,0.56,0.68,0.75,0.24, Decision Tree,0.63,0.72,0.64,0.65,0.57, Naive Bayes,0.50,0.91,0.65,0.45,0.31, Random Forest,0.92,0.56,0.70,0.80,0.20","The table above shows the comparison of different models - SVM, Decision Tree, Naive Bayes, and Random Forest - based on various performance evaluation metrics. The evaluation metrics included are precision, recall, F1 score, accuracy, and Brier Loss. The results indicate that the Random Forest model performed the best in terms of precision, achieving a score of 0.92, while the Naive Bayes model had the highest recall or sensitivity score of 0.91. Interestingly, despite having high accuracy, the SVM only achieved an F1-score of 0.68, lower than the Decision Tree's score of 0.64. Additionally, the Brier Loss score showed that the Random Forest model had the smallest mean squared difference between its predicted probability of outcomes and the actual outcomes."
1400,"caption: Performance of various models using different evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.85,0.83,0.82,0.84, K-Nearest Neighbors,0.78,0.74,0.75,0.73, Decision Tree,0.79,0.75,0.77,0.73, Random Forest,0.88,0.87,0.89,0.85, Gradient Boosting Tree,0.86,0.85,0.85,0.87","The table displays the performances of different models based on several evaluation metrics such as Accuracy, F1-score, Precision, and Recall. The models evaluated are Logistic Regression, K-Nearest Neighbors, Decision Tree, Random Forest, and Gradient Boosting Tree. Notably, the Random Forest model exhibited the highest accuracy score of 0.88, while the Gradient Boosting Tree model scored the highest F1-score of 0.85. The highest precision score of 0.89 was obtained by the Random Forest model, while the highest recall score of 0.87 was obtained by the Gradient Boosting Tree model. Overall, the table highlights the variances in performance achieved by these models, and could guide the choice of a suitable model for a particular task."
1401,"caption: Performance Metrics for Different Modelstable: Model,Precision,Recall,F1-score,Accuracy, Model 1,0.92,0.79,0.85,0.91, Model 2,0.81,0.86,0.77,0.88, Model 3,0.87,0.83,0.84,0.89, Model 4,0.94,0.91,0.92,0.93, Model 5,0.79,0.87,0.76,0.87","The above table presents the performance of five different models evaluated using various metrics. The models were assessed based on Precision, Recall, F1-score, and Accuracy. Model 1 achieved the highest precision score of 0.92, while Model 4 obtained the highest F1-score of 0.92 and the highest accuracy of 0.93. Interestingly, while Model 5 scored relatively low in precision and F1-score, it achieved a high recall of 0.87. Models 2 and 3 showed relatively balanced performance, with Model 2 and Model 3 achieving a high recall and precision score, respectively. The table provides valuable information for choosing the best model according to the required evaluation metrics."
1402,"caption: Comparison of Different Models Based on Multiple Evaluation Metrics.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.89,0.92,0.91,0.94, Decision Trees,0.83,0.89,0.84,0.97, Naive Bayes,0.77,0.84,0.76,0.92, Random Forest,0.92,0.94,0.93,0.95, XGBoost,0.94,0.96,0.96,0.95","The table above shows the comparison of five different models in terms of accuracy, F1-score, precision, and recall. The SVM model achieved the highest accuracy of 0.89, while the XGBoost model was the most successful in terms of F1-score, with a near-perfect score of 0.96. Similarly, the XGBoost model showed the highest precision and the SVM model had the highest recall rate. Random Forest also performed fairly well in all metrics and achieved an impressive accuracy of 0.92. The results suggest that the XGBoost model is a promising candidate for classification problems where high precision and recall rates are critical."
1403,"caption: Evaluation metrics for various classification models on the dataset.table: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.82,0.81,0.84,0.78, Decision Tree,0.73,0.71,0.70,0.73, Random Forest,0.87,0.86,0.88,0.84, XGBoost,0.89,0.88,0.90,0.87, Support Vector Machine,0.80,0.79,0.81,0.78","The table depicts the performance comparison of different classification models, namely Logistic Regression, Decision Tree, Random Forest, XGBoost, and Support Vector Machine on a given dataset. The models were evaluated based on various performance metrics, including Accuracy, F1-score, Precision and Recall. The results suggest that the XGBoost model shows the best performance among all models, having achieved an accuracy score of 0.89. The Random Forest model also performed well, achieving an accuracy score of 0.87. On the other hand, the Decision Tree model shows less promising performance compared to other models, with an accuracy score of 0.73, though recording a reasonable F1-score of 0.71. Additionally, the table reveals that all models' Precision scores range from 0.70 to 0.90, while Recall scores range from 0.73 to 0.87, suggesting that these models can be effective in a classification problem."
1404,"caption: Model performance on the test set using different classifiers and evaluation metrics.table: Model name,Precision (%),Recall (%),F-1 Score (%),AUC-ROC, Random Forest,92.7,83.9,87.9,0.845, Logistic Regression,91.1,82.6,86.5,0.821, Support Vector Machine,89.5,81.5,85.3,0.808, Neural Network,91.8,84.3,87.9,0.824","The table shows the comparative evaluation of different classifiers' performance based on different evaluation metrics on the test set. The evaluated metrics were precision, recall, F1-score, and AUC-ROC. The results display that the Random Forest classifier achieved the highest precision rate of 92.7% and the highest AUC-ROC of 0.845. The Neural Network classifier attained the highest F-1 score of 87.9%. On the other hand, the SVM classifier showed the weakest overall performance compared to other classifiers, scoring the lowest in all metrics."
1405,"caption: The table compares the performance of different models using evaluation metrics such as Accuracy, Precision, Recall, and F1 Score. The models evaluated include Logistic Regression, Decision Tree, Random Forest, Support Vector Classifier, and Gradient Boosting Classifier.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.792,0.652,0.715,0.631, Decision Tree,0.765,0.664,0.595,0.609, Random Forest,0.806,0.731,0.611,0.664, Support Vector Classifier,0.778,0.683,0.615,0.608, Gradient Boosting Classifier,0.814,0.740,0.642,0.689","The table presented illustrates the performance of five different models using evaluation metrics such as Accuracy, Precision, Recall, and F1 Score. The results show that the Gradient Boosting Classifier has the highest Accuracy score of 0.814, while Random Forest has the highest Precision score of 0.731. The Logistic Regression model achieved the highest Recall score of 0.715, and Gradient Boosting Classifier has the highest F1 Score of 0.689. Notably, the precision and recall scores vary significantly among the models, indicating that they have different strengths in classifying the target variable."
1406,"caption: Performance comparison of different models using different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, Model A,0.92,0.89,0.92,0.90, Model B,0.91,0.91,0.88,0.89, Model C,0.95,0.94,0.96,0.95, Model D,0.90,0.88,0.93,0.90, Model E,0.96,0.95,0.96,0.96","Table shows a performance comparison of five models using different evaluation metrics. The presented models are labeled as Model A, Model B, Model C, Model D, and Model E. The evaluation included metrics such as Accuracy, Precision, Recall, and F1-score. The best-performing model in terms of metrics differed for each evaluation metric. Model E showed the highest accuracy score of 0.96, and Model C exhibited the best Precision, Recall, and F1-score achieving a score of 0.94, 0.96, and 0.95, respectively. Notably, Model B showed a good overall balance of metrics with an accuracy rate of 0.91 and a relatively high F1-score of 0.89."
1407,"caption: Table 4: Performance evaluation of machine learning models.table: Model,Precision,Recall,F1 Score,Accuracy, SVM,0.81,0.71,0.75,0.83, Deep Learning,0.79,0.68,0.73,0.81, Ensemble,0.84,0.74,0.78,0.85, Random Forest,0.82,0.72,0.76,0.84","Table 4 shows various machine learning models' performance evaluated through four different metrics: Precision, Recall, F1 Score, and Accuracy. The models were named SVM, Deep Learning, Ensemble, and Random Forest. The table demonstrates that the Ensemble model outperformed the other models in terms of precision, F1 score, and accuracy. However, the Random Forest model showed the highest recall score of 0.72. In terms of precision, the Ensemble model had the highest score of 0.84, whereas the SVM model had the highest accuracy of 0.83. Overall, the results indicate that the Ensemble model is the most balanced and robust among the four models evaluated."
1408,"caption: Comparison of model performances based on multiple evaluation metricstable: Model,Accuracy,F1-Score,Precision,Recall, SVM (rbf kernel),0.92,0.91,0.94,0.89, Random Forest,0.87,0.83,0.85,0.82, MLPClassifier,0.91,0.89,0.90,0.88, Decision Tree,0.83,0.76,0.77,0.74","Table presents the comparison of multiple models based on accuracy, F1-score, precision, and recall evaluation metrics. The SVM model with an rbf kernel shows the best accuracy score of 0.92 and a high precision score of 0.94. The Random Forest model shows the lowest performance based on all evaluation metrics. The MLPClassifier model performs well with an accuracy of 0.91 and F1-score of 0.89. The Decision Tree model has the lowest accuracy score of 0.83 among all models. However, its precision score of 0.77 is slightly higher than the Random forest model. Overall, the SVM model with an rbf kernel shows the best performance among all."
1409,"caption: Table 4: Model performance on classification of spam emails using different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.88,0.90,0.87,0.88, KNN,0.84,0.79,0.91,0.85, RF,0.90,0.92,0.89,0.90, XGB,0.91,0.94,0.88,0.91","Table 4 presents a comparison of different models' performance on the classification of spam emails based on different evaluation metrics. The table shows model performance in terms of accuracy, precision, recall, and F1-score, where higher values denote better performance. The Support Vector Machine (SVM) model achieved an accuracy of 0.88, precision of 0.90, recall of 0.87, and F1-score of 0.88. The Random Forest (RF) model showed the highest accuracy score of 0.90, while XGBoost (XGB) model demonstrated the best precision score of 0.94. The K-Nearest Neighbor (KNN) model achieved the highest recall value of 0.91. Overall, the results suggest that XGB and RF models provide excellent performance on the classification of spam emails."
1410,"caption: Comparison of different models based on different evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.83,0.84,0.85,**0.92**, Decision Tree,0.81,**0.85**,**0.89**,0.82, Random Forest,0.84,0.83,0.86,0.82, Support Vector Machine (SVM),**0.89**,0.82,0.88,0.77, Naive Bayes,0.81,0.80,0.89,0.71, K-Nearest Neighbors (KNN),0.82,0.80,0.84,0.78","Table presents the comparison of six different models, namely Logistic Regression, Decision Tree, Random Forest, Support Vector Machine (SVM), Naive Bayes, and K-Nearest Neighbors (KNN). The models have been evaluated based on different evaluation metrics like Accuracy, F1-Score, Precision, and Recall. Interestingly, the best performing models based on each of these metrics are different. For example, the SVM model achieves the highest accuracy of 0.89, while the Decision Tree model has the highest F1-Score and Precision with 0.85 and 0.89, respectively. However, the Logistic Regression model outperforms others in Recall with a score of 0.92."
1411,"caption: Table 4: Model performance based on different evaluation metricstable: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.87,0.88,0.89,0.86, Support Vector Machine,0.91,0.89,0.92,0.86, Random Forest,0.94,0.93,0.94,0.93, Naive Bayes,0.81,0.84,0.78,0.90, Gradient Boosting,0.92,0.91,0.93,0.89","Table 4 compares the performance of five models based on different evaluation metrics. These models are Logistic Regression, Support Vector Machine, Random Forest, Naive Bayes, and Gradient Boosting. The evaluation metrics here are Accuracy, F1 Score, Precision, and Recall, respectively. The Random Forest model has the highest Accuracy, F1 Score, Precision, and Recall, with scores of 0.94, 0.93, 0.94, and 0.93, respectively. The Naive Bayes model stands out as the worst performing model with the lowest Accuracy, F1 Score, Precision, and Recall, with scores of 0.81, 0.84, 0.78, and 0.90, respectively. Overall, it can be concluded that the Random Forest model performed better than the other models concerning all the evaluation metrics."
1412,"caption: Model performance based on the evaluation metricstable: Model,Accuracy,F1-Score,Precision,Recall, Logistic Reg.,0.87,0.87,0.88,0.86, Random Forest,0.93,0.93,0.92,0.95, SVM,0.83,0.82,0.84,0.81, MLP,0.90,0.90,0.89,0.92, XGBoost,0.92,0.92,0.92,0.93","The table presents the performance of different models based on the evaluation metrics such as Accuracy, F1-Score, Precision, and Recall. The models in this table include Logistic Regression, Random Forest, SVM, MLP, and XGBoost. Overall, the Random forest model has performed the best among all models with the highest accuracy of 0.93 and F1 score of 0.93. The Logistic Regression model and the MLP models are close in performance, with a high score in the other metrics but lower accuracy compared to the Random Forest and XGBoost models. SVM has the lowest accuracy of 0.83, while XGBoost stands out with the second-highest performance score in all the metrics."
1413,"caption: Table 4: Evaluation metrics and scores for different models on the datasettable: Model,F1-score,Precision,Recall,Accuracy, Random Forest,0.93,0.92,0.94,0.92, Logistic Regression,0.88,0.85,0.92,0.85, K-Nearest Neighbor,0.78,0.81,0.75,0.80, Decision Tree,0.89,0.88,0.90,0.88, Naive Bayes,0.84,0.80,0.88,0.81","Table 4 presents the F1-score, precision, recall, and accuracy for five different models on the given dataset. The models’ performances were evaluated based on the evaluation metrics mentioned above and the scores listed in the table. The Random Forest model showed the best F1-Score of 0.93 with a precision score of 0.92 and recall score of 0.94. However, the Logistic Regression model had the highest precision score of 0.85. The Decision Tree model had the highest recall score of 0.90, while Naive Bayes had the highest accuracy with a score of 0.81. The K-Nearest Neighbor model had the lowest F1-score of 0.78."
1414,"caption: Table 4: Model performance based on accuracy, precision, recall and F1-Score.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.85,0.85,0.87,0.86, Random Forest,0.83,0.85,0.83,0.82, Support Vector Machine,0.81,0.83,0.82,0.80, Naive Bayes,0.79,0.82,0.80,0.79, Decision Tree,0.72,0.75,0.73,0.71","Table 4 outlines the performance of different models, including Logistic Regression, Random Forest, Support Vector Machine, Naive Bayes, and Decision Tree, based on the evaluation metrics of accuracy, precision, recall, and F1-Score. Notably, Logistic Regression performed the best in accuracy, precision, and F1-Score, achieving scores of 0.85, 0.85, and 0.86, respectively. However, Random Forest model recorded the best performance in recall with a score of 0.83, followed closely by Support Vector Machine. Surprisingly, Naive Bayes had relatively lower performances in comparison to other models in all evaluation metrics despite having achieved the best accuracy of 0.79."
1415,"caption: Comparison of Model Performances using Different Evaluation Metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.85,0.87,0.79,0.83, K-NN,0.76,0.68,0.87,0.76, Decision Trees,0.81,0.85,0.72,0.78, Random Forest,0.88,0.92,0.83,0.87","Table: The table compares the performances of four different models, Logistic Regression, K-NN, Decision Trees, and Random Forest, based on four evaluation metrics: Accuracy, Precision, Recall, and F1 Score. The Random Forest model achieved the highest accuracy score of 0.88, while the K-NN model achieved the lowest accuracy score of 0.76. In terms of precision, the Random Forest model had the highest score of 0.92, while the K-NN model had the lowest score of 0.68. The K-NN model had the highest recall of 0.87, while the Decision Tree had the lowest score of 0.72. Lastly, the F1 scores ranged from 0.78 for Decision Trees to 0.87 for Random Forest, indicating good performances of all models, but the Random Forest model outperformed the others in all metrics."
1416,"caption: Table 4: Model performance based on multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression (class_weight),0.85,0.85,0.86,0.85, Decision Tree (SMOTE),0.91,0.91,0.91,0.91, Random Forest (class_weight),0.94,0.94,0.93,0.94, Gradient Boosting Classifier,0.93,0.93,0.93,0.93, MLP Classifier (SGD),0.88,0.89,0.86,0.87","Table 4 shows the evaluation results of different models using multiple evaluation metrics. The evaluation metrics used in this table are Accuracy, Precision, Recall, and F1-Score. The results presented in this table present the performance of Logistic Regression with class_weighting, Decision Tree with SMOTE balancing, Random Forest with class_weighting, Gradient Boosting Classifier, and MLP Classifier with stochastic gradient descent. Notably, the best performer over all evaluation metrics is the Random Forest model with class_weighting scoring an Accuracy of 0.94, Precision of 0.94, Recall of 0.93, and F1-Score of 0.94. However, the performance of the other models is quite reasonable, achieved an Accuracy ranging from 0.85 to 0.94, Precision ranging from 0.85 to 0.94, Recall ranging from 0.86 to 0.93 and F1-Score ranging from 0.85 to 0.94."
1417,"caption: Comparison of Different Machine Learning Models' Performance Using Multiple Metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.87,0.91,0.83,0.87, Decision Tree,0.85,0.87,0.85,0.86, Random Forest,0.91,0.93,0.90,0.91, K-Nearest Neighbor,0.83,0.86,0.81,0.83, Support Vector Machine,0.89,0.92,0.87,0.89","Table 1 compares the performance of different machine learning models in terms of multiple evaluation metrics based on the test set. The metrics used for evaluation are Accuracy, Precision, Recall, and F1-Score. The table exhibits that the Random Forest model performs the best across all evaluation metrics, with an Accuracy of 0.91, Precision of 0.93, Recall of 0.90, and F1-Score 0.91. The Logistic Regression and Support Vector Machine models also provide excellent results, with Accuracy scores of 0.87 and 0.89, respectively. The Decision Tree and K-Nearest Neighbor models offer slightly lower results. The comparison emphasizes the Random Forest model's superiority in this experiment, as it achieves the highest scores across all evaluation metrics."
1418,"caption: A comparison of different machine learning models' performance on a classification task using various evaluation metrics.table: Model Name,Accuracy,Precision,Recall,F1-Score, Support Vector Machine,0.91,0.90,0.94,0.92, Random Forest,0.88,0.84,0.91,0.87, Neural Network,0.93,0.92,0.95,0.93, Gradient Boosting,0.87,0.83,0.90,0.86, Logistic Regression,0.89,0.86,0.92,0.89","Table presents a comparison of the performance results of five different machine learning models: Support Vector Machine, Random Forest, Neural Network, Gradient Boosting, and Logistic Regression on a classification task. The models were evaluated using multiple performance metrics, including Accuracy, Precision, Recall, and F1-Score. Interestingly, the Neural Network model achieved the highest performance scores across all the evaluation metrics, with an accuracy of 0.93, precision of 0.92, recall of 0.95, and F1-score of 0.93. The Support Vector Machine and Logistic Regression models also showed comparably good results. However, the Random Forest and Gradient Boosting models perform relatively worse than the other models across all the metrics."
1419,"caption: Table 4: A comparison of different models based on multiple evaluation metrics.table: Model,Precision,Recall,F1 Score,AUC, SVM,0.87,0.91,0.89,0.95, KNN,0.81,0.89,0.85,0.91, Naive Bayes,0.68,0.95,0.79,0.87, Decision Tree,0.76,0.82,0.78,0.88, Random Forest,0.91,0.93,0.92,0.96","Table 4 compares the performance of different models based on precision, recall, F1 score, and AUC. The models are SVM, KNN, Naive Bayes, Decision Tree, and Random Forest. The SVM and Random Forest models achieved the highest precision scores of 0.87 and 0.91, respectively. Naive Bayes achieved the highest recall score of 0.95, while the Random Forest achieved the highest F1 score of 0.92. Overall, the Random Forest model had the best performance with an AUC of 0.96."
1420,"caption: Comparison of model performances for a binary classification task using six different models and evaluation metrics.table: Model,Accuracy,Precision,Recall,F1_score,AUC, XGBoost,0.925,0.952,0.883,0.916,0.973, Random Forest,0.921,0.920,0.935,0.927,0.978, SVM,0.901,0.902,0.893,0.897,0.948, Adaboost,0.861,0.873,0.825,0.848,0.907, Neural Network,0.892,0.903,0.885,0.894,0.920, Logistic Regression,0.801,0.796,0.808,0.802,0.862","Table 4 presents a comparison of multiple models' performance, including XGBoost, Random Forest, SVM, Adaboost, Neural Network, and Logistic Regression based on six evaluation metrics: Accuracy, Precision, Recall, F1_score, and AUC. The table shows that XGBoost outperformed other models in terms of Accuracy, Precision, Recall, and F1_score. At the same time, the Random Forest model achieved the highest AUC score of 0.978. Noteworthy, the Logistic Regression model demonstrated the lowest performance score across all evaluation metrics. Overall, the table highlights that every model performed differently and that comparison based on multiple evaluation metrics is essential for model selection."
1421,"caption: Table 4: Model performances using different metricstable: Model,Accuracy,Precision,Recall,F1-Score,AUC, SVM,0.89,0.92,0.88,0.89,0.97, KNN,0.82,0.88,0.80,0.81,0.90, Decision Tree,0.85,0.83,0.84,0.83,0.89, Random Forest,0.91,0.92,0.91,0.91,0.96, Gradient Boosting,0.92,0.93,0.92,0.92,0.97","Table 4 presents the comparison of different models using various evaluation metrics. The table shows accuracy, precision, recall, F1-score, and the area under the curve (AUC) results of SVM, KNN, Decision Tree, Random Forest, and Gradient Boosting models. The Random Forest and Gradient Boosting achieved the highest accuracy of 0.91 and 0.92, respectively. Although Gradient Boosting shows the highest precision, recall, F1-score, and AUC, there is not a clear winner amongst the various models as each metric has different criteria for optimal performance. Overall, the table emphasizes the importance of selecting the appropriate evaluation metric when comparing different models."
1422,"caption: Table 4: Model performances based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.85,0.89,0.84,0.86, Support Vector Machine,0.83,0.87,0.82,0.84, Decision Tree,0.77,0.79,0.75,0.77, Random Forest,0.82,0.86,0.82,0.84, Gradient Boosting,0.86,0.89,0.85,0.87","Table 4 shows the model performances of five different algorithms - Logistic Regression, Support Vector Machine, Decision Tree, Random Forest, and Gradient Boosting. Each algorithm's performance is evaluated based on four distinct evaluation metrics: accuracy, precision, recall, and F1-score, respectively. Notably, the Gradient Boosting model records the highest accuracy of 0.86, while it also has the highest F1-score of 0.87. However, the Logistic Regression algorithm achieved the highest precision of 0.89, with a recall score of 0.84. Therefore, it is essential to consider all evaluation metrics to choose the best model instead of relying on only one evaluation metric."
1423,"caption: Performance of different classification models on the test dataset.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.91,0.89,0.92,0.864, Random Forest,0.92,0.90,0.94,0.867, KNN,0.90,0.89,0.91,0.870, XGBoost,0.93,0.91,0.95,0.879, Logistic Regression,0.88,0.86,0.87,0.862","The presented table shows the comparison of the accuracy, F1-score, precision, and recall scores of different classification models on the test dataset. We can observe that XGBoost outperformed all other models with the highest overall accuracy of 0.93. Besides, it obtained the highest precision score of 0.95, indicating that the model had a lower false-positive rate. Random Forest also showed a good performance slightly lower than XGBoost, with an accuracy of 0.92 and a precision score of 0.94. Whereas, Logistic Regression showed the lowest accuracy of 0.88 and F1-score of 0.86. Nonetheless, all models had an F1-score above 0.86, suggesting that all had reasonable performance overall."
1424,"caption: Table 4: Performance results of different classifiers on the test data.table: Model Name,Precision,Recall,F1-Score,ROC-AUC,PR-AUC, Random Forest,0.92,0.82,0.85,0.70,0.72, Decision Tree,0.78,0.71,0.73,0.60,0.60, Logistic Regression,0.85,0.77,0.80,0.68,0.69, Naïve Bayes,0.77,0.85,0.74,0.62,0.66, Multi-Layer Perceptron (MLP),0.89,0.84,0.86,0.73,0.76","The table presents performance results of five classifiers: Random Forest, Decision Tree, Logistic Regression, Naïve Bayes, and Multi-Layer Perceptron (MLP) based on test data. Evaluation metrics are Precision, Recall, F1-Score, ROC-AUC, and PR-AUC. The Random Forest performs the best in terms of precision, recall, and F1 score, followed by MLP. However, the MLP model has the best ROC-AUC and PR-AUC values, portraying better performance in ranking and predicting. The Naïve Bayes model shows the lowest performance while Decision Tree and Logistic Regression models show mid-range performance results in the evaluation metrics."
1425,"caption: Model Performance Comparison for Various Classification Modelstable: Model name,Metric,Result, Logistic Regression,Accuracy,0.81, Logistic Regression,Precision,0.85, Logistic Regression,Recall,0.75, SVM,Accuracy,0.76, SVM,Precision,0.88, SVM,Recall,0.60, Random Forest,Accuracy,0.92, Random Forest,Precision,0.91, Random Forest,Recall,0.93, Naive Bayes,Accuracy,0.78, Naive Bayes,Precision,0.75, Naive Bayes,Recall,0.85","The table provides a comparison of different classification models' performance based on different evaluation metrics, including accuracy, precision, and recall. The models examined in this study are logistic regression, SVM, random forest, and naive Bayes. The results reveal that the random forest model outperformed other models in terms of accuracy, with a score of 0.92. In contrast, the logistic regression model has the highest precision score of 0.85. Interestingly, Naive Bayes model has the highest recall score of 0.85. These findings emphasize the importance of considering multiple evaluation metrics when comparing the performance of various models."
1426,"caption: Table 4: Evaluation metrics for different models on two target variables.table: Models,S1-precision,S1-recall,S1-f1-score,S2-precision,S2-recall,S2-f1-score, Model A,0.93,0.87,0.90,0.95,0.91,0.93, Model B,0.92,0.85,0.88,0.94,0.90,0.92, Model C,0.94,0.89,0.91,0.96,0.92,0.94, Model D,0.91,0.84,0.87,0.93,0.89,0.91","Table 4 presents the evaluation metrics for four different models on two target variables (S1 and S2). The metrics were measured using precision, recall, and f1-score. Notably, Model C reported the highest scores for both S1 and S2 targets' precision, recall, and f1-score. However, Model A has the second-highest scores, which are very close to those of Model C. The results show that the scores for S2 are slightly higher than those for S1 across all models. Overall, Model C appears to be the best performing in terms of all metrics for both target variables."
1427,"caption: Model performance on different evaluation metrics of SVM, Naive Bayes, Decision Tree, Logistic Regression and Random Forest models.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.85,0.87,0.92,0.83, NB,0.81,0.78,0.85,0.72, DT,0.76,0.73,0.78,0.69, LR,0.86,0.88,0.91,0.84, RF,0.89,0.92,0.94,0.9","The table presents the performance evaluation of five different classification algorithms - SVM, Naive Bayes, Decision Tree, Logistic Regression, and Random Forest. The algorithms were evaluated for accuracy, F1-score, precision, and recall using the same dataset. The Random Forest algorithm performed best on all metrics, with an accuracy score of 0.89, F1-score of 0.92, precision of 0.94, and a recall of 0.9. Both SVM and Logistic Regression algorithms also performed well, while Naive Bayes and Decision Tree algorithms showed comparatively lower performance on all metrics. Overall, the results suggest that the Random Forest algorithm performs the best amongst the algorithms in this study."
1428,"caption: Performance comparison of different classifiers on the test dataset.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.85,0.78,0.82,0.74, KNN,0.75,0.72,0.68,0.77, LR,0.91,0.86,0.89,0.84, RF,0.94,0.92,0.92,0.93, XGB,0.93,0.91,0.91,0.91","Table presents the comparison of different classifiers on the test dataset based on various evaluation metrics such as Accuracy, F1-score, Precision, and Recall. The models SVM, KNN, LR, RF, and XGB exhibit their corresponding accuracy, F1-score, precision, and recall results. Notably, the random forest (RF) model shows the highest accuracy of 0.94 and average F1-score of 0.92. The logistic regression (LR) model also shows promising results with an accuracy of 0.91 and an F1-score of 0.86. Conversely, KNN performed worse among all classifiers with an accuracy of 0.75 and an F1-score of 0.72. Overall, the results demonstrate the superiority of ensemble-based techniques such as RF and XGB over the other models."
1429,"caption: Evaluation metrics of different models based on the binary classification task.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.845,0.82,0.88,0.85, Decision Tree,0.80,0.78,0.81,0.79, Random Forest,0.87,0.85,0.88,0.86, K-Nearest Neighbors,0.78,0.76,0.80,0.78, Support Vector Machine,0.86,0.84,0.87,0.85","The table presents the evaluation metrics of five different models concerning binary classification. The models include Logistic Regression, Decision Tree, Random Forest, K-Nearest Neighbors, and Support Vector Machine. The evaluation metrics consist of Accuracy, Precision, Recall, and F1-Score. Random Forest model achieved the highest Accuracy score of 0.87, while Logistic Regression had the best Precision score of 0.82. Interestingly, Decision Tree performed the worst concerning all metrics. Support Vector Machine scored the highest for Recall at 0.87 but was not the best in any other metric. Overall, the table provides insights into the different models' performance in binary classification tasks."
1430,"caption: Performance metrics of multiple modelstable: Model Name,Accuracy,Precision,Recall,F1 Score, Model A,0.84,0.87,0.82,0.84, Model B,0.81,0.76,0.90,0.82, Model C,0.79,0.82,0.73,0.77, Model D,0.85,0.85,0.87,0.86, Model E,0.87,0.92,0.82,0.87","In this table, we present the evaluation results of different models based on various metrics, including Accuracy, Precision, Recall and F1-Score. The table shows Model A through Model E's evaluation scores. Model E has the highest Accuracy value of 0.87 and the highest Precision value of 0.92, indicating that the model correctly predicted more positive-class examples. Meanwhile, Model B has the highest Recall value of 0.90, correctly identifying the most negative-class examples, and Model D has the highest F1-Score value of 0.86, reflecting an optimal balance between Precision and Recall. These variations in performance scores demonstrate the importance of considering different evaluation metrics for appropriate model selection."
1431,"caption: Performance metrics of different models tested on the classification task.table: Model,F1 Score,Precision Score,Recall Score,Accuracy Score, Logistic Regression,0.75,0.67,**0.88**,0.80, Naive Bayes,0.68,0.56,0.86,0.72, Decision Tree,0.85,0.82,0.88,0.83, Random Forest,**0.92**,**0.91**,0.92,**0.91**, Boosted Trees,0.88,0.87,0.89,0.88","The table presents the evaluation metrics- F1 score, precision score, recall score, and accuracy score- of different models on a classification task. The models compared are Logistic Regression, Naive Bayes, Decision Tree, Random Forest, and Boosted Trees. Notably, Random Forest has the highest F1 score of 0.92 and accuracy score of 0.91, while Logistic Regression has the highest recall score of 0.88. Boosted Trees also show good scores across all metrics. However, Naive Bayes has the lowest scores. These results show that Random Forest model can provide the best overall performance in the classification task when compared to the other models."
1432,"caption: Model comparison table based on different evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, Model A,0.85,0.84,0.87,0.82, Model B,0.82,0.79,0.84,0.76, Model C,0.88,0.89,0.86,0.91, Model D,0.83,0.81,0.85,0.78, Model E,0.87,0.86,0.89,0.83","The table above presents the comparative evaluation metrics of multiple models. The table includes five models, Model A, Model B, Model C, Model D, and Model E, and evaluates their accuracy, F1-Score, Precision, and Recall. Model C showcases the best overall performance across all four evaluation metrics, with 0.88 accuracy, 0.89 F1-Score, 0.86 precision, and 0.91 recall. Interestingly, Model E outperformed other models in accuracy, F1-Score, and precision, but it has lower recall compared to Model C. Model B shows the lowest performance amongst all the models across different evaluation metrics."
1433,"caption: Table 4: Classification model performance results using various evaluation metrics.table: Model,Accuracy,F1-score,Area under ROC Curve, Model A,0.85,0.81,0.94, Model B,0.89,0.86,0.97, Model C,0.76,0.68,0.84, Model D,0.92,0.89,0.98, Model E,0.83,0.78,0.91","Table 4 displays the performance results of five different classification models, Model A to Model E. The models were evaluated using three different metrics, namely Accuracy, F1-score, and Area under ROC Curve. Model D performed the best across all the evaluation metrics with an accuracy of 0.92, F1-score of 0.89, and Area under ROC Curve of 0.98. Model B also showed excellent performance, achieving an accuracy of 0.89, F1-score of 0.86, and Area under ROC Curve of 0.97. In contrast, Model C had the lowest performance in all evaluation metrics. This table provides useful insights into how various models perform against different metrics, which can aid in selecting the best suitable model for a given task."
1434,"caption: Comparison of Model Performances using multiple evaluation metricstable: Model,F1 Score,Precision,Recall,Accuracy, Logistic Regression,0.86,0.81,0.92,0.87, Decision Tree,0.89,0.92,0.87,0.88, Support Vector Machine,0.82,0.75,0.91,0.83, Random Forest,0.91,0.92,0.91,0.91, Gradient Boosting,0.93,0.93,0.94,0.93","The table above compares different models' performances based on their F1 score, precision, recall and accuracy. It appears that the Gradient Boosting model shows the highest F1 score of 0.93 and Accuracy of 0.93, followed by the Random Forest model with an F1 Score of 0.91 and Accuracy of 0.91. On the other hand, Decision Tree model produces the highest Precision of 0.92, while Logistic Regression model and Gradient Boosting model shared the highest recall of 0.92. The table exhibits the variance of model performance to different performance metrics."
1435,"caption: Model Evaluation Metrics Tabletable: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.86,0.81,0.79,0.80, Decision Tree,0.72,0.74,0.68,0.67, Random Forest,0.93,0.94,0.91,0.91, K-Nearest Neighbors,0.82,0.83,0.80,0.80, AdaBoost,0.86,0.85,0.81,0.82","The table compares the performance of five different models by evaluating their accuracy, precision, recall, and F1-score. The SVM model achieves the highest accuracy of 0.86 with a decent performance for precision, recall, and F1-score. The Random Forest model scores the best on all evaluation metrics except precision, where it achieves 0.94. The Decision Tree model shows the lowest accuracy and performs poorly on precision, recall, and F1-Score. Despite achieving similar accuracy to SVM, K-Nearest Neighbors model shows worse performances on precision, recall, and F1-score. The AdaBoost model produces an overall decent result across all evaluation metrics."
1436,"caption: Model performances measured by different evaluation metrics.table: Models,Accuracy,F1 Score,Recall,Precision, Model A,0.91,0.92,0.95,0.9, Model B,0.88,0.8,0.82,0.78, Model C,0.85,0.87,0.83,0.92, Model D,0.93,0.94,0.92,0.95, Model E,0.89,0.89,0.88,0.9","The table represents the accuracy, F1 score, recall, and precision performance measures for Model A, Model B, Model C, Model D, and Model E. Model D performs the best in terms of accuracy, with an accuracy score of 0.93. In contrast, Model C has a high F1 score of 0.87 and Model A has the highest precision of 0.9. However, Model D is generally outperforming the other models with its high precision, recall, and F1 score. Model B has the lowest accuracy (0.88) and F1 score (0.8) but has a comparable recall and precision score to other models."
1437,"caption: Performance metrics of different modelstable: Model,Accuracy,Precision,Recall,F1 Score, Model A,0.89,0.78,0.92,0.84, Model B,0.83,0.65,0.79,0.71, Model C,0.91,0.83,0.93,0.87, Model D,0.86,0.75,0.85,0.80, Model E,0.87,0.69,0.88,0.77","The table presents the performance evaluation metrics of five different models. The metrics included are Accuracy, Precision, Recall, and F1 Score. Model C achieved the highest Accuracy of 0.91 while Model B had the lowest Accuracy score at 0.83. Model C outperformed all other models in terms of Precision with a score of 0.83, while Model E with a score of 0.69 had the lowest Precision. Model C also achieved the highest recall score of 0.93, while Model B had the lowest recall score of 0.79. Finally, Model C achieved the highest F1 Score at 0.87, while Model B had the lowest F1 Score of 0.71. In summary, Model C shows the best performance overall, with the highest Accuracy, Precision, Recall, and F1 score."
1438,"caption: Table 2: Model Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.75,0.81,0.67,0.73, Decision Tree,0.65,0.70,0.65,0.66, Random Forest,0.83,0.89,0.81,0.85, Gradient Boosting,0.80,0.86,0.78,0.81, Support Vector Machines,0.76,0.81,0.75,0.78, Multilayer Perceptron,0.77,0.83,0.77,0.80","Table 2 presents the evaluation metrics for six different models, namely Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, Support Vector Machines, and Multilayer Perceptron. In addition to accuracy, the table shows precision, recall, and F1-score. The evaluation metrics help in measuring the classification models' performance. Interestingly, the Random Forest model achieved the highest accuracy score of 0.83, while Gradient Boosting and Multilayer Perceptron had accuracy scores of 0.80 and 0.77, respectively. The precision score was highest for the Random Forest model, and the Multilayer Perceptron had the highest recall score. Finally, the Random Forest model had the highest F1-score."
1439,"caption: Model performance evaluation for binary classification tasktable: Model,Accuracy,AUC-dev,Precision,Recall, DNN,0.92,0.86,0.94,0.90, CNN,0.93,0.87,0.92,0.96, SVM,0.91,0.88,0.92,0.94, KNN,0.87,0.79,0.86,0.90","The table presents the performance of four different models evaluated by several metrics, accuracy, AUC-dev, precision, and recall, for a binary classification problem. DNN, CNN, SVM, and KNN models are stated in columns, where the rows represent different evaluation metrics. From the table, CNN has the highest accuracy (0.93) and AUC-dev (0.87), while precision and recall of CNN are 0.92 and 0.96, respectively. The SVM model has the highest AUC-dev score (0.88). Interestingly, the DNN model has the highest Precision score (0.94) and recall (0.90) but with the lowest AUC-dev of 0.86. Finally, the KNN model has the worst performance comparatively. Overall, from the observed evaluation metrics, the CNN model appears to perform the best."
1440,"caption: Comparison of Model Performances based on Multiple Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1-Score,AUC, Model 1,0.85,0.75,0.95,0.84,0.91, Model 2,0.82,0.70,0.93,0.80,0.89, Model 3,0.88,0.83,0.90,0.86,0.90, Model 4,0.90,0.74,0.98,0.85,0.92, Model 5,0.91,0.89,0.92,0.90,0.95","Table presents the accuracy, precision, recall, F1-score, and AUC for five different models. Model 1 shows the highest recall score of 0.95, while Model 4 achieved the highest precision (0.98) and AUC (0.92). The F1-score result showed that Model 5 with a score of 0.90 was the best performing model overall, closely followed by Model 3 with a score of 0.86. Interestingly, Model 5 achieved the highest AUC score of 0.95, indicating the model's effectiveness in capturing true positives while maintaining low false positives. Overall, Model 5 performs best on most of the evaluation metrics."
1441,"caption: Model performance comparison based on different evaluation metrics.table: Models,Accuracy,F1-Score,Precision,Recall, Model A,0.87,0.86,0.89,0.83, Model B,0.89,0.85,0.92,0.79, Model C,0.85,0.87,0.84,0.90, Model D,0.92,0.91,0.93,0.89, Model E,0.88,0.88,0.90,0.87","The table presents a comparison of multiple models' performances using different evaluation metrics, namely accuracy, F-1 score, precision, and recall. The models, Model A to Model E, were subjected to the same dataset and classification task. Model D achieved the highest performance scores across all four metrics, with an accuracy of 0.92, F-1 score of 0.91, precision of 0.93, and recall of 0.89. Model B outperformed the other models in terms of precision, achieving the highest score of 0.92, while Model C showed the highest recall score of 0.90. Overall, the results showed that the models performed moderately to high in the classification task."
1442,"caption: Table 1: Model performances based on Precision, Recall, F1-score, and AUC score.table: Model,Precision,Recall,F1 Score,AUC Score, Logistic Regression,0.82,0.79,0.80,0.89, Random Forest,0.90,0.87,0.88,0.94, Gradient Boosting,0.83,0.89,0.86,0.94, Support Vector Machine,0.78,0.85,0.81,0.91, Naive Bayes,0.71,0.96,0.82,0.86","Table 1 exhibits the models' performance through metrics such as precision, recall, F1-score, and AUC score. The models compared are Logistic Regression, Random Forest, Gradient Boosting, Support Vector Machine, and Naive Bayes. The Random Forest model demonstrated the best performance based on Precision (0.90), Recall (0.87), and F1-score (0.88). Further, the Gradient Boosting model showed excellent performance based on AUC Score (0.94), compared to other models. Interestingly, Naive Bayes had the highest Recall (0.96), although it had the lowest Precision (0.71). Overall, the Random Forest and Gradient Boosting models displayed the highest performances among the presented models."
1443,"caption: Performance comparison of different classification models based on different evaluation metrics.table: Model,Precision (P),Recall (R),F1-Score,ROC-AUC,PR-AUC, Logistic Regression,0.82,0.68,0.74,0.85,0.75, Random Forest,0.85,0.75,0.80,0.89,0.82, Gradient Boosting,0.83,0.75,0.78,0.87,0.80, SVM,0.84,0.69,0.75,0.86,0.78, Naive Bayes,0.78,0.83,0.75,0.76,0.68","The table compares the performances of five different classification models. These models were evaluated based on five different metrics - Precision (P), Recall (R), F1-Score, ROC-AUC, and PR-AUC. The table illustrates that the Random Forest model outperformed the rest of the models. It achieved the highest precision (0.85), recall (0.75), F1-score (0.80), ROC-AUC (0.89) and PR-AUC (0.82). The Naive Bayes model, on the other hand, had the lowest precision (0.78), recall (0.83), F1-score (0.75), ROC-AUC (0.76) and PR-AUC (0.68). Interestingly, although the SVM model had a high precision score (0.84), it had a lower recall score (0.69), affecting its overall F1-score (0.75)."
1444,"caption: Table 4: Performance Comparisons of Various Models.table: Model,F1-score,Precision,Recall,Accuracy, LogReg,0.789,0.794,0.783,0.887, SVM-linear,0.801,0.807,0.795,0.895, SVM-RBF,0.790,0.795,0.785,0.891, Random Forest,0.834,0.832,0.840,0.912, Neural Net,0.826,0.820,0.833,0.916","Table 4 represents the performance comparisons of various models, LogReg, SVM-linear, SVM-RBF, Random Forest, and Neural Net. The table shows multiple evaluation metrics, including F1-score, precision, recall, and accuracy, representing the models' performances. Notably, all models were trained on the same dataset and tested on an independent dataset. Random Forest shows the best F1-score of 0.834 and accuracy of 0.912. Alternatively, the Neural Net has the highest accuracy of 0.916 and a close F1-score of 0.826. Interestingly, SVM-linear has the highest precision of 0.807 and recall of 0.795, while the Random Forest has the highest recall of 0.840. The results suggest that both Random Forest and Neural Net are well-equipped for the classification task based on the evaluation metrics."
1445,"caption: Model performance comparison for classification task using different models.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.89,0.89,0.87,0.91, KNN,0.82,0.80,0.85,0.76, Random forest,0.93,0.93,0.92,0.94, Naive Bayes,0.78,0.76,0.80,0.73","The table presents a comparison of different models' performance in the classification task using multiple evaluation metrics, including Accuracy, F1-Score, Precision, and Recall. It can be observed that the Random Forest model performs the best in terms of all evaluation metrics with an accuracy score of 0.93, F1-Score of 0.93, Precision of 0.92, and Recall of 0.94. The SVM model also shows good performance with an accuracy score of 0.89 and equal F1-Score of 0.89. However, the KNN model shows lower performance compared to the SVM and the Random forest model with an accuracy score of 0.82. Surprisingly, the Naive Bayes model shows the worst performance among all models with an accuracy score of 0.78."
1446,"caption: Model performance comparison based on multiple evaluation metrics.table: ```, Model,Accuracy,Precision,Recall,F1-score,AUC-ROC, Model 1,0.87,0.86,0.89,0.87,0.92, Model 2,0.89,0.87,0.90,0.88,0.93, Model 3,0.90,0.88,0.91,0.89,0.94, Model 4,0.88,0.86,0.92,0.89,0.91, Model 5,0.91,0.88,0.94,0.91,0.95","Table presents the performance comparison of five different models based on multiple evaluation metrics. The models are evaluated in terms of Accuracy, Precision, Recall, F1-score, and AUC-ROC. Out of the five models, Model 5 scored the highest accuracy of 0.91, Precision of 0.88, Recall of 0.94, F1-score of 0.91, and AUC-ROC of 0.95. Model 5 as the best performing model indicates its high predictive power, making it the most suitable model for the given dataset."
1447,"caption: Comparison of different models' performance on the classification task.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.92,0.89,0.92,0.87, Naive Bayes,0.87,0.82,0.84,0.81, Random Forest,0.95,0.94,0.95,0.94, KNN,0.89,0.85,0.87,0.84","The table above presents a comparison of various models' performance on the classification task. Four different models, namely SVM, Naive Bayes, Random Forest, and KNN, were trained and tested on the same dataset. The models were evaluated using four different metrics, namely Accuracy, F1 Score, Precision, and Recall. The Random Forest model outperforms all other models in all four evaluation metrics, achieving an accuracy of 0.95, F1-Score of 0.94, Precision of 0.95, and Recall of 0.94. SVM has the second-best performance, while Naive Bayes and KNN show comparable performance. The table's results suggest that the Random Forest model is the best model for the classification task."
1448,"caption: Performance metrics of different modelstable: Model,F1-score,Accuracy,Precision,Recall, Model A,0.82,0.85,0.78,0.86, Model B,0.79,0.82,0.72,0.87, Model C,0.85,0.89,0.82,0.89, Model D,0.76,0.78,0.72,0.80, Model E,0.81,0.84,0.78,0.83","Table 1 displays the performance metrics of five different models, including F1-score, Accuracy, Precision, and Recall. Model C shows the highest F1-score of 0.85, followed by Model A and Model E, which had F1-scores of 0.82 and 0.81, respectively. In terms of Accuracy, Model C had the highest score of 0.89, while Model D had the lowest score with 0.78. Moreover, Model C and Model E had the highest Precision scores of 0.82 and 0.78, respectively, whereas Model B had the lowest score of 0.72. Finally, Model A had the highest Recall score with 0.86, while Model D had the lowest score of 0.80."
1449,"caption: Table 4: Evaluation metrics for multiple different modelstable: Models,Accuracy,F1 Score,Precision,Recall, Model A,0.85,0.84,0.86,0.83, Model B,0.81,0.82,0.77,0.86, Model C,0.87,0.88,0.89,0.87, Model D,0.76,0.75,0.79,0.72, Model E,0.91,0.90,0.93,0.87","Table 4 presents the evaluation metrics for multiple different models. The table compares the accuracy, F1 score, precision, and recall of Model A, Model B, Model C, Model D and Model E. Notably, Model E performed the best across all measures, with an accuracy score of 0.91, F1 score of 0.90, precision of 0.93, and recall of 0.87. However, Model D shows the lowest accuracy and F1 scores, scoring 0.76 and 0.75, respectively. Model B, despite having the lowest accuracy score, had the highest recall score of 0.86. Overall, the table demonstrates the varying performances of different models based on different evaluation metrics."
1450,"caption: Model comparison results based on different evaluation metrics.table: Model Name,Metric 1,Metric 2,Metric 3, SVM,0.72,0.79,0.68, Naive Bayes,0.60,0.81,0.75, Random Forest,0.84,0.90,0.82, XGBoost,0.86,0.92,0.89, Logistic Regression,0.65,0.75,0.71","The table compares the performance of five different models, including SVM, Naive Bayes, Random Forest, XGBoost, and Logistic Regression based on three evaluation metrics. The evaluation metrics used were Metric 1, Metric 2, and Metric 3. Notably, Random Forest and XGBoost models show consistently superior performance across all three metrics compared to other models. Particularly, XGBoost shows the highest performance for every metric, with a score of 0.86 for Metric 1, 0.92 for Metric 2, and 0.89 for Metric 3. However, the Naive Bayes model exhibits a relatively lower score in Metric 1 but a higher score in Metric 2 and Metric 3 compared to other models. Oh the other hand, SVM and Logistic Regression exhibit relatively consistent but inferior performance across all three metrics."
1451,"caption: Table 4: Model Evaluation Metrics and Resultstable: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.78,0.79,0.82,0.76, KNN,0.74,0.72,0.75,0.69, ANN,0.81,0.81,0.81,0.81, DT,0.75,0.74,0.77,0.71, RF,0.82,0.82,0.81,0.83","Table 4 presents a comparison of multiple machine learning models' performance in terms of accuracy, F1-Score, precision and recall. The models evaluated in the table are Support Vector Machine (SVM), K-Nearest Neighbor (KNN), Artificial Neural Network (ANN), Decision Tree (DT), and Random Forest (RF). The table reveals that Random Forest achieved the highest accuracy of 0.82, followed by Artificial Neural Network with 0.81. Furthermore, these two models also achieved the highest F1-Score, precision and recall values, indicating better model performance. In contrast, KNN model showed the lowest accuracy of 0.74, whereas Decision Tree stands out with a lower precision value of 0.77."
1452,"caption: Model performances using different evaluation metricstable: ```, Model Name,F1-score,Accuracy,Precision,Recall, Model A,0.80,0.85,0.75,0.85, Model B,0.72,0.78,0.68,0.85, Model C,0.62,0.73,0.55,0.75, Model D,0.85,0.89,0.80,0.90","Table above shows the performance of four different models measured using four different evaluation metrics, namely F1-score, accuracy, precision, and recall. The Model A has the best F1-score of 0.80, while the Model D has the best performance in accuracy with 0.89. The Model D also has the highest precision and recall with a value of 0.80 and 0.90, respectively. Interestingly, although Model A achieved the best F1-score, it has the lowest accuracy and recall value among all. This table shows how different evaluation metrics may lead to different conclusions, and hence, it is essential to choose evaluation metrics wisely to measure a model's performance."
1453,"caption: Model Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1-Score,AUC, SVM,0.92,0.93,0.91,0.92,0.96, KNN,0.75,0.73,0.68,0.71,0.78, Decision Tree,0.85,0.85,0.81,0.83,0.89, Random Forest,0.93,0.94,0.92,0.93,0.97, MLP,0.89,0.88,0.86,0.87,0.92","This table presents a comparison of the performance of five different models – SVM, KNN, Decision Tree, Random Forest, and MLP – based on various evaluation metrics. The models were evaluated on accuracy, precision, recall, F1-Score, and AUC. Notably, the Random Forest model showed the highest accuracy at 0.93, followed closely by the SVM model at 0.92. Similarly, the Random Forest model also exhibited the best performance in terms of precision, recall, F1-Score, and AUC with metrics of 0.94, 0.92, 0.93, and 0.97, respectively. However, the MLP model showed a noticeable score in all metrics, scoring 0.88, 0.86, 0.87, and 0.92 on precision, recall, F1-Score, and AUC, respectively. On the other hand, the KNN showed the lowest performance scores across all metrics, achieving the lowest accuracy of 0.75, among others."
1454,"caption: Performance comparison of different models across multiple evaluation metrics.table: Model,Precision,Recall,F1-score,Accuracy, Model A,0.85,0.92,0.88,0.91, Model B,0.76,0.78,0.77,0.79, Model C,0.90,0.87,0.88,0.89, Model D,0.82,0.86,0.84,0.85, Model E,0.91,0.89,0.90,0.92","The table above compares the performance of Model A through E across multiple evaluation metrics. Precision, Recall, F1-score, and Accuracy were used as the evaluation metrics. Notably, Model E demonstrated the highest values across all the metrics. The highest precision score was obtained by Model E (0.91), while the highest recall score was achieved by Model A (0.92). On the other hand, Model C and Model E demonstrated the highest F1-score (0.88). Similarly, Model E displayed the highest accuracy score (0.92) evaluated against the dataset used. Overall, Model E appears to be the best performing model based on this evaluation."
1455,"caption: Comparison of classification models based on various evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.78,0.75,0.77,0.74, Naive Bayes,0.81,0.76,0.79,0.74, Random Forest,0.84,0.82,0.83,0.81, XGBoost,0.86,0.84,0.84,0.85","The presented table showcases the comparison of different classification models based on accuracy, F1-score, precision, and recall metrics. The models evaluated in this study are SVM, Naive Bayes, Random Forest, and XGBoost. As per the table, XGBoost scored the highest accuracy (0.86), F1-score (0.84), and recall (0.85), whereas Random Forest obtained the highest precision score of 0.83. Naive Bayes scored the lowest in terms of accuracy (0.81), F1-score (0.76), and recall (0.74). Overall, this table can guide us to select the best model for classification tasks based on the desired evaluation metrics."
1456,"caption: Comparison of different models' performance based on multiple evaluation metrics.table: Model,Accuracy,F1 Score,AUC-ROC,Precision,Recall, Model A,0.85,0.81,0.9,0.83,0.8, Model B,0.89,0.87,0.93,0.88,0.88, Model C,0.92,0.88,0.95,0.94,0.82, Model D,0.87,0.82,0.91,0.8,0.86, Model E,0.95,0.91,0.98,0.93,0.9","The table illustrates a comparison of five different models' performance based on five evaluation metrics, including Accuracy, F1 Score, AUC-ROC, Precision, and Recall. Model E showcased the best overall performance, achieving the highest values in Accuracy, F1 Score, and AUC-ROC. Model C achieved the highest values for Precision but didn't perform well in recall, while model B showed the highest recall. There was a significant difference in the models' performance metrics, with the lowest accuracy score of 0.85 and the highest score of 0.95, which highlights the importance of careful selection and evaluation of models."
1457,"caption: Table 4: Model performances  based on Accuracy, Recall, Precision, and F1-score.table: Model,Accuracy,Recall,Precision,F1-score, Logistic,0.743,0.547,0.632,0.586, Random Forest,0.820,0.688,0.724,0.706, XGBoost,0.825,0.716,0.728,0.722, SVM,0.805,0.675,0.701,0.688, LightGBM,0.813,0.689,0.728,0.708","Table 4 demonstrates the evaluation metrics' scores of different models. The presented models include Logistic, Random Forest, XGBoost, SVM, and LightGBM. The models were evaluated based on Accuracy, Recall, Precision, and F1-score scores. It can be observed that the XGBoost model performed the best for accuracy and recall, scoring 0.825 and 0.716, respectively. On the other hand, the Random Forest model showed excellent results for precision and F1-score with scores of 0.724 and 0.706, respectively. It is worth noting that the LightGBM model also shows decent scores for accuracy, recall, and F1-score."
1458,"caption: Model evaluation results of different classification models.table: Model,Accuracy,Precision,Recall,F1-Score,AUC, Logistic Regression,0.89,0.86,0.91,0.88,0.92, Random Forest,0.91,0.89,0.94,0.91,0.94, Support Vector Machine,0.87,0.82,0.92,0.86,0.90, Multilayer Perceptron,0.92,0.91,0.89,0.90,0.93","The above table presents multiple classification models' performance evaluation results on a particular dataset using different evaluation metrics, such as accuracy, precision, recall, F1-score, and AUC. The table exhibits Logistic Regression, Random Forest, Support Vector Machine, and Multilayer Perceptron models' performance results. The Random Forest model shows the highest accuracy of 0.91, precision of 0.89, recall of 0.94, F1-score of 0.91, and AUC of 0.94. Interestingly, the Multilayer Perceptron model achieved the highest scores in precision and AUC, while the Logistic Regression model exhibited the highest scores in recall and F1-score metrics. This table provides an overview of different models' effectiveness while making classification decisions on the dataset."
1459,"caption: Evaluation metrics of different models on the test dataset.table: Models,Precision,Recall,F1-score,Accuracy, Model A,0.91,0.86,0.88,0.95, Model B,0.87,0.90,0.88,0.93, Model C,0.88,0.85,0.87,0.94, Model D,0.92,0.80,0.85,0.93, Model E,0.94,0.83,0.88,0.95","Table present model performances for multiple evaluation metrics, including Precision, Recall, F1-score, and Accuracy. The table includes five different models and their respective performances. Interestingly, Model E shows the highest precision value (0.94) based on the test dataset, while Model A achieved the highest Recall value (0.86). Model D has the highest performance accuracy (0.93), while Model A also provides a good F1-score value (0.88). Lastly, the models' performance results suggest that Model B and Model C did not perform as well as the other models in the evaluation metrics."
1460,"caption: Model performance for various classification algorithms based on accuracy, F1-score, precision, and recall.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.80,0.79,0.85,0.75, Logistic Regression,0.76,0.75,0.84,0.67, Random Forest,0.88,0.87,0.90,0.85, K-Nearest Neighbors,0.72,0.70,0.75,0.66, XGBoost,0.90,0.89,0.92,0.86","The table presents a comparison of different classification models tested with four different performance metrics: accuracy, F1-score, precision, and recall. The evaluated models are SVM, Logistic Regression, Random Forest, K-Nearest Neighbors, and XGBoost. The Random Forest and XGBoost models performed best in terms of accuracy, both achieving a score of 0.88 or higher. As for the F1-score, XGBoost has outperformed the other models, with a score of 0.89 with a slight improvement over Random Forest. The Random Forest model demonstrated the best performance scores for precision and recall, both at 0.90 and 0.85, respectively, making it the most balanced model. However, the XGBoost model showed the highest precision score of 0.92. Overall, the Random Forest and XGBoost models are the recommended choices for the given classification task based on the observed performance measures."
1461,"caption: Table 4: Model evaluation metrics for different classifierstable: Model,Accuracy,F-Score,Recall,Precision,AUC, Logistic Regression,0.789,0.771,0.816,0.742,0.844, SVM (linear),0.817,0.804,0.844,0.768,0.874, Decision Tree,0.729,0.707,0.732,0.684,0.688, Random Forest,0.836,0.826,0.862,0.793,0.918, XGBoost,0.857,0.850,0.881,0.822,0.934","Table 4 summarizes the evaluation metrics for different classifiers, including Logistic Regression, SVM (linear), Decision Tree, Random Forest, and XGBoost. Each model's accuracy, F-score, recall, precision, and AUC are presented in the table. Interestingly, we observe that the XGBoost model has the highest performance in all metrics except accuracy, where SVM (linear) has a slightly higher score. The Random Forest model also demonstrates strong performance in all metrics except precision. Conversely, the Decision Tree model exhibits the lowest performance in all metrics. Overall, the results suggest that XGBoost and Random Forest may be the appropriate classifiers for the given dataset."
1462,"caption: Table 4: Model performances based on different evaluation metrics.table: Model,F1 Score,Precision,Recall,Accuracy, SVM,0.82,0.85,0.79,0.87, KNN,0.75,0.77,0.73,0.82, Random Forest,0.87,0.89,0.85,0.90, XGBoost,0.88,0.90,0.86,0.91, MLP,0.83,0.85,0.82,0.86","Table 4 summarizes the performances of various models in terms of four evaluation metrics - F1 Score, Precision, Recall, and Accuracy. The models include SVM, KNN, Random Forest, XGBoost, and MLP. Based on the results, the Random Forest model achieved the highest F1 Score of 0.87, followed by XGBoost with 0.88. The MLP and SVM models achieved the lowest and over a similar F1 Score of 0.83 and 0.82, respectively. This table's main observation is that ensemble methods (Random Forest and XGBoost) performed better than other models, while the SVM model showed the lowest performance in terms of evaluation metrics."
1463,"caption: Table 4: Performance comparison of multiple models using different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Model 1,0.85,0.87,0.81,0.84, Model 2,0.82,0.83,0.86,0.84, Model 3,0.80,0.82,0.77,0.79, Model 4,0.89,0.90,0.85,0.87, Model 5,0.90,0.91,0.91,0.91","Table 4 shows the comparative performance of five different models based on four key evaluation metrics - Accuracy, Precision, Recall, and F1-Score. The model performances range from an accuracy score of 0.80 to 0.90. Model 5 achieved the highest accuracy score of 0.90. In contrast, Model 3 had the lowest accuracy score of 0.80. Interestingly, all five models scored better in Precision and F1-Score than in Recall. Model 5 was found to be the top-performing model in all the metrics, with scores ranging from 0.91 to 0.90. On the other hand, Model 3 had the lowest precision, recall, and F1-Score scores."
1464,"caption: Model performances using different evaluation metricstable: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.86,0.80,0.81,0.79, Random Forest,0.89,0.87,0.84,0.90, Gradient Boosting,0.91,0.90,0.92,0.89, Support Vector Machines,0.85,0.81,0.79,0.84, Neural Network,0.92,0.91,0.93,0.89","Table presented is a comparison of different models' performances using multiple evaluation metrics, including accuracy, F1-score, precision, and recall. The models included in this table are Logistic Regression, Random Forest, Gradient Boosting, Support Vector Machines, and Neural Network. The results show that the Neural Network model achieved the highest accuracy of 0.92 among all models. Meanwhile, the Gradient Boosting model produced the highest F1-score of 0.90. Interestingly, the Logistic Regression model presented the highest precision and the lowest recall, indicating a high number of true positives but also a high number of false negatives. The Random Forest and Gradient Boosting models showed balanced results between precision and recall."
1465,"caption: Table 4: Model performance comparison based on different evaluation metrics.table: Model,Precision,F1 Score,Accuracy,AUC-ROC,AUC-PR, SVM,0.86,0.87,0.85,0.90,0.78, Random Forest,0.92,0.90,0.91,0.93,0.89, KNN,0.79,0.82,0.80,0.86,0.74, XGBoost,0.88,0.89,0.88,0.91,0.84","Table 4 depicts the comparison of model performance based on different evaluation metrics such as Precision, F1 Score, Accuracy, AUC-ROC, and AUC-PR. The table includes SVM, Random Forest, KNN, and XGBoost models' performance results. Random Forest achieving the highest precision and F1 score of 0.92 and 0.90, respectively, whereas the highest accuracy and AUC-ROC are obtained by SVM having 0.85 and 0.90, respectively. Additionally, Random Forest has the highest AUC-PR value of 0.89 while XGBoost has the second-highest AUC-PR of 0.84."
1466,"caption: Table 4: Performance comparison of different classification models using multiple performance measures.table: Model,Accuracy,Precision,Recall,F1 Score, SVM,0.84,0.82,0.85,0.82, Random forest,0.88,0.90,0.84,0.87, Naive Bayes,0.81,0.78,0.85,0.81, Decision tree,0.84,0.86,0.80,0.82, Logistic regression,0.86,0.84,0.89,0.86, Neural network,0.89,0.88,0.92,0.90, K-nearest neighbors,0.79,0.76,0.80,0.77","Table 4 displays the models' performances for the given task using multiple evaluation metrics. Models such as SVM, Random forest, Naive Bayes, Decision trees, Logistic regression, Neural network, and K-nearest neighbors were evaluated. The table shows the accuracy, precision, recall, and F1 score for each model. Notably, the Neural Network model performed the best overall, achieving an accuracy of 0.89 and an F1 score of 0.90. The Random Forest model also performed well, achieving the highest precision score of 0.90. The Naive Bayes model, on the other hand, had the lowest accuracy of 0.81. Overall, the model performances vary significantly based on the evaluation metric used."
1467,"caption: Performance scores of different machine learning models on a classification task.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.83,0.84,0.85,0.83, KNN,0.80,0.78,0.81,0.76, RF,0.88,0.88,0.89,0.87, MLP,0.86,0.85,0.87,0.84","The above table shows the machine learning models' performance scores, namely SVM, KNN, RF, and MLP, on a classification task. The evaluation metrics for each model include Accuracy, F1-Score, Precision, and Recall. The Random Forest (RF) outperforms other models with the highest accuracy of 0.88, F1-Score of 0.88, Precision of 0.89, and Recall of 0.87. Support Vector Machine (SVM) is the second-best model with 0.83 Accuracy, 0.84 F1-Score, 0.85 Precision, and 0.83 Recall. K-Nearest Neighbor (KNN) achieved the lowest scores, with all evaluation metrics below 0.81. Interestingly, the MLP model scored between the RF and SVM models, with an Accuracy score of 0.86, F1-Score of 0.85, Precision of 0.87, and Recall of 0.84."
1468,"caption: Performance Metrics of Various Modelstable: **Model**,**Accuracy**,**Precision**,**Recall**,**F1-Score**, Model 1,0.91,0.92,0.87,0.89, Model 2,0.87,0.85,0.81,0.83, Model 3,0.89,0.81,0.90,0.84, Model 4,0.92,0.93,0.94,0.93, Model 5,0.86,0.80,0.88,0.83","The above table presents the performance metrics of five different models evaluated based on accuracy, precision, recall, and F1-score. Model 4 shows the highest accuracy value of 0.92, while also performing best in precision, recall, and F1-score with scores of 0.93, 0.94, and 0.93, respectively. Model 1 follows closely with an accuracy of 0.91 and F1-score of 0.89. Interestingly, Model 5 achieved the lowest score in all four evaluation metrics, having an accuracy of 0.86, precision of 0.80, recall of 0.88, and F1-score of 0.83. Overall, the table provides a clear comparison of the models' performance across various evaluation metrics."
1469,"caption: Table 4: Model performances based on multiple evaluation metrics.table: Model,F1 Score,Accuracy,Precision,Recall, SVM,0.84,0.91,0.87,0.82, KNN,0.67,0.78,0.75,0.60, LR,0.79,0.88,0.81,0.77, RF,0.91,0.94,0.92,0.90, XGB,0.89,0.92,0.91,0.87","Table 4 summarizes the results of different models' performances based on multiple evaluation metrics, including F1 Score, Accuracy, Precision, and Recall on a given dataset. The table exhibits five models, including SVM, KNN, LR, RF, and XGB. The RandomForest model achieved the highest F1 Score, Accuracy, Precision, and Recall with scores of 0.91, 0.94, 0.92, and 0.90, respectively. Interestingly, the XGB model also showed a promising performance with an F1 Score of 0.89 and an Accuracy of 0.92. In contrast, KNN shows the lowest F1 Score, Precision, and Recall with a score of 0.67, 0.75, and 0.60, respectively."
1470,"caption: Performance of various models on evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score,AUC Score, Logistic Regression,0.80,0.84,0.76,0.79,0.867, Random Forest,0.82,0.80,0.86,0.83,0.881, Gradient Boosting,0.85,0.81,0.91,0.86,0.885, Deep Learning,0.87,0.85,0.88,0.86,0.896","Table presents the comparison of different models' performances based on multiple evaluation metrics. The table includes four different models: Logistic Regression, Random Forest, Gradient Boosting, and Deep Learning. The table exhibits the performance scores for each model based on evaluation metrics such as Accuracy, Precision, Recall, F1 Score, and AUC Score. The best-performing model based on the evaluation metrics in the table is the Deep Learning model, with the highest scores for Accuracy, Precision, and Recall. Interestingly, Random Forest and Gradient Boosting models were almost equally matched in all the metrics, except for the Precision metric, which was higher for the Random Forest model."
1471,"caption: Table 4: Model Comparison Metricstable: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.89,0.91,0.87,0.89, SVM,0.82,0.83,0.81,0.82, Decision Tree,0.78,0.80,0.76,0.77, Naive Bayes,0.75,0.73,0.70,0.72","Table 4 displays a comparison of different models' performance based on multiple evaluation metrics, including accuracy, precision, recall and F1-score. The models that were evaluated include Logistic Regression, SVM, Decision Tree and Naive Bayes. According to the table, Logistic Regression performed the best overall with the highest accuracy of 0.89 and precision score of 0.91. The SVM model had the second-highest accuracy of 0.82 and precision score of 0.83. However, Naive Bayes showed the lowest score in all metrics. Overall, this table provides valuable insight into the model performances that could assist in making an informed decision while selecting the most suitable model."
1472,"caption: Table 4: Model performance of different models based on various evaluation metricstable: model_name,f1_score,recall,precision,accuracy, Random Forest,0.93,0.89,0.98,91.2%, XGBoost,0.91,0.92,0.92,92.1%, Support Vector,0.87,0.95,0.83,89.6%, Multi-Layer Perceptron,0.88,0.84,0.92,89.4%, K-Nearest Neighbors,0.86,0.82,0.90,88.6%","Table 4 summarizes the performance of five different models based on various evaluation metrics, including f1_score, recall, precision, and accuracy. Random Forest achieves the highest f1_score of 0.93, while Support Vector has the highest recall of 0.95. Multi-Layer Perceptron has the highest precision of 0.92, whereas XGBoost achieves the highest accuracy of 92.1%. Notably, K-Nearest Neighbors has the lowest performance metrics among the five models with the lowest f1_score and accuracy metrics. The results suggest that Random Forest, XGBoost, and Multi-Layer Perceptron may provide more reliable algorithms based on the particular evaluation metrics."
1473,"caption: Table 4: Performance of five models in classification tasktable: Model,Precision,Recall,F1-Score,Accuracy, Logistic Regression,0.75,0.60,0.67,0.78, Decision Trees,0.68,0.72,0.70,0.75, Random Forest,0.79,0.71,0.75,0.81, Gradient Boosting,0.77,0.74,0.75,0.81, Support Vector Machine,0.80,0.65,0.71,0.80","Table 4 presents the performances of five models on a classification task based on four different metrics, namely, precision, recall, F1-Score, and accuracy. Logistic Regression, Decision Trees, Random Forest, Gradient Boosting, and Support Vector Machine (SVM) models are evaluated on the provided dataset. Interestingly, Random Forest achieved the highest precision score of 0.79, while SVM had the second-highest precision score of 0.80. The Decision Trees model exhibited the greatest recall score of 0.72, slightly higher than Gradient Boosting's recall score of 0.74. However, Random Forest achieves the highest accuracy score of 0.81 along with Gradient Boosting."
1474,"caption: Performance comparison of various modelstable: Model,Accuracy,PR-AUC,F1-Score,MCC, SVM,0.89,0.75,0.61,0.63, Random Forest,0.90,0.78,0.63,0.66, Gradient Boosting,0.91,0.80,0.65,0.69, Multilayer Perceptron,0.88,0.72,0.58,0.60, Logistic Regression,0.86,0.66,0.53,0.55","Table 4 compares the performance of different models based on evaluation metrics such as Accuracy, PR-AUC, F1-Score, and MCC. Among the models, Gradient Boosting performs the best in terms of Accuracy, PR-AUC, F1-Score, and MCC, achieving 0.91, 0.80, 0.65, and 0.69, respectively. Random Forest and SVM also performed satisfactorily, while Multilayer Perceptron and Logistic Regression models show relatively worse performance. These results signify that the choice of the machine learning model is crucial to achieve better accuracy and other metrics in solving classification problems."
1475,"caption: Model performances based on different evaluation metricstable: Model,Accuracy,F1 Score,Precision,Recall,AUC, Logistic Regression,0.87,0.87,0.91,0.83,0.79, Decision Tree,0.78,0.78,0.78,0.78,0.73, Random Forest,0.92,0.92,0.94,0.91,0.89, SVM,0.84,0.84,0.89,0.80,0.76, XGBoost,0.93,0.93,0.94,0.92,0.91","The table above illustrates the comparison of different machine learning models' performances based on different evaluation metrics, including Accuracy, F1 Score, Precision, Recall, and AUC. The models tested in this experiment are Logistic Regression, Decision Tree, Random Forest, SVM, and XGBoost. Interestingly, the Random Forest and XGBoost models exhibit outstanding performances in all evaluation metrics. Specifically, the Random Forest model had an accuracy of 0.92 and AUC score of 0.89, while the XGBoost model had the best F1 Score of 0.93 and Recall of 0.92. On the other hand, Decision Tree exhibited the worst performance in terms of AUC, having a score of 0.73."
1476,"caption: Performance comparison of different models using various evaluation metrics.table: Model,F1 Score,AUC Score,Recall,Precision, Model A,0.92,0.93,0.94,0.90, Model B,0.76,0.86,0.80,0.72, Model C,0.88,0.79,0.92,0.84, Model D,0.94,0.82,0.96,0.92","This table presents the performance comparison of different models using multiple evaluation metrics. Four models are evaluated based on their F1 Score, AUC Score, Recall, and Precision. The highest F1 Score of 0.94 is achieved by Model D, which also has the highest Recall and Precision with scores of 0.96 and 0.92, respectively. In contrast, Model B shows the lowest F1 Score and AUC Score of 0.76 and 0.86, respectively. Additionally, Model C has higher Recall and Precision scores, but a lower AUC Score of 0.79. Overall, Model D outperforms the others in terms of its evaluation metrics."
1477,"caption: Table 4: Model Evaluation Metrics for Different Modelstable: Model,Accuracy,F1 Score,Precision, SVM,0.85,0.84,0.86, NB,0.72,0.78,0.65, KNN,0.78,0.80,0.76, RF,0.89,0.90,0.88, XGB,0.91,0.92,0.91","Table 4 presents an evaluation of different models based on multiple performance metrics. The table exhibits SVM, NB, KNN, RF, and XGB models' accuracy, F1 score, and precision. The best overall performance is obtained by the XGB model, with the highest accuracy, F1 score, and precision of 0.91, 0.92, and 0.91, respectively. In contrast, the NB model shows the lowest performance across all metrics, with an accuracy of 0.72, F1 score of 0.78, and precision of 0.65. This table shows that the XGB model has better overall performance than the other models."
1478,"caption: Performance comparison of various classification models.table: Model,F1 Score,Precision,Recall,Accuracy,MCC,AUC, Random Forest,0.934,0.931,0.937,0.935,0.870,0.990, Logistic Regression,0.928,0.930,0.926,0.933,0.864,0.978, XGBoost,0.929,0.924,0.937,0.930,0.862,0.972, Multilayer Perceptron (1 hidden layer),0.922,0.918,0.927,0.925,0.853,0.953",
1479,"caption: Table 4: Performance evaluation of different models using multiple evaluation metricstable: Models,Precision,Recall,Accuracy,F1 Score, Model A,0.90,0.78,0.85,0.84, Model B,0.87,0.82,0.87,0.84, Model C,0.95,0.73,0.82,0.82, Model D,0.78,0.85,0.81,0.81, Model E,0.89,0.84,0.88,0.86","Table 4 shows the performance evaluation of five different models based on four different evaluation metrics, namely precision, recall, accuracy, and F1 score. Model A achieves the best precision and Model C achieves the highest recall. Model E has the best accuracy while Model A and Model B have the highest F1 scores. Overall, Model B has a balanced performance, with the second-highest precision, the third-highest recall, and the highest accuracy and F1 score among all models. The results indicate that different models may have diverse strengths and weaknesses, which can be reflected by different evaluation metrics."
1480,"caption: Performance results of different classification models using various evaluation metrics.table: Model Name,Accuracy,Precision,Recall,F1-Score,AUC, Logistic Regression,0.85,0.89,0.78,0.82,0.89, Random Forest,0.86,0.91,0.80,0.84,0.91, Decision Tree,0.82,0.90,0.75,0.81,0.89, Gradient Boosting,0.87,0.92,0.81,0.85,0.93, Support Vector Machine,0.84,0.88,0.80,0.84,0.89","The table presents the performance evaluation of five different classification models using multiple evaluation metrics. The models included in the comparison are Logistic Regression, Random Forest, Decision Tree, Gradient Boosting, and Support Vector Machine. The evaluation metrics used in the comparison were Accuracy, Precision, Recall, F1-Score, and AUC. The Gradient Boosting model achieved the highest values of all evaluation metrics, with an AUC of 0.93, Precision of 0.92, and Accuracy of 0.87. Nonetheless, the Random Forest model performed with the second-highest values for almost all evaluation metrics. Thus, both Gradient Boosting and Random Forest are suggested as the best classification models based on this comparison."
1481,"caption: Performance comparison of multiple models based on different evaluation metrics.table: Model Name,Accuracy,F1 Score,Precision,Recall, Model 1,0.85,0.84,0.88,0.81, Model 2,0.82,0.81,0.85,0.79, Model 3,0.89,0.88,0.92,0.84, Model 4,0.81,0.80,0.83,0.77, Model 5,0.86,0.85,0.89,0.82","Table X presents a performance comparison of five different models, including their accuracy, F1 score, precision, and recall metrics. Each model was evaluated using the same dataset and testing conditions. Model 3 achieved the highest accuracy score of 0.89, with a corresponding F1 score of 0.88, the best among the five models. Similarly, Model 3 exhibited the highest precision score of 0.92, indicating that it had the highest true positive rate among the models. However, Model 1 had the highest recall score, indicating that it had the lowest number of false negatives of all the models. Overall, the table provides a comprehensive comparison of model performance based on multiple metrics."
1482,"caption: Model performance for different classification modelstable: Model,Accuracy,F1 Score,Recall,Precision,AUC ROC,AUC PR, Random Forest,0.873,0.873,0.931,0.823,0.920,0.906, SVM,0.820,0.824,0.903,0.755,0.854,0.886, Naive Bayes,0.657,0.669,0.865,0.532,0.709,0.816, Gradient Boosting,0.897,0.898,0.912,0.885,0.941,0.933, Multilayer Perceptron,0.901,0.897,0.892,0.903,0.931,0.919","The above table presents a comparison of different classification models' performance based on different evaluation metrics. The models' accuracy, F1 Score, recall, precision, AUC ROC, and AUC PR were tested and recorded. The Random Forest model shows the highest accuracy of 0.873, the Gradient Boosting model has the best AUC ROC of 0.941, while the Multilayer Perceptron model has the best AUC PR of 0.919. Interestingly, the Naive Bayes model achieved the lowest accuracy of 0.657, with a precision score of 0.532. This table provides valuable insights for selecting the appropriate model based on specific evaluation metrics."
1483,"caption: Table 4. Model performance based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.92,0.89,0.94,0.91, Random Forest,0.93,0.90,0.93,0.91, Neural Network,0.87,0.84,0.87,0.83, Naive Bayes,0.85,0.83,0.86,0.82","Table 4 summarizes the evaluation results of four different models on a classification problem. The table presents the models' accuracy, precision, recall, and F1-score. Notably, the Random Forest model exhibits the highest accuracy of 0.93 and a scores high in precision, recall, and F1-score. The SVM model also attained good performance with an accuracy of 0.92 and the highest precision of 0.89. The Neural Network and Naive Bayes models attained lower performance, with F1-scores of 0.83 and 0.82, respectively. Overall, the table shows that the Random Forest and SVM models excel in all evaluation metrics compared to Naive Bayes and Neural Network models."
1484,"caption: Performance evaluation of different models using multiple metrics.table: Model Name,Accuracy,Precision,Recall,F1-Score, Model A,0.78,0.82,0.74,0.77, Model B,0.84,0.74,0.92,0.82, Model C,0.76,0.78,0.71,0.74, Model D,0.88,0.85,0.91,0.88, Model E,0.79,0.76,0.84,0.80","The table above shows the performance evaluation of five different models using four evaluation metrics - accuracy, precision, recall, and F1-score. Model A exhibited an overall accuracy of 0.78 with precision, recall, and F1-score of 0.82, 0.74, and 0.77, respectively. Model B showed the highest accuracy score of 0.84 with precision, recall, and F1-score of 0.74, 0.92, and 0.82, respectively. Model D also had a high accuracy score of 0.88, accompanied by the best precision and recall scores of 0.85 and 0.91, respectively, resulting in an F1-score of 0.88. Notably, Model C had the lowest performance across all evaluation metrics."
1485,"caption: Table 4: Performance comparison of different models using multiple evaluation metricstable: Model,Precision,Recall,F1-Score,Accuracy, Logistic Regression,0.83,0.85,0.84,0.82, Decision Tree,0.77,0.81,0.79,0.74, Random Forest,0.94,0.91,0.92,0.94, K-Nearest Neighbor,0.87,0.80,0.82,0.84","Table 4 displays a comparison of model performance using various evaluation metrics, including precision, recall, F1-score, and accuracy. The table includes four models: Logistic Regression, Decision Tree, Random Forest, and K-Nearest Neighbor. The Random Forest model outperformed all the other models, with the highest precision of 0.94, a recall of 0.91, F1-score of 0.92, and accuracy of 0.94.# Interestingly, the Logistic Regression model has a slightly higher precision score of 0.83 compared to the K-Nearest Neighbor model with 0.87. However, the K-Nearest Neighbor model had a higher recall score of 0.80. Decision Tree had the lowest performance in the comparison, with an accuracy of 0.74."
1486,"caption: Table 4: Model performance with multiple evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.85,0.87,0.99,0.93, KNN,0.78,0.80,0.89,0.84, Random Forest,0.91,0.93,0.98,0.96, Multinomial Naive Bayes,0.81,0.85,0.88,0.86, Gradient Boosting,0.93,0.94,0.99,0.97, Decision Tree,0.82,0.83,0.95,0.89","Table 4 exhibits the performance evaluation of multiple models using different metrics. The evaluation metrics used were Accuracy, Precision, Recall, and F1-Score. The SVM model shows the highest Recall value of 0.99 and F1-Score of 0.93. The Random Forest model outperforms other models with the highest Accuracy score of 0.91 and Precision score of 0.93. Interestingly, the Gradient Boosting model had the highest Recall score of 0.99. The results suggest that different models exhibit different evaluation performance, depending on the evaluation metric used."
1487,"caption: Table 4: Model Performance on Classification Task with Different Evaluation Metricstable: Model,Accuracy,F1-Score,AUC Score, Logistic Regression,0.82,0.80,0.90, Decision Tree,0.78,0.79,0.85, Random Forest,0.86,0.85,0.94, XGBoost,0.89,0.87,0.96, Support Vector Machine,0.81,0.76,0.87","Table 4 presents the model performance comparison for a classification task based on different evaluation metrics. The table compares Logistic Regression, Decision Tree, Random Forest, XGBoost, and Support Vector Machine (SVM) models based on Accuracy, F1-Score, and AUC Score. The Random Forest model had the highest Accuracy and F1-Score of 0.86 and 0.85, respectively, while XGBoost had the highest AUC Score of 0.96. Interestingly, the Decision Tree model had the lowest AUC Score of 0.85. Moreover, the SVM model had the lowest F1-Score of 0.76 and the second-lowest Accuracy of 0.81."
1488,"caption: Model performance based on multiple evaluation metricstable: Model,Accuracy,F1 Score,Precision,Recall, Model A,0.76,0.82,0.72,0.94, Model B,0.84,0.79,0.89,0.72, Model C,0.80,0.85,0.77,0.95, Model D,0.81,0.78,0.78,0.78, Model E,0.88,0.87,0.90,0.84","The table presents the performance of five different models based on various evaluation metrics, including Accuracy, F1 Score, Precision, and Recall. Model B has the highest accuracy score of 0.84, while Model E attains the highest F1 Score of 0.87. Model E also achieves the highest Precision (0.90) and Model A attains the highest Recall score (0.94). These results illustrate the variations of each model's performance based on different metrics."
1489,"caption: Table 4: Model performances based on different evaluation metrics.table: Model Name,Accuracy,Precision,Recall,F1-Score, Naive Bayes,0.86,0.93,0.83,0.88, Decision Tree,0.81,0.85,0.78,0.81, Random Forest,0.90,0.92,0.89,0.91, Support Vector Machines,0.85,0.87,0.84,0.85","Table 4 presents the performance metrics of four different models, namely Naive Bayes, Decision Tree, Random Forest, and Support Vector Machines (SVM). The performance metrics that were considered include accuracy, precision, recall, and F1-Score. From the table, Random Forest has the highest accuracy of 0.90, with a precision and F1-Score of 0.92 and 0.91, respectively, while Naive Bayes achieved the highest precision of 0.93. On the other hand, the decision tree model has the lowest performance results among the models considered. Therefore, based on the table, Random Forest is the best performing model for this dataset."
1490,"caption: Table showing the performance results of four different models using three different evaluation metrics.table: Model 1,Model 2,Model 3,Model 4, Metric 1,0.85,0.79,0.62,0.75, Metric 2,0.91,0.72,0.84,0.67, Metric 3,0.52,0.35,0.49,0.58","The table presents the performance results of four different models using three different evaluation metrics. Metric 1 ranges from 0 to 1, and the higher the score, the better the model's performance. Model 1 demonstrated the best performance with a score of 0.85, while models 2, 3, and 4 achieved scores of 0.79, 0.62, and 0.75, respectively. Metric 2 is similar, with higher scores indicating better model performance. Model 1 and Model 3 are almost level with 0.91 and 0.84 scores, respectively, while Model 2 and Model 4 have lower scores of 0.72 and 0.67, respectively. Metric 3 was also computed, where a higher score indicates better performance. In this case, Model 4 leads with a score of 0.58, while Models 1, 2, and 3 have scores of 0.52, 0.35, and 0.49, respectively."
1491,"caption: Table 4: Model comparison based on multiple evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall,AUC, Model 1,0.78,0.77,0.68,0.91,0.82, Model 2,0.83,0.78,0.84,0.73,0.85, Model 3,0.74,0.72,0.64,0.91,0.75, Model 4,0.86,0.84,0.82,0.87,0.90","Table 4 presents the comparison of four different models based on multiple evaluation metrics- Accuracy, F1 Score, Precision, Recall, and AUC. Model 1 achieved an accuracy of 0.78, F1 score of 0.77, precision of 0.68, recall of 0.91, and an AUC of 0.82. Model 2 performed better with an accuracy of 0.83, F1 score of 0.78, precision of 0.84, recall of 0.73, and an AUC of 0.85. Model 3 achieved an accuracy of 0.74, F1 score of 0.72, precision of 0.64, recall of 0.91, and an AUC of 0.75. Notably, Model 4 had the best overall performance, achieving an accuracy of 0.86, F1 score of 0.84, precision of 0.82, recall of 0.87, and an AUC of 0.90."
1492,"caption: Model performances evaluated using multiple metricstable: Model,F1 Score,Accuracy,Recall,Precision, Logistic Regression,0.85,0.81,0.87,0.84, Random Forest,0.88,0.82,0.90,0.87, Decision Tree,0.75,0.68,0.81,0.70, Support Vector Machine,0.87,0.80,0.88,0.85, K-Nearest Neighbors,0.78,0.75,0.82,0.74",
1493,"caption: Model Performance using Different Evaluation Metricstable: Model,Accuracy,F1 Score,Cohen's Kappa, Random Forest,0.92,0.91,0.87, Logistic Regression,0.87,0.85,0.75, Decision Tree,0.83,0.80,0.69, Support Vector Machine,0.90,0.88,0.81","The table above shows the performance of four different models in terms of accuracy, F1 score, and Cohen's Kappa. The models evaluated are Random Forest, Logistic Regression, Decision Tree, and Support Vector Machine. The Random Forest model achieved the highest accuracy score of 0.92, F1 score of 0.91, and Cohen's Kappa of 0.87, outperforming the other models. The Support Vector Machine model had the second-highest accuracy score of 0.90, F1 score of 0.88, and Cohen's Kappa of 0.81, while the Logistic Regression model obtained the third position in terms of performance. Interestingly, the Decision Tree model achieved the lowest performance among all the models. Therefore, the Random Forest model seems to be the most promising model for the given task based on the evaluation metrics used in the study."
1494,"caption: Performance comparison of various classification models.table: Model,Accuracy,Precision,Recall,F1-Score,AUC, SVM,0.924,0.933,0.844,0.886,0.963, K-NN,0.878,0.839,0.812,0.825,0.921, Naive Bayes,0.906,0.923,0.875,0.895,0.935, Logistic Regression,0.932,0.946,0.882,0.912,0.964, Random Forest,0.957,0.965,0.931,0.947,0.984","The table presents the performance results of five different classification models based on multiple evaluation metrics. The models include SVM, K-NN, Naive Bayes, Logistic Regression, and Random Forest. The evaluation metrics used are accuracy, precision, recall, F1-Score, and AUC. Random Forest displayed the best performance across all metrics, achieving an accuracy of 0.957, precision of 0.965, recall of 0.931, F1-Score of 0.947, and AUC of 0.984. Logistic Regression and SVM rank as the next two best performing models, while K-NN and Naive Bayes achieved comparatively weaker results."
1495,"caption: Table 4: Performance Comparison of Different Models using Multiple Evaluation Metricstable: Model,Precision,Recall,F1 score,Accuracy, Logistic Regression,0.89,0.92,0.90,0.87, Random Forest,0.85,0.88,0.86,0.83, Naive Bayes,0.92,0.75,0.82,0.81, Gradient Boosting,0.87,0.89,0.88,0.84, Decision Tree,0.80,0.85,0.83,0.79",
1496,"caption: Performance comparison of multiple classification models.table: Model,Accuracy,Precision,Recall,F1 Score, MLP,0.75,0.69,0.76,0.71, SVM,0.85,0.81,0.87,0.84, KNN,0.68,0.64,0.76,0.66, Decision Tree,0.72,0.68,0.65,0.67, Random Forest,0.87,0.82,0.89,0.85","This table exhibits a performance comparison of multiple classification models based on various evaluation metrics of accuracy, precision, recall, and F1 score. The models compared in this table are MLP, SVM, KNN, Decision Tree, and Random Forest. In terms of accuracy and F1 score, Random Forest achieved the highest score of 0.87 and 0.85, respectively. While in terms of precision and recall, SVM outperforms with precision and recall score of 0.81 and 0.87, respectively. Interestingly, KNN has the lowest accuracy score of 0.68 but performed better than MLP in terms of F1 score with a score of 0.66. From the results obtained, it is safe to conclude that Random Forest and SVM models can yield superior classification performance when accuracy metrics are of paramount importance, while KNN and MLP models may be viable alternatives when recall and precision are the primary considerations for performance evaluation."
1497,"caption: Table 4: Performance metrics of different modelstable: Model,Accuracy,Precision,F1-score,AUC, Model A,0.92,0.85,0.83,0.93, Model B,0.88,0.79,0.81,0.89, Model C,0.91,0.84,0.82,0.91, Model D,0.89,0.80,0.80,0.88, Model E,0.93,0.87,0.87,0.94","Table 4 compares the performance metrics of five models based on four different evaluation metrics, namely Accuracy, Precision, F1-score, and AUC. The table shows that Model E has the highest values in all performance metrics, with an Accuracy of 0.93, Precision of 0.87, F1-score of 0.87, and AUC of 0.94. On the other hand, Model B has the lowest performance metrics with an Accuracy of 0.88, Precision of 0.79, F1-score of 0.81, and AUC of 0.89. Overall, the table indicates that Model E performed the best, while Model B showed the poorest performance among the five models."
1498,"caption: Table 4: Performance metrics of different models used for classification task.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.85,0.78,0.88,0.82, Random Forest,0.84,0.76,0.89,0.82, Logistic Regression,0.82,0.72,0.88,0.79, Multilayer Perceptron,0.85,0.77,0.87,0.82, Naive Bayes,0.81,0.69,0.85,0.77","Table 4 shows the classification performance metrics for five different models on a given task. All models were evaluated on four different metrics, namely Accuracy, Precision, Recall, and F1-Score. The table indicates that the SVM model displays the highest precision (0.78) and recall (0.88), with an accuracy of 0.85 and an F1-Score of 0.82. Random Forest model shows an accuracy of 0.84 and the same Precision and F1-score of 0.76 and 0.82 as the SVC. Motiely, Logistic Regression to perform a little lower on all metrics and Naive Bayes had the lowest precision and recall at 0.69 and 0.85, respectively."
1499,"caption: Table 4: Performance comparison of different models based on multiple evaluation metrics.table: Model,F1 Score,Accuracy,ROC-AUC, Model A,0.84,0.72,0.85, Model B,0.80,0.68,0.76, Model C,0.89,0.80,0.81, Model D,0.78,0.75,0.71, Model E,0.94,0.90,0.92","Table 4 presents a comparison of the performance of five different models based on multiple evaluation metrics, including F1 Score, Accuracy, and ROC-AUC. The best F1 Score, Accuracy, and ROC-AUC were achieved by Model E with scores of 0.94, 0.90, and 0.92, respectively, indicating its exceptional performance. Model C also demonstrated competitive performance with an F1 Score of 0.89, Accuracy of 0.80, and ROC-AUC of 0.81. Model A also performed well with an F1 Score of 0.84, while Model D exhibited the lowest F1 Score of 0.78. Overall, the table highlights that Model E outperformed other models in terms of all three evaluation metrics."
1500,"caption: Comparison of different models' performance on sentiment analysistable: Model,Accuracy,F1 Score,Precision,Recall, Naive Bayes,0.87,0.84,0.85,0.85, SVM,0.92,0.91,0.90,0.92, KNN,0.87,0.80,0.83,0.85, Random Forest,0.94,0.93,0.92,0.95, XGBoost,0.95,0.94,0.93,0.95","The table shows the accuracy, F1 Score, precision, and recall of five different models used for sentiment analysis. The models are Naive Bayes, SVM, KNN, Random Forest, and XGBoost. Out of all the models, XGBoost performed the best, achieving an accuracy of 0.95, and an F1 score of 0.94, precision of 0.93, and recall of 0.95. Random Forest achieved the second-best performance, with an accuracy of 0.94, and an F1 score of 0.93, precision of 0.92, and recall of 0.95. SVM achieved the third-best performance, with an accuracy of 0.92, and an F1 score of 0.91, precision of 0.9, and recall of 0.92."
1501,"caption: Comparison of Model Performances using Different Evaluation Metricstable: Model,Accuracy,F1 score,Precision,Recall, Model A,0.86,0.84,0.87,0.82, Model B,0.89,0.87,0.89,0.85, Model C,0.81,0.78,0.80,0.77, Model D,0.92,0.91,0.92,0.90, Model E,0.84,0.82,0.86,0.80","This table provides a comparison of five different models using different evaluation metrics - Accuracy, F1 score, Precision, and Recall. The models are presented with their corresponding scores under each evaluation metric. It is observed that Model D has the highest Accuracy, F1 score, Precision, and Recall scores among all models. Model B also shows considerably good performance with a high Accuracy score of 0.89 and F1 score of 0.87. On the other hand, Model C has the lowest performance among all models with the lowest Accuracy, F1 score, Precision, and Recall scores of 0.81, 0.78, 0.80, and 0.77, respectively."
1502,"caption: Comparison of different models based on their performance using different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Model A,0.85,0.82,0.87,0.84, Model B,0.87,0.84,0.88,0.86, Model C,0.89,0.86,0.91,0.88, Model D,0.83,0.80,0.85,0.82, Model E,0.88,0.85,0.89,0.87","Table displayed above provides a comparison of five different models: Model A, Model B, Model C, Model D, and Model E based on their performance using multiple evaluation metrics, including Accuracy, Precision, Recall, and F1-Score. Model C ranks the highest out of all models with an accuracy score of 0.89 and F1-score of 0.88. Additionally, Model E has the highest precision score of 0.85, whereas Model D has the lowest accuracy score of 0.83. Overall, Model C shows the best results for the evaluation metrics, followed closely by Model E and Model B, respectively."
1503,"caption: Table 4: Performance metrics of different modelstable: Model,Accuracy,F1-score,Precision,Recall, Model A,0.96,0.95,0.97,0.93, Model B,0.98,0.97,0.98,0.96, Model C,0.94,0.93,0.95,0.90, Model D,0.99,0.98,0.99,0.97, Model E,0.91,0.89,0.93,0.86","Table 4 presents a comparison of different models' performance metrics where accuracy, F1-score, precision, and recall are used as evaluation metrics. The table contains five different models: Model A, Model B, Model C, Model D, and Model E, and their respective performance results in the mentioned evaluation metrics. Notably, Model D shows the best performance with a high accuracy of 0.99, F1-score of 0.98, precision of 0.99, and recall of 0.97. Moreover, Model B achieved high performance results, with an accuracy of 0.98, F1-score of 0.97, precision of 0.98, and recall of 0.96. Conversely, Model E displayed lower accuracy of 0.91, F1-score of 0.89, precision of 0.93, and recall of 0.86."
1504,"caption: Model performances based on accuracy, F1-score, precision, and recall metrics.table: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.89,0.88,0.86,0.89, Decision Tree,0.78,0.76,0.78,0.78, Random Forest,0.92,0.91,0.89,0.92, Gradient Boosting,0.93,0.92,0.92,0.93, Support Vector Machine,0.88,0.87,0.85,0.88","The table shows the models' performances based on the accuracy, F1-score, precision, and recall metrics. The models evaluated in this table include Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Support Vector Machine. The model performances range from an accuracy score of 0.78 (Decision Tree) to 0.93 (Gradient Boosting). Random Forest and Gradient Boosting achieved the highest F1-score with a score of 0.91 and 0.92, respectively. Interestingly, Gradient Boosting achieved the highest precision and recall score of 0.92 and 0.93, respectively, proving its dominance in all the metrics evaluated."
1505,"caption: Comparison of model performance based on different evaluation metrics.table: Model,F1-Score,Accuracy,Precision,Recall, Model 1,0.85,0.80,0.82,0.88, Model 2,0.79,0.74,0.87,0.73, Model 3,0.88,0.85,0.84,0.93, Model 4,0.74,0.78,0.69,0.83, Model 5,0.91,0.88,0.89,0.93","The table provides a comparison of five different models' performances using F1-Score, accuracy, precision, and recall metrics. As per the findings, Model 5 secured the best performance score across all measures. Specific to individual measures, Model 3 performed best for F1-Score, with a score of 0.88, while Model 2 turned out to be the weakest with the lowest F1-Score of 0.79. Model 3 also achieved the best precision score of 0.84, while Model 1 achieved the best recall score with a score of 0.88. Overall, based on the measures taken into consideration, it can be concluded that Model 5 outperformed all other models."
1506,"caption: Table 4: Model Performance Based on Different Evaluation Metricstable: Model Name,Accuracy,Precision,Recall,F1-Score, Model 1,0.85,0.96,0.87,0.91, Model 2,0.81,0.89,0.96,0.92, Model 3,0.78,0.82,0.75,0.78, Model 4,0.87,0.94,0.89,0.91, Model 5,0.82,0.86,0.92,0.89","Table 4 shows the comparison of several models' performances using different evaluation metrics, including accuracy, precision, recall, and F1-Score. The models' names are listed in the first column, and the corresponding scores for each evaluation metric are presented in the subsequent columns. Model 1 had the highest accuracy score, while Model 4 had the highest precision score. Model 2 showed the highest recall score, while Model 5 had the highest F1-Score. The results show that different models can perform differently based on the evaluation metric used, highlighting the importance of using multiple metrics to assess model performance."
1507,"caption: Table 4: Performance comparison of different models based on various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Random Forest,0.87,0.89,0.84,0.86, SVM,0.83,0.86,0.79,0.82, Naive Bayes,0.75,0.78,0.73,0.75, MLP,0.90,0.92,0.87,0.89","Table 4 presents a performance comparison of different models based on various evaluation metrics, including Accuracy, Precision, Recall, and F1 Score. The table includes Random Forest, SVM, Naive Bayes, and MLP models. It shows that the MLP model has the highest accuracy score of 0.90 and the highest precision score of 0.92. The Random Forest model achieved the highest recall score of 0.84, whereas the MLP model had the highest recall score of 0.87. Lastly, the SVM model showed the lowest performance across all metrics. Overall, the MLP model seems to be the best performer in terms of achieving higher scores across all evaluation metrics."
1508,"caption: Model Performance based on Different Evaluation Metricstable: Model,Accuracy,F1-score,Precision,Recall,AUC, Logistic Regression,0.753,0.755,0.764,0.747,0.817, Naive Bayes,0.601,0.604,0.735,0.522,0.707, Decision Tree,0.809,0.809,0.819,0.798,0.874, Random Forest,0.892,0.889,0.909,0.870,0.953, Gradient Boosting,0.903,0.900,0.919,0.881,0.964, Neural Network,0.887,0.882,0.913,0.853,0.945","Table 4 summarizes the performance of six models based on multiple evaluation metrics, including Accuracy, F1-score, Precision, Recall, and AUC. The models include Logistic Regression, Naive Bayes, Decision Tree, Random Forest, Gradient Boosting, and Neural Network. Interestingly, Random Forest achieved the highest accuracy (0.892), F1-score (0.889), and AUC (0.953) among all models. While the Gradient Boosting model had the highest Precision and Recall, with values of 0.919 and 0.881 respectively. Based on these results, the Gradient Boosting model could be considered the best model for achieving a balance between Precision and Recall, while the Random Forest model is the best model for achieving high accuracy and AUC."
1509,"caption: Table 4: Performance comparison of different models based on multiple evaluation metrics.table: Model Name,Accuracy,Precision,Recall,F1 Score, SVM,0.81,0.84,0.80,0.82, Random Forest,0.84,0.88,0.82,0.85, XGBoost,0.86,0.89,0.85,0.87, Neural Network,0.83,0.85,0.83,0.84","Table 4 shows the comparison of different models' performance on multiple evaluation metrics. The models include SVM, Random Forest, XGBoost, and Neural Network, while the evaluation metrics include accuracy, precision, recall, and F1 score. Notably, the Random Forest model achieved the highest accuracy (0.84) and F1 Score (0.85) while maintaining the highest precision (0.88) and recall (0.82). On the other hand, XGBoost achieved the highest accuracy (0.86), precision (0.89), recall (0.85), and F1 Score (0.87), indicating it is the best-performing algorithm among all. Additionally, the Neural Network model scored an accuracy of 0.83, precision of 0.85, recall of 0.83, and F1 Score of 0.84, making it an effective alternative to the top performers."
1510,"caption: Table 4: Model performances with different evaluation metrics.table: Model,Accuracy,F1-Score,Recall,Specificity, SVM,0.870,0.860,0.930,0.800, Naive Bayes,0.820,0.790,0.760,0.860, Random Forest,0.890,0.880,0.880,0.890, Multi-layer Perceptron,0.905,0.900,0.920,0.890, K-Nearest Neighbor,0.860,0.840,0.870,0.850","Table 4 exhibits the performances of five different models with various evaluation metrics. The table presents the accuracy, F1-Score, Recall, and Specificity of SVM, Naive Bayes, Random Forest, Multi-layer Perceptron, and K-Nearest Neighbor models. The Random Forest model holds the highest accuracy and F1-Score of 0.89 and 0.88, followed by the Multi-layer Perceptron model with an accuracy of 0.905 and F1-Score of 0.9. On the other hand, SVM showed the highest recall of 0.93 while Naive Bayes showed the highest specificity of 0.86. The table showcases the different performances of models in different evaluation metrics and can be used to select a model based on a specific metric requirement."
1511,"caption: Model performances with multiple evaluation metricstable: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.85 (+/- 0.02),0.85 (+/- 0.02),0.83 (+/- 0.04),0.84 (+/- 0.03), Decision Tree,0.82 (+/- 0.03),0.81 (+/- 0.04),0.79 (+/- 0.04),0.80 (+/- 0.03), Random Forest,0.88 (+/- 0.02),0.88 (+/- 0.02),0.87 (+/- 0.03),0.87 (+/- 0.02), K Nearest Neighbor,0.83 (+/- 0.02),0.82 (+/- 0.03),0.81 (+/- 0.03),0.81 (+/- 0.02)","The table above presents a comparison of four different models - Logistic Regression, Decision Tree, Random Forest, and K Nearest Neighbor. The models' performance is evaluated using four different metrics - Accuracy, Precision, Recall, and F1-score, with mean scores and standard deviation shown in parentheses. Based on the results, Random Forest displayed the highest Accuracy, Precision, Recall, and F1-score with a mean score of 0.88 (+/- 0.02), closely followed by Logistic Regression. However, Decision Tree and K Nearest Neighbor lagged behind in all measured metrics, scoring lower compared to the other models."
1512,"caption: Performance of different models on different evaluation metrics.table: Model,Metric,Performance, Random Forest,F1 Score,0.82, Accuracy,0.88, Precision,0.75, SVM,F1 Score,0.76, Accuracy,0.84, Precision,0.62, Logistic Regression,F1 Score,0.89, Accuracy,0.92, Precision,0.85, Neural Network,F1 Score,0.90, Accuracy,0.93, Precision,0.89","The table presents the comparison of multiple models, Random Forest, SVM, Logistic Regression, and Neural Network, based on their performance on multiple evaluation metrics, F1 Score, Accuracy, and Precision. The Random Forest model shows the highest accuracy of 0.88, while the Logistic Regression model has the highest F1 Score and Precision, 0.89 and 0.85, respectively. Interestingly, the Neural Network model achieves high performance on all the evaluation metrics, with an F1 Score, Accuracy, and Precision of 0.90, 0.93, and 0.89, respectively. Overall, the Neural Network outperforms the other models, showing promising results for this dataset."
1513,"caption: Table 4: Performance comparison of different models using multiple metrics.table: Model,Precision,Recall,F1-score,ROC-AUC,PR-AUC, Model A,0.92,0.86,0.89,0.78,0.87, Model B,0.85,0.89,0.87,0.79,0.85, Model C,0.91,0.82,0.86,0.82,0.85, Model D,0.88,0.91,0.89,0.85,0.89, Model E,0.93,0.85,0.87,0.81,0.85","Table 4 compares the performance of five different models, Model A to E, using multiple metrics. The table presents the Precision, Recall, F1-score, ROC-AUC, and PR-AUC for each model. Notably, Model A achieved the highest Precision score of 0.92, while Model E achieved the highest F1-score of 0.93. However, Model D had the highest Recall and PR-AUC, with a score of 0.91 and 0.89, respectively. Model D also had the highest ROC-AUC with a score of 0.85. The results demonstrate that different evaluation metrics can lead to different model selection outcomes, thereby illustrating the importance of carefully defining the evaluation criteria based on the study's objectives."
1514,"caption: Comparison of multiple models based on different evaluation metrics.table: Model,F1 score,Accuracy,Precision,Recall, Model A,0.86,0.89,0.92,0.82, Model B,0.91,0.92,0.88,0.94, Model C,0.89,0.91,0.85,0.94, Model D,0.88,0.92,0.91,0.86, Model E,0.93,0.94,0.91,0.95","Table presents a comparison of Model A to Model E based on different evaluation metrics, including F1 score, accuracy, precision, and recall. All models were trained and tested using the same dataset. Model E has the highest F1 score of 0.93, with an accuracy score of 0.94, precision score of 0.91, and recall score of 0.95. Model B has the highest accuracy score of 0.92 and recall score of 0.94. Model A achieved the highest precision score of 0.92. Interestingly, Model C has the lowest F1 score of 0.89, despite achieving a high recall score of 0.94."
1515,"caption: The table displays five different models' evaluation metrics based on accuracy, F1-score, precision, and recall.table: Model Name,Accuracy,F1-Score,Precision,Recall, Model 1,0.923,0.916,0.901,0.931, Model 2,0.907,0.898,0.880,0.918, Model 3,0.856,0.847,0.821,0.876, Model 4,0.936,0.927,0.917,0.938, Model 5,0.899,0.891,0.873,0.912","The table illustrates five different models' evaluation metrics via four different performance indicators, namely, accuracy, F1-score, precision, and recall. Model 1 is the top performer on accuracy with a score of 0.923, while model 4 has the highest accuracy in F1 score, precision, and recall with scores of 0.927, 0.917, and 0.938, respectively. Notably, model 5 has the lowest score across all performance metrics. The table presents an easy-to-read format to compare models' performances based on their evaluation metrics."
1516,"caption: Model performances based on accuracy, F1-score, precision, and recall metrics.table: Model name,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.83,0.54,0.79,0.46, Decision tree,0.82,0.56,0.76,0.51, Random forest,0.86,0.64,0.83,0.54, Naive Bayes,0.78,0.49,0.71,0.38, XGBoost,0.87,0.65,0.84,0.56","Table above presents a comparison of five classification models' performances based on accuracy, F1-score, precision, and recall metrics. The table demonstrates that XGBoost outperformed other models in all metrics. Specifically, it achieved the highest accuracy of 0.87, the highest F1-score of 0.65, the highest precision of 0.84, and the highest recall of 0.56. The Random forest model also demonstrated excellent performance, achieving an accuracy of 0.86, an F1-score of 0.64, a precision of 0.83, and a moderate recall score of 0.54. The Naive Bayes model performed comparatively worse than all other models."
1517,"caption: Model performance results based on different evaluation metricstable: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.89,0.83,0.85,0.82, KNN,0.82,0.77,0.79,0.77, LR,0.91,0.86,0.90,0.83, DT,0.75,0.68,0.71,0.67, RF,0.94,0.90,0.92,0.88, XGB,0.93,0.89,0.91,0.87","The table above presents the performance of different models in terms of accuracy, F1 Score, precision, and recall. Six models, including SVM, KNN, LR, DT, RF, and XGB, were evaluated using the same dataset. The highest accuracy score was achieved by the RF model with a score of 0.94, while the SVM model achieved 0.89. Interestingly, the Linear Regression (LR) model had the highest precision score of 0.9, while the SVM model had the highest recall score of 0.82. The Random Forest (RF) model produced the highest F1 score of 0.9. Overall, the results suggest that the RF model appears to provide the best performance across all evaluation metrics."
1518,"caption: Comparison table of multiple models based on accuracy, F1-score, precision, and recall metrics.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.92,0.88,0.93,0.84, Random Forest,0.96,0.94,0.92,0.96, MLP,0.91,0.87,0.87,0.87, XGBoost,0.94,0.92,0.95,0.90","The table presents a comparison between SVM, Random Forest, MLP, and XGBoost models based on their accuracy, F1-score, precision, and recall metrics. The Random Forest model performed the best in terms of accuracy with a score of 0.96, followed by XGBoost with 0.94, and SVM with 0.92. For the F1-score metric, the Random Forest also achieved the highest score of 0.94, while XGBoost had the second-best score with 0.92. Regarding precision, SVM had the highest score of 0.93, followed closely by XGBoost with 0.95. For recall, the Random Forest had the highest score with 0.96, while SVM had the lowest score with 0.84. Therefore, the results suggest that the Random Forest model is the best performing because it achieved the highest scores in two out of the four metrics analyzed."
1519,"caption: Model performances across different classifiers based on evaluation metricstable: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.85,0.83,0.86,0.84, Logistic Reg.,0.83,0.81,0.84,0.82, Random Forest,0.88,0.86,0.89,0.86, Naïve Bayes,0.75,0.73,0.76,0.74, KNN,0.81,0.79,0.83,0.80","This table displays the performances of multiple different models - SVM, Logistic Regression, Random Forest, Naïve Bayes, and KNN - across multiple evaluation metrics - Accuracy, F1 Score, Precision, and Recall. From the table, the Random Forest classifier had the highest accuracy of 0.88. The SVM classifier had the highest precision score of 0.86, while the Naïve Bayes had the lowest score in all metrics with a score of 0.75 in accuracy, 0.73 in F1 score, 0.76 in precision, and 0.74 in recall. The table provides insights into which classifier may be suitable for a specific application based on the chosen evaluation metrics."
1520,"caption: Model evaluation using different metrics and approaches.table: Model,Metric,Performance, Model 1,Accuracy,0.764, Model 1,F1 Score,0.773, Model 1,Precision,0.757, Model 1,Recall,0.793, Model 2,Accuracy,0.800, Model 2,F1 Score,0.812, Model 2,Precision,0.792, Model 2,Recall,0.834, Model 3,Accuracy,0.689, Model 3,F1 Score,0.698, Model 3,Precision,0.675, Model 3,Recall,0.724, Model 4,Accuracy,0.820, Model 4,F1 Score,0.833, Model 4,Precision,0.814, Model 4,Recall,0.854","This table displays a comparison of four different models' evaluation results using various metrics. Model 1 had the lowest performance among all models, with  Accuracy of 0.764, F1 Score of 0.773, Precision of 0.757, and Recall of 0.793. Meanwhile, Model 2, Model 3, and Model 4 had better outcomes. Model 4 performed the best, with an Accuracy of 0.820, F1 Score of 0.833, Precision of 0.814, and Recall of 0.854, closely followed by Model 2, showing the second-best performance. The performance outcomes indicate that the different models' performances vary significantly based on the evaluation metric."
1521,"caption: Performance Results of Different Models with Different Evaluation Metricstable: Model,Accuracy,F1 score,AUC score, Logistic,0.86,0.87,0.74, Random Forest,0.91,0.92,0.82, SVM,0.82,0.84,0.71, KNN,0.88,0.89,0.79, Naive Bayes,0.79,0.82,0.63","Table presents the performance results of five different models, including Logistic, Random Forest, SVM, KNN, and Naive Bayes. Each model's accuracy, F1 score, and AUC score are represented in this table. It is observed that the Random Forest model shows the best results in all three evaluation metrics; the highest accuracy of 0.91, highest F1 score of 0.92, and highest AUC score of 0.82. On the other hand, Naive Bayes performs the worst among all models with the lowest accuracy of 0.79, the lowest F1 score of 0.82, and the lowest AUC score of 0.63. Interestingly, both KNN and Logistic models show a close performance with accuracy, F1 score, and AUC score of above 0.88."
1522,"caption: Table 4: Performance comparison of different classification models based on multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.79,0.81,0.67,0.73, Naïve Bayes,0.62,0.35,0.79,0.48, Decision Tree,0.84,0.82,0.72,0.76, Random Forest,0.89,0.87,0.83,0.85, Gradient Boosting,0.91,0.90,0.87,0.88","Table 4 shows the performance comparison of different classification models based on evaluation metrics, including Accuracy, Precision, Recall, and F1-Score. The models compared are Logistic Regression, Naïve Bayes, Decision Tree, Random Forest and Gradient Boosting with accuracy scores of 0.79, 0.62, 0.84, 0.89, and 0.91, respectively. The Random Forest and Gradient Boosting models achieved the highest accuracy scores of 0.89 and 0.91, respectively, while Naïve Bayes recorded the lowest accuracy score of 0.62. For Precision, Gradient Boosting had the highest score of 0.90, whilst Naïve Bayes had the lowest score of 0.35. For Recall, Gradient Boosting performed the best with a score of 0.87, while Naïve Bayes had the highest score of 0.79. Finally, Gradient Boosting also had the highest F1 score of 0.88 among the other models compared."
1523,"caption: Model performance of various algorithms based on different evaluation metrics.table: Model,F1-score,Precision,Recall,Accuracy, Random forest,0.91,0.93,0.89,0.94, Logistic Regression,0.85,0.87,0.83,0.86, Support Vector Machines,0.89,0.91,0.87,0.90, K-Nearest Neighbors,0.82,0.84,0.80,0.83","The table above provides a comparison of various models' performances based on different evaluation metrics, including F1-score, precision, recall, and accuracy. The Random forest model attained the best F1-score of 0.91, with high precision of 0.93 and recall of 0.89, and accuracy of 0.94. Support vector machines achieved an F1-score of 0.89 with a precision of 0.91, recall of 0.87, and accuracy of 0.90. Logistic regression had the least performance on all metrics, recording F1-score of 0.85, precision of 0.87, recall of 0.83, and accuracy of 0.86. Interestingly, the K-nearest neighbors model recorded the lowest F1-score of 0.82 but still had moderate performance on other metrics."
1524,"caption: Performance comparison of different models with various evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, Model_1,0.82,0.81,0.814,0.809, Model_2,0.88,0.87,0.864,0.879, Model_3,0.76,0.75,0.745,0.756, Model_4,0.91,0.91,0.908,0.913, Model_5,0.85,0.84,0.832,0.852","The table above shows a comparison of the performance metrics of five unique models. The models evaluated include Model_1, Model_2, Model_3, Model_4, and Model_5, with evaluation metrics consisting of accuracy, F1-score, precision, and recall. Notably, Model_4 performed the best across all evaluation metrics, achieving an accuracy score of 0.91, an F1 score of 0.91, precision of 0.908, and recall of 0.913. Model_2 had the second-highest performance metrics, with an accuracy score of 0.88, F1-score of 0.87, precision of 0.864, and recall of 0.879. Interestingly, Model_3 had the lowest scores across all evaluation metrics, with an accuracy score of 0.76, an F1 score of 0.75, precision of 0.745, and recall of 0.756."
1525,"caption: Table 4: Performance metrics comparison of different models.table: Model,Precision,Recall,F1-score,Accuracy, Logistic Regression,0.82,0.75,0.78,0.80, Naive Bayes,0.62,0.84,0.71,0.79, Random Forest,0.90,0.87,0.88,0.88, Decision Tree,0.79,0.75,0.76,0.78, Support Vector Machine,0.85,0.79,0.82,0.83","Table 4 shows the comparison of different classification models based on various performance metrics, including Precision, Recall, F1-score, and Accuracy. The table includes Logistic Regression, Naive Bayes, Random Forest, Decision Tree, and Support Vector Machine models. The Random Forest model resulted in the highest Precision, Recall, and F1-score of 0.90, 0.87, and 0.88, respectively, surpassing the other models. Interestingly, the Naive Bayes model achieved the highest Recall rate of 0.84, while the Support Vector Machine model showed the highest precision rate of 0.85. Overall, the Random Forest model appears to be the strongest performer with the highest combined scores in Precision, Recall, and F1-score."
1526,"caption: Model performance of several classification algorithmstable: Model,Accuracy,F1-score,Precision,Recall,Specificity, Logistic Regression,0.83,0.84,0.83,0.85,0.81, Decision Tree,0.78,0.76,0.73,0.80,0.75, Random Forest,0.88,0.88,0.87,0.88,0.86, Gradient Boosting,0.89,0.89,0.88,0.89,0.88, Support Vector Machine,0.84,0.85,0.84,0.86,0.81","The table presents a comparison between five classification models, Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Support Vector Machines. Each model's accuracy, F1-score, precision, recall, and specificity were evaluated to measure their performance. Gradient Boosting and Random Forest models have the highest accuracy (0.89 and 0.88, respectively), while Decision Tree model has the lowest accuracy (0.78). The Gradient Boosting Model also achieved the highest F1-score (0.89), Recall (0.89), and Specificity (0.88). Conversely, the Decision Tree model achieved the lowest F1-score (0.76), Recall (0.80), and Specificity (0.75). Overall, Gradient Boosting and Random Forest models outperform the other three models across all measures."
1527,"caption: A comparison of Model A, Model B, and Model C based on different evaluation metrics.table: Metric,Model A,Model B,Model C, Precision,0.82,0.91,0.74, Recall,0.79,0.61,0.67, F1-Score,0.81,0.73,0.7, Accuracy,0.82,0.88,0.76","The table provides a comparison of three different models (Model A, Model B, and Model C) based on four evaluation metrics: Precision, Recall, F1-Score, and Accuracy. It is clear from the table that Model B shows the highest performance results in all evaluation metrics except for Precision, where Model A shows the highest score. When considering Recall, Model C performs better than Model A and Model B. However, the accuracy score reveals that Model B performs better with an accuracy score of 0.88 while Model A and Model C have an accuracy score of 0.82 and 0.76, respectively."
1528,"caption: Table 4: Model Performance on Various Evaluation Metricstable: Model Name,Metric 1,Metric 2,Metric 3, Model 1,0.823,0.616,0.722, Model 2,0.897,0.600,0.780, Model 3,0.862,0.558,0.650, Model 4,0.906,0.715,0.900, Model 5,0.888,0.721,0.850","Table 4 showcases the model performance on various evaluation metrics for five different models. Model 1 achieved the highest score for Metric 1 (0.823), while Model 2 performed best for Metric 2 with a score of 0.897. Interestingly, Model 4 scored the best for Metric 3 with an impressive result of 0.9. Overall, all the models performed well in each of the metrics, but Model 4 had the highest average score. This suggests that Model 4 is likely the best-performing model overall based on the given evaluation metrics."
1529,"caption: A comparison table of model performances based on different evaluation metricstable: Model,Accuracy,F1-score,Precision,Recall, SVM,0.85,0.84,0.85,0.83, KNN,0.78,0.77,0.78,0.79, Log. Regression,0.87,0.89,0.90,0.88, Decision Tree,0.75,0.76,0.77,0.75, Random Forest,0.92,0.91,0.93,0.89","The table depicts the model performances based on multiple different evaluation metrics such as Accuracy, F1-score, Precision, and Recall. The table includes five different models, SVM, KNN, Logistic Regression, Decision Tree, and Random Forest. The Random Forest model shows the best performance across the board with an accuracy score of 0.92, F1-score of 0.91, precision of 0.93, and recall of 0.89. Interestingly, the Logistic regression model exhibited strong performance in all metrics, scoring anaccuracy score of 0.87, F1-score of 0.89, precision of 0.90, and recall of 0.88. The Decision Tree model shows the weakest performance, with all performance metrics lower than other models except for Recall, where it outperformed the KNN model."
1530,"caption: Comparison of Model Performances on Dataset XYZtable: Model,Accuracy,F1 Score,Precision,Recall,AUC, SVM,0.78,0.76,0.72,0.80,0.85, KNN,0.83,0.82,0.82,0.83,0.88, Random Forest,0.87,0.85,0.85,0.84,0.91, Gaussian NB,0.61,0.65,0.59,0.72,0.65, XGBoost,0.90,0.88,0.88,0.89,0.93","The table presents a comparison of five different models' performances on dataset XYZ based on multiple evaluation metrics - accuracy, F1 score, precision, recall, and AUC. The SVM model achieved an accuracy score of 0.78 and an AUC of 0.85. The KNN model showed the highest accuracy of 0.83, F1 score of 0.82, and precision of 0.82. On the other hand, Random Forest achieved an AUC of 0.91, which is the highest of all models. Gaussian NB had the lowest performance with an accuracy of 0.61 and AUC of 0.65. Overall, the table provides an overview of each model's performance and can help a researcher choose the best model for their specific use case."
1531,"caption: Performance comparison of different machine learning models using various evaluation metricstable: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.75,0.72,0.76,0.69, Random Forest,0.81,0.78,0.82,0.75, k-NN,0.67,0.62,0.69,0.59, Naive Bayes,0.72,0.68,0.70,0.73, Decision Tree,0.72,0.67,0.72,0.63","The table displays the accuracy, F1 Score, precision, and recall results of five distinct machine learning models, including SVM, Random Forest, k-NN, Naive Bayes, and Decision Tree. They showed performance variations, where Random Forest and SVM performed the best in terms of Accuracy (0.81) and Precision (0.76), respectively. Interestingly, the Random Forest also demonstrated superior results in terms of F1 Score (0.78) while the SVM had the highest Recall (0.69). The k-NN method had the poorest performance in all metrics. Overall, the table suggests the Random Forest and SVM methods could be well-suited for classifying the given data."
1532,"caption: Model performance comparison based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.825,0.827,0.738,0.780, KNN,0.790,0.769,0.706,0.736, RF,0.867,0.893,0.787,0.836, XGB,0.884,0.903,0.832,0.866",
1533,"caption: Performance Comparison of Various Machine Learning Modelstable: Model,F1-score,AUC-ROC,Accuracy,Sensitivity,Specificity, Model 1,0.83,0.89,0.76,0.79,0.82, Model 2,0.84,0.87,0.75,0.87,0.80, Model 3,0.82,0.91,0.77,0.75,0.85, Model 4,0.85,0.93,0.79,0.83,0.87, Model 5,0.81,0.88,0.72,0.78,0.79","In this table, we compare the performance of five different machine learning models based on F1-score, AUC-ROC, accuracy, sensitivity, and specificity. Model 4 produced the best results for all evaluation metrics when compared to all other models, with an F1-score of 0.85, AUC-ROC of 0.93, accuracy of 0.79, sensitivity of 0.83, and specificity of 0.87. Model 1 and Model 3 produced the least accurate prediction with an accuracy of 0.76 and 0.77, respectively. It is also interesting to note that all models performed well with F1-scores ranging from 0.81 to 0.85."
1534,"caption: Table 4: Performance of different models based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression (Baseline),0.902,0.896,0.905,0.896, Decision Tree,0.908,0.905,0.912,0.900, Random Forest,0.934,0.932,0.935,0.932, Support Vector Machine,0.916,0.917,0.913,0.911, K-Nearest Neighbors,0.899,0.897,0.900,0.896","Table 4 shows the performance of different machine learning models based on multiple evaluation metrics such as accuracy, precision, recall, and F1-score. The Logistic Regression model acts as a baseline, and other models include Decision Tree, Random Forest, Support Vector Machine, and K-Nearest Neighbors. The Random Forest model shows the best accuracy of 0.934, while the Decision Tree model achieved the highest precision of 0.905. Interestingly, the Support Vector Machine model has the best recall of 0.913, whereas the Random Forest and K-Nearest Neighbors models are tied for the highest F1-score of 0.932."
1535,"caption: Model Performance Metrics on a Classification Problemtable: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.84,0.82,0.86,0.78, Decision Tree,0.81,0.79,0.77,0.80, Random Forest,0.89,0.87,0.92,0.82, Support Vector Machine,0.86,0.84,0.87,0.82, K-Nearest Neighbors,0.83,0.79,0.74,0.85","The table presents performance metrics of five different models trained on a classification problem. The evaluated metrics are Accuracy, F1 Score, Precision, and Recall. Random Forest model achieves the highest accuracy of 0.89, and Logistic Regression achieves the highest precision of 0.86. However, the Random Forest model generates the highest F1 score of 0.87, and Recall of 0.82. The K-Nearest Neighbors model demonstrated relatively low precision than other models, resulting in a low F1 score of 0.79. These findings suggest that different models have different strengths and weaknesses, and it is essential to evaluate multiple metrics to get the whole picture of the models' performance."
1536,"caption: Table 4: Performance results of multiple models using different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Model A,0.85,0.87,0.85,0.85, Model B,0.90,0.86,0.92,0.89, Model C,0.91,0.93,0.90,0.91, Model D,0.88,0.89,0.86,0.87, Model E,0.93,0.92,0.94,0.93","Table 4 presents the performance results of multiple models using different evaluation metrics. The models' accuracy, precision, recall, and F1-score values are shown in the table. Model C exhibits the best accuracy of 0.91, while Model E achieved the highest precision, recall, and F1-score values of 0.92, 0.94, and 0.93, respectively. Interestingly, Model B shows a high accuracy score of 0.90 but has a lower precision score than some other models. These results demonstrate the importance of using multiple evaluation metrics to get a comprehensive understanding of models' performance."
1537,"caption: Model performance evaluation using several metrics.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.89,0.83,0.92,0.87, LR,0.86,0.78,0.89,0.83, GNB,0.81,0.74,0.79,0.76, KNN,0.87,0.81,0.85,0.83, RF,0.91,0.86,0.93,0.89","The table presents the performance evaluation of five different models using multiple different metrics. The models are evaluated based on their accuracy, precision, recall, and F1-Score scores. The Random Forest model shows the best performance in all metrics with an accuracy score of 0.91, precision score of 0.86, recall score of 0.93, and F1-Score of 0.89. SVM and KNN models also achieve notable performances with accuracy scores of 0.89 and 0.87, respectively. However, the GNB model had the lowest performance among all models, with an accuracy score of 0.81. Overall, the RF model is the most suitable model for this classification task based on the results."
1538,"caption: Table 1: Evaluation of various classifiers on the datasettable: Model,F1 Score,Precision,Recall,AUC-ROC,Accuracy, XGBoost,0.89,0.92,0.89,0.96,0.87, Random Forest,0.91,0.91,0.94,0.95,0.88, Logistic Regression,0.85,0.90,0.81,0.90,0.81, Support Vector Machine,0.88,0.90,0.85,0.91,0.86","Table 1 presents the performance of different classifiers, XGBoost, Random Forest, Logistic Regression, and Support Vector Machine (SVM), based on different evaluation metrics. Each metric is an important aspect of evaluating the classifier's performance. The evaluation metrics used in this table are F1 score, Precision, Recall, AUC-ROC, and Accuracy. Random Forest gives the best F1 score of 0.91 followed by XGBoost with 0.89 F1 score. Logistic Regression had the lowest precision, while SVM scored the lowest Recall. However, XGBoost produced the highest Precision and Recall values, which makes it the best classifier in terms of classification accuracy."
1539,"caption: A Comparison of Different Models' Performances on the Dataset.table: Model,Accuracy,F1-score,Precision,Recall, Logistic regression,0.85,0.85,0.86,0.84, Support vector machine,0.82,0.82,0.83,0.81, Decision tree,0.79,0.78,0.78,0.79, Random forest,0.88,0.88,0.89,0.88","The table shows the performance comparison of different models based on different metrics such as Accuracy, F1-score, Precision, and Recall, on a given dataset. The models include Logistic Regression, Support Vector Machine, Decision Tree, and Random Forest. Interestingly, the Random Forest model outperformed other models and had the highest accuracy, 88%, followed by Logistic Regression with 85%. The Support Vector Machine model had the lowest accuracy score of 82%. The Random Forest model has the highest F1-score, precision, and recall, indicating its superiority in classification. Overall, the Random Forest model would be recommended for this dataset."
1540,"caption: Model performances evaluated on different metricstable: Model,Accuracy,Precision,Recall,F1 Score,AUC Score, Model 1,0.94,0.92,0.93,0.92,0.98, Model 2,0.86,0.85,0.89,0.87,0.95, Model 3,0.80,0.79,0.82,0.80,0.92, Model 4,0.96,0.94,0.96,0.95,0.99, Model 5,0.91,0.90,0.89,0.88,0.97",
1541,"caption: Model performance of different classifiers on the test dataset.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.83,0.88,0.86,0.89, Random Forest,0.86,0.89,0.87,0.91, Logistic Regression,0.81,0.85,0.82,0.89, Naive Bayes,0.78,0.83,0.79,0.88, KNN,0.79,0.83,0.80,0.86","The above table shows the model performance of different classifiers on the test dataset evaluated based on multiple metrics, including accuracy, F1-score, precision, and recall. The highest accuracy was achieved by the Random Forest model, with a score of 0.86, whereas the lowest accuracy was observed in Naive Bayes with a score of 0.78. The Random Forest model also had the highest F1-score of 0.89, indicating a better balance between precision and recall. On the other hand, the lowest F1-score of 0.83 was observed in both Naive Bayes and KNN. Overall, the Random Forest model appears to outperform the other models in terms of most evaluation metrics."
1542,"caption: Model performance comparison using different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score,ROC-AUC, Model A,0.83,0.78,0.85,0.81,0.81, Model B,0.77,0.82,0.70,0.75,0.76, Model C,0.89,0.87,0.90,0.88,0.87, Model D,0.79,0.66,0.75,0.70,0.71, Model E,0.92,0.90,0.94,0.92,0.92","The table summarises the performance of five different models based on various evaluation metrics. The models include Model A, B, C, D and E, and the evaluation metrics are Accuracy, Precision, Recall, F1-Score, and ROC-AUC. The highest accuracy is achieved by Model E with a result of 0.92, followed by Model C with 0.89. Model A shows the highest Precision of 0.78 and Model E exhibits the highest Recall of 0.94. Interestingly, although Model E has the highest accuracy, it is not necessarily the best in terms of other performance metrics. These results suggest the importance of considering different evaluation metrics for model performance comparison."
1543,"caption: Table 1: Evaluation of different classification models on the dataset.table: Model,Accuracy,F1-score,Precision,Recall,AUC, Logreg,89.2,0.81,0.80,0.84,0.92, SVM (Linear),85.1,0.77,0.78,0.75,0.87, KNN,80.6,0.74,0.72,0.78,0.84, Decision tree,76.8,0.69,0.72,0.66,0.80, Random Forest,92.4,0.85,0.85,0.86,0.96, XGBoost,91.6,0.84,0.83,0.86,0.95, AdaBoost,89.3,0.80,0.81,0.79,0.93, Gradient Boosting,90.5,0.82,0.83,0.80,0.94","Table 1 presents the evaluation results of different classification models: Logistic Regression, Support Vector Machine (Linear), K-Nearest Neighbor (KNN), Decision Tree, Random Forest, XGBoost, AdaBoost, and Gradient Boosting, on a given dataset. The models used multiple evaluation metrics, including accuracy, F1 score, precision, recall, and AUC, for performance analysis. The attained results revealed that Random Forest and XGBoost models yielded the highest accuracies of 92.4% and 91.6%, respectively. Gradient Boosting achieved the highest F1 score of 0.82, while the Random Forest model obtained the highest precision and recall scores. Furthermore, Random Forest and XGBoost models also achieved the highest AUC scores, indicating their superior predictive abilities."
1544,"caption: Model performances based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, SVM,0.85,0.88,0.83,0.85, Decision Tree,0.78,0.72,0.80,0.75, Random Forest,0.89,0.91,0.88,0.89, KNN,0.76,0.85,0.70,0.77, XGBoost,0.92,0.94,0.91,0.92","Table presents a comparison of different models' evaluation metrics, including Accuracy, Precision, Recall, and F1-Score. SVM, Decision Tree, Random Forest, KNN, and XGBoost models' performances were evaluated using these metrics. Interestingly, the XGBoost model outperformed the other models with the highest accuracy score of 0.92. The Random Forest model performed the best in terms of Precision and Recall with a score of 0.91 and 0.88, respectively. Moreover, the Random Forest and XGBoost models had the same F1-Score of 0.89. In contrast, the Decision Tree model showed the weakest performance with an overall F1-Score of 0.75. Therefore, based on these metrics, the Random Forest and XGBoost models can be considered as the most promising models."
1545,"caption: Table 4: Comparison of different models based on multiple evaluation metricstable: Models,Accuracy,F1-score,Precision,Recall,AUC-ROC, Logisitic Regression,0.87,0.82,0.81,0.85,0.93, Decision Tree,0.78,0.76,0.72,0.81,0.71, Random Forest,0.89,0.87,0.85,0.89,0.96, Gradient Boosting,0.91,0.89,0.88,0.90,0.97, Support Vector Machine,0.88,0.86,0.84,0.89,0.94","The performance of different models such as Logisitic Regression, Decision Tree, Random Forest, Gradient Boosting, and Support Vector Machine are presented in Table 4. The models are evaluated based on multiple performance metrics such as accuracy, F1-score, precision, recall, and AUC-ROC. Notably, Gradient Boosting model outperforms all other models for all metrics and achieves the highest AUC-ROC score of 0.97. Meanwhile, Decision Tree has the lowest performance metrics compared to other models. Overall, the table indicates the effectiveness of the Gradient Boosting model in this evaluation."
1546,"caption: Performance results of different models evaluated using multiple metrics.table: Metric,Model 1,Model 2,Model 3,Model 4,Model 5, Accuracy,0.87,0.85,0.81,0.89,0.83, Precision,0.92,0.88,0.77,0.91,0.88, Recall,0.82,0.91,0.78,0.89,0.85, F1_score,0.87,0.91,0.76,0.89,0.86, ROC_AUC_score,0.93,0.89,0.82,0.92,0.88","The table presents the model comparison with respect to accuracy, precision, recall, F1_score, and ROC_AUC_score. The evaluation metrics are used to assess the models' different performance criteria. Five different models are compared based on their performance results. Interestingly, Model 1 exhibits the highest accuracy score of 0.87, followed closely by Model 4, which shows the second-highest accuracy score of 0.89. Model 2 has the highest precision score of 0.88, while Model 1 and Model 4 are the best in recall with 0.82 and 0.89, respectively. Finally, the ROC_AUC_score's highest score of 0.93 is exhibited by Model 1, while Model 4 is just behind with a score of 0.92."
1547,"caption: Table 4: Performance Comparison of Different Models Based on Multiple Evaluation Metrics.table: Model,Precision,Recall,F1-Score,Accuracy, SVM,0.78,0.75,0.74,0.79, Naïve Bayes,0.80,0.66,0.72,0.78, Decision Tree,0.65,0.55,0.58,0.71, Random Forest,0.85,0.71,0.72,0.83, Gradient Boosting,0.88,0.77,0.80,0.85","Table 4 presents a comparison of different models' performances based on multiple evaluation metrics. The table exhibits SVM, Naïve Bayes, Decision Tree, Random Forest, and Gradient Boosting models' Precision, Recall, F1-Score, and Accuracy metrics. The table suggests that Gradient Boosting achieved the best performance with an accuracy of 0.85. SVM, the second-best performing model, obtained an accuracy of 0.79, whereas the Decision Tree model had the lowest accuracy of 0.71. Notably, the Random Forest model achieved the highest precision score of 0.85, while the Gradient Boosting had the highest F1-Score of 0.80. These results highlight the usefulness of evaluating models using multiple metrics to obtain a comprehensive understanding of their performance."
1548,"caption: Comparison of different models performance based on different evaluation metrics.table: Model,Precision,Recall,F1-Score,AUC, Model A,0.85,0.88,0.86,0.92, Model B,0.81,0.85,0.83,0.89, Model C,0.91,0.79,0.84,0.88, Model D,0.84,0.92,0.88,0.94, Model E,0.78,0.85,0.81,0.87","The table presents a comparison of different models' performance based on various evaluation metrics. We have used precision, recall, and F1-score to evaluate the models' performance in binary classification tasks. Additionally, the AUC (area under the curve) metric is also used to evaluate the models' performance in predicting probabilities. Model D shows the best overall performance in terms of precision, recall, F1-score, and AUC. It achieved a precision score of 0.84, a recall score of 0.92, an F1-score of 0.88, and an AUC of 0.94. Notably, Model E had the lowest precision score of 0.78, while Model C had the lowest recall score of 0.79. Overall, the table highlights the importance of evaluating models' performance based on various metrics to get a comprehensive understanding of their strengths and weaknesses."
1549,"caption: Comparison of model performances using different evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.87,0.88,0.90,0.86, Decision Tree,0.78,0.77,0.73,0.82, Random Forest,0.92,0.91,0.94,0.89, Support Vector Machine,0.84,0.85,0.87,0.83, Gradient Boosting,0.90,0.89,0.92,0.86","The table above summarizes the performance of multiple models evaluated using various metrics. The metrics used are accuracy, F1-score, precision, and recall. The table shows that the Random Forest model achieved the highest accuracy score of 0.92, followed by Gradient Boosting with 0.90. Meanwhile, Decision Tree obtained the lowest accuracy score of 0.78. For F1-score, Random Forest and Gradient Boosting models also achieved the highest score of 0.91 and 0.89, respectively. On the other hand, Decision Tree achieved the lowest F1-score with 0.77. Additionally, the results present that most models achieved a high precision score, ranging from 0.73 to 0.94. Similarly, the recall score ranges from 0.83 to 0.89, with Random Forest having the highest score and Decision Tree having the lowest. In conclusion, these results demonstrate that Random Forest and Gradient Boosting are more likely to perform better based on the combined evaluation metrics."
1550,"caption: Model performance from different classifiers based on various evaluation metrics.table: Model,Accuracy,F1 Score,Matthews Correlation Coefficient,Precision,Recall, Logistic Regression,0.87,0.81,0.58,0.80,0.86, Random Forest,0.91,0.85,0.71,0.91,0.80, Decision Tree,0.79,0.81,0.57,0.74,0.88, Multi-layer Perceptron,0.90,0.84,0.68,0.86,0.82, BERT-base-uncased,0.89,0.83,0.66,0.82,0.84","The above table compares the performances of various classifiers based on different evaluation metrics. The models included in the table are Logistic Regression, Random Forest, Decision Tree, Multi-layer Perceptron, and BERT-base-uncased. The evaluation metrics are Accuracy, F1-Score, Matthews Correlation Coefficient, Precision, and Recall. Interestingly, the Random Forest model achieved the best performance in terms of accuracy (0.91) and Matthews Correlation Coefficient (0.71), whilst the Decision Tree's Precision (0.74) and BERT-base-uncased's recall (0.84) were exceptional compared to the other models. In contrast, the Multi-layer Perceptron model achieved overall balanced performance, achieving the second-best result in all evaluation metrics."
1551,"caption: Table 4: Performance comparison of different models based on accuracy, F1 Score, Precision, and Recall.table: Model,Accuracy,F1 Score,Precision,Recall, Model A,0.80,0.78,0.83,0.74, Model B,0.82,0.79,0.81,0.80, Model C,0.85,0.84,0.85,0.83, Model D,0.87,0.86,0.88,0.85, Model E,0.89,0.88,0.90,0.86","Table 4 compares the performance results of five models based on evaluation metrics accuracy, F1 Score, Precision, and Recall. The table shows that Model E has the highest accuracy of 0.89, while Model D has the highest F1 score of 0.86. Model A depicts the lowest accuracy of 0.80 and F1 score of 0.78. On the other hand, Model E has the highest precision of 0.90, whereas Model A has the lowest precision of 0.83. Finally, Model D has the highest recall of 0.85, and Model A has the lowest recall of 0.74. Overall, Model E presents the most consistent and best performing results."
1552,"caption: Evaluation metrics and results of multiple models.table: Model,Metric,Result, Model 1,Accuracy,0.87, Precision,0.90, Recall,0.80, Model 2,Accuracy,0.75, Precision,0.80, Recall,0.70, Model 3,Accuracy,0.92, Precision,0.91, Recall,0.94, Model 4,Accuracy,0.72, Precision,0.70, Recall,0.78, Model 5,Accuracy,0.82, Precision,0.85, Recall,0.76","The table summarizes multiple models' performance on different evaluation metrics, particularly Accuracy, Precision, and Recall. Model 1 achieved the highest scores for Accuracy and Precision, while Model 5 achieved the highest score for Recall. Interestingly, Model 3 achieved a fairly balanced metric score, being the model with the highest Accuracy and Precision, and the second-highest Recall score. On the other hand, Model 4 shows the lowest scores for all metrics. These results provide insight into each model's strengths and areas of opportunity for improvement."
1553,"caption: Comparison of different models' performances using various evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.85,0.83,0.87,0.81, KNN,0.82,0.79,0.85,0.74, RF,0.91,0.90,0.92,0.88, XGB,0.90,0.89,0.91,0.87, MLP,0.88,0.86,0.89,0.83","Table presents a comparison of the accuracy, f1-score, precision, and recall of SVM, KNN, RF, XGB, and MLP models. The RF model achieved the highest Accuracy (0.91) and F1-score (0.90). The SVM model achieved the highest precision score (0.87), while the recall score was the highest for the RF model (0.88). It is interesting to note that the KNN model achieved the lowest recall score (0.74), indicating that it was less effective at identifying relevant information. Conversely, the Random Forest model outperformed all other models overall and exhibited robust capabilities in all evaluation metrics."
1554,"caption: Evaluation Metrics and Performance Results of Different Models.table: Model Name,Precision,Recall,F1-Score,Accuracy, Model A,0.77,0.84,0.80,0.75, Model B,0.80,0.82,0.81,0.73, Model C,0.74,0.85,0.79,0.74, Model D,0.82,0.80,0.81,0.72","Table X presents the Precision, Recall, F1-Score, and Accuracy results of different models- Model A, B, C, and D. Performance metrics are frequently adopted to evaluate a model's efficiency, effectiveness, and accuracy. In this table, each model's evaluation metrics exhibit different results. Model A shows the highest Precision score of 0.77, while Model D has the highest Precision score of 0.82. Model C has the highest Recall score of 0.85, while Model B has the lowest. Interestingly, all models have almost the same F1-Score (around 0.80). However, Model B has the lowest Accuracy score of 0.73. The table's results show it is best to use Model D for high Precision applications while Model C should be employed for high Recall applications."
1555,"caption: Performance comparison of different models on the classification task.table: Model,Accuracy,Precision,Recall,F1-Score, Decision Tree,0.79,0.80,0.76,0.78, Naive Bayes,0.85,0.75,0.95,0.84, Random Forest,0.89,0.92,0.83,0.87, K-Nearest Neighbors,0.84,0.82,0.86,0.84, Support Vector Machine,0.91,0.90,0.92,0.91","The table above presents the performance comparison of different models on a classification task using four evaluation metrics: Accuracy, Precision, Recall, and F1-Score. The models compared in the table are Decision Tree, Naive Bayes, Random Forest, K-Nearest Neighbors, and Support Vector Machine. The results show that the Support Vector Machine has the highest accuracy of 0.91 and F1-score of 0.91, indicating its ability to predict True Positives and True Negatives with high accuracy. On the other hand, Naive Bayes has the highest recall score of 0.95, indicating its ability to predict the actual positive cases in the dataset. Thus, depending on the specific objective of the classification task, the best-performing model might vary."
1556,"caption: Table 4: Model performances based on different evaluation metricstable: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.87,0.85,0.83,0.84, Decision Tree,0.79,0.79,0.77,0.78, Random Forest,0.91,0.93,0.90,0.91, Support Vector Machines,0.85,0.83,0.81,0.81, Neural Networks,0.90,0.91,0.88,0.89","Table 4 summarizes the performance evaluation metrics of five different models: Logistic Regression, Decision Tree, Random Forest, Support Vector Machines, and Neural Networks. These models were trained and tested on the same dataset. The table illustrates the accuracy, precision, recall, and F1 score of each model. It is interesting to note that the Random Forest model showed the highest accuracy of 0.91. On the other hand, the Neural Networks model demonstrated the highest precision of 0.91, while Decision Trees had the lowest scores in all evaluation metrics. Overall, this table shows how each model performed based on different evaluation metrics, providing an insight into their abilities in capturing certain aspects of data."
1557,"caption: Comparison of model evaluation metrics for different models.table: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.755,0.784,0.707,0.743, KNN,0.703,0.748,0.614,0.675, Decision Tree,0.714,0.707,0.730,0.719, Random Forest,0.789,0.816,0.743,0.777, SVM,0.745,0.773,0.690,0.730","The table presents a comparison of the evaluation metrics, accuracy, precision, recall, and F1-score for different models, including Logistic Regression, K-Nearest Neighbors (KNN), Decision Tree, Random Forest, and Support Vector Machine (SVM). The results demonstrate that Random Forest exhibits the highest accuracy of 0.789, precision of 0.816, recall of 0.743, and F1-score of 0.777. Logistic Regression demonstrates the second-best performance with an accuracy of 0.755 and precision of 0.784. It is interesting to note that KNN had the lowest accuracy of 0.703, while Decision Tree had the highest recall of 0.730. SVM's precision, recall, and F1-score were moderate with values of 0.773, 0.690, and 0.730, respectively."
1558,"caption: Performance metrics of various classification modelstable: Model,Precision,Recall,F1-Score,AUC-ROC, Model 1,0.87,0.78,0.81,0.92, Model 2,0.78,0.88,0.83,0.84, Model 3,0.75,0.70,0.72,0.81, Model 4,0.92,0.95,0.94,0.88, Model 5,0.80,0.85,0.81,0.79","The above table presents the precision, recall, F1-score, and AUC-ROC performance metrics of five models' classification results. The table shows Model 1, Model 2, Model 3, Model 4, and Model 5 precision, recall, F1-score, and AUC-ROC results. Interestingly, Model 4 achieved the highest precision score of 0.92 and recall score of 0.95, leading to the highest F1-score of 0.94. Model 1 had the highest AUC-ROC score of 0.92. Overall, the table provides a holistic comparison of models based on diverse classification performance metrics."
1559,"caption: Table 4: Model evaluation metrics for various modelstable: Model,F1 (macro),F1 (micro),Precision,Recall,AUC, Model A,0.85,0.87,0.88,0.87,0.93, Model B,0.78,0.80,0.81,0.80,0.89, Model C,0.80,0.81,0.85,0.81,0.88, Model D,0.83,0.84,0.86,0.84,0.92, Model E,0.90,0.91,0.92,0.91,0.94","Table 4 shows the evaluation metrics for different models, including Model A, Model B, Model C, Model D, and Model E. The table displays F1 scores (macro and micro), precision, recall, and AUC (Area Under the Receiver Operating Characteristic Curve). Notably, Model E recorded the best performance across all evaluation metrics, with an F1 (macro) score of 0.90, F1 (micro) score of 0.91, precision of 0.92, recall of 0.91, and AUC of 0.94. However, Model B displayed the lowest performance among all the models with the lowest F1 (macro) score of 0.78, F1 (micro) score of 0.80, precision of 0.81, recall of 0.80, and AUC of 0.89. Model A, Model C, and Model D displayed reasonably similar performance, with varying differences in their evaluation metrics."
1560,"caption: Model performances with different evaluation metricstable: Model name,F1-score,Precision,Recall,Balanced accuracy,AUC, Logistic Regression,0.865,0.850,0.880,0.865,0.926, Random Forest,0.912,0.908,0.916,0.913,0.971, Naive Bayes,0.767,0.959,0.632,0.754,0.843, SVM,0.906,0.899,0.913,0.906,0.958, Decision Tree,0.889,0.890,0.888,0.889,0.937","The table shows the performances of various models based on different evaluation metrics such as F1, Precision, Recall, Balanced Accuracy, and AUC. The logistic regression model achieved an F1-score of 0.865 with a balanced accuracy of 0.865 and an AUC of 0.926. The Random Forest model achieved the highest F1-score of 0.912 with a balanced accuracy of 0.913 and an AUC of 0.971. Naive Bayes shows the lowest performance with an F1-score of 0.767 only. The table guides in selecting the best model based on specific evaluation metrics."
1561,"caption: Performance of different models with multiple evaluation metricstable: Model,Accuracy,Precision,Recall,F1, Random Forest,0.95,0.95,0.94,0.94, SVM (kernel=Linear),0.93,0.93,0.91,0.91, SVM (kernel=Gaussian),0.97,0.97,0.96,0.96, Logistic Regression,0.93,0.93,0.91,0.91, Naive Bayes,0.89,0.89,0.87,0.87, Decision Tree,0.93,0.93,0.92,0.92, Neural Network (1 layer),0.95,0.95,0.94,0.94, Neural Network (3 layer),0.97,0.97,0.96,0.96","The table above presents the performance comparison of eight diverse models based on multiple evaluation metrics. The models analysed were Random Forest, SVM (kernel=Linear), SVM (kernel=Gaussian), Logistic Regression, Naive Bayes, Decision Tree, Neural Network with one layer, and Neural Network with three layers. The evaluation metrics compared are Accuracy, Precision, Recall, and F1 score. The best overall performance is obtained by the SVM (kernel=Gaussian) with an Accuracy score of 0.97 and a Precision score of 0.97. Notably, the Neural Network model with three layers also showed impressive performance with an Accuracy score of 0.97 and a Precision score of 0.97. However, the Decision Tree model had the lowest Recall score of 0.92."
1562,"caption: Table 4: Performance metrics of various classification modelstable: Model,Accuracy,F1 score,Recall,Precision, Random Forest,0.92,0.91,0.90,0.92, Support Vector Machine,0.84,0.82,0.79,0.86, Logistic Regression,0.90,0.89,0.87,0.91, Gradient Boosting,0.88,0.86,0.84,0.88, Naive Bayes,0.79,0.76,0.82,0.71","Table 4 shows the summary of performance metrics of different classification models. The table highlights the evaluation of the Random Forest, Support Vector Machine, Logistic Regression, Gradient Boosting, and Naive Bayes models based on accuracy, F1 score, recall, and precision metrics. The Random Forest model achieved the highest accuracy of 0.92, while Naive Bayes model had the lowest performance measures across all metrics. The Logistic Regression model ranked the highest in F1 score and precision metrics, while the Support Vector Machine model had the lowest recall score. Overall, the table presents a clear comparison of the performances of the models."
1563,"caption: Evaluation metrics of different Classification modelstable: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.87,0.89,0.86,0.87, Random Forest,0.91,0.94,0.89,0.91, K-Nearest Neighbors,0.84,0.87,0.82,0.84","This table presents the evaluation metrics of different classification models, including Accuracy, Precision, Recall, and F1-Score. The models compared are Logistic Regression, Random Forest, and K-Nearest Neighbors. The results reveal that Random Forest outperforms the other models in terms of Accuracy, with a score of 0.91. The Precision value of Random Forest is 0.94, which is also the highest among the models. However, Logistic Regression achieved the highest Recall of 0.86. Finally, Random Forest outperformed the other models in F1-Score too, achieving a score of 0.91, with Logistic Regression following closely behind with a score of 0.87."
1564,"caption: The performance of different classifiers based on various evaluation metrics.table: Evaluation Metric,Logistic Regression,Decision Tree,Random Forest,AdaBoost, F1-score,0.82,0.78,0.92,0.88, Precision,0.89,0.75,0.89,0.83, Recall,0.78,0.89,0.95,0.95, Accuracy,0.85,0.81,0.93,0.87","The table gives an overview of multiple classifiers' performance on evaluating the F1-score, precision, recall, and accuracy metrics. The classifiers include Logistic Regression, Decision Tree, Random Forest, and AdaBoost. The Random Forest model shows the highest F1-score of 0.92, followed by AdaBoost with 0.88. However, the Decision Tree and Logistic Regression models' F1-score are lower than the other two classifiers. On precision evaluation, all these classifiers show good precision results that range between 0.75 to 0.89. The Random Forest model exhibited the highest recall score of 0.95, and AdaBoost scored the same. In addition, the Random Forest model showcased the highest accuracy score of 0.93. It is worth mentioning that the performance of classifiers based on different evaluation metrics varies."
1565,"caption: Performance metrics of various classification models on a test set.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.875,0.879,0.937,0.907, Decision Tree,0.827,0.873,0.860,0.866, K-Nearest Neighbors,0.854,0.855,0.929,0.890, Random Forest,0.902,0.907,0.943,0.925, Gradient Boosting,0.897,0.901,0.938,0.919",
1566,"caption: Comparative analysis of different models' performance based on multiple evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall,AUC, Model 1,0.93,0.84,0.76,0.96,0.89, Model 2,0.91,0.80,0.73,0.88,0.84, Model 3,0.87,0.70,0.64,0.79,0.81, Model 4,0.94,0.88,0.81,0.95,0.92, Model 5,0.90,0.78,0.69,0.90,0.87","The table presents a comparative analysis of different models based on multiple evaluation metrics, including accuracy, F1-score, precision, recall, and AUC. The models are named as Model 1, Model 2, Model 3, Model 4, and Model 5. Each model's performance is presented based on the metrics mentioned above. The best performance model among all models varies based on the evaluation metric considered. Model 4 shows the highest accuracy and F1-Score, with 0.94 and 0.88, respectively. On the other hand, Model 1 has the highest precision of 0.76 and recall of 0.96. Lastly, Model 4 shows the highest AUC of 0.92 among all models. Overall, these results suggest that there is no one best model that outperforms the others on all the evaluation metrics."
1567,"caption: Table 4: Performance metrics of different models on a dataset.table: Model,Accuracy,F1-Score,Precision,Recall,AUC, Model A,0.86,0.84,0.76,0.95,0.91, Model B,0.89,0.83,0.82,0.85,0.92, Model C,0.92,0.91,0.89,0.93,0.95, Model D,0.85,0.80,0.82,0.79,0.88, Model E,0.90,0.88,0.85,0.90,0.93","Table 4 presents performance metrics of different models on a dataset, including Accuracy, F1-score, Precision, Recall, and AUC. Model A achieved 0.86 accuracy score, 0.84 F1-score, 0.76 Precision, 0.95 recall, and 0.91 AUC. Model C shows superior performances in all metrics, particularly with 0.92 accuracy, 0.91 F1-score, 0.89 Precision, 0.93 recall, and 0.95 AUC. Model E attained an accuracy score of 0.90, a F1-score of 0.88, a precision of 0.85, a recall of 0.90, and an AUC of 0.93. However, Model D had a relatively poor performance compared to the other models with accuracy, the F1-score, precision, recall, and AUC of 0.85, 0.80, 0.82, 0.79, and 0.88, respectively."
1568,"caption: Evaluation metrics for various classification models.table: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.85,0.86,0.84,0.85, Random Forest,0.89,0.91,0.86,0.88, SVM,0.88,0.88,0.89,0.88, Naïve Bayes,0.82,0.79,0.88,0.83","The table presents the evaluation of four classification models, including Logistic Regression, Random Forest, SVM, and Naïve Bayes, using accuracy, precision, recall, and F1-score metrics. The highest accuracy performance was observed with Random Forest with 0.89, whereas Logistic Regression had the lowest score with 0.85. In terms of precision, Random Forest had the highest score of 0.91, whereas Naïve Bayes had the lowest score of 0.79. SVM had the highest recall score of 0.89, and Naïve Bayes had the lowest recall score of 0.88. Finally, the F1-score metric revealed that Random Forest had the best performance with a score of 0.88. However, Naïve Bayes had the lowest overall F1-Score, with a score of 0.83."
1569,"caption: Comparison of Different Models' Performance Based on Multiple Evaluation Metricstable: Model,F1-score,Precision,Recall,Accuracy, SVM,0.825,0.859,0.794,0.875, LR,0.815,0.831,0.800,0.865, RF,0.846,0.881,0.815,0.890, MLP,0.821,0.849,0.795,0.872","The table is a comparison of different models' performances based on multiple evaluation metrics. The models considered are Support Vector Machine (SVM), Logistic Regression (LR), Random Forest (RF), and Multi-Layer Perceptron (MLP). The table displays the F1-score, precision, recall, and accuracy measures of the models. The results show that the Random Forest model has the highest performance in terms of F1-score (0.846), precision (0.881), recall (0.815), and accuracy (0.890). SVM also performs well, especially in terms of precision (0.859). Overall, the table exhibits the varying strengths and weaknesses of each model and provides valuable insights for selecting an appropriate model based on the evaluation metrics of interest."
1570,"caption: Table 4: Evaluation metrics comparison of different classification models.table: Model,Accuracy,Precision,Recall,F1 Score, Random Forest,0.82,0.86,0.78,0.82, Logistic Regression,0.76,0.79,0.72,0.75, Decision Tree,0.69,0.70,0.68,0.68, Support Vector Machine,0.81,0.84,0.77,0.80","Table 4 displays a comparison of multiple classification models' evaluation metrics based on a dataset of interest. The models include Random Forest, Logistic Regression, Decision Tree, and Support Vector Machine. The table presents the accuracy, precision, recall, and F1 score of each model's performance. Interestingly, the Random Forest model had the highest accuracy (0.82), precision (0.86), and F1 score (0.82). Nevertheless, the Support Vector Machine model outperformed the other models in Recall (0.77). Decision Tree model showed the poorest performance across all four evaluation metrics."
1571,"caption: Table 4: Model performances based on different evaluation metrics.table: Model Name,Precision,Recall,F1 Score,ROC AUC,PR AUC, Support Vector Machine,0.92,0.62,0.74,0.89,0.68, Random Forest,0.89,0.80,0.84,0.91,0.73, AdaBoost,0.85,0.77,0.81,0.88,0.62, XGBoost,0.90,0.81,0.85,0.92,0.77","Table 4 shows the performances of Support Vector Machine (SVM), Random Forest, AdaBoost, and XGBoost models on a binary classification task with multiple evaluation metrics. The evaluation metrics include Precision, Recall, F1 Score, ROC AUC, and PR AUC. Notably, the table indicates that the Random Forest model achieves the highest Precision score of 0.89, while the Support Vector Machine model demonstrates the highest Recall score of 0.62. In terms of F1 Score, the XGBoost model shows the best performance with a score of 0.85, followed closely by the Random Forest model which obtained a score of 0.84. Additionally, XGBoost achieves the highest ROC AUC of 0.92, and PR AUC of 0.77."
1572,"caption: Evaluation metrics of multiple models.table: Model,Accuracy,Precision,Recall,F1-Score, Model A,0.85,0.83,0.89,0.86, Model B,0.78,0.72,0.82,0.76, Model C,0.91,0.89,0.93,0.91, Model D,0.83,0.81,0.86,0.83, Model E,0.95,0.93,0.97,0.95","The table presents a comparison of multiple models based on various performance metrics, including accuracy, precision, recall, and F1-score. The table includes Model A, Model B, Model C, Model D, and Model E. Notably, Model E shows the highest performance score on all metrics with accuracy of 0.95, precision of 0.93, recall of 0.97, and F1-score of 0.95. Meanwhile, Model B exhibits the lowest performance on all metrics, with accuracy of 0.78, precision of 0.72, recall of 0.82, and F1-score of 0.76. Interestingly, Model C shows the highest accuracy but not the best performance on all other metrics."
1573,"caption: Model performances of different algorithms based on multiple evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, Decision Tree,0.80,0.77,0.81,0.74, Naive Bayes,0.60,0.68,0.58,0.80, K-NN (k=5),0.72,0.70,0.65,0.75, SVM (linear kernel),0.81,0.79,0.84,0.74, Random Forest,0.85,0.83,0.85,0.82, XGBoost,0.82,0.81,0.81,0.81","Table presents a comparison of the classification models' performances using multiple evaluation metrics, including accuracy, F1-score, precision, and recall. The evaluated models are Decision Tree, Naive Bayes, K-NN (k=5), SVM (linear kernel), Random Forest, and XGBoost. The table indicates that the Random Forest model outperformed all other models with an accuracy score of 0.85 and an F1-score of 0.83. The SVM model with a linear kernel achieved the highest precision score of 0.84, while the K-NN (k=5) model yielded the best recall score of 0.75. Overall, the table provides a comprehensive comparison of model performances with different evaluation metrics."
1574,"caption: Table 4: Evaluation metrics comparison of different machine learning models.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.85,0.82,0.88,0.85, Random Forest,0.92,0.89,0.94,0.91, Decision Tree,0.82,0.80,0.83,0.81, Support Vector Machine,0.88,0.86,0.90,0.88, Neural Network,0.89,0.87,0.91,0.89","Table 4 above shows the evaluation metrics comparison of different machine learning models. The metrics displayed are accuracy, precision, recall, and their harmonic mean, F1-score. These different models are Logistic Regression, Random Forest, Decision Tree, Support Vector Machine, and Neural Network. The table exhibits that Random Forest had the highest accuracy of 0.92, and the highest precision and recall equal to 0.89 and 0.94, respectively. The Decision Tree has the lowest accuracy, while the Logistic Regression model records the least precision and recall result. Interestingly, Neural Network appears to have a relatively fair balance of the evaluation metrics as it has an accuracy, precision, recall, and F1-Score of 0.89."
1575,"caption: Comparison of different models based on Precision, Recall, F1-score, AUC, and Accuracy.table: Model,Precision,Recall,F1-Score,AUC,Accuracy, SVM,0.93,0.87,0.90,0.83,0.89, NB,0.85,0.77,0.80,0.79,0.83, KNN,0.89,0.82,0.85,0.81,0.87, ANN,0.92,0.86,0.89,0.84,0.88, LR,0.94,0.91,0.92,0.89,0.91","Table X presents a comparison of five different models based on multiple evaluation metrics, including Precision, Recall, F1-score, AUC, and Accuracy. The table includes SVM, NB, KNN, ANN, and LR models. The SVM model produced the highest Precision (0.93) among all the models, followed closely by LR with a Precision score of 0.94. However, NB had the lowest Precision score of 0.85. In terms of Recall, all models performed relatively well, with SVM having the highest Recall score of 0.87 and NB having the lowest score of 0.77. Additionally, LR had the highest F1-score of 0.92, followed by SVM with a score of 0.90, while NB had the lowest score of 0.80. When it comes to AUC and Accuracy, LR produced the highest scores of 0.89 and 0.91, respectively, while NB had the lowest scores of 0.79 and 0.83. Overall, the table demonstrates that different models produced varied performance results based on different evaluation metrics."
1576,"caption: Table 4: Comparison of different models based on evaluation metricstable: Model,Accuracy,F1 Score,Precision,Recall, Model 1,0.83,0.85,0.83,0.87, Model 2,0.84,0.86,0.85,0.87, Model 3,0.81,0.83,0.81,0.85, Model 4,0.85,0.87,0.85,0.89, Model 5,0.84,0.89,0.87,0.91","Table 4 presents a comparison of different models' performances based on multiple evaluation metrics, including accuracy, F1 score, precision, and recall. Model 4 performed the best in terms of accuracy, achieving a score of 0.85, while Model 5 achieved the highest F1 score and recall score with scores of 0.89 and 0.91, respectively. Interestingly, Model 1 achieved the lowest F1 score but the highest precision score amongst all models with a score of 0.83. Overall, the table showcases the importance of considering multiple evaluation metrics while comparing the performances of different models."
1577,"caption: Table 4: Model comparison based on multiple evaluation metrics.table: Model,F1-score,Accuracy,Precision,Recall,Specificity, SVM-linear,0.82,0.82,0.82,0.82,0.84, SVM-RBF,0.80,0.79,0.78,0.84,0.73, Random forest,0.85,0.85,0.84,0.85,0.87, Gradient boosting,0.84,0.84,0.83,0.84,0.85, Decision tree,0.75,0.74,0.74,0.74,0.74","Table 4 provides a comprehensive comparison of five different models in terms of the F1-score, Accuracy, Precision, Recall, and Specificity. The five models compared include SVM-linear, SVM-RBF, Random forest, Gradient boosting, and Decision tree. The Random forest model outperforms the others by achieving the highest F1-score of 0.85, Accuracy of 0.85, Precision of 0.84, and Specificity of 0.87. The Gradient boosting model closely follows with an F1-score of 0.84, Accuracy of 0.84, Precision of 0.83, and Specificity of 0.85. SVM-linear and Decision tree models achieve moderate performance, while the SVM-RBF model demonstrates weaker performance with the least F1-score, Accuracy, and Precision, but relatively high Recall."
1578,"caption: Performance comparison of different models on a binary classification problem.table: Model Name,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.85,0.84,0.85,0.84, Random Forest,0.87,0.86,0.87,0.86, Gradient Boosting,0.89,0.87,0.89,0.87, Naive Bayes,0.78,0.76,0.78,0.76, K-Nearest Neighbors,0.81,0.80,0.81,0.80","The table provides a performance comparison of different models on a binary classification problem based on different evaluation metrics such as accuracy, F1-score, precision, and recall. Among the models, Gradient Boosting outperformed other models, achieving the highest accuracy score of 0.89 compared to Logistic Regression, Random Forest, Naive Bayes, and K-Nearest Neighbors models with the accuracy scores of 0.85, 0.87, 0.78, and 0.81, respectively. However, Naive Bayes and K-Nearest Neighbors models had the lowest performance scores, achieving an F1-score of 0.76 and 0.80, respectively, compared to other models. These results suggest that Gradient Boosting is a promising approach to this binary classification problem."
1579,"caption: Performance of different classification models on the test datasettable: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.85,0.83,0.88,0.86, KNN,0.76,0.77,0.71,0.74, Random Forest,0.89,0.89,0.90,0.89, Naive Bayes,0.82,0.79,0.85,0.81, Neural Network,0.90,0.92,0.87,0.89","Table 1 reports the performance of five models - SVM, KNN, Random Forest, Naive Bayes, and Neural Network - based on four evaluation metrics - accuracy, precision, recall, and F1-score - in classifying a test dataset. The Neural Network model yielded the highest accuracy score of 0.90, while Random Forest model scored the highest in terms of recall and precision with 0.90 and 0.89, respectively. On the other hand, KNN had the lowest F1-Score of 0.74. Overall, the Random Forest and Neural Network models demonstrate high performance across all evaluation metrics and, therefore, are recommended for further usage."
1580,"caption: Performance comparison of different classifiers using multiple evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.89,0.88,0.87,0.88, RF,0.91,0.90,0.92,0.89, LR,0.85,0.87,0.83,0.91, NB,0.78,0.79,0.72,0.87, KNN,0.83,0.84,0.81,0.88","The table highlights the performance comparison of different classifiers using multiple evaluation metrics, including Accuracy, F1-score, Precision, and Recall. SVM, RF, LR, NB, and KNN models' performance results are presented in the table. RF shows the best Accuracy and F1-score with scores of 0.91 and 0.90, respectively, while NB exhibits the worst performance for all evaluation metrics. Furthermore, LR and KNN have the highest and lowest Recall scores, respectively. The Precision metric shows that the RF model has the highest precision, while the NB model has the lowest precision score."
1581,"caption: Performance of different classification models based on Accuracy, Precision, Recall, and F1 Score evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Model A,0.82,0.83,0.84,0.83, Model B,0.75,0.73,0.89,0.80, Model C,0.80,0.76,0.85,0.80, Model D,0.84,0.76,0.93,0.84, Model E,0.78,0.88,0.67,0.76","Table above presents the model performances using different classification models with Accuracy, Precision, Recall, and F1 Score evaluation metrics. Model A attained the highest Accuracy score of 0.82 with a good Precision value of 0.83. Model D performed the best in Recall with a score of 0.93. Interestingly, Model B demonstrated the highest Precision score of 0.73 and Recall score of 0.89, despite having the lowest Accuracy score of 0.75. Lastly, Model E had the highest Precision score of 0.88 but the lowest Recall score of 0.67, with an overall average performance. Overall, Model D demonstrates the best performance based on the four evaluation metrics."
1582,"caption: Evaluation metrics of different models on a binary classification tasktable: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.85,0.88,0.84,0.86, Support Vector Machine,0.82,0.82,0.81,0.81, Random Forest,0.87,0.88,0.88,0.87, XGBoost,0.89,0.89,0.89,0.89","The table presents models' performance evaluation metrics for a binary classification task, including the Logistic Regression, Support Vector Machine (SVM), Random Forest, and XGBoost models. Multiple evaluation metrics such as Accuracy, Precision, Recall, and F1-Score are used to measure the model's performance. XGBoost is the best performer with an accuracy of 0.89, Precision of 0.89, Recall of 0.89, and F1-score of 0.89. On the other hand, the Random Forest model scored 0.87 in Accuracy, 0.88 in Precision and Recall, and 0.87 in F1-Score. The Logistic Regression model achieved moderate results with an accuracy of 0.85, Precision of 0.88, Recall of 0.84, and F1-Score of 0.86, while SVM's performance is the lowest in all four evaluation metrics."
1583,"caption: Performance Results of Different Classification Models Using Multiple Evaluation Metrics.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.92,0.92,0.93,0.91, kNN,0.86,0.85,0.87,0.84, MLP,0.94,0.94,0.95,0.93, RF,0.95,0.95,0.96,0.94",
1584,"caption: Table showing the performance metrics of different classification models using the same dataset.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.7572,0.7898,0.7065,0.7468, Naive Bayes,0.8742,0.9036,0.8225,0.8619, Decision Tree,0.7323,0.7516,0.7141,0.7329, Random Forest,0.8453,0.8645,0.8012,0.8316, XGBoost,0.8652,0.8851,0.8202,0.8513","The table compares the classification performance of five different models: Logistic Regression, Naive Bayes, Decision Tree, Random Forest, and XGBoost. The models were trained and tested on the same dataset, and their accuracy, precision, recall, and F1 score were evaluated. The Naive Bayes model showed the best result with an accuracy score of 0.8742 and F1 score of 0.8619. However, the XGBoost model had the best precision score of 0.8851. The Decision Tree showed the least satisfactory result in terms of all the performance metrics considered. Overall, the table provides a comprehensive comparison of the different models' classification performance, highlighting the Naive Bayes model as the best for this particular dataset."
1585,"caption: Table 4: Model performance based on different evaluation metrics.table: Model Name,Accuracy,Precision,Recall,F1-Score,AUC-ROC, Model 1,0.92,0.91,0.93,0.92,0.85, Model 2,0.94,0.93,0.95,0.94,0.87, Model 3,0.85,0.88,0.80,0.83,0.80, Model 4,0.91,0.93,0.88,0.90,0.84, Model 5,0.93,0.94,0.91,0.92,0.88","Table 4 presents a comparison of multiple models' performance based on different evaluation metrics, including Accuracy, Precision, Recall, F1-Score, and AUC-ROC. Model 2 shows the highest accuracy (0.94) and F1-Score (0.94) among all models. Also, Model 5 attained the highest AUC-ROC of 0.88. Conversely, Model 3 shows the lowest performance based on almost all evaluation metrics, where its Recall metric is the only exception, which scored 0.80. The comparison aims to help in selecting the right model for specific applications, considering the essential evaluation metrics."
1586,"caption: Performance metrics of different models on a binary classification problem.table: Model,Accuracy,Precision,Recall,F1-Score,AUC-ROC, Logistic Regression,0.87,0.83,0.74,0.78,0.94, Decision Tree,0.80,0.75,0.68,0.71,0.82, Random Forest,0.91,0.86,0.81,0.83,0.97, Support Vector Machine,0.83,0.81,0.67,0.72,0.89, Naive Bayes,0.79,0.70,0.61,0.62,0.75","The table displays the accuracy, precision, recall, F1-Score, and AUC-ROC values for different models in a binary classification problem. The evaluated models include Logistic Regression, Decision Tree, Random Forest, Support Vector Machine, and Naive Bayes. Notably, the Random Forest model displays the highest accuracy (0.91) and AUC-ROC (0.97) values, while the Logistic Regression model shows the best precision (0.83). On the other hand, Naive Bayes presents the lowest overall performance metrics. The table highlights the importance of comparing different models' different metrics to choose the most optimal model for a given problem."
1587,"caption: Table 4: Model performance of various classifiers based on different evaluation metrics.table: Model,F1 Score,Precision,Recall,AUC Score,Accuracy, Random Forest,0.81,0.87,0.76,0.89,0.82, Logistic Regression,0.77,0.81,0.73,0.83,0.79, SVM,0.73,0.7,0.77,0.75,0.74, Naive Bayes,0.65,0.68,0.62,0.71,0.68, Decision Tree,0.68,0.72,0.63,0.73,0.71","Table 4 compares the performance of five different classification algorithms: Random Forest, Logistic Regression, SVM, Naive Bayes, and Decision Tree. The table presents the F1 Score, Precision, Recall, AUC Score, and Accuracy evaluation metrics for each model. Notably, the Random Forest model shows the highest F1 Score of 0.81, the highest Precision of 0.87 and the highest AUC score of 0.89. Meanwhile, the Logistic Regression model has the highest Recall score of 0.73. The accuracy metric shows that Random Forest still has the highest score of 0.82, while Naive Bayes has the lowest accuracy score of 0.68. It is interesting to observe that the model with the highest F1 score is not the model with the highest Accuracy score."
1588,"caption: Performance comparison of multiple models based on different evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, Model A,0.91,0.93,0.94,0.92, Model B,0.89,0.91,0.89,0.94, Model C,0.87,0.90,0.91,0.89, Model D,0.84,0.85,0.86,0.84, Model E,0.82,0.82,0.86,0.80","The table compares the performance of different models based on multiple evaluation metrics such as accuracy, F1-score, precision, and recall. Model A shows the highest accuracy and F1-score results of 0.91 and 0.93, respectively. Similarly, Model D performed the best in terms of precision with a score of 0.86. For recall score, Model B obtained the highest score with 0.94. Interestingly, Model C achieved a high F1-score of 0.90 but had a moderate accuracy score of 0.87. The table suggests that different models could show varying performance results, and a suite of evaluation metrics should be used to assess the model's performance comprehensively."
1589,"caption: A comparison of different models' performance based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, Model 1,0.85,0.82,0.87,0.84, Model 2,0.82,0.76,0.91,0.83, Model 3,0.87,0.85,0.81,0.83, Model 4,0.84,0.80,0.89,0.84, Model 5,0.81,0.75,0.93,0.83","The table illustrates a comparison of different models' evaluation metrics, namely accuracy, precision, recall and F1-score. Model 1 had the highest accuracy (0.85), while Model 3 had the highest precision score (0.85). Model 2 had the highest recall score (0.91), whereas Model 5 had the highest F1-score (0.83). Notably, the accuracy scores of Models 1, 4, and 5 were close, with the difference between their scores not exceeding 0.04. On the other hand, there were distinct differences among the precision, recall, and F1-score metrics scores among different models."
1590,"caption: Performance comparison of multiple models using various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score,AUC, Logistic Reg,0.87,0.89,0.84,0.87,0.93, SVM,0.86,0.86,0.82,0.84,0.91, Random Forest,0.92,0.93,0.91,0.92,0.96, XGBoost,0.93,0.92,0.93,0.93,0.97","The table displays a performance comparison of four different models, including Logistic Regression, SVM, Random Forest, and XGBoost, based on various evaluation metrics. The models were trained and tested on the same dataset. The evaluation metrics used here include accuracy, precision, recall, F1 score, and AUC. Notably, the Random Forest and XGBoost models outperform the rest of the models in all evaluation metrics. Both models show high accuracy of 0.92 and above while achieving F1 scores and AUCs of 0.92 and above, indicating significant performance. The table suggests that Random Forest and XGBoost are suitable models for the given task."
1591,"caption: Model Performance on the Test Settable: Model,Accuracy,F1 Score,Precision,Recall,AUC Score, Logistic Regression,0.87,0.80,0.85,0.77,0.92, Random Forest,0.89,0.82,0.86,0.80,0.93, Support Vector Machine,0.91,0.85,0.88,0.83,0.94, Gradient Boosting Classifier,0.90,0.84,0.87,0.82,0.93, Multilayer Perceptron,0.87,0.80,0.85,0.77,0.91","The table presents the performance of different models on the test set. The models include Logistic Regression, Random Forest, Support Vector Machine, Gradient Boosting Classifier, and Multilayer Perceptron. The table presents accuracy, F1 score, precision, recall, and AUC score. Support Vector Machine had the highest accuracy of 0.91, while Random Forest, Gradient Boosting Classifier, and Support Vector Machine scored similarly in all other metrics. However, the differences in the metrics are relatively small, and these models have shown impressive performance on the test set. On the other hand, Logistic Regression and Multilayer Perceptron exhibited the lowest scores in all evaluation metrics."
1592,"caption: Table 4: Performance of different models using various evaluation metrics.table: Model,Precision,Recall,F1-score,ROC AUC,PR AUC, Multinomial Naive Bayes,0.794,0.756,0.773,0.876,0.670, Logistic Regression,0.828,0.802,0.813,0.888,0.706, Random Forest,0.836,0.831,0.833,0.912,0.741, Support Vector Machines,0.834,0.832,0.833,0.900,0.729, Gradient Boosting Classifier,0.842,0.841,0.841,0.916,0.762","Table 4 presents a comparison between five different models using various evaluation metrics to measure their performance. The table shows the precision, recall, F1-score, ROC AUC, and PR AUC of the Multinomial Naive Bayes, Logistic Regression, Random Forest, Support Vector Machines, and Gradient Boosting Classifier models. Interestingly, the Gradient Boosting Classifier model outperformed the other models, achieving the highest F1-score of 0.841 and the highest PR AUC of 0.762. The Random Forest model demonstrated the best ROC AUC with a score of 0.912. Overall, the table provides valuable insights on the performance of different models, allowing for informed decision-making on model selection."
1593,"caption: Table 4: Model performance based on different evaluation metrics.table: Model,Precision,Recall,F1-Score,Accuracy, SVM,0.86,0.88,0.87,0.85, KNN,0.89,0.81,0.85,0.87, Naive Bayes,0.77,0.89,0.83,0.80, Decision Tree,0.83,0.87,0.85,0.83, Random Forest,0.92,0.92,0.92,0.91","Table 4 presents a comparison of different models' performances using various evaluation metrics. The table exhibits five models: SVM, KNN, Naive Bayes, Decision Tree, and Random Forest. The models' evaluation metrics are Precision, Recall, F1-Score, and Accuracy. Interestingly, the Random Forest model shows the best performance results, achieving the highest precision, recall, F1-score, and accuracy of 0.92, 0.92, 0.92, and 0.91, respectively. Additionally, KNN achieved the highest precision score of 0.89, whereas Naive Bayes yielded the highest recall score of 0.89. Therefore, the decision to select the best model depends on the specific use-case and evaluation metrics of importance."
1594,"caption: Model performance metrics for different models.table: Models,F1 Score,Precision,Recall,AUC-ROC,AUC-PR, Model 1,0.9,0.93,0.87,0.94,0.91, Model 2,0.92,0.89,0.96,0.88,0.97, Model 3,0.88,0.86,0.9,0.91,0.8, Model 4,0.91,0.92,0.9,0.97,0.94, Model 5,0.93,0.96,0.9,0.95,0.95","The table displays the F1 Score, Precision, Recall, AUC-ROC, and AUC-PR for multiple machine learning models, including Model 1 to Model 5. The F1 Score shows how well the model balances Precision and Recall, while Precision and Recall measure correctly predicted positive samples and true positive samples, respectively. A higher AUC-ROC score indicates better classification accuracy between positive and negative samples, and higher AUC-PR scores indicate a model capable of optimizing Precision and Recall simultaneously. Model 2 has the highest F1 Score, Precision, and Recall, while Model 4 represents the top-performing model, with the highest AUC-ROC and AUC-PR scores."
1595,"caption: Table 4: Performance metrics of multiple models.table: Model,Precision,Recall,F1-score,PR-AUC,ROC-AUC, Model 1,0.85,0.78,0.81,0.87,0.89, Model 2,0.79,0.83,0.81,0.79,0.77, Model 3,0.96,0.73,0.81,0.93,0.95, Model 4,0.94,0.91,0.91,0.92,0.93, Model 5,0.89,0.92,0.90,0.88,0.87","Table 4 presents the performance evaluation of five different models through various metrics, including Precision, Recall, F1-score, PR-AUC, and ROC-AUC. Model 1 and Model 4 achieved the highest precision scores with 0.85 and 0.94, respectively. Model 3 obtained the highest precision-recall AUC score (PR-AUC) of 0.93, while Model 1 and Model 4 achieved the highest ROC-AUC scores with 0.89 and 0.93, respectively. Interestingly, Model 5 achieved the highest recall score with 0.92. The results show that each model had different strengths with respect to different evaluation metrics."
1596,"caption: Model performance comparison based on accuracy, precision, recall, and F1-score.table: Model,Accuracy (%),Precision (%),Recall (%),F1-score, Model A,78.4,82.5,75.0,78.5, Model B,79.1,86.2,70.2,77.8, Model C,81.5,76.2,80.5,78.2, Model D,82.6,81.4,81.2,81.3, Model E,77.8,72.1,82.6,77.0","The table compares the performance of five different models (Model A, B, C, D, E) based on four evaluation metrics: accuracy, precision, recall, and F1-score. Model D demonstrated the best accuracy of 82.6%, followed by Model C with 81.5%. Model B had the highest precision of 86.2%, while Model A had the highest recall of 75.0%. Model D had the best F1-score of 81.3%. Interestingly, Model E had the highest recall but the lowest F1-score of 77.0%. This table comparison provides insights to choose the best performing model based on multiple evaluation metrics."
1597,"caption: Table 4: Model performance comparison based on different evaluation metrics.table: Model 1,Model 2,Model 3,Model 4, Metric 1,0.86,0.91,0.93,0.87, Metric 2,0.74,0.85,0.88,0.75, Metric 3,0.92,0.89,0.94,0.93, Metric 4,0.68,0.76,0.81,0.71","Table 4 provides a comparison of multiple different models based on four different evaluation metrics. From left to right in the table, the models are named Model 1, Model 2, Model 3, and Model 4. The metrics evaluated in the table are Metric 1, Metric 2, Metric 3, and Metric 4. Interestingly, Model 3 showed the highest scores in all metrics, with scores of 0.93, 0.88, 0.94, and 0.81, respectively. Notably, Model 1 performed the worst in all evaluated metrics. It received scores of 0.86, 0.74, 0.92, and 0.68, respectively. Additionally, Model 2 and Model 4 showed competitive scores in each metric."
1598,"caption: Comparison of Accuracy, F1 Score, Precision, and Recall metrics across different models.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.87,0.84,0.89,0.81, Naive Bayes,0.78,0.72,0.62,0.85, Decision Tree,0.82,0.76,0.79,0.73, Random Forest,0.91,0.89,0.92,0.88, KNN,0.79,0.75,0.68,0.85, XGBoost,0.92,0.91,0.92,0.90","Table 1 presents a comparison of different models' performance based on accuracy, F1 score, precision, and recall metrics. The SVM model achieved the highest accuracy of 0.87, closely followed by the Random Forest model with an accuracy of 0.91.  On the other hand, the XGBoost model showed the highest F1 score, precision, and recall metrics where it scored 0.91, 0.92, and 0.90, respectively. The Naive Bayes model had a lower performance with an accuracy of 0.78, F1 score of 0.72, precision of 0.62, and recall of 0.85. Similarly, the KNN model showed sub-optimal performance with an accuracy of 0.79, F1 score of 0.75, precision of 0.68, and recall of 0.85."
1599,"caption: Table 2: Model Performance Evaluation using Precision, Recall, F1-Score and Accuracy Metrics.table: Model,Precision,Recall,F1-score,Accuracy, SVM,0.82,0.78,0.80,0.83, NB,0.52,0.92,0.67,0.55, KNN,0.70,0.80,0.74,0.73, RF,0.86,0.85,0.84,0.87","Table 2 presents the performance evaluation of four models; SVM, NB, KNN and RF, using different evaluation metrics: precision, recall, F1-score and accuracy. The table compares the results of these models on the same dataset. RF model shows the highest precision (0.86) and accuracy (0.87), while SVM model has the highest recall (0.78). In contrast, NB model exhibits the lowest precision (0.52), F1-score (0.67), and accuracy (0.55). Overall, RF model performs best in terms of the evaluated metrics."
1600,"caption: Model performance based on various evaluation metricstable: Model,Accuracy,Precision,Recall,F1 score, Logistic regression,0.82,0.79,0.75,0.77, Decision tree,0.78,0.75,0.72,0.73, Random forest,0.88,0.85,0.81,0.83, XGBoost,0.90,0.87,0.84,0.86, Support vector machine,0.81,0.77,0.76,0.75","The table presents the performance evaluation of multiple models based on different evaluation metrics, including Accuracy, Precision, Recall, and F1 score. The models compared in this table are Logistic regression, Decision tree, Random forest, XGBoost, and Support vector machine. Among the models, XGBoost shows the highest accuracy score of 0.90 and a Precision score of 0.87, highlighting its overall advantage over other models. Similarly, Random forest also shows good performance based on its high F1 score of 0.83 and Recall score of 0.81. Decision tree, Logistic regression, and Support vector machine models fall behind the other two models in terms of their evaluation metrics."
1601,"caption: Model performance on binary classification task.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,87.5,0.85,0.92,0.81, NB,76.2,0.71,0.88,0.60, LR,89.0,0.87,0.90,0.85, RF,91.3,0.90,0.93,0.88, KNN,82.4,0.80,0.83,0.77","Table titled ""Model Performance on Binary Classification Task"" exhibits numerous models' evaluation metrics used to classify a binary dataset. The models evaluated on their accuracy, F1 score, precision, and recall are SVM, NB, LR, RF, and KNN. Notably, the Random Forest classifier achieved the best overall performance with the highest accuracy of 91.3%, an F1 score of 0.90, precision of 0.93, and recall of 0.88, followed by Logistic Regression (89.0% accuracy, F1 score: 0.87, Precision: 0.90, Recall: 0.85). The SVM model achieved the highest precision of 0.92, while KNN obtained the lowest accuracy, F1 score, precision and recall amongst all the models."
1602,"caption: Table 4: Model performance from different approaches based on multiple evaluation metrics.table: Model,Accuracy,F1-score,Cohen's Kappa, Logistic Regression,0.87,0.85,0.63, K-Nearest Neighbors,0.84,0.81,0.56, Random Forest,0.90,0.83,0.67, Support Vector Machines,0.88,0.84,0.65","Table 4 shows a comparison of the model performance results from various approaches based on multiple evaluation metrics, including accuracy, F1-score, and Cohen's Kappa. The table comprises four different models that are Logistic Regression, K-Nearest Neighbors, Random Forest, and Support Vector Machines. Each model's performance is measured based on its accuracy, F1-score, and Cohen's Kappa value. Notably, the Random Forest model achieved the highest accuracy (0.90) and Cohen's Kappa (0.67), whereas the Logistic Regression approach performed best in terms of F1-score (0.85)."
1603,"caption: Table 4: Performance comparison of multiple models using different evaluation metrics.table: Model,Accuracy,F1-score,Recall,Precision, Model A,0.85,0.80,0.75,0.86, Model B,0.72,0.60,0.68,0.64, Model C,0.93,0.89,0.92,0.86, Model D,0.87,0.64,0.78,0.55, Model E,0.94,0.90,0.95,0.87","Table 4 shows the performance comparison of five different models using various evaluation metrics. The evaluation metrics in the table include Accuracy, F1-score, Recall, and Precision. Model C performed the best with an accuracy score of 0.93 and F1-score of 0.89. It also showed high recall and lower precision, indicating that the model correctly identified most of the positive cases but may have generated false positives. Interestingly, Model E achieved the highest precision score of 0.87, indicating that it was less likely to generate false positives. However, it had a lower recall score, indicating that it might have missed some positive cases. In contrast, Model B showed the poorest performance, with the lowest accuracy and F1-score."
1604,"caption: Performance metrics of various machine learning models.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.85,0.83,0.84,0.87, Decision Tree,0.81,0.79,0.80,0.83, Random Forest,0.89,0.87,0.89,0.85, XGBoost,0.91,0.90,0.91,0.88, SVM,0.83,0.80,0.83,0.79","The table compares different machine learning models' performance in terms of accuracy, F1 score, precision, and recall metrics. Logistic Regression, Decision Tree, Random Forest, XGBoost, and SVM models were evaluated on the same dataset using 10-fold cross-validation. The highest accuracy was achieved by XGBoost, with a score of 0.91. Similarly, the XGBoost model achieved the highest F1 score and precision score of 0.90 and 0.91, respectively. However, Random Forest model managed to obtain the highest recall score of 0.85. The performances of Decision Tree and SVM models were comparatively lower."
1605,"caption: A comparison of different models' accuracy, precision, recall, and F1-score on a binary classification problem.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.85,0.92,0.80,0.86, LR,0.87,0.91,0.85,0.88, KNN,0.83,0.85,0.78,0.81, RF,0.90,0.93,0.89,0.91",
1606,"caption: Performance comparison of different models based on different evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.830,0.820,0.845,0.800, KNN,0.812,0.793,0.826,0.762, RF,0.855,0.844,0.869,0.821, MLP,0.825,0.814,0.829,0.799","The table presents the accuracy, F1-Score, precision, and recall of four different models: Support Vector Machine (SVM), k-Nearest Neighbors (KNN), Random Forest (RF), and Multi-Layer Perceptron (MLP). The table shows that the RF model performed the best with an accuracy of 0.855, F1-Score of 0.844, precision of 0.869, and recall of 0.821. The SVM model achieved the second-best results, with an accuracy of 0.830, F1-Score of 0.820, precision of 0.845, and recall of 0.800. However, the RF model had relatively high precision and recall among all the models. The KNN and MLP models also showed competitive results, with accuracy scores of 0.812 and 0.825, respectively."
1607,"caption: Model performances based on various evaluation metricstable: Model,Accuracy,F1 Score,Precision,Recall,Specificity, Logistic Regression,0.89,0.85,0.86,0.84,0.94, Decision Tree,0.74,0.71,0.72,0.70,0.78, Random Forest,0.91,0.87,0.90,0.84,0.97, Support Vector Machines,0.85,0.81,0.78,0.85,0.75","The table presents the comparison of four different models based on multiple evaluation metrics. The models used in this experiment were Logistic Regression, Decision Tree, Random Forest, and Support Vector Machines (SVM). The evaluation metrics used to assess the models' performance are Accuracy, F1 Score, Precision, Recall, and Specificity. The Random Forest model outperforms all other models with the highest Accuracy score of 0.91 and F1 score of 0.87. The Logistic Regression model performs second-best with an accuracy score of 0.89 and F1 score of 0.85. On the other hand, the Decision Tree model has the lowest accuracy score of 0.74 and F1 score of 0.71, showing inferior performance. Additionally, the table shows that the Random Forest model has the highest Precision score of 0.9, while the SVM model has the highest Recall score of 0.85. Finally, the Specificity score shows that the Random Forest model performed best as it scored 0.97, denoting that it was very effective in classifying actual negative results."
1608,"caption: Evaluation metrics of various models on a classification task.table: Model,Precision,Recall,F1-Score, Logistic Regression,0.84,0.93,0.88, Random Forest,0.81,0.80,0.80, Decision Tree,0.72,0.70,0.71, SVM,0.88,0.86,0.87, Naive Bayes,0.77,0.88,0.82","The table compares the performance of different models on a classification task using multiple evaluation metrics, including Precision, Recall, and F1-Score. The table shows five different models, namely Logistic Regression, Random Forest, Decision Tree, SVM, and Naive Bayes. Interestingly, the Logistic Regression model has the highest Precision score of 0.84, while the SVM model has the highest Recall score of 0.86. Furthermore, the Naive Bayes model has the highest F1-Score of 0.82, indicating balanced performance between Precision and Recall. Overall, the table shows that different models perform differently on various evaluation metrics, and selecting the best model depends on the evaluation metric most important to the task."
1609,"caption: Performance comparison of different machine learning models using accuracy, precision, recall, and F1-score as evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.85,0.86,0.83,0.82, KNN,0.80,0.82,0.78,0.75, RF,0.89,0.91,0.88,0.87, ANN,0.92,0.94,0.91,0.92","Table presents a performance comparison of four machine learning models using accuracy, precision, recall, and F1-score as evaluation metrics. SVM achieved the highest accuracy of 0.85, while ANN performs the highest accuracy of 0.92. Similar to accuracy, ANN had the highest precision, recall, and F1-score of 0.94, 0.91, and 0.92, respectively. RF showed competitive results, with accuracy, precision, recall, and F1-score of 0.89, 0.91, 0.88, and 0.87, respectively. In contrast, KNN had the lowest performance among the four models, achieving an accuracy of only 0.80."
1610,"caption: Table 4: Model evaluation using different metricstable: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.83,0.82,0.86,0.84, Random Forest,0.91,0.92,0.89,0.91, Naive Bayes,0.77,0.71,0.87,0.78, Support Vector Machine,0.87,0.88,0.85,0.86, XGBoost,0.93,0.93,0.91,0.92","The table compares the model performance of Logistic Regression, Random Forest, Naive Bayes, Support Vector Machine (SVM), and XGBoost based on the evaluation metrics - Accuracy, Precision, Recall, and F1-Score. XGBoost model performed the best in all evaluation metrics, demonstrating the highest Accuracy (0.93), Precision (0.93), Recall (0.91), and F1-Score (0.92). The Random Forest model also showed good performance with an Accuracy of 0.91 and an F1-Score of 0.91. Naive Bayes had the lowest Accuracy of 0.77 but outperformed other models in terms of Recall (0.87). Overall, this table indicates that XGBoost and Random Forest models are suitable for the given classification task."
1611,"caption: Table 4: Model evaluation metrics and performance results for different classifiers using the same dataset.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.84,0.86,0.81,0.83, KNN,0.77,0.71,0.89,0.79, Naive Bayes,0.81,0.84,0.75,0.79, Random Forest,0.90,0.91,0.89,0.90, XGBoost,0.92,0.93,0.91,0.92","Table 4 presents a comparison of different classifiers' model performance evaluated using multiple metrics on the same dataset. The table displays the model name, accuracy, precision, recall, and F1-score. Notably, the Random Forest model achieved the highest accuracy score of 0.90, while XGBoost achieved the highest accuracy score of 0.92. Furthermore, XGBoost had the highest precision, recall, and F1-score with scores of 0.93, 0.91, and 0.92, respectively. Interestingly, KNN had the lowest accuracy score of 0.77, although it had the highest recall score of 0.89. Overall, these results show that different classifiers have different strengths and should be evaluated using multiple metrics to determine their efficiency."
1612,"caption: Comparison of models with different evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score, LogReg,0.85,0.78,0.86,0.82, SVM,0.83,0.77,0.84,0.80, RF,0.89,0.82,0.90,0.86, XGB,0.87,0.80,0.88,0.84","Table shows a comparison of different models using multiple evaluation metrics such as accuracy, precision, recall, F1-score. The comparison is performed for LogReg, SVM, RF, and XGB models. The dataset used for training and testing the models is the same, which assures equal representation for all models. The RF model has the highest accuracy (0.89) and F1-score (0.86) among other models. However, LogReg model has the highest recall score of 0.86, followed by SVM and XGB with the same recall score of 0.84. Moreover, the RF model achieves the highest precision with a score of 0.82."
1613,"caption: Table 4: Various Model Performances Using Different Evaluation Metrics.table: Model Name,Precision,Recall,F1 Score,Accuracy,AUC-ROC,AUC-PR, Logistic Regression,0.88,0.76,0.82,0.81,0.89,0.78, Decision Tree,0.79,0.84,0.81,0.75,0.78,0.71, Naive Bayes,0.94,0.61,0.74,0.68,0.73,0.61, Random Forest,0.89,0.86,0.87,0.84,0.92,0.87, SVM,0.91,0.79,0.85,0.85,0.92,0.81","Table 4 demonstrates the comparison of different models' performances using multiple evaluation metrics, including Precision, Recall, F1 Score, Accuracy, AUC-ROC, and AUC-PR. The presented models include Logistic Regression, Decision Tree, Naive Bayes, Random Forest, and Support Vector Machine (SVM), each model trained and tested using the same dataset. Random Forest achieved the highest F1 score of 0.87 and AUC-PR of 0.87. Logistic Regression yielded the best Precision with a score of 0.88, and Naive Bayes has the highest Precision with a score of 0.94. The SVM model gives the highest accuracy score of 0.85. Overall, the Random Forest model appears to be the best performer, achieving high scores in most evaluation metrics."
1614,"caption: Performance comparison of different classification models.table: Model,Accuracy,F1-score,ROC AUC,PR AUC, SVM,0.75,0.72,0.81,0.69, Logistic Reg.,0.82,0.75,0.86,0.77, Random Forest,0.80,0.73,0.85,0.79, XGBoost,0.85,0.81,0.89,0.84, Gradient Boost.,0.83,0.79,0.88,0.83","The table above shows the performance comparison of different classification models using four evaluation metrics - Accuracy, F1-score, ROC AUC, and PR AUC. The models compared are SVM, Logistic Regression, Random Forest, XGBoost, and Gradient Boost. The highest performing model across all metrics is XGBoost with an accuracy of 0.85, F1-score of 0.81, ROC AUC of 0.89, and PR AUC of 0.84. Random Forest and Gradient Boost models follow behind XGBoost with competitive performance in all metrics. However, the SVM model shows the lowest performance in all metrics compared to other models."
1615,"caption: Performance of different models on binary classification task.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.822,0.755,0.749,0.752, Random Forest,0.902,0.848,0.803,0.825, K-Nearest Neigh.,0.854,0.791,0.772,0.779, Naive Bayes,0.789,0.684,0.739,0.683","The table presents the performance of different models on a binary classification task using different evaluation metrics, including Accuracy, Precision, Recall, and F1-Score. From the table, Random Forest achieved the highest accuracy of 0.902, while Naive Bayes performed the worst with an accuracy of 0.789. However, Naive Bayes had the highest Recall and SVM the highest Precision. Therefore, it can be said that the choice of evaluation metric influences the model performance assessment, and model selection should be based on the specific task requirement."
1616,"caption: Table 4: Evaluation Metrics for Different Modelstable: Model,Accuracy,F1-Score,AUC, Logistic Regression,0.82,0.81,0.75, Random Forest,0.84,0.82,0.80, SVM,0.81,0.79,0.73, XGBoost,0.87,0.86,0.84, AdaBoost,0.83,0.82,0.77","Table 4 showcases the evaluation metrics for different models, namely Logistic Regression, Random Forest, SVM, XGBoost, and AdaBoost. The table presents three evaluation metrics: Accuracy, F1-Score, and AUC. From the table, we can see that the XGBoost model outperformed other models with the highest accuracy score of 0.87, F1-Score of 0.86, and AUC of 0.84. It is also notable that the Random Forest model performed the second-best with an accuracy score of 0.84, F1-Score of 0.82, and AUC of 0.80. Through table 4, we can compare different models' performance and select the best model based on the evaluation metrics."
1617,"caption: Table 4: Model performance comparison based on different evaluation metrics.table: Model Name,F1 Score,Accuracy,Precision,Recall, Logistic Regression,0.82,0.84,0.85,0.80, Random Forest,0.88,0.86,0.84,0.92, Support Vector Machine,0.78,0.79,0.82,0.76, Multilayer Perceptron,0.83,0.81,0.79,0.88","Table 4 compares the performance of different models based on four evaluation metrics - F1 score, accuracy, precision, and recall. Four models - Logistic Regression, Random Forest, Support Vector Machine, and Multilayer Perceptron are assessed here. Among these, Random Forest demonstrates the highest F1 score (0.88) and accuracy (0.86). Contrarily, Support Vector Machine achieved the lowest F1 score (0.78) and accuracy (0.79). The Precision metric indicates the Logistic Regression model as the best-performing model (0.85), while the Support Vector Machine model had the lowest precision (0.82). Additionally, Random Forest and Multilayer Perceptron show better recall scores (0.92 and 0.88, respectively) than the other two models. Therefore, Random Forest might be considered the most reliable option for the task at hand."
1618,"caption: Table 4: Performance of different models on evaluation metricstable: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.85,0.82,0.79,0.80, Random Forest,0.93,0.90,0.92,0.91, Decision Tree,0.73,0.68,0.66,0.67, K-Nearest Neighbors,0.80,0.78,0.75,0.76, Support Vector Machine,0.88,0.85,0.82,0.83","Table 4 displays the performance of various models on different evaluation metrics. The table shows the accuracy, precision, recall, and F1 score of Logistic Regression, Random Forest, Decision Tree, K-Nearest Neighbors, and Support Vector Machine models. Notably, the Random Forest model exhibits the highest accuracy of 0.93 and an impressive F1 score of 0.91. In contrast, the Decision Tree model performs the worst among the models presented, with the lowest accuracy of 0.73 and F1 score of 0.67. The Precision and Recall scores across all models vary, indicating different models' strengths in binary classification tasks."
1619,"caption: Performance comparison of different classification models for sentiment analysis.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.85,0.83,0.82,0.87, Naive Bayes,0.81,0.78,0.85,0.73, Random Forest,0.89,0.88,0.86,0.92, K-Nearest Neighbor,0.80,0.77,0.81,0.74","The above table provides a comparison of different classification models used for sentiment analysis based on multiple evaluation metrics, such as Accuracy, F1 Score, Precision, and Recall. The models included in the table are SVM, Naive Bayes, Random Forest, and K-Nearest Neighbor. The Random Forest achieved the highest Accuracy of 0.89, and the highest F1 score of 0.88, with high Precision and Recall scores of 0.86 and 0.92, respectively. The SVM model showed the highest Recall score of 0.87, with Precision, F1-Score, and Accuracy scores almost uniformly high. The Naive Bayes model had the lowest accuracy and F1-Score of 0.81 and 0.78, respectively, with Precision and Recall of 0.85 and 0.73, respectively. The K-nearest Neighbor model performed relatively worse than the other models, achieving an Accuracy score of 0.80 and a Recall score of 0.74. Overall, the Random Forest model appears to be the best performing model for sentiment analysis, followed by SVM and Naive Bayes models in terms of different evaluation metrics."
1620,"caption: Model performance comparison based on accuracy, f1-score, precision, and recalltable: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.86,0.80,0.79,0.83, Random Forest,0.88,0.83,0.82,0.85, Support Vector Machine,0.85,0.78,0.74,0.82, Artificial Neural Network,0.90,0.85,0.84,0.86, Gradient Boosting Machine,0.89,0.84,0.83,0.86","The table presents a comparison of various machine learning models based on their accuracy, f1-score, precision, and recall measures. The models compared in the table include Logistic Regression, Random Forest, Support Vector Machine, Artificial Neural Network, and Gradient Boosting Machine. It's noteworthy that the Artificial Neural Network model had the highest accuracy with a score of 0.90. Conversely, the Support Vector Machine model had the lowest accuracy with a score of 0.85. Furthermore, the Artificial Neural Network model also showed the highest F1-score, precision, and recall compared to other models. In contrast, the Logistic Regression model had the lowest F1-score, precision, and recall measures. These observations suggest that the Artificial Neural Network model may be the best fit for this dataset based on multiple metrics."
1621,"caption: Table 4: Model Performance Comparison across Different Metrics.table: Model,Accuracy,F1 Score,Precision,Recall,AUC, Logistic Regression,0.84,0.83,0.84,0.83,0.91, Random Forest,0.88,0.88,0.88,0.88,0.95, Decision Tree,0.77,0.75,0.76,0.77,0.89, SVM,0.82,0.81,0.83,0.82,0.92, Neural Network,0.89,0.89,0.89,0.89,0.96","Table 4 presents a comparison of model performances using various evaluation metrics like Accuracy, F1 Score, Precision, Recall, and AUC. The table comprises results from five different models- Logistic Regression, Random Forest, Decision Tree, SVM, and Neural Network. The Random forest and Neural Network models showed superior performance in all evaluation metrics, with an accuracy score of 0.88 and 0.89, respectively. The Neural Network model achieved the highest AUC score of 0.96, with the Random Forest achieving the second-highest score of 0.95. The Decision Tree model exhibited the lowest performance among the models, with an accuracy score of 0.77 and AUC score of 0.89."
1622,"caption: Comparative analysis of different machine learning models based on various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, Random forest,0.92,0.92,0.95,0.93, SVM,0.89,0.85,0.90,0.86, KNN,0.83,0.77,0.86,0.80, Naive Bayes,0.77,0.69,0.80,0.74, Decision Tree,0.78,0.75,0.76,0.75","The table above shows a comparative analysis of different machine learning models' performances based on various evaluation metrics, including Accuracy, Precision, Recall, and F1-score. The models evaluated are Random forest, SVM, KNN, Naive Bayes, and Decision Tree. Notably, the Random forest model performed the best, achieving the highest accuracy, precision, recall, and F1 scores of 0.92, 0.92, 0.95, and 0.93, respectively. On the other hand, the Decision Tree model achieved the lowest accuracy, precision, and F1 scores, but had the highest recall score of 0.76. The performance comparison helps to choose the most appropriate machine learning model for the given task based on the evaluation metrics."
1623,"caption: Performance of different models with different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.79,0.83,0.71,0.76, KNN,0.76,0.80,0.66,0.71, LR,0.83,0.87,0.75,0.80, RF,0.85,0.87,0.79,0.82, DT,0.75,0.77,0.68,0.69, MLP,0.87,0.89,0.82,0.84","The table shows the performance of six different models (SVM, KNN, LR, RF, DT, and MLP) used to classify a dataset. The classification accuracy, precision, recall, and F1 score are evaluated. MLP achieves the highest accuracy of 0.87 and F1-score of 0.84. However, the RF model outperforms others concerning precision and recall with 0.87 and 0.79, respectively. SVM model achieved the lowest recall score (0.71) in this comparison. Generally, these metrics can provide insights about a model's strengths and weaknesses and help to select the best model for a given task."
1624,"caption: Performance comparison of four different classifiers using four different evaluation metrics.table: Model,Recall,Precision,F1-score,Accuracy, SVM,0.89,0.92,0.90,0.92, Random Forest,0.92,0.90,0.91,0.91, Logistic Regression,0.88,0.94,0.91,0.92, Multilayer Perceptron,0.93,0.88,0.90,0.90","The table above compares the performance of SVM, Random Forest, Logistic Regression, and Multilayer Perceptron models using recall, precision, F1-score, and accuracy evaluation metrics. The SVM has the highest precision and recall scores of 0.92 and 0.89, respectively, while the Multilayer Perceptron outperforms other models in recall, achieving a score of 0.93. On the other hand, Logistic Regression showed the highest F1-score of 0.91. Finally, the SVM and Logistic Regression models have the highest accuracy of 0.92, while Random Forest and Multilayer Perceptron models have slightly lower accuracy scores of 0.91 and 0.90, respectively."
1625,"caption: Model Comparison Tabletable: Model,Accuracy,F1 Score,Precision,Recall, Decision tree,0.864,0.865,0.895,0.838, Random forest,0.926,0.925,0.953,0.900, Logistic regression,0.906,0.902,0.922,0.883, SVM,0.892,0.886,0.921,0.853, K-NN,0.881,0.876,0.896,0.858, Naive Bayes,0.834,0.829,0.816,0.843","The table presents a comparison of different models' performances in terms of Accuracy, F1 Score, Precision, and Recall metrics on a dataset. The models evaluated include Decision tree, Random forest, Logistic regression, SVM, K-NN, and Naive Bayes. Interestingly, the Random forest model exhibited the highest accuracy (0.926) and F1 Score (0.925), while Decision tree had the highest precision (0.895) and Naive Bayes has the highest recall (0.843). The observed differences in the models' performances could be vital in model selection depending on the data and the problem we want to solve."
1626,"caption: Table 4: Comparison of model performance based on multiple evaluation metrics.table: Model,Accuracy,F1-Score,Cohen's Kappa, SVM,0.875,0.85,0.75, MLP,0.89,0.87,0.78, LR,0.82,0.80,0.67, RF,0.91,0.89,0.82, XGB,0.88,0.86,0.76","Table 4 displays the performance of different models based on accuracy, F1-Score, and Cohen's Kappa. The models compared in this table are SVM, MLP, LR, RF, and XGB. The Random Forest model shows the best performance in all metrics with an accuracy of 0.91, F1-Score of 0.89 and Cohen's Kappa of 0.82. Both MLP and XGB algorithms show similar outstanding performance with the accuracy ranging between 0.88 - 0.89 and the F1-Score ranging between 0.86 - 0.87. SVM and LR models are inferior to the other three models, achieving lower scores in all metrics."
1627,"caption: Table 4: Model performances based on different evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.84,0.82,0.81,0.83, SVM,0.93,0.93,0.95,0.91, Random Forest,0.91,0.91,0.91,0.91, Naive Bayes,0.76,0.73,0.75,0.71, Decision Tree,0.87,0.87,0.87,0.87","Table 4 summarizes the performances of various machine learning models based on different evaluation metrics, including accuracy, F1-score, precision, and recall. The table presents five models, namely Logistic Regression, SVM, Random Forest, Naive Bayes, and Decision Tree. Interestingly, SVM demonstrated the best accuracy of 0.93 followed by Random Forest and Decision Tree at 0.91. SVM also had the highest F1-score of 0.93, while Naive Bayes had performed the worst in all the evaluation metrics. It is worth noting that all models have shown an acceptable level of performance, with no model under-performing below 0.70 in any evaluation metric."
1628,"caption: Table 4: Model performance of seven different models using multiple evaluation metricstable: Model Names,Precision,Recall,F1-score,Accuracy,ROC-AUC, Logistic Regression,0.83,0.85,0.84,0.82,0.95, Decision Tree,0.77,0.74,0.75,0.76,0.63, Random Forest,0.92,0.78,0.80,0.82,0.89, Support Vector Machines,0.88,0.92,0.90,0.84,0.87, k-Nearest Neighbors,0.69,0.62,0.62,0.70,0.73, Naive Bayes,0.66,0.73,0.68,0.65,0.71, Multi-Layer Perceptron,0.90,0.86,0.87,0.83,0.91","Table 4 compares several models based on five evaluation metrics - Precision, Recall, F1-Score, Accuracy, and ROC-AUC. The evaluated models are Logistic Regression, Decision Tree, Random Forest, Support Vector Machines, k-Nearest Neighbors, Naive Bayes, and Multi-Layer Perceptron. The best performance is shown by the Random Forest model having the highest Precision score of 0.92. The MLP model has a good overall performance with high scores in Precision (0.90), Recall (0.86), and F1-Score (0.87). However, the logistic regression model has the highest ROC-AUC of 0.95. Conversely, the Naive Bayes model performed poorly, achieving the lowest scores in all the metrics."
1629,"caption: Table 4: Performance of various machine learning models on predicting disease.table: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.93,0.92,0.94,0.93, Random Forest,0.91,0.89,0.93,0.91, K-Nearest Neighbor,0.89,0.86,0.92,0.89, Support Vector Machine (SVM),0.92,0.90,0.93,0.91, AdaBoost,0.84,0.83,0.85,0.84","Table 4 presents the performance of logistic regression, random forest, k-nearest neighbor, support vector machine (SVM), and AdaBoost models for predicting a disease using multiple evaluation metrics such as accuracy, precision, recall, and F1-score. The logistic regression model shows the highest accuracy score of 0.93, while the random forest model had the second-best score of 0.91. The K-Nearest Neighbor model scored the lowest accuracy among the models with 0.89. The AdaBoost's precision, recall, and F1-score are the lowest among all other models, although it shows a reasonable accuracy score of 0.84. Overall, the results suggest that the logistic regression and random forest models are more suited for predicting the disease based on the given dataset."
1630,"caption: Table 4: Model performance comparison based on accuracy, F1-score, precision, and recall.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.85,0.83,0.80,0.86, RF,0.81,0.78,0.77,0.82, MLP,0.87,0.85,0.83,0.88, XGB,0.83,0.81,0.78,0.85","Table 4 displays a comparison of multiple machine learning models based on their performance regarding accuracy, F1-score, precision, and recall. The table presents the performance results of SVM, RF, MLP, and XGB models. The accuracy values achieved by the models range between 0.81 and 0.87, with MLP exhibiting the highest accuracy value. Additionally, MLP achieved the highest precision and recall values, while SVM obtained the highest F1-score. Interestingly, the RF model achieved the lowest accuracy, F1-score, precision, and recall scores despite the similar dataset used to train and test all models."
1631,"caption: Table 4: Performance comparison of different models based on multiple evaluation metricstable: Model,Acc,Prec,Recall,F1,ROC-AUC,PR-AUC, SVM,0.845,0.865,0.878,0.866,0.823,0.707, Random Forest,0.863,0.872,0.905,0.880,0.861,0.722, MLP,0.882,0.897,0.896,0.895,0.889,0.761, XGBoost,0.872,0.856,0.920,0.877,0.856,0.731","Table 4 presents a performance comparison of multiple models based on various evaluation metrics. The models considered in the table include SVM, Random Forest, MLP, and XGBoost, while the evaluation metrics comprise accuracy (Acc), precision (Prec), recall (Recall), F1 score (F1), ROC-AUC, and PR-AUC. Interestingly, the MLP model attained the best PR-AUC score of 0.761, followed closely by the Random Forest model with a PR-AUC score of 0.722 and highest Recall score of 0.905. On the other hand, the SVM attained the highest precision score of 0.865, while the XGBoost model had the highest ROC-AUC score of 0.856. Overall, the MLP model demonstrated the best model performance based on the evaluation metrics used."
1632,"caption: Table 4: Model performances of different classifiers based on several evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.85,0.86,0.83,0.84, Random Forest,0.90,0.87,0.91,0.89, XGBoost,0.92,0.92,0.90,0.91, MLP,0.88,0.91,0.85,0.88","Table 4 presents the performance evaluation of multiple classifiers based on various evaluation metrics. The evaluated classifiers are Support Vector Machine (SVM), Random Forest, XGBoost, and Multi-layer Perceptron (MLP). The evaluation metrics include Accuracy, Precision, Recall, and F1-Score. Interestingly, the XGBoost classifier achieved the highest Accuracy score of 0.92. The MLP classifier had the highest Precision score of 0.91, while the Random Forest classifier achieved the highest Recall score of 0.91. Finally, the F1-Score showed that the Random Forest classifier had the best performance with a score of 0.89."
1633,"caption: Classification performance of different models using multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.89,0.91,0.86,0.88, K-Nearest Neighbors,0.92,0.87,0.97,0.92, Decision Tree,0.86,0.88,0.83,0.85, Random Forest,0.93,0.93,0.92,0.92, Support Vector Machine,0.91,0.93,0.87,0.90","Table presents the classification performances of Logistic Regression, K-Nearest Neighbors, Decision Tree, Random Forest, and Support Vector Machine using multiple evaluation metrics. The evaluation metrics include accuracy, precision, recall, and F1-score. The Random Forest model achieved the highest scores in all metrics, with accuracy, precision, recall, and F1-score of 0.93, 0.93, 0.92, and 0.92, respectively. Notably, the K-Nearest Neighbors model obtained high scores in all metrics except accuracy, where it got the highest score of 0.92. The Logistic Regression and Support Vector Machine models both had an accuracy score above 0.90 but had slightly lower scores in recall and F1-score. Nevertheless, all models showed robust performance in classification, which suggests that they could be suitable for classification tasks in other areas."
1634,"caption: Performance comparison of different models using various evaluation metrics.table: Models,Accuracy,Precision,Recall,F1-score,AUC-ROC,PR-AUC, Model 1,0.923,0.934,0.845,0.888,0.954,0.920, Model 2,0.891,0.909,0.791,0.845,0.929,0.876, Model 3,0.899,0.892,0.825,0.857,0.941,0.863, Model 4,0.921,0.934,0.841,0.885,0.952,0.918","Table presents a performance comparison of four different models using six different evaluation metrics: Accuracy, Precision, Recall, F1-Score, AUC-ROC, and PR-AUC. The models perform well overall, with accuracy scores ranging from 0.891 to 0.923. Intuitively, Model 1 and Model 4 have comparable performance, with the highest accuracy and PR-AUC scores of 0.923 and 0.920, respectively. However, when examining the precision and recall scores, Model 4 performs marginally better with precision and recall scores of 0.934 and 0.841, respectively. Conversely, Model 2 has the lowest precision and recall scores - 0.909 and 0.791, respectively- but still, achieved an impressive overall performance."
1635,"caption: Table 4: Model Performances Based on Accuracy, F1 Score, Precision, and Recall Metricstable: Model,Accuracy,F1 Score,Precision,Recall, Random Forest,0.915,0.912,0.933,0.892, XGBoost,0.914,0.912,0.925,0.902, Naïve Bayes,0.856,0.861,0.940,0.794, Support Vector,0.904,0.899,0.901,0.897","Table 4 displays the performance of multiple models based on different evaluation metrics. The table includes the models Random Forest, XGBoost, Naïve Bayes, and Support Vector, all of which have varying degrees of accuracy, F1 Score, Precision, and Recall. Interestingly, Random Forest and XGBoost models have the same accuracy and F1 score. However, the Random Forest model has more precision (0.933) than XGBoost (0.925). On the other hand, Naïve Bayes has the highest precision of 0.940, but its accuracy is lower than both Random Forest and XGBoost models. Ultimately, the Support Vector model shows consistency in its accuracy, F1 score, and recall, making it a balanced model amongst all the models presented."
1636,"caption: Table 4: Model evaluation metrics and performance results.table: Model,Accuracy (%),F1-Score (%),Precision (%),Recall (%), Logistic Regression,89.5,87.4,86.1,88.7, Support Vector Machines,92.3,91.6,90.2,93.3, Naive Bayes,86.2,82.1,80.5,83.9, Random Forest,94.7,94.3,94.1,94.6, XGBoost,95.2,95.1,94.6,95.6","Table 4 compares the performance of five different models using various evaluation metrics, including Accuracy, F1-Score, Precision, and Recall. Each row of the table pertains to a single model, and each column represents the performance score of that model using a particular metric. The Random Forest and XGBoost models perform the best with an accuracy score of 94.7 and 95.2% and an F1-Score of 94.3 and 95.1%, respectively. When the focus shifts to Precision, the XGBoost model outperforms all others with a score of 94.6%. The Recall metric for the Support Vector Machines model is the highest at 93.3%."
1637,"caption: Comparison of different models based on various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Model 1,0.90,0.92,0.89,0.91, Model 2,0.85,0.81,0.90,0.85, Model 3,0.89,0.85,0.91,0.88, Model 4,0.91,0.92,0.90,0.91, Model 5,0.83,0.75,0.85,0.80","The table offers a comparison of multiple different models based on four different evaluation metrics, namely Accuracy, Precision, Recall, and F1-Score. Model 1 and Model 4 show very similar performance results across all metrics. Model 2 demonstrated high Precision, but the Recall score is low. On the other hand, Model 3 displays reasonably balanced precision and recall with overall decent Accuracy and F1-Score. Contrarily, Model 5 demonstrated low Precision and F1-Score, while the Recall score is not bad. Overall, the table provides insights into various model performances, and one can choose a suitable model based on the evaluation metric's priority."
1638,"caption: Performance comparison of different models based on multiple evaluation metrics.table: Model 1,Model 2,Model 3,Model 4, Metric 1,0.76,0.92,0.68,0.81, Metric 2,0.62,0.87,0.47,0.71, Metric 3,0.82,0.95,0.74,0.90, Metric 4,0.51,0.91,0.63,0.76","The table compares the performance of four different models using multiple evaluation metrics. For each model, the table presents the results of Metric 1, Metric 2, Metric 3, and Metric 4. Interestingly, all models show the highest performance on different metrics. Specifically, Model 2 demonstrates the overall best performance by obtaining the highest scores on 3 out of 4 metrics. On the other hand, Model 3 demonstrates the poorest performance by obtaining the lowest scores on 3 out of 4 metrics. The table presents valuable insights into the performance comparison of the models with different metrics, which can help researchers choose the best model for their respective use-cases."
1639,"caption: Model performance on classification tasks based on accuracy, F1 score, precision, and recall.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic Reg.,0.89,0.91,0.93,0.89, Decision Tree,0.79,0.79,0.77,0.79, Random Forest,0.92,0.93,0.93,0.93, XGBoost,0.93,0.93,0.95,0.92, SVM,0.88,0.88,0.91,0.88","The table presents the evaluation metrics, accuracy, F1 score, precision, and recall for multiple models trained on a classification task. The models used in this experiment include Logistic Regression, Decision Tree, Random Forest, XGBoost, and SVM. Each model's performance results are documented in the table alongside the evaluation metrics. Interestingly, the Random Forest and XGBoost models achieve the highest accuracy, F1 score, and recall, with the XGBoost model having the highest precision score. The Decision Tree model shows the lowest performance among the five models in all evaluation metrics, and the Logistic Regression model scores consistently on all metrics except for recall."
1640,"caption: Table 4: Model performance comparison using different evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, LogReg,0.84,0.75,0.68,0.82, SVM,0.83,0.74,0.67,0.81, KNN,0.79,0.71,0.61,0.84, RF,0.82,0.72,0.64,0.82, XGB,0.83,0.73,0.66,0.81","The table presents a model performance comparison of Logistic Regression (LogReg), Support Vector Machine (SVM), k-Nearest Neighbors (KNN), Random Forest (RF), and XGBoost (XGB) models using different evaluation metrics, including accuracy, F1-score, precision, and recall. The results indicate that LogReg had the highest accuracy score of 0.84, whereas KNN achieved the highest recall score of 0.84. On the other hand, RF yielded the highest precision score of 0.64. Lastly, the F1-score values range from 0.71 to 0.75 across all models. Overall, the results suggest that these models have relatively similar performance but differ in specific evaluation metrics."
1641,"caption: Table 4: Evaluation metrics of different regression models for predicting housing prices.table: Model,Mean Absolute Error,Root Mean Squared Error,R-Squared, Linear Regression,2.49,3.60,0.72, Decision Tree,2.71,4.04,0.68, Random Forest,2.20,3.30,0.79, XGBoost,2.30,3.53,0.76, Support Vector Regression,2.43,3.53,0.73","Table 4 presents a comparison of different regression models used for predicting housing prices with their respective mean absolute error, root mean squared error, and r-squared metric. Linear regression achieved an MAE of 2.49, RMSE of 3.60, and r-squared of 0.72. The decision tree model exhibited an MAE of 2.71, RMSE of 4.04, and r-squared of 0.68. Random forest attained the best performance across evaluation metrics with an MAE of 2.20, RMSE of 3.30, and r-squared of 0.79. XGBoost achieved an MAE of 2.30, RMSE of 3.53, and r-squared of 0.76 while Support Vector Regression scored an MAE of 2.43, RMSE of 3.53, and r-squared of 0.73."
1642,"caption: Table 4: Model performance based on different evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.85,0.84,0.81,0.88, Decision Tree,0.79,0.78,0.81,0.77, Support Vector Machine,0.83,0.82,0.85,0.80, Random Forest,0.87,0.87,0.86,0.88, XGBoost,0.88,0.88,0.87,0.90","Table 4 compares the performances of five different models based on different evaluation metrics. The evaluation metrics analyzed in this table are Accuracy, F1-Score, Precision, and Recall. The Logistic Regression model achieved the highest Accuracy of 0.85, resulting from a balanced prediction of true positives and true negatives. The highest F1-score of 0.88 was obtained with the XGBoost model; however, it has the lowest recall of 0.90. Additionally, Random Forest and XGBoost models provided the highest Precision and Recall. Overall, each model has unique strengths based on the metrics analyzed."
1643,"caption: Table 4: Model performances based on multiple evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.87,0.86,0.89,0.83, Random Forest,0.92,0.91,0.94,0.89, SVM,0.85,0.84,0.87,0.81, Naive Bayes,0.81,0.80,0.83,0.76","Table 4 compares the performance of different models using multiple evaluation metrics, including accuracy, F1-score, precision, and recall. The table includes Logistic Regression, Random Forest, SVM, and Naive Bayes models. The Random Forest model achieved the highest accuracy of 0.92, while the Logistic Regression model had the highest precision of 0.89. The Random Forest and Logistic Regression models show the highest F1-score of 0.91 and recall of 0.89, respectively. Interestingly, the SVM model achieved the lowest accuracy of 0.85, but it had a lower score in all other metrics compared to other models."
1644,"caption: Model performances based on different evaluation metricstable: Model,Accuracy,F1-score,AUC, Log Regression,0.83,0.70,0.79, SVM,0.81,0.68,0.81, Random Forest,0.90,0.82,0.91, XGBoost,0.89,0.81,0.90, MLP,0.86,0.76,0.85","The table presents a comparison of classification models based on three different evaluation metrics, which are accuracy, F1-score, and AUC. The models evaluated in the table are Log Regression, SVM, Random Forest, XGBoost, and MLP (Multi-Layer Perceptron). The Random Forest model outperforms all the others on all metrics, with accuracy of 0.90, F1-score of 0.82, and AUC of 0.91. SVM, XGBoost, and MLP follow closely, with a maximum difference of 0.03 on any of the three metrics. Interestingly, Log Regression has the lowest performance among all the models on all three criteria, indicating its limited usage for the classification task at hand."
1645,"caption: Comparison of model performance based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score,ROC-AUC,PR-AUC, Model 1,0.91,0.79,0.93,0.86,0.92,0.72, Model 2,0.92,0.81,0.91,0.86,0.89,0.70, Model 3,0.93,0.87,0.93,0.90,0.93,0.80, Model 4,0.90,0.75,0.94,0.83,0.91,0.69, Model 5,0.91,0.80,0.90,0.85,0.91,0.72","The table presents a comparison of five different models' performances based on various evaluation metrics. The models were evaluated using accuracy, precision, recall, F1-score, ROC-AUC, and PR-AUC metrics. Notably, Model 3 shows the best performance results, achieving the highest accuracy of 0.93, precision of 0.87, recall of 0.93, F1-score of 0.9, ROC-AUC of 0.93, and PR-AUC of 0.8. However, Model 2 and Model 5 perform marginally better than Model 3 in terms of accuracy, achieving 0.92 and 0.91, respectively. Model 4 is the least performing model, showing the lowest scores across all the evaluation metrics."
1646,"caption: Performance of models for binary classification problem using different evaluation metricstable: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.76,0.77,0.73,0.81, SVM,0.78,0.79,0.75,0.84, Random Forest,0.79,0.8,0.76,0.85, XGBoost,0.81,0.82,0.79,0.86, MLP,0.83,0.84,0.8,0.89","The table above presents the performance of different models using different evaluation metrics for a binary classification problem. The models in the table are Logistic Regression, SVM, Random Forest, XGBoost, and MLP. The evaluation metrics include Accuracy, F1 Score, Precision, and Recall. Notably, the MLP model shows the best overall performance for all metrics with an accuracy of 0.83, F1 Score of 0.84, precision of 0.8, and recall of 0.89. The XGBoost model also performs well with an accuracy of 0.81, F1 Score of 0.82, precision of 0.79, and recall of 0.86. It is interesting to note that all models performed reasonably well with accuracy scores ranging from 0.76 to 0.83, and F1 Scores ranging from 0.77 to 0.84."
1647,"caption: Performance evaluation of different models using multiple metrics.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.89,0.91,0.87,0.89, Naive Bayes,0.85,0.87,0.80,0.83, Random Forest,0.93,0.94,0.92,0.93, K-Nearest Neighbor,0.85,0.86,0.84,0.85, Gradient Boosting,0.91,0.93,0.89,0.90","The table above shows the results of different machine learning models based on their accuracy, precision, recall, and F1-score. Five models were evaluated in this study, namely SVM, Naive Bayes, Random Forest, K-Nearest Neighbor, and Gradient Boosting. The Random Forest model achieved the highest accuracy of 0.93, followed by Gradient Boosting with 0.91 accuracy. The highest precision was observed in the Random Forest model, with a score of 0.94, and the highest recall was in the SVM model with a score of 0.87. Lastly, the highest F1-score was achieved by the SVM and Random Forest models with 0.89 and 0.93, respectively. Overall, the Random Forest model appears to perform the best across all metrics."
1648,"caption: Comparison of Different Machine Learning Models Based on Different Evaluation Metricstable: Model,Accuracy,F1 Score,Precision,Recall,AUC Score, Logistic Regression,0.85,0.87,0.88,0.86,0.92, Random Forest,0.93,0.94,0.95,0.93,0.97, KNN,0.78,0.79,0.81,0.80,0.84, SVM,0.91,0.92,0.93,0.91,0.95","The table presents the comparison of four different machine learning models, namely Logistic Regression, Random Forest, KNN, and SVM, based on different evaluation metrics. The metrics include Accuracy, F1 Score, Precision, Recall, and AUC Score. The results indicate that the Random Forest model performs impressively better than the rest with an Accuracy of 0.93, F1 Score of 0.94, Precision of 0.95, Recall of 0.93, and AUC Score of 0.97. SVM also exhibits an impressive performance with Accuracy, F1 Score, Precision, Recall, and AUC Score of 0.91, 0.92, 0.93, 0.91, and 0.95, respectively, while the KNN model seems to perform relatively weakly among the models."
1649,"caption: Model Performance Comparison Using Different Evaluation Metrics.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.78,0.62,0.65,0.63, Naïve Bayes,0.82,0.72,0.77,0.74, Decision Tree,0.77,0.64,0.67,0.65, Random Forest,0.84,0.78,0.82,0.79, Gradient Boosting,0.85,0.81,0.83,0.81","The table presents a comparison of five different models using four evaluation metrics - accuracy, precision, recall, and F1-Score. The models include SVM, Naïve Bayes, Decision Tree, Random Forest, and Gradient Boosting. Each of the models was trained and tested using the same dataset. From the table, Random Forest produced the best result in terms of accuracy with a score of 0.84, while Gradient Boosting produced the highest precision and recall with scores of 0.81 and 0.83, respectively. Naïve Bayes produced the best result in terms of F1-Score with a score of 0.74, while SVM produced the worst F1-Score with a score of 0.63. The results suggest that Random Forest and Gradient Boosting are suitable for tasks where high accuracy, recall and precision are vital."
1650,"caption: Performance of Different Models based on Multiple Evaluation Metrics.table: Model Name,Accuracy,Precision,Recall,F1-Score,AUROC,AUPRC, Logistic Regression,0.85,0.87,0.82,0.845,0.91,0.86, Random Forest,0.82,0.81,0.85,0.83,0.89,0.81, Support Vector Machine,0.87,0.88,0.84,0.855,0.92,0.864, Multi-layer Perceptron,0.83,0.76,0.9,0.825,0.88,0.79","The table above illustrates the performance of four machine learning models in the classification problem based on multiple evaluation metrics such as accuracy, precision, recall, F1-score, AUROC, and AUPRC. The evaluated models in this study are Logistic Regression, Random Forest, Support Vector Machine, and Multi-layer Perceptron. It is detected that Logistic Regression has the highest accuracy of 0.85, while Support Vector Machine outperforms over other models with the highest AUROC of 0.92. On the other hand, the Multi-layer Perceptron model attains the highest recall of 0.90 with low precision and AUPRC. The Random Forest model scores the highest precision of 0.81. It can be concluded that each model has different strengths and weaknesses based on the evaluation metrics used for the classification problem."
1651,"caption: Table 4: Model performance based on accuracy, precision, recall, and F1-score.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.87,0.85,0.89,0.87, KNN,0.80,0.78,0.82,0.80, Logistic Regression,0.91,0.90,0.92,0.91, Random Forest,0.93,0.95,0.90,0.92, XGBoost,0.94,0.95,0.93,0.94","Table 4 shows the performance of different models based on their accuracy, precision, recall, and F1-score. The table presents five models, including SVM, KNN, Logistic Regression, Random Forest, and XGBoost. Interestingly, the two ensemble models, Random Forest, and XGBoost outperformed the other three models regarding accuracy, with 0.93 and 0.94 scores, respectively. The Random Forest model achieved the highest precision score of 0.95 and KNN model attained the lowest precision value of 0.78. On the other hand, SVM model delivered the highest recall score of 0.89, while Logistic Regression and XGBoost both scored 0.93 for recall. Finally, XGBoost showcased the highest F1-score of 0.94, followed by Random Forest with 0.92 and the other three models scoring 0.87, 0.80, and 0.91, respectively."
1652,"caption: Table 4: Performance comparison of different models based on different evaluation metrics.table: Models,Metric 1 (Score),Metric 2 (Score),Metric 3 (Score), Model A,0.68,0.45,0.92, Model B,0.75,0.38,0.90, Model C,0.80,0.51,0.87, Model D,0.72,0.60,0.85, Model E,0.81,0.57,0.89, Model F,0.77,0.63,0.91","Table 4 presents a comparison of different models' performance based on three different evaluation metrics. The models include Model A, Model B, Model C, Model D, Model E, and Model F. The three evaluation metrics considered are Metric 1, Metric 2, and Metric 3. Interestingly, Model E outperformed all the other models based on all three metrics with scores of 0.81, 0.57, and 0.89 for Metric 1, Metric 2, and Metric 3, respectively. Model A achieved the least score for Metric 2, while Model D had the least scores for Metric 1 and Metric 3. Overall, the table demonstrates the relative performance of the different models based on diverse evaluation criteria."
1653,"caption: Model performance based on different evaluation metrics.table: Model,Accuracy,F1 Score,Specificity,Sensitivity, KNN,0.82,0.80,0.91,0.73, Logistic Reg,0.79,0.77,0.89,0.68, SVM,0.84,0.81,0.93,0.73, Naive Bayes,0.72,0.70,0.83,0.56, Random Forest,0.88,0.86,0.94,0.77, XGBoost,0.90,0.89,0.95,0.82","Table 1 represents model performance using multiple evaluation metrics, including Accuracy, F1 score, Specificity, and Sensitivity. The table contains six models, including KNN, Logistic Regression, SVM, Naive Bayes, Random Forest, and XGBoost models. Random Forest performs the best among these models with an Accuracy of 0.88, F1 Score of 0.86, Specificity of 0.94, and Sensitivity of 0.77. Notably, XGBoost also demonstrates impressive results with an Accuracy of 0.90, F1 Score of 0.89, Specificity of 0.95, and Sensitivity of 0.82. It should be noted that SVM also exhibited excellent results with an Accuracy of 0.84, F1 Score of 0.81, Specificity of 0.93, and Sensitivity of 0.73."
1654,"caption: Performance results for different models using multiple evaluation metrics including Accuracy, Precision, Recall, and F1-score.table: Model,Accuracy,Precision,Recall,F1-score, LogisticRegression,0.90,0.89,0.91,0.90, Decision Tree,0.85,0.82,0.89,0.85, Random Forest,0.94,0.93,0.95,0.94, SVM,0.87,0.85,0.91,0.88","Table above compares the performance results of four models, namely Logistic Regression, Decision Tree, Random Forest, and SVM based on four evaluation metrics: accuracy, precision, recall, and F1-score. Random Forest achieved the highest accuracy of 0.94, while Logistic Regression had the highest value for precision (0.89), recall (0.91), and F1-score (0.90), respectively. SVM had the lowest accuracy (0.87) and precision (0.85), but a higher recall value (0.91) as compared to Decision Tree (0.89). Overall, Random Forest and Logistic Regression demonstrated better performance on the given classification task."
1655,"caption: Table 4: Performance comparison of various models based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.75,0.69,0.63,0.65, Naive Bayes,0.80,0.68,0.89,0.77, Decision Tree,0.84,0.81,0.73,0.76, Random Forest,0.86,0.86,0.80,0.82, XGBoost,0.88,0.88,0.84,0.85","The table above exhibits the performance comparison of five different models, namely Logistic Regression, Naive Bayes, Decision Tree, Random Forest, and XGBoost. The models' performance is measured based on different evaluation metrics such as Accuracy, Precision, Recall, and F1-score. The results show that XGBoost outperformed the other models with an accuracy score of 0.88 and achieved the highest F1-score of 0.85. On the other hand, Naive Bayes had the highest Recall score of 0.89. Logistic Regression had the lowest F1-score score among all the models, standing at 0.65. Overall, the table provides an informative comparison of the various models' performance based on multiple evaluation metrics."
1656,"caption: Performance comparison of different classification modelstable: Model,Accuracy,F1 Score,Recall,Precision, SVM,0.83,0.84,0.86,0.82, Naive Bayes,0.76,0.75,0.73,0.79, Random Forest,0.88,0.89,0.92,0.87, XGBoost,0.91,0.92,0.93,0.91, AdaBoost,0.86,0.87,0.88,0.86","Table presents five different classification models' performance results evaluated on accuracy, F1 score, recall, and precision metrics. Notably, XGBoost model exhibits the best accuracy score of 0.91, and F1 score of 0.92. Moreover, the Random Forest model on evaluation with recall metric outperforms other models with a score of 0.92, whereas Naive Bayes performs the lowest with a recall score of 0.73. The Precision metric shows that the Random Forest model performs the best with a score of 0.87, while Naive Bayes is the worst-performing model with a precision score of 0.79. Overall, XGBoost and Random Forest models exhibit the best overall performance based on the evaluation metrics."
1657,"caption: Table 2: Model performance metrics for SVM, KNN, RF, and XGBoost.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.87,0.85,0.86,0.89, KNN,0.78,0.75,0.72,0.77, RF,0.92,0.91,0.93,0.90, XGBoost,0.94,0.93,0.95,0.92","Table 2 exhibits the evaluation metrics of different models, SVM, KNN, RF, and XGBoost. The table reports the accuracy, F1-score, precision, and recall measures of each model. It indicates that all models achieved above 0.75 F1-score and 0.85 accuracy. The RF model performed exceptionally well in all metrics, achieving the highest accuracy of 0.92, F1-score, and precision of 0.91 and 0.93 respectively. The XGBoost model also performed well, having an accuracy of 0.94 and high precision and recall scores of 0.95 and 0.92, respectively. The KNN model showed the lowest performance among all models."
1658,"caption: Table 4: Performance comparison of different models based on different evaluation metrics.table: Model,F1 Score,Precision,Recall,Accuracy, SVM,0.80,0.72,0.91,0.89, Decision Tree,0.78,0.82,0.75,0.86, Random Forest,0.85,0.81,0.90,0.88, XGBoost,0.88,0.87,0.88,0.91, Neural Network,0.89,0.91,0.88,0.92","Table 4 shows the performance comparison of different models based on multiple evaluation metrics, including F1 Score, Precision, Recall, and Accuracy. The table presents the results of five models: SVM, Decision Tree, Random Forest, XGBoost, and Neural Network. The Random Forest model achieved the highest F1 Score of 0.85, Precision of 0.81, and Recall of 0.90, while the Neural Network model shows the highest Accuracy of 0.92. Notably, the SVM and Neural Network models show the lowest and highest Precision scores, respectively. These results indicate the varying performance of different models based on different evaluation metrics."
1659,"caption: Table 4: Model evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.93,0.94,0.92,0.93, KNN,0.87,0.90,0.80,0.85, Naive Bayes,0.84,0.85,0.86,0.85, Decision Tree,0.91,0.94,0.88,0.91, Random Forest,0.95,0.96,0.94,0.95, XGBoost,0.96,0.97,0.96,0.97","Table 4 presents the evaluation metrics of various models on a classification task. Five models, including Support Vector Machine (SVM), K-Nearest Neighbors (KNN), Naive Bayes, Decision Tree, Random Forest and XGBoost, were evaluated based on performance metrics, namely, Accuracy, Precision, Recall, and F1-Score. The results show that Random Forest performs the best across all metrics, achieving 0.95 accuracy, 0.96 precision, 0.94 recall and 0.95 F1-Score. SVM achieves the highest accuracy with 0.93, while XGBoost has the best Precision, Recall and F1-Score with 0.97, 0.96, and 0.97, respectively."
1660,"caption: Evaluation metrics for multiple modelstable: Model,Precision,Recall,F1 Score,Accuracy,AUC, Model A,0.8,0.9,0.84,0.78,0.91, Model B,0.74,0.81,0.77,0.76,0.87, Model C,0.75,0.78,0.76,0.72,0.78, Model D,0.85,0.65,0.73,0.79,0.89","The table compares the performance of four models (Model A, Model B, Model C, and Model D) based on multiple evaluation metrics, including Precision, Recall, F1 Score, Accuracy, and AUC. Model A has the highest AUC score of 0.91, followed by Model D with a score of 0.89. Model D performed the best in the Precision evaluation with a score of 0.85, while Model A performed the best in the Recall evaluation with a score of 0.9. It is interesting to note that Model C performed similarly to Model B in all evaluation metrics except for the AUC score, with a difference of 0.09 in favor of Model B. Overall, the results suggest that Model A and Model D are the best-performing models based on these evaluation metrics."
1661,"caption: Table 4 - Model Performance based on Different Evaluation Metricstable: Model Name,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.88,0.76,0.79,0.74, Random Forest,0.92,0.82,0.87,0.78, Decision tree,0.81,0.71,0.72,0.70, Support Vector Machine,0.89,0.78,0.81,0.76, XGBoost,0.94,0.88,0.91,0.85","Table 4 presents a comparison of different models based on different evaluation metrics such as accuracy, F1-Score, precision, and recall. The table has five different models, namely Logistic Regression, Random Forest, Decision tree, Support Vector Machine, and XGBoost. The Random Forest model performs better in all the metrics except Accuracy, which is highest for the XGBoost model. The Decision tree model does not perform well when compared to other models in the table, especially with a low recall value of 0.70. It is observed that the XGBoost model has the highest score among all models in all four evaluation metrics except precision where Random Forest performed better."
1662,"caption: Table 1: Performance comparison of multiple models using various evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Model A,0.87,0.85,0.89,0.84, Model B,0.84,0.81,0.85,0.78, Model C,0.88,0.87,0.91,0.85, Model D,0.82,0.79,0.84,0.74, Model E,0.90,0.89,0.92,0.87","Table 1 shows a performance comparison of multiple models using various evaluation metrics. The evaluation metrics used in the table are Accuracy, F1 Score, Precision, and Recall. The table exhibits five different models, namely Model A, Model B, Model C, Model D, and Model E, and their corresponding evaluation metric values. Among the models, Model E achieved the highest scores in all evaluation metrics, with an Accuracy of 0.90, F1 Score of 0.89, Precision of 0.92, and Recall of 0.87. Meanwhile, Model D represents the worst performance in the table, with an Accuracy of 0.82, F1 Score of 0.79, Precision of 0.84, and Recall of 0.74."
1663,"caption: Performance comparison of different models based on various metrics.table: Model,Accuracy,Precision,Recall,F1 score, Model A,0.87,0.89,0.82,0.85, Model B,0.88,0.85,0.92,0.88, Model C,0.82,0.79,0.88,0.83, Model D,0.91,0.92,0.89,0.91, Model E,0.90,0.91,0.85,0.88","Table 1 shows a performance comparison of five different models based on four evaluation metrics, including accuracy, precision, recall, and F1 score. Model D outperformed the other models, achieving the highest accuracy score of 0.91. Model B exhibited the highest precision score of 0.85 and recall score of 0.92, while Model D achieved the highest F1 score of 0.91. On the other hand, Model C showed the lowest accuracy score of 0.82, precision of 0.79, and F1 score of 0.83 among the presented models. Overall, this table provides valuable insights into the models' strengths and weaknesses, enabling the selection of the most appropriate model for a given task."
1664,"caption: Performance metrics for different classification models.table: Model,Accuracy,Precision,Recall,F1-score, MLP,0.89,0.9,0.87,0.88, SVM,0.83,0.85,0.78,0.8, Random Forest,0.87,0.86,0.9,0.87, Decision Tree,0.79,0.7,0.92,0.79, Gradient Boosting,0.91,0.89,0.93,0.91","The table presents the performance of several classification models, including MLP, SVM, Random Forest, Decision Tree, and Gradient Boosting, evaluated based on four different metrics: Accuracy, Precision, Recall, and F1-score. The MLP and Gradient Boosting models achieved the highest accuracy with 0.89 and 0.91, respectively. On the other hand, SVM had the lowest accuracy of 0.83 but outperformed other models in precision with a score of 0.85. Similarly, Decision Tree had the highest recall value, while Random Forest had the highest F1-score. These results suggest that the model performance differs for different evaluation metrics. Thus, it is crucial to choose the appropriate metric depending on the intended use case."
1665,"caption: Table 4: Model performance based on various evaluation metricstable: Model,Precision,Recall,F1 Score,AUC-PR,AUC-ROC, SVM,0.85,0.75,0.80,0.78,0.87, Random Forest,0.79,0.82,0.80,0.80,0.82, KNN,0.75,0.64,0.68,0.67,0.71, AdaBoost,0.80,0.75,0.74,0.76,0.81, XGBoost,0.83,0.76,0.78,0.80,0.83","Table 4 presents a comparison of different models based on precision, recall, F1 score, AUC-PR, and AUC-ROC. The table includes SVM, Random Forest, KNN, AdaBoost, and XGBoost models. Interestingly, the SVM model achieved the highest AUC-ROC of 0.87, while the Random Forest model scored the best AUC-PR of 0.80. Additionally, XGBoost model shows the best precision, recall, and F1 score among all other models. The comparison of these evaluation metrics can help to understand and select the best-performing model based on the specific requirements of the problem at hand."
1666,"caption: Table 4: Model performance based on Accuracy, F1 score, Precision, and Recall.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic,0.85±0.01,0.84±0.01,0.86±0.02,0.81±0.03, Random Forest,0.87±0.02,0.86±0.03,0.88±0.02,0.84±0.02, KNN,0.80±0.01,0.79±0.02,0.81±0.02,0.77±0.03, SVM (Linear),0.86±0.02,0.86±0.02,0.87±0.03,0.85±0.02, SVM (RBF),0.82±0.02,0.81±0.03,0.83±0.02,0.79±0.03","Table 4 shows the results of a comparison of the performance of five different models - Logistic, Random Forest, KNN, SVM (Linear), and SVM (RBF) using four evaluation metrics - Accuracy, F1 score, Precision, and Recall. Each model's performance was analyzed using the same dataset to ensure consistency. The analysis indicates that the Random Forest model performed the best in terms of Accuracy with a score of 0.87±0.02, followed by SVM (Linear) at 0.86±0.02. The same two models also had the highest F1 Scores at 0.86±0.03 and 0.86±0.02, respectively. The Precision score was highest for Random Forest at 0.88±0.02, and the Recall score was highest for SVM (Linear) at 0.85±0.02. The KNN model had the lowest performance across all evaluation metrics. Overall, the comparison allows researchers to make informed choices when selecting the best model based on the evaluation metric chosen."
1667,"caption: Performance comparison of different models using various evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.87,0.87,0.88,0.86, KNN,0.82,0.80,0.82,0.78, Naive Bayes,0.65,0.72,0.86,0.63, Decision Tree,0.75,0.74,0.76,0.73, Random Forest,0.90,0.90,0.91,0.89","The table presents a comparison of different models' performances using various evaluation metrics, including Accuracy, F1-Score, Precision, and Recall. SVM achieved the highest accuracy score of 0.87, closely followed by Random Forest with a score of 0.90. Notably, Random Forest also shows the highest F1-Score, Precision, and Recall values of 0.90, 0.91, and 0.89, respectively, among the models. Even though Naive Bayes shows low Accuracy and F1-Score scores of 0.65 and 0.72, it achieves the best Precision score of 0.86 among all other models. Meanwhile, KNN and Decision Tree models show moderate performance with an Accuracy score of 0.82 and 0.75, respectively."
1668,"caption: Performance metrics of different modelstable: Model,Accuracy,F1 score,AUC score,Precision, Model A,0.822,0.813,0.829,0.818, Model B,0.808,0.809,0.814,0.811, Model C,0.794,0.802,0.802,0.800, Model D,0.858,0.844,0.870,0.851, Model E,0.872,0.859,0.880,0.865","Table above presents the accuracy, F1 score, AUC score, and precision of multiple different models (Model A to Model E). It can be observed that Model E shows the highest overall performance results in terms of accuracy (0.872), F1 score (0.859), AUC score (0.880), and precision (0.865). On the other hand, Model C has the lowest results in all performance metrics compared to other models (accuracy of 0.794, F1 score of 0.802, AUC score of 0.802, and precision of 0.800). The results suggest that Model E outperforms all other models in terms of accuracy, F1 score, AUC score, and precision."
1669,"caption: Performance of Different Machine Learning Modelstable: Model,Accuracy,F1-score,ROC-AUC,PR-AUC, XGBoost,0.87,0.85,0.93,0.92, Random Forest,0.88,0.87,0.91,0.90, SVM,0.78,0.77,0.83,0.80, Logistic Regression,0.76,0.75,0.79,0.77, Neural Network,0.84,0.82,0.87,0.85","The table above summarizes the performance of multiple machine learning models on the test set using different evaluation metrics. The models include XGBoost, Random Forest, SVM, Logistic Regression, and Neural Network, showing their respective accuracy, F1-score, ROC-AUC, and PR-AUC scores. Interestingly, the Random Forest model achieved the highest F1-score of 0.87, closely followed by XGBoost at 0.85. In terms of accuracy, Random Forest and XGBoost both outperformed the rest of the models at 0.88 and 0.87, respectively. The SVM model had the lowest accuracy at 0.78, while Logistic regression had the lowest F1-score of 0.75. For both ROC-AUC and PR-AUC scores, XGBoost and Random Forest models outperformed other models, indicating their stronger ability in distinguishing positive and negative samples."
1670,"caption: Performance comparison of various supervised models on the classification task.table: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.75,0.73,0.76,0.71, Random Forest,0.81,0.80,0.81,0.78, SVM,0.68,0.62,0.72,0.55, Decision Tree,0.76,0.75,0.76,0.73","Table above compares multiple supervised models for the given classification task in terms of accuracy, f1-score, precision, and recall. The models include Logistic Regression, Random Forest, SVM, and Decision Tree algorithms. Random Forest shows the highest accuracy, f1-score, and precision of 0.81, 0.80, and 0.81, respectively, while Logistic Regression has the highest recall of 0.71. SVM has the worst performance in terms of all evaluation metrics, implying its possible unsuitability for this classification task."
1671,"caption: Performance metrics of multiple modelstable: Model Name,Accuracy,Precision,Recall,F1 Score,AUC-ROC, Model 1,0.92,0.88,0.80,0.84,0.94, Model 2,0.94,0.92,0.85,0.88,0.96, Model 3,0.89,0.82,0.78,0.80,0.92, Model 4,0.95,0.94,0.91,0.92,0.97, Model 5,0.97,0.91,0.95,0.93,0.98","The presented table displays the evaluation results of different models based on their accuracy, precision, recall, F1 score, and AUC-ROC. The evaluation metrics were obtained using the same dataset, with each model's weights separately trained and tested on the dataset. Model 5 achieved the highest accuracy of 0.97, while Model 1 achieved the lowest accuracy of 0.92. Model 4 obtained the best precision score of 0.94, and Model 5 achieved the best recall of 0.95. Furthermore, Model 5 also achieved the highest F1 score of 0.93, while Model 4 and Model 5 obtained the best AUC-ROC of 0.97 and 0.98, respectively. Notably, Model 3 showed the lowest performance result in all metrics, indicating poor performance compared to other models."
1672,"caption: Performance comparison of different models using various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Model A,79.1,0.83,0.70,0.76, Model B,81.6,0.76,0.81,0.78, Model C,78.4,0.81,0.68,0.72, Model D,83.2,0.78,0.85,0.81, Model E,76.5,0.75,0.74,0.72","The table shows a performance comparison of five models( Model A, B, C, D, and E) using various evaluation metrics. The evaluation metrics include Accuracy, Precision, Recall, and F1-Score. Model D achieves the highest accuracy of 83.2 %, while Model E has the lowest accuracy of 76.5%. Model A shows the best Precision of 0.83, whereas Model E has the lowest Precision of 0.75. Model D has the highest Recall of 0.85, whereas Model C has the lowest Recall of 0.68. Model D also has the highest F1-Score of 0.81, whereas Model E has the lowest F1-Score of 0.72."
1673,"caption: Table 4. Performance evaluation of different models using multiple metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.89,0.79,0.91,0.84, Random Forest,0.92,0.86,0.93,0.89, AdaBoost,0.88,0.76,0.87,0.80, SVM,0.91,0.84,0.94,0.89","Table 4 shows the performance evaluation of different models using multiple metrics, which include Accuracy, Precision, Recall, and F1 Score. Logistic Regression, Random Forest, Adaboost, and SVM were evaluated in this table. Random Forest got the highest accuracy of 0.92, while SVM had the highest precision of 0.84. Logistic Regression had the highest recall of 0.91, while Random Forest had the highest F1 score of 0.89. Overall, Random Forest appears to be the best model since it has the best accuracy, precision, and F1 score compared to the other models. Nonetheless, logistic regression's high recall means it also could be good for some use cases."
1674,"caption: Performance of different models on evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Model 1,0.85,0.83,0.88,0.85, Model 2,0.82,0.85,0.79,0.82, Model 3,0.87,0.88,0.83,0.85, Model 4,0.86,0.81,0.91,0.85, Model 5,0.84,0.80,0.92,0.85","The table above exhibits the comparison of different models based on their evaluation metrics including Accuracy, Precision, Recall, and F1 Score. The models are distinguished by Model 1, Model 2, Model 3, Model 4, and Model 5. Interesting findings from the table reveal that Model 3 had the highest Accuracy of 0.87. On the other hand, Model 2 had the highest Precision of 0.85, while Model 5 had the highest Recall of 0.92. Model 1 and Model 4 achieved similar results. This table provides valuable insights into the performances of different models on classification tasks based on multiple metrics."
1675,"caption: Table 4: Model Comparison based on Different Evaluation Metricstable: Model Name,Accuracy,F1 Score,Precision,Recall, Model A,0.85,0.86,0.82,0.90, Model B,0.81,0.82,0.75,0.92, Model C,0.80,0.81,0.77,0.85, Model D,0.75,0.77,0.69,0.87, Model E,0.89,0.90,0.88,0.92","Table 4 provides a comparison of the performance of five different models based on different evaluation metrics. The evaluation metrics include accuracy, F1 score, precision, and recall. Notably, all models were evaluated using the same dataset. The best-performing model for F1 score, precision, and Recall was Model E, with scores of 0.90, 0.88, and 0.92, respectively. On the other hand, Model A achieved the highest accuracy with a score of 0.85. It is crucial to note that Model E outperformed the other models in all the metrics except accuracy, indicating its potential for improving the overall performance of data classification using this dataset."
1676,"caption: Performance results of different classification models on a dataset without class imbalance.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.78,0.65,0.71,0.48, RF,0.80,0.68,0.73,0.53, NB,0.71,0.59,0.66,0.44, MLP,0.75,0.63,0.69,0.49, KNN,0.70,0.57,0.63,0.43","The table presents the performance results of different classification models on a dataset without class imbalance. The models are evaluated based on multiple metrics - Accuracy, F1 Score, Precision, and Recall. The table depicts that the Random Forest model has the highest accuracy and F1 score of 0.80 and 0.68, respectively. In contrast, Naive Bayes has the lowest accuracy and F1 Score of 0.71 and 0.59. Interestingly, the Random Forest model generated the highest Precision score of 0.73, while the MLP has the highest Recall of 0.49. Overall, the Random Forest model appears to perform the best across all four metrics among the five considered models."
1677,"caption: Table 4: Model performance using different evaluation metrics.table: Model Name,Precision,Recall,F1-Score, Naive Bayes Classifier,0.76,0.62,0.68, Support Vector Machine,0.82,0.79,0.80, Random Forest,0.88,0.88,0.88, AdaBoost,0.84,0.81,0.81, K-Nearest Neighbors,0.73,0.84,0.77","Table 4 summarizes the performance of multiple models using different evaluation metrics like Precision, Recall, and F1-Score. The models are Naive Bayes Classifier, Support Vector Machine, Random Forest, AdaBoost, and K-Nearest Neighbors. From the table, we can see that the Random Forest model performs the best with a precision score of 0.88 and recall score of 0.88, which translates into the highest F1-Score of 0.88. It is interesting to note that the K-Nearest Neighbors model has the highest recall score of 0.84 but lacks precision, resulting in a lower F1-Score of 0.77. Overall, while Random Forest is the best-performing model across all metrics, other models offer better recall, precision, or a combination of the two depending on the context of the problem."
1678,"caption: Table 4: Performance of Classification Models on Predicting Heart Disease.table: Model,Classification Accuracy,Sensitivity,Specificity,Precision,F1-Score, SVM,0.86,0.82,0.89,0.84,0.83, KNN,0.82,0.78,0.85,0.81,0.79, Naive Bayes,0.77,0.73,0.80,0.76,0.74, Decision Trees,0.79,0.77,0.81,0.80,0.78, Random Forest,0.88,0.87,0.89,0.89,0.88","Table 4 presents the performance of five different classification models to predict heart disease, measured using classification accuracy, sensitivity, specificity, precision, and F1-score. The models evaluated include SVM, KNN, Naive Bayes, Decision Trees, and Random Forest. Notably, the Random Forest model shows the best classification accuracy of 0.88, with the highest sensitivity of 0.87 and specificity of 0.89. The Naive Bayes model achieved the lowest classification accuracy of 0.77. Interestingly, the Decision Trees model shows the highest precision score of 0.80, while the Random Forest demonstrates the highest F1-score of 0.88. These results suggest that Random Forest may be a useful model for predicting heart disease, given its high classification accuracy and balanced sensitivity and specificity performances."
1679,"caption: Performance comparison of different classification modelstable: Model Name,Precision,Recall,F1-score,Support, Decision tree,0.936,0.943,0.939,500, Naive Bayes,0.941,0.926,0.933,500, Random Forest,0.961,0.952,0.956,500, Multi-Layer Perceptron,0.957,0.942,0.94,500, K-Nearest Neighbors,0.929,0.955,0.938,500, Support Vector Machines,0.944,0.949,0.947,500, Logistic Regression,0.921,0.94,0.93,500, Gradient Boosting,0.956,0.952,0.954,500","The table compares the performance of several classification models according to precision, recall, F1-score, and support metrics. The performance evaluation was run on a dataset of 500 samples. The best performing model was Random Forest with a Precision score of 0.961, Recall of 0.952 and an F1-score of 0.956; followed closely by Gradient Boosting with an F1-score of 0.954. Interestingly, Multi-Layer Perceptron had the highest Precision score of 0.957 which is better than Random Forest. Logistic Regression had the lowest Precision score of 0.921 but still managed to have a decent F1-score of 0.93. Overall, the models in the table performed relatively well, and the results can aid in choosing the best classification models for a given dataset."
1680,"caption: Performance of Different Models on the Test Datatable: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.80,0.84,0.76,0.80, Decision Tree,0.74,0.75,0.72,0.73, Random Forest,0.82,0.87,0.76,0.81, K-Nearest Neighbors,0.69,0.68,0.72,0.70","The table displays the evaluation of various classifiers on the test set. We have used Accuracy, Precision, Recall, and F1-score as performance metrics. The Logistic Regression achieved the highest accuracy of 0.80, while the Random Forest model exhibited the highest precision value of 0.87 and an F1-score of 0.81. Additionally, the Decision Tree classifier achieved a decent recall value of 0.72. On the other hand, K-nearest Neighbors presented the lowest accuracy of 0.69 in the test set. In summary, our results suggest that the Random Forest model outperforms well in this classification task."
1681,"caption: Table 4: Model performance based on various evaluation metricstable: Model Name,Accuracy,F1 Score,Precision,Recall, Model A,0.85,0.87,0.89,0.85, Model B,0.89,0.88,0.90,0.86, Model C,0.91,0.91,0.92,0.90, Model D,0.87,0.86,0.88,0.84","Table 4 summarises the performance of multiple different models based on various evaluation metrics, namely, Accuracy, F1 Score, Precision, and Recall. Model A showed the second-highest accuracy of 0.85 and the highest F1 Score of 0.87 among all models. Model C achieved the highest accuracy of 0.91 and the highest Precision of 0.92. Model B had the highest Precision of 0.90, and Model D had the highest Recall of 0.84. This table's results demonstrate that different models could excel in different metrics, thus emphasising the importance of carefully selecting the appropriate metric based on the problem's objectives."
1682,"caption: Table 4: Model performance based on accuracy, precision, recall, and F1-score.table: Model,Accuracy,Precision,Recall,F1-score, Random forest,0.92,0.89,0.91,0.90, Support Vector Machine,0.90,0.82,0.89,0.85, Multilayer Perceptron,0.86,0.75,0.85,0.79, Decision Trees,0.81,0.69,0.79,0.73","Table 4 presents four different models' performance based on four evaluation metrics: accuracy, precision, recall, and F1-score. Based on the results, the Random forest model achieved the highest accuracy score of 0.92 and recall score of 0.91. The Support Vector Machine model performed relatively well in precision with a score of 0.82, while the Multilayer Perceptron model had the lowest precision score of 0.75. The Decision Trees model had the lowest scores in all evaluation metrics, indicating that it has the weakest performance among the four models."
1683,"caption: Performance comparison of different models based on various evaluation metricstable: Models,Accuracy,Precision,Recall,F1-score,ROC-AUC, Decision Tree,0.862,0.863,0.854,0.858,0.862, Naive Bayes,0.789,0.676,0.888,0.769,0.789, SVM (linear kernel),0.897,0.907,0.885,0.895,0.897, Random Forest,0.903,0.910,0.894,0.900,0.903, XGBoost,0.921,0.928,0.915,0.921,0.921","Table presents a comparison of Decision tree, Naive Bayes, SVM (linear kernel), Random Forest, and XGBoost models based on different evaluation metrics such as Accuracy, Precision, Recall, F1-score, and ROC-AUC. The Random Forest and XGBoost models exhibit the highest Accuracy of 0.903 and 0.921, respectively. Similarly, XGBoost and SVM models demonstrate the highest Precision with scores of 0.928 and 0.907. SVM and Random Forest highlight the best recall with a score of 0.885 and 0.894, respectively. Notably, XGBoost and Random Forest models have a similar F1-score of 0.921. Finally, XGBoost and Random Forest models outperform other models with the highest ROC-AUC score of 0.921 and 0.903, respectively."
1684,"caption: Table 4: Various model performances based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Model A,85.2,0.76,0.82,0.79, Model B,80.2,0.62,0.88,0.73, Model C,88.7,0.84,0.74,0.79, Model D,91.5,0.92,0.88,0.90, Model E,79.6,0.69,0.67,0.68","Table 4 presents the performances of different models based on multiple evaluation metrics, including accuracy, precision, recall, and F1-score. The table shows Model A, B, C, D, and E performances in terms of all the evaluation parameters, where Model D shows the best results across all metrics, achieving the highest accuracy of 91.5 and an F1-score of 90. Model A exhibited the second-highest accuracy and F1-score. However, Model C has a relatively high precision of 0.84, but it has a low recall of 0.74. It is also seen that Model E performed poorly compared to other models across all the evaluation metrics."
1685,"caption: Performance comparison of multiple models for different evaluation metrics.table: Model,Accuracy,F1 Score,Recall,Precision, Model A,0.83,0.88,0.90,0.86, Model B,0.81,0.87,0.88,0.86, Model C,0.79,0.85,0.86,0.84, Model D,0.85,0.89,0.91,0.89, Model E,0.88,0.92,0.94,0.91","The table compares the five different models' performance based on multiple evaluation metrics, including accuracy, F1 score, recall, and precision. Model A achieved the highest accuracy (0.83), Model E achieved the highest F1 score (0.92), and Model E has the highest recall (0.94). All models have high precision scores, with Model A having the lowest but still above 0.85. The results suggest that Model E outperforms the other models based on F1 score and recall metrics, but Model A also has high accuracy. The evaluation metrics are essential to determine the model's overall performance, allowing for the selection of the best-performing model for a specific task."
1686,"caption: Analysis of the Performance of Different Models.table: Model,Precision,Recall,F1 Score,Accuracy, Logistic Regression,0.80,0.85,0.82,0.88, Decision Tree 1,0.72,0.65,0.68,0.75, Decision Tree 2,0.78,0.80,0.79,0.80, Random Forest,0.84,0.84,0.84,0.85, Gradient Boosting,0.86,0.86,0.86,0.87","The above table represents the performance of five different models. The models were evaluated based on four different evaluation metrics such as Precision, Recall, F1 Score, and Accuracy. Interestingly, the Random Forest model exhibits the best result in terms of Precision with a score of 0.84. On the other hand, the Gradient Boosting model shows the best results in terms of Recall, F1 Score, and Accuracy with a score of 0.86, 0.86, and 0.87 respectively. The Decision Tree models seem to have a moderate performance with varying Precision, Recall, and F1 Score. The Logistic Regression model displays an average performance, getting outperformed by some models."
1687,"caption: Numerical results of different classifiers on a classification task.table: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.874,0.876,0.872,0.874, Decision Tree,0.864,0.878,0.845,0.861, Random Forest,0.913,0.914,0.912,0.913, KNN,0.828,0.828,0.831,0.827, Naive Bayes,0.794,0.831,0.725,0.771",
1688,"caption: Performance comparison of multiple models on various evaluation metrics.table: Metric,Model 1,Model 2,Model 3,Model 4, AUC,0.92,0.87,0.89,0.85, F1 Score,0.78,0.81,0.85,0.76, Precision,0.92,0.78,0.84,0.91, Recall,0.67,0.96,0.91,0.54","Table represents the comparison of four models' performances on various evaluation metrics, including AUC, F1 score, precision, and recall. Model 1 achieved the highest AUC score of 0.92, while Model 3 achieved the highest F1 score of 0.85. Model 4 had the highest precision score of 0.91, and Model 2 attained the highest recall score of 0.96. The table suggests that different models perform differently on various evaluation metrics, and researchers need to consider multiple metrics before selecting the best model."
1689,"caption: Table 4: Classification model performance evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.85,0.84,0.85,0.84, Decision Tree,0.82,0.77,0.76,0.78, Random Forest,0.89,0.88,0.89,0.87, Support Vector,0.83,0.82,0.83,0.82, Gradient Boosting,0.91,0.91,0.92,0.90","Table 4 shows the performance evaluation metrics of five classification models: Logistic Regression, Decision Tree, Random Forest, Support Vector, and Gradient Boosting. The models were evaluated using four different metrics: Accuracy, F1 Score, Precision, and Recall. The Random Forest model achieved the highest accuracy of 0.89, while Gradient Boosting model achieved the highest F1 Score, Precision, and Recall of 0.91, 0.92, and 0.90, respectively. Interestingly, the Decision Tree model, which showed the poorest accuracy at 0.82, had the highest Recall score of 0.78."
1690,"caption: Table 4: Evaluation metrics of different modelstable: Models,Precision,Recall,F1-Score,Accuracy, Model_1,0.87,0.68,0.76,0.83, Model_2,0.70,0.92,0.78,0.78, Model_3,0.93,0.60,0.73,0.76, Model_4,0.82,0.72,0.76,0.82","Table 4 compares the performance of four different models based on evaluation metrics such as precision, recall, F1-score, and accuracy. Model_1 shows the highest precision score of 0.87, while Model_3 has the highest recall score of 0.60. The highest F1-score is shown by Model_2, with a score of 0.78. Interestingly, the accuracy scores of both Model_1 and Model_4 are very close, being 0.83 and 0.82, respectively. This table can help in selecting the best model based on evaluation metrics considered important for the task at hand."
1691,"caption: Table 4: Model performance based on different evaluation metricstable: Model,F1-score,Precision,Recall,Accuracy, SVM,0.85,0.82,0.88,0.81, KNN,0.80,0.77,0.86,0.76, Decision Tree,0.73,0.72,0.77,0.69, Logistic Regression,0.88,0.85,0.92,0.84, Random Forest,0.89,0.86,0.93,0.85","Table 4 presents the F1-score, Precision, Recall, and Accuracy performance measures of five different machine learning models, namely SVM, KNN, Decision Tree, Logistic Regression, and Random Forest. Among the five models, Random Forest achieved the highest F1-score of 0.89, while Logistic Regression had the highest Precision of 0.85 and Recall of 0.92. Interesting to note, Decision Tree had the lowest F1-score of 0.73 compared to other models. These results provide insights into the performance of different machine learning models with multiple evaluation metrics, which could help researchers to select the appropriate model for specific tasks."
1692,"caption: Comparison of classification model performances based on various evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.85,0.81,0.83,0.81, Decision Tree,0.81,0.75,0.78,0.73, Naive Bayes,0.78,0.72,0.76,0.69, Random Forest,0.89,0.85,0.87,0.84, XGBoost,0.91,0.88,0.89,0.88, Multi-Layer Perceptron,0.83,0.78,0.82,0.76","The table presents a comparison of the classification model performance based on different evaluation metrics. The table consists of different models, namely SVM, Decision Tree, Naive Bayes, Random Forest, XGBoost, and Multi-layer Perceptron (MLP). The metrics used to evaluate the classifiers are Accuracy, F1-Score, Precision, and Recall. Notably, the Random Forest model outperforms all models with the highest Accuracy, F1-Score, Precision, and Recall scores of 0.89, 0.85, 0.87, and 0.84, respectively. Similarly, the XGBoost model shows the second-best performance in all metrics with a high Accuracy score of 0.91. Conversely, the Naive Bayes model had the lowest performance scores of Accuracy, F1-Score, Precision, and recall at 0.78, 0.72, 0.76, and 0.69, respectively, exhibiting poor classification performance."
1693,"caption: The table represents the performance metrics of the logistic regression, decision trees, random forest, XGBoost, and MLP models based on AUC, ACC, and F1 evaluation metrics.table: Models,AUC,ACC,F1, Logistic Regression,0.865±0.003,0.785±0.002,0.498±0.012, Decision Trees,0.763±0.009,0.702±0.003,0.470±0.122, Random Forest,0.889±0.013,0.811±0.005,0.512±0.030, XGBoost,0.904±0.018,0.824±0.003,0.531±0.020, MLP,0.876±0.016,0.803±0.005,0.508±0.050","The table represents the performance metrics of different machine learning models using AUC, ACC, and F1 evaluation metrics. The logistic regression model has an AUC of 0.865±0.003, ACC of 0.785±0.002, and F1 score of 0.498±0.012. The random forest and XGBoost models have shown significantly better performance than the rest of the models, with an AUC of 0.889±0.013, 0.904±0.018, ACC of 0.811±0.005, 0.824±0.003, and F1 score of 0.512±0.030, 0.531±0.020, respectively. The MLP model has also shown a good performance, with an AUC of 0.876±0.016, ACC of 0.803±0.005, and F1 score of 0.508±0.050. It is worth mentioning that the results are based on the same dataset and evaluated using the same experimental setup to maintain consistency."
1694,"caption: Model evaluation metrics comparisontable: Model,F1-Score (micro),F1-Score (macro),Accuracy,Precision (macro),Precision (micro),Recall (macro),Recall (micro), Random Forest,0.91,0.87,0.94,0.86,0.93,0.89,0.95, Logistic Regression,0.88,0.78,0.94,0.76,0.89,0.81,0.91, kNN,0.85,0.77,0.90,0.72,0.86,0.80,0.88, MLP,0.89,0.74,0.92,0.68,0.87,0.83,0.91","The table presents evaluations for four different models: Random Forest, Logistic Regression, kNN, and MLP. The evaluation metrics include F1-Score (micro), F1-Score (macro), Accuracy, Precision (macro), Precision (micro), Recall (macro), and Recall (micro). Notably, the Random Forest model showed the highest F1-Score (micro) of 0.91 and F1-Score (macro) of 0.87, as well as the best accuracy of 0.94. The MLP model achieved the second-best performance with an F1-Score (micro) of 0.89 and the highest Precision (macro) score of 0.68. Additionally, Logistic Regression and kNN models had a relatively lower F1-Score (macro) of 0.78 and 0.77, respectively, compared to the Random Forest and MLP models."
1695,"caption: Table 4: Performance of Different Models using Multiple Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1-Score,AUC-ROC, Logistic Regression,0.85,0.84,0.87,0.85,0.93, Random Forest,0.89,0.91,0.85,0.88,0.95, SVM,0.84,0.82,0.89,0.85,0.92, Naive Bayes,0.77,0.8,0.73,0.76,0.85","Table 4 presents the performance assessment of four different machine learning algorithms, namely Logistic Regression, Random Forest, SVM, and Naive Bayes, using multiple evaluation metrics, including accuracy, precision, recall, F1-score, and AUC-ROC. The results showcase that Random Forest achieved the highest accuracy of 0.89, followed by Logistic Regression with 0.85, SVM with 0.84, and Naive Bayes with the lowest accuracy of 0.77. However, Naive Bayes showed the highest precision among all models, with a score of 0.8. In contrast, SVM exhibited the highest recall score of 0.89. For F1-score, Random Forest performed the best among all with a score of 0.88. Finally, the AUC-ROC score was highest for the Random Forest model with 0.95, followed by Logistic Regression, SVM, and Naive Bayes."
1696,"caption: Performance comparison of different models based on multiple evaluation metrics.table: Model,Metric 1,Metric 2,Metric 3, Model A,0.85,0.67,0.92, Model B,0.62,0.79,0.71, Model C,0.76,0.80,0.64, Model D,0.91,0.59,0.85, Model E,0.69,0.74,0.88","Table 4 presents a performance comparison of different models based on three evaluation metrics, namely Metric 1, Metric 2, and Metric 3. The models examined in this table are Model A, Model B, Model C, Model D, and Model E. These models were trained and tested on the same dataset. Based on the results in the table, it is interesting to note that Model D achieved the highest score for Metric 1 (0.91) and Metric 3 (0.85). However, Model A obtained the highest score for Metric 2 (0.67). Overall, the performance of the models varied across the different evaluation metrics, implying that the most appropriate model selection depends on the required metric."
1697,"caption: Comparison of model performance using different evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.82,0.74,0.70,0.78, Decision Tree,0.75,0.67,0.62,0.74, Random Forest,0.87,0.80,0.76,0.85, XGBoost,0.89,0.82,0.79,0.87",
1698,"caption: Evaluation metrics for different models.table: Model,Precision,Recall,F1-Score,Accuracy,AUC-ROC, Logistic Regression,0.78,0.91,0.84,0.87,0.92, Decision Tree,0.86,0.88,0.87,0.85,0.83, Random Forest,0.90,0.91,0.90,0.88,0.93, Support Vector Machine,0.83,0.93,0.88,0.90,0.94, Multi-Layer Perceptron,0.87,0.88,0.87,0.86,0.91","The table presented above shows the evaluation metrics, including Precision, Recall, F1-score, Accuracy, and AUC-ROC score, for five different models, i.e., Logistic Regression, Decision Tree, Random Forest, Support Vector Machine, and Multi-Layer Perceptron. As per the table, the Random Forest model shows the best performance with an F1-score of 0.90, Precision of 0.90, Recall of 0.91, Accuracy of 0.88, and the highest AUC-ROC score of 0.93. The Support Vector Machine model achieved the highest AUC-ROC score of 0.94, which is the best score among the five models. The Decision Tree model shows good performance with all metric scores higher than 0.8, while Logistic Regression and Multi-Layer Perceptron fall in between Decision Tree and Random Forest with average to good performance scores."
1699,"caption: Comparison of different machine learning models' performance based on multiple evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Support Vector Machine,0.83,0.82,0.86,0.78, Logistic Regression,0.89,0.88,0.91,0.85, Random Forest,0.91,0.90,0.94,0.87, K-Nearest Neighbors,0.82,0.81,0.84,0.78, Gradient Boosting,0.90,0.89,0.92,0.86","Table presents a comparison of several machine learning models' performance based on multiple evaluation metrics, including Accuracy, F1 Score, Precision, and Recall. The table records the performance of Support Vector Machine (SVM), Logistic Regression, Random Forest, K-Nearest Neighbors (KNN), and Gradient Boosting models. Interestingly, Random Forest achieved the highest Accuracy (0.91) compared to other models, while Logistic Regression had the highest F1 Score (0.88). Among these models, the Precision values vary between 0.84 and 0.94, indicating the model's ability to predict positive samples accurately. Lastly, all models have moderate to high Recall values ranging from 0.78 to 0.87. The table shows that Random Forest has the highest Recall (0.87), while SVM has the lowest Recall (0.78)."
1700,"caption: Table 4: Evaluation Metrics for Different Modelstable: Model Name,Precision,Recall,F1-Score,AUC Score, Model 1,0.89,0.78,0.83,0.925, Model 2,0.91,0.81,0.85,0.917, Model 3,0.87,0.75,0.80,0.923, Model 4,0.85,0.72,0.76,0.890, Model 5,0.90,0.76,0.82,0.909","Table 4 displays evaluation metrics, including Precision, Recall, F1-Score and AUC score, for different models. Model 1 achieved the highest Precision of 0.89, while Model 2 had the highest Recall score of 0.81. Model 2 also had the highest F1-Score of 0.85. Notably, Model 1 achieved the highest AUC score of 0.925 which indicates that it performed best in terms of separating positive and negative classes. Model 4 achieved the lowest score for all metrics. The table provides a comprehensive overview of model performance based on different evaluation metrics."
1701,"caption: Performance comparison of different classification models.table: Model,Accuracy,Sensitivity,Specificity,Precision, Logistic Regression,0.73,0.80,0.65,0.69, Decision Tree,0.66,0.60,0.72,0.58, Random Forest,0.81,0.89,0.73,0.78, XGBoost,0.84,0.86,0.83,0.83, SVM,0.70,0.82,0.58,0.64","Table 1 compares the performance of five classification models, namely Logistic Regression, Decision Tree, Random Forest, XGBoost, and SVM, based on evaluation metrics like Accuracy, Sensitivity, Specificity, and Precision. Among these models, Random Forest and XGBoost showed the highest accuracy scores of 0.81 and 0.84, respectively. While the highest sensitivity score was recorded by the Random Forest with 0.89, the SVM model had the lowest with 0.82. Similarly, Random Forest showed the highest specificity with 0.73, and the XGBoost model had the highest precision with 0.83. Overall, this table provides useful insights into the relative strengths and weaknesses of various classification models."
1702,"caption: Performance measures for four models on a classification task.table: Model,Accuracy,Precision,Recall,F1-score, Random Forest,0.85,0.86,0.84,0.84, SVM,0.89,0.87,0.92,0.89, Logistic Regression,0.76,0.81,0.72,0.74, KNN,0.81,0.82,0.80,0.79","Table presents the performance of four models on a classification problem evaluated by using accuracy, precision, recall, and F1-score metrics. SVM outperforms all models with 0.89 accuracy score and the highest recall score of 0.92. Random Forest has the highest precision with 0.86 but slightly lower than SVM's precision. The K-nearest neighbor (KNN) model has a lower F1-score compared to the other models. It suggests that KNN is less robust in identifying both the positive and negative classes. Logistic regression has the lowest accuracy and recall scores of 0.76 and 0.72, respectively, pointing to a less precise prediction of positive or non-positive cases."
1703,"caption: Table 1: Model evaluation metrics and performance results.table: Model,Accuracy,Precision,Recall,F1-score,AUC, SVM,0.957,0.961,0.926,0.942,0.984, Random Forest,0.962,0.963,0.941,0.951,0.988, K-Nearest,0.943,0.953,0.902,0.925,0.968, Decision Tree,0.943,0.939,0.916,0.923,0.950, Gradient Boost,0.964,0.962,0.952,0.957,0.991","Table 1 shows the evaluation metrics and performance results of different models. The models are SVM, Random Forest, K-Nearest, Decision Tree, and Gradient Boost. The evaluation metrics are accuracy, precision, recall, F1-score, and AUC. The Random Forest and Gradient Boost models demonstrate the highest performance results with the most accurate predictions, highest precision, recall, F1-score, and AUC. In contrast, the K-Nearest model shows the lowest performance results in all evaluation metrics. The SVM and Decision Tree models show similar performance results in all evaluation metrics, with accuracy, precision, recall, F1-score, and AUC scores ranging between 0.943 and 0.961."
1704,"caption: Performance comparison of classification modelstable: Model,Accuracy,F1-score,Recall,Precision, Logistic Reg.,0.85,0.78,0.79,0.77, Decision Tree 1,0.79,0.70,0.74,0.67, Decision Tree 2,0.91,0.83,0.83,0.82, SVM,0.87,0.81,0.82,0.80, Random Forest,0.94,0.90,0.90,0.89","The table shows the performance comparison of five different classification models. The evaluation metrics include accuracy, F1-score, recall, and precision. The Random Forest model achieved the best performance across all metrics with an accuracy of 0.94, F1-score of 0.90, recall of 0.90, and precision of 0.89. The Decision Tree 2 model also performed well with an accuracy of 0.91 and F1-score of 0.83. The Logistic Regression model had the lowest F1-score of 0.78, while the Decision Tree 1 model had the lowest accuracy of 0.79. Overall, the table shows the importance of evaluating models using multiple metrics to get a comprehensive picture of their performance."
1705,"caption: Table 4: Model performances based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.876,0.913,0.814,0.861, Random Forest,0.883,0.926,0.804,0.857, Logistic Regression,0.867,0.888,0.833,0.860, k-NN (k=10),0.831,0.862,0.708,0.777, Naive Bayes,0.782,0.664,0.845,0.745","Table 4 illustrates the performances of multiple classification models for a specific task based on different metrics, including Accuracy, Precision, Recall, and F1-Score. SVM achieved the highest accuracy of 0.876, whereas Random Forest achieved the highest precision of 0.926.  Naive Bayes gives the highest recall of 0.845, while SVM has the highest F1-score of 0.861. Remarkably, the k-NN model achieved the lowest results across all metrics, with an accuracy of 0.831, precision of 0.862, recall of 0.708 and F1-Score of 0.777."
1706,"caption: Table 4: Model performance from different algorithms based on evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.85,0.89,0.82,0.84, Decision Tree,0.79,0.74,0.88,0.80, Random Forest,0.92,0.96,0.89,0.92, k-Nearest Neighbors (k=5),0.83,0.86,0.81,0.83, SVM,0.86,0.89,0.84,0.86","Table 4 exhibits model performance from multiple algorithms based on evaluation metrics. The table exhibits accuracy, precision, recall, and F1 score metrics from five algorithms: Logistic Regression, Decision Tree, Random Forest, k-Nearest Neighbors, and SVM. Notably, the Random Forest algorithm showed the best performance in accuracy (0.92), precision (0.96), and F1 score (0.92) metrics. Alternatively, the Decision Tree algorithm had the best recall score with a value of 0.88."
1707,"caption: Table 4: Evaluation results of different classification methods.table: Method Name,F1 Score,Precision,Recall,Accuracy, Support Vector Machine,0.82,0.75,0.91,0.82, Decision Tree,0.70,0.60,0.85,0.70, Random Forest,0.85,0.82,0.89,0.85, K-Nearest Neighbor,0.62,0.64,0.61,0.62, Multilayer Perceptron,0.80,0.72,0.92,0.80","Table 4 presents the evaluation performance results of five different classification methods based on multiple evaluation metrics. The evaluation metrics include F1 Score, Precision, Recall, and Accuracy. The table displays that the Random Forest method achieved the highest F1 score of 0.85 and Accuracy score of 0.85, indicating that the model performed well in both precision and recall. Meanwhile, the Support Vector Machine (SVM) method obtained the highest precision of 0.75, indicating that the SVM model had a high degree of relevant results among its retrieved results. On the other hand, the Multilayer Perceptron (MLP) method achieved the highest recall score of 0.92, indicating that the MLP model had a low number of false negatives."
1708,"caption: Table 4: Comparison of Model Performance Using Multiple Evaluation Metrics.table: Model,Precision,Recall,F1 Score,Cohen's Kappa, Decision Tree,0.68,0.69,0.67,0.42, Random Forest,0.73,0.76,0.74,0.50, Support Vector Machine,0.75,0.71,0.73,0.51, Logistic Regression,0.71,0.76,0.73,0.47","Table 4 illustrates the performance results of Decision Tree, Random Forest, Support Vector Machine (SVM), and Logistic Regression models using multiple evaluation metrics, including precision, recall, F1 score, and Cohen's kappa. The highest precision is achieved by the SVM model with a score of 0.75, while Random Forest had the highest recall score of 0.76. This resulted in the highest F1 score, with a value of 0.74. Interestingly, Logistic Regression achieved the highest Cohen's kappa score of 0.47, indicating a significant agreement beyond chance. Overall, the results demonstrate that the Random Forest and SVM models outperform Decision Tree and Logistic Regression in a balanced classification problem."
1709,"caption: Performance comparison of various classification models using multiple evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, Random Forest,0.89,0.90,0.91,0.89, Support Vector,0.88,0.87,0.91,0.84, K-Nearest,0.86,0.86,0.87,0.86, Neural Network,0.87,0.86,0.88,0.85","The presented table shows the performance comparison of various classification models based on different evaluation metrics, including accuracy, F1-score, precision, and recall. The Random Forest model shows the highest accuracy of 0.89, whereas the K-Nearest Neighbor model shows the lowest accuracy of 0.86, on the evaluation dataset. Notably, the Random Forest model also shows impressive F1-score, precision, and recall scores with 0.90, 0.91, and 0.89, respectively. However, the Support Vector machine produces the highest precision of 0.91, while the K-Nearest Neighbor shows the highest F1-score and recall scores of 0.86 and 0.86, respectively. Overall, the table illustrates that the Random Forest model performed best across all evaluation metrics."
1710,"caption: Table 4 Performance results for different models using various evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic,0.89,0.88,0.89,0.89, Random Forest,0.79,0.78,0.79,0.84, SVM,0.92,0.91,0.92,0.92, Naive Bayes,0.75,0.74,0.76,0.80","Table 4 presents a comparative analysis of the accuracy, F1 score, precision, and recall performance of different models - Logistic, Random Forest, SVM, and Naive Bayes. The models were evaluated on a binary classification problem on a particular dataset. As shown in the table, the SVM model outperforms the other models in all performance measures, achieving an accuracy score of 0.92, F1 score of 0.91, precision of 0.92, and recall of 0.92. Notably, the Naive Bayes model had the lowest accuracy of 0.75, whereas the Logistic and Random Forest models achieved similar accuracies of 0.89 and 0.79, respectively. These results suggest that SVM is the most appropriate model for the problem domain."
1711,"caption: Model performance of different classification models based on evaluation metricstable: Model,Accuracy,F1-score,AUC-ROC, Model A,0.857,0.876,0.923, Model B,0.892,0.908,0.920, Model C,0.903,0.912,0.928, Model D,0.874,0.897,0.919, Model E,0.919,0.932,0.942","The table compares the performance of five different classification models based on three evaluation metrics - accuracy, F1-score, and AUC-ROC. Model E shows the best performance on all three metrics with an accuracy of 0.919, F1-score of 0.932, and AUC-ROC of 0.942. Model C also performed well, achieving an accuracy of 0.903, F1-score of 0.912, and AUC-ROC of 0.928. Model B had a higher accuracy of 0.892 but had slightly lower F1-score and AUC-ROC than Model C. Model A and Model D show the lowest performance across all the three metrics. Overall, Model E shows the best performance with the highest values on all metrics, while Model A and Model D show the lowest performance."
1712,"caption: Table 4: Classifier Performance Evaluationtable: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.89,0.86,0.92,0.83, Naive Bayes,0.80,0.74,0.91,0.62, Decision Tree,0.82,0.79,0.83,0.76, Random Forest,0.92,0.90,0.94,0.89, XGBoost,0.91,0.88,0.93,0.84",
1713,"caption: Comparison of model performances using different evaluation metrics.table: Models,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.85,0.87,0.76,0.80, Decision Tree,0.87,0.79,0.92,0.85, Random Forest,0.91,0.91,0.87,0.89, Gradient Boosting,0.90,0.92,0.86,0.89, Support Vector Machine,0.83,0.85,0.79,0.80",
1714,"caption: Performance metrics of different modelstable: Model Name,Precision,Recall,F1 Score,Accuracy, Model A,0.87,0.92,0.89,0.95, Model B,0.91,0.87,0.89,0.94, Model C,0.83,0.96,0.89,0.92, Model D,0.76,0.81,0.78,0.89, Model E,0.95,0.94,0.95,0.97","Table presents the performance comparison of five models. The models' precision, recall, F1 score, and accuracy were evaluated. Model E has the best performance among them in all metrics, with perfect precision, high recall, and accuracy of 0.95 or higher. Model B scored the second-best F1 score and accuracy with a slightly lower precision and recall than Model E. Model A and Model C show close performance to Model B, except for their precision and recall values, respectively. Model D shows the lowest F1 score and accuracy among the models, with the lowest precision and recall values."
1715,"caption: Table 4: Model performances based on different evaluation metricstable: Model,F1-score,Precision,Recall,Accuracy, Random Forest,0.89,0.86,0.93,0.88, SVM,0.86,0.81,0.92,0.86, Logistic Reg.,0.85,0.79,0.93,0.85, Naive Bayes,0.78,0.67,0.93,0.78","Table 4 shows the F1-score, precision, recall, and accuracy of four different models: Random forest, SVM, Logistic Regression, and Naive Bayes. The table aims to compare the models' overall performance based on different evaluation metrics. The Random Forest model shows the highest F1-score of 0.89, while the Naive Bayes model had the lowest F1-score of 0.78. The Naive Bayes model, surprisingly, achieved the highest recall among the models with a score of 0.93. Noticeably, the precision scores of all models were close, with SVM having the highest precision and Naive Bayes having the lowest precision. Furthermore, Random Forest and Logistic Regression models have similar accuracy scores of 0.88 and 0.85, respectively; while SVM and Naive Bayes models achieved 0.86 and 0.78 accuracy scores, respectively."
1716,"caption: Model performance comparison using different evaluation metrics.table: Model name,Precision,Recall,Specificity,F1 score,Accuracy, Logistic Regression,0.82,0.70,0.90,0.75,0.81, Random Forest,0.85,0.81,0.88,0.83,0.84, Support Vector Machine,0.81,0.68,0.87,0.73,0.79, K-Nearest Neighbors,0.79,0.61,0.85,0.69,0.76, Neural Network,0.87,0.80,0.89,0.83,0.84","The table compares the performance of five different models based on various evaluation metrics. The models include Logistic Regression, Random Forest, Support Vector Machine (SVM), K-Nearest Neighbors, and Neural Networks. The evaluation metrics used for comparison are Precision, Recall, Specificity, F1 score, and Accuracy. The Random Forest model performed the best in most metrics, achieving an F1 score of 0.83, Precision of 0.85, Recall of 0.81, Specificity of 0.88, and Accuracy of 0.84. However, the Neural Network model outperformed all other models in Precision with a score of 0.87. Overall, the table shows that the Random Forest model gave the highest performance results across most of the evaluation metrics compared to other models."
1717,"caption: Table 4: Performance comparison of different models based on multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, ModelA,0.874,0.804,0.925,0.861, ModelB,0.892,0.826,0.928,0.854, ModelC,0.891,0.818,0.939,0.861, ModelD,0.901,0.847,0.910,0.883, ModelE,0.885,0.801,0.943,0.853","Table 4 presents the performance comparison of five different models based on the evaluation metrics of Accuracy, Precision, Recall, and F1-Score. The table exhibits varying performance scores, with ModelD showing the highest accuracy of 0.901 and F1-Score of 0.883. Interestingly, even though ModelB has the second-highest accuracy, it shows the highest precision score of 0.826. ModelC, on the other hand, exhibits the highest recall score of 0.939. Finally, ModelA and ModelE have the same recall score of 0.925 and 0.943, respectively."
1718,"caption: Comparison of different models based on Precision, Recall, F1 Score, and Accuracy.table: Model Name,Precision,Recall,F1 Score,Accuracy, SVM,0.85,0.86,0.85,0.85, Logistic Regression,0.72,0.70,0.69,0.71, Decision Tree,0.79,0.81,0.80,0.80, Random Forest,0.85,0.86,0.86,0.86, AdaBoost,0.83,0.82,0.82,0.83, Gradient Boosting,0.86,0.85,0.85,0.85","Table presents a comparison between SVM, Logistic Regression, Decision Tree, Random Forest, AdaBoost, and Gradient Boosting models' performance metrics such as Precision, Recall, F1 Score, and Accuracy. From the table, the Random Forest model achieved the highest precision, recall, and F1 score with a score of 0.85, 0.86 and 0.86, respectively. However, all different models show high accuracy, with the lowest score being 0.71 obtained by Logistic Regression. Interestingly, AdaBoost and SVM models show the same precision score of 0.83. The Gradient Boosting model achieved the highest precision score of 0.86. Overall, the table indicates that the Random Forest model has the best overall performance compared to the other models."
1719,"caption: Performance comparison of different models using various evaluation metrics.table: Models,Accuracy,Precision,Recall,F1 Score, Model A,0.87,0.85,0.89,0.87, Model B,0.84,0.81,0.90,0.85, Model C,0.91,0.92,0.87,0.89, Model D,0.88,0.90,0.84,0.87, Model E,0.93,0.91,0.96,0.93","Table above exhibits five different models' performance in terms of accuracy, precision, recall, and F1 score. Model C has the highest accuracy of 0.91, and Model E exhibits the best Precision and Recall score with 0.91 and 0.96, respectively. Additionally, Model D has the highest specificity with a precision score of 0.90. However, Model E again demonstrated the best F1 score with 0.93, indicating the highest balanced performance among all models. Overall, the table provides comprehensive evaluation metrics to judge models' performance from different angles, facilitating more informed decisions in model selection."
1720,"caption: Table 4: Model performances based on different evaluation metrics.table: Model,Accuracy,F1 Score,AUC, Model A,0.85,0.82,0.92, Model B,0.93,0.91,0.84, Model C,0.76,0.65,0.73, Model D,0.96,0.94,0.98, Model E,0.87,0.76,0.79","Table 4 displays the model performances of five different models based on three different evaluation metrics, namely Accuracy, F1 Score, and AUC. Model D achieved the best result of 0.96 in terms of Accuracy, followed by Model B, which showed an accuracy of 0.93. Model E has an Accuracy score of 0.87. In terms of F1 Score, Model D showed a score of 0.94, which is the highest among all the models. Model A showed the highest AUC score of 0.92, and Model D had an AUC score of 0.98, which is noticeably higher than the other models. Interestingly, Model D showed the best performances in two different evaluation metrics, namely Accuracy and F1 Score."
1721,"caption: Model performance evaluation based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, SVM,0.89,0.91,0.84,0.87, KNN,0.85,0.88,0.78,0.80, Logistic Regression,0.91,0.93,0.87,0.90, Random Forest,0.92,0.94,0.89,0.91, XGBoost,0.94,0.95,0.92,0.93","The above table, captioned 'Model performance evaluation based on different evaluation metrics', presents the performance evaluation of various models based on different evaluation metrics. The table reports five different models, including SVM, KNN, Logistic Regression, Random Forest, and XGBoost. The table records the models' respective accuracy, precision, recall, and F1 scores. The results show that the XGBoost model performs the best with an accuracy, precision, recall, and F1 score of 0.94, 0.95, 0.92, and 0.93, respectively. The Random Forest model follows closely with an accuracy, precision, recall, and F1 score of 0.92, 0.94, 0.89, and 0.91, respectively. The KNN model performs the worst with an accuracy, precision, recall, and F1 score of 0.85, 0.88, 0.78, and 0.80, respectively."
1722,"caption: Performance evaluation metrics for different modelstable: ```, Model,Accuracy,F1-Score,Precision,Recall, Model A,0.80,0.78,0.86,0.71, Model B,0.85,0.81,0.89,0.74, Model C,0.83,0.75,0.80,0.70, Model D,0.87,0.82,0.92,0.75","Table 1 shows the performance evaluation metrics, including accuracy, F1-score, precision, and recall, for different models, A, B, C, and D. The models were developed and tested using the same dataset under the same experimental conditions. Model D achieved the highest accuracy of 0.87, followed by Model B at 0.85. Similarly, Model D performed well in the F1-score, precision, and recall metrics with 0.82, 0.92, and 0.75, respectively. In contrast, Model C had the lowest accuracy and F1-score with 0.83 and 0.75, respectively. Overall, the results show that Model D outperformed the other models in all the evaluation metrics, making it the best performing model."
1723,"caption: Performance comparison of four different models for classification tasks using various evaluation metrics.table: Model,Accuracy,F1,AUC-ROC,Precision,Recall, Model 1,0.89,0.78,0.65,0.68,0.91, Model 2,0.93,0.82,0.73,0.75,0.90, Model 3,0.87,0.76,0.69,0.64,0.91, Model 4,0.92,0.80,0.78,0.76,0.84","Table presents a performance comparison between four different models for classification tasks using multiple evaluation metrics. The table includes Accuracy, F1 score, AUC-ROC, Precision, and Recall measures. Interestingly, Model 2 shows the highest accuracy score of 0.93, while Model 1 has the highest F1 score of 0.78. Model 4 has the best performance with AUC-ROC measure, achieving a score of 0.78. However, Model 2 also performed well with an AUC-ROC score of 0.73 and Precision value of 0.75. Model 1, on the other hand, had the highest Recall measure of 0.91."
1724,"caption: Table 4: Comparison of model performances based on multiple evaluation metrics.table: Algorithm,Metric,Result, SVM,F1 Score,0.89, Precision,0.91, Recall,0.87, Accuracy,0.92, Logistic Regression,F1 Score,0.92, Precision,0.93, Recall,0.91, Accuracy,0.94, Random Forest,F1 Score,0.93, Precision,0.93, Recall,0.94, Accuracy,0.93","Table 4 compares the performance of different models based on multiple evaluation metrics, including F1 Score, Precision, Recall, and Accuracy. The table showcases the performance results of three models- SVM, Logistic regression, and Random Forest. It indicates that all three models have shown high accuracy, with the Logistic regression model performing the best with an accuracy of 0.94. The Random forest model performed the best in F1 Score and Recall with a score of 0.93 and 0.94, respectively. Finally, the Logistic regression model also exhibited the highest precision score of 0.93. Overall, the table suggests that the Logistic regression model performs the best among the three models across all performance metrics."
1725,"caption: Performance of different classifiers on the datasettable: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.82,0.81,0.85,0.83, SVM,0.81,0.76,0.88,0.80, Decision Tree,0.78,0.77,0.78,0.77, Random Forest,0.87,0.87,0.87,0.87, Neural Network,0.93,0.94,0.92,0.93","Table presents the evaluation of various classifiers on the dataset based on different evaluation metrics. The models include Logistic Regression, SVM, Decision Tree, Random Forest, and Neural Network. The evaluation metrics include Accuracy, Precision, Recall, and F1 Score. The results show that the Neural Network model achieved the highest Accuracy, Precision, and F1 Score of 0.93, 0.94, and 0.93 respectively. The SVM model achieved the highest recall of 0.88. Interestingly, Logistic Regression and Decision Tree models show similar performances across all evaluation metrics. Finally, the Random Forest model performed considerably well with an overall accuracy of 0.87."
1726,"caption: Comparison of different models' performances on the sentiment analysis task based on multiple metrics.table: Model,Precision,Recall,F1-Score,Accuracy, LR,0.72,0.68,0.70,0.76, SVM,0.68,0.65,0.66,0.72, NB,0.62,0.84,0.72,0.64, DT,0.61,0.57,0.59,0.66, RF,0.75,0.85,0.80,0.82, XGB,0.88,0.78,0.83,0.86, LSTM,0.86,0.88,0.87,0.81, BERT,0.90,0.93,0.92,0.88","Table presents a comparison of multiple machine learning models' performances for sentiment analysis tasks. The models were evaluated using precision, recall, F1-score, and accuracy metrics. The table exhibits the results for Logistic Regression (LR), Support Vector Machines (SVM), Naive Bayes (NB), Decision Trees (DT), Random Forests (RF), XGBoost (XGB), LSTM, and BERT models. Notably, the XGBoost model shows the best overall performance with the highest accuracy score of 0.86. Interestingly, the LSTM model demonstrates the best precision score of 0.86, whereas the BERT model shows the best recall score of 0.93. The Random Forests model achieved the best F1-score of 0.80. These results demonstrate that different models excel concerning different metrics."
1727,"caption: Table 4. Model performances based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.85,0.84,0.85,0.84, Random Forest,0.87,0.88,0.87,0.87, XGBoost,0.88,0.89,0.88,0.88, Support Vector Machine,0.84,0.85,0.84,0.84, Multi-layer Perception,0.86,0.87,0.86,0.86","Table 4 summarises the performance of different machine learning models using various evaluation metrics. The table includes accuracy, precision, recall, and F1-score metrics, which are important measures of the model's effectiveness. The models used in this study are Logistic Regression, Random Forest, XGBoost, Support Vector Machine, and Multi-layer Perception. Based on the results, XGBoost demonstrated the best overall performance with an accuracy of 0.88, precision of 0.89, recall of 0.88 and F1-score of 0.88. However, Random Forest achieved the second-highest performance among the models, with an accuracy of 0.87, precision of 0.88, recall of 0.87, and F1-score of 0.87."
1728,"caption: Comparison of models' classification metrics on the test set.table: Model,Precision,Recall,F1-score,ROC-AUC,PR-AUC, SVM,0.74,0.82,0.78,0.69,0.79, RF,0.80,0.73,0.76,0.76,0.81, AdaBoost,0.78,0.81,0.79,0.73,0.78, KNN,0.70,0.70,0.70,0.61,0.68, NB,0.62,0.72,0.66,0.52,0.67","The table presents a comparison of the classification metrics of five models: Support Vector Machine (SVM), Random Forest (RF), AdaBoost, K-Nearest Neighbors (KNN), and Naive Bayes (NB). The models were trained and tested on the same test set, and the table presents their performance metrics for precision, recall, F1-score, ROC-AUC, and PR-AUC. According to the results, the RF model has the highest precision value of 0.80, while the SVM model achieved the highest recall value of 0.82. The AdaBoost model performed the best in terms of F1-score with a score of 0.79. Additionally, the RF model exhibited the highest ROC-AUC and PR-AUC scores of 0.76 and 0.81, respectively. Overall, the comparison highlights the varying performances of different models, suggesting that the choice of model should depend on the objective of the analysis."
1729,"caption: Table 4. Performance comparison of different models based on multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score,AUC, Logistic Regression,0.72,0.73,0.57,0.63,0.78, Random Forest,0.93,0.94,0.88,0.91,0.98, Support Vector Machine,0.82,0.79,0.74,0.75,0.88, Gradient Boosting,0.96,0.96,0.93,0.94,0.99, K-Nearest Neighbors,0.87,0.85,0.80,0.82,0.93","Table 4 provides a comparison of multiple machine learning models' performance based on various evaluation metrics. The models' accuracy, precision, recall, F1 score, and AUC were evaluated and presented. The models used in this comparison were Logistic regression, Random forest, Support Vector Machine, Gradient Boosting, and K-Nearest Neighbors. The Random Forest model outperformed other models and has shown the highest accuracy (0.93), precision (0.94), recall (0.88), F1 score (0.91), and AUC (0.98). The Gradient Boosting model showed the second-best performance with a high accuracy of 0.96, precision of 0.96, and an AUC of 0.99. The Logistic Regression model showed the lowest performance in all evaluated metrics."
1730,"caption: Model Performance Results with multiple metrics for different Machine Learning models.table: Model,Accuracy,F1-score,Precision,Recall, Decision Tree,0.83,0.91,0.89,0.93, SVM,0.77,0.87,0.83,0.91, Logistic Regression,0.79,0.89,0.85,0.93, KNN,0.75,0.85,0.82,0.89, Random Forest,0.88,0.94,0.92,0.96","Table 4 shows the performance results of multiple machine learning algorithms, including Decision Tree, SVM, Logistic Regression, KNN, and Random Forest. This table has multiple evaluation metrics, such as accuracy, F1-score, precision, and recall. Among the different models, Random Forest appears to show the best accuracy of 0.88, followed by Decision Tree with 0.83. The Random Forest model shows the highest F1-score of 0.94. The Decision Tree model has good precision and recall with 0.89 and 0.93, respectively. The SVM model shows the lowest accuracy score of 0.77, but still has a reasonable F1-score and high precision and recall. Overall, the Random Forest model outperforms all other models in the evaluation metrics on this dataset."
1731,"caption: Table 4: Model Evaluation Metrics on Different Modelstable: Model,Accuracy,F1 Score,Precision,Recall, Model A,0.86,0.89,0.91,0.87, Model B,0.84,0.87,0.92,0.83, Model C,0.82,0.86,0.88,0.85, Model D,0.89,0.91,0.93,0.89, Model E,0.87,0.90,0.92,0.88","Table 4 demonstrates the accuracy, F1 score, precision, and recall metrics for five different models. Model D performs the best, with an accuracy rate of 0.89, an F1 score of 0.91, a precision score of 0.93 and a recall score of 0.89. Model A and Model E also provide high accuracy rates of 0.86 and 0.87, respectively. However, Model A outperforms Model E in terms of F1 score, precision, and recall. Model C has the lowest accuracy rate of 0.82 and F1 score of 0.86. Interestingly, all models have a high precision score, indicative of their ability to for correct positives."
1732,"caption: Comparison of Different Classification Models' Performance Based on Multiple Evaluation Metricstable: Model,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.88,0.64,0.56,0.85, Decision Tree,0.84,0.58,0.48,0.73, K-Nearest Neighbors,0.90,0.68,0.71,0.65, Support Vector Machine,0.92,0.73,0.75,0.72, Random Forest,0.95,0.85,0.81,0.9, Gradient Boosting,0.93,0.78,0.75,0.81","Table presents a comparison of classification models' performance based on multiple evaluation metrics, including Accuracy, F1-Score, Precision, and Recall. The Logistic Regression model achieved an accuracy of 0.88, F1-Score of 0.64, Precision of 0.56, and Recall of 0.85. The Random Forest achieved the highest overall score in Accuracy, F1-Score, and Recall, with 0.95, 0.85, and 0.9 scores respectively. The Gradient Boosting model also showed good performance in terms of F1-Score at 0.78. The Support Vector Machine model showed the highest Precision with the score of 0.75. No model consistently outperformed in all metrics, indicating the importance of evaluating classification models using multiple metrics."
1733,"caption: Comparison of Different Models Based on Multiple Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1-Score, Model 1,0.81,0.78,0.80,0.79, Model 2,0.85,0.82,0.84,0.83, Model 3,0.87,0.85,0.87,0.86, Model 4,0.82,0.81,0.79,0.80, Model 5,0.84,0.83,0.86,0.84","The table presents the performance of five different classification models, Model 1, Model 2, Model 3, Model 4, and Model 5, based on multiple evaluation metrics, including accuracy, precision, recall, and F1-Score. Model 3 appears to be the best performer with an accuracy score of 0.87 and the highest precision and recall scores of 0.85 and 0.87, respectively. However, Model 5 shows the highest F1-Score of 0.84. The results suggest that different models may perform better in different evaluation metrics, and practitioners should consider multiple metrics instead of relying on a single metric to evaluate the models' performance."
1734,"caption: Model performances based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.83,0.84,0.82,0.83, Naive Bayes,0.77,0.70,0.80,0.73, Decision Tree (max depth=3),0.79,0.80,0.76,0.78, Random Forest (n=100),0.86,0.85,0.87,0.86, Gradient Boosting (n=100),0.88,0.88,0.89,0.88","The table above exhibits the performances based on different evaluation metrics for different models, namely Logistic Regression, Naive Bayes, Decision Tree, Random Forest, and Gradient Boosting. The models were evaluated using accuracy, precision, recall, and F1-score metrics, with the highest value indicating better performance. The Gradient Boosting model attained the best performance in all metrics except accuracy, where the Random Forest model showed the highest score. The Naive Bayes model displayed the lowest performance among all models in the table, while the Logistic Regression model achieved moderate results compared to others. It can be observed that the more advanced models such as Random Forest and Gradient Boosting outperformed the simple models such as Naive Bayes and Logistic Regression."
1735,"caption: Model evaluation metrics for different classifierstable: Model,Precision,Recall,F1-Score,MCC,AUC, SVM,0.78,0.88,0.83,0.62,0.75, MLP,0.75,0.85,0.80,0.57,0.72, KNN,0.73,0.80,0.76,0.52,0.68, NB,0.62,0.97,0.75,0.56,0.61, RF,0.82,0.89,0.85,0.69,0.78","Table 1 shows the performance results of different classifiers by evaluating multiple metrics on the same dataset. The table presents precision, recall, F1-score, Matthews Correlation Coefficient (MCC), and Area Under Curve (AUC) for SVM, MLP, KNN, NB, and RF classifiers. The RF classifier shows the highest precision, recall, F1-score, MCC, and AUC values of 0.82, 0.89, 0.85, 0.69, and 0.78, respectively. Notably, the naive Bayesian (NB) classifier has a high recall score of 0.97, even though its precision is lower than other classifiers. The SVM classifier is better than the MLP and KNN in all the metrics, except for AUC."
1736,"caption: Table 4: Model performances based on different evaluation metrics.table: Model Name,Metric 1 (Score),Metric 2 (Score),Metric 3 (Score), Model A,0.78,0.62,0.91, Model B,0.58,0.85,0.73, Model C,0.91,0.67,0.62, Model D,0.64,0.71,0.83, Model E,0.80,0.79,0.87","Table 4 shows the aggregated performance results of different models based on multiple evaluation metrics. The table displays the scores of Metric 1, Metric 2, and Metric 3 for Model A to E. The highest scores for Metric 1 is achieved by Model C with 0.91, whereas the lowest score is obtained by Model B with 0.58. Model B scores the highest Metric 2 score with 0.85, while Model C ranks lowest with 0.67. Model A demonstrates the highest Metric 3 score with 0.91, and Model C exhibits the lowest score with 0.62. Overall, the highest-performing model is Model C with the highest scores in Metric 1 and Metric 3."
1737,"caption: Table 4: Performance results of different models based on multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.87,0.85,0.92,0.88, KNN,0.80,0.71,0.91,0.80, MLP,0.88,0.84,0.93,0.88, DT,0.75,0.70,0.89,0.79, RF,0.92,0.91,0.94,0.92, XGB,0.89,0.87,0.92,0.89","The table report the performance results of six different models based on multiple evaluation metrics. The accuracy, precision, recall, and F1-score have been calculated for each model. The SVM, MLP, and XGB models show good overall performance based on accuracy score, with accuracy scores of 0.87, 0.88, and 0.89, respectively. Interestingly, the Random Forest model had the highest accuracy score of 0.92. Similarly, the Random Forest model had the highest precision and the recall scores of 0.91 and 0.94, respectively. Overall, the Random Forest model performed the best across all evaluation metrics, whereas the KNN and Decision Tree models exhibited the lowest performance scores among all models."
1738,"caption: Comparative performance analysis of different modelstable: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.86,0.89,0.85,0.87, Random Forest,0.92,0.91,0.94,0.93, SVM,0.83,0.81,0.84,0.83, Neural Network,0.89,0.92,0.88,0.90","The table presents a comparative performance analysis of different models using various evaluation metrics such as Accuracy, Precision, Recall, and F1-score. Four models, namely Logistic Regression, Random Forest, SVM, and Neural Network, were assessed and compared. The Random Forest model showed the best overall performance with an accuracy score of 0.92 and an F1-score of 0.93. The Logistic Regression model displayed the highest precision rate of 0.89, while Neural Network demonstrated an impressive recall score of 0.88. SVM showed the least accuracy among the models assessed, with an accuracy of 0.83."
1739,"caption: Table 4: Model Performance Comparison based on Accuracy, F1 Score, Precision, and Recall.table: Model,Accuracy,F1 Score,Precision,Recall, Model 1,0.81,0.84,0.75,0.95, Model 2,0.85,0.89,0.81,0.98, Model 3,0.77,0.80,0.77,0.83, Model 4,0.89,0.91,0.89,0.94, Model 5,0.92,0.94,0.90,0.99","Table 4 presents a comparison of different models' performance based on multiple evaluation metrics such as Accuracy, F1 Score, Precision, and Recall. The table reflects the accuracy of Model 1, Model 2, Model 3, Model 4, and Model 5, being 0.81, 0.85, 0.77, 0.89, and 0.92, respectively. Furthermore, F1 scores of Model 1, Model 2, Model 3, Model 4, and Model 5 are determined to be 0.84, 0.89, 0.80, 0.91, and 0.94, respectively. Interestingly, Model 5 exhibit the highest precision of 0.90, while Model 1 showed the lowest precision of 0.75. Similarly, Model 5 attained the highest recall score of 0.99, while Model 3 had the lowest recall score of 0.83."
1740,"caption: Performance evaluation of different models using Acc, F1-score, Precision, and Recall.table: Model,Acc (%),F1-score,Precision,Recall, Model A,81.2,0.792,0.796,0.799, Model B,80.5,0.785,0.792,0.789, Model C,78.9,0.771,0.770,0.774, Model D,82.1,0.800,0.806,0.795","The presented table displays the performance evaluation of four different models based on four different metrics, namely Acc, F1-score, Precision, and Recall. The four models, Model A, B, C, and D, are evaluated based on their classification performance using the said metrics. Interestingly, the Acc and F1-score measurements indicate that Model D performs the best with scores of 82.1% and 0.800, respectively. Conversely, the Precision metric shows that Model D and Model A share the same best score of 0.806. Furthermore, Model C has the lowest scores across all the metrics evaluated in this table."
1741,"caption: Comparison of different models’ performances based on various evaluation metrics.table: Model,Mean Absolute Error (MAE),Root Mean Squared Error (RMSE),R2 Score, Model 1,3.2,4.8,0.76, Model 2,4.0,5.1,0.63, Model 3,2.8,4.5,0.83, Model 4,6.1,7.3,0.38, Model 5,3.5,4.9,0.70","The table compares five different models’ performances based on various evaluation metrics- Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and R2 Score. Model 3 shows the highest R2 score of 0.83, indicating a better fit of the model than others. Model 1 has the lowest MAE of 3.2, while Model 3 has the lowest RMSE of 4.5. On the other hand, Model 4 has the highest RMSE of 7.3 and the lowest R2 score of 0.38, highlighting its poor performance. Overall, Model 3 seems to perform better than other models due to its high R2 score and low RMSE."
1742,"caption: Table 4: Model Performance Metricstable: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.89,0.87,0.91,0.89, Decision Tree,0.85,0.80,0.87,0.83, Random Forest,0.91,0.92,0.93,0.92, Support Vector Machine,0.86,0.85,0.87,0.86","Table 4 presents the performance metrics, namely Accuracy, Precision, Recall, and F1-Score, of different models such as Logistic Regression, Decision Tree, Random Forest, and Support Vector Machines evaluated on a given dataset. The best performing model based on Accuracy, Precision, and F1-Score is the Random Forest model with a score of 0.91, 0.92, and 0.92, respectively. However, the Logistic Regression models have the highest Recall score of 0.91, indicating the model's ability to identify true positives. The Decision Tree model performed the weakest with the lowest score across all performance metrics."
1743,"caption: Performance of different models on the classification task.table: Model,Precision,Recall,F1-Score,MCC, Logistic Regression,0.83,0.74,0.78,0.58, Decision tree,0.82,0.66,0.71,0.5, Random Forest,0.86,0.75,0.78,0.62, Gradient Boosting,0.89,0.76,0.81,0.66, Support Vector Machine,0.85,0.68,0.74,0.55","The table compares the performance of five algorithms on a classification task. The models evaluated are Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Support Vector Machine. The evaluation metrics used to assess each model's performance are precision, recall, f1-score, and Matthews Correlation Coefficient (MCC).  The Gradient Boosting model outperforms the other models with the highest precision, recall, f1-score, and MCC scores of 0.89, 0.76, 0.81, and 0.66, respectively. Logistic Regression, Random Forest, and Support Vector Machine attained comparable scores, while the decision tree model has inferior performance compared to the other models."
1744,"caption: Performance comparison of SVM, Random Forest, and XGBoost models using multiple evaluation metrics.table: Model,Metric,Result 1,Result 2, SVM,Accuracy,0.82,0.74, Precision,0.89,0.69, Recall,0.74,0.89, F1-score,0.80,0.77, Random Forest,Accuracy,0.84,0.76, Precision,0.87,0.71, Recall,0.80,0.87, F1-score,0.83,0.78, XGBoost,Accuracy,0.85,0.75, Precision,0.88,0.68, Recall,0.81,0.89, F1-score,0.84,0.77","The table summarizes the performance comparison of SVM, Random Forest, and XGBoost models using accuracy, precision, recall, and F1-score. The results are shown separately for two evaluations. The first column identifies the models, and the second column indicates the utilized metric. The table highlights that XGBoost and Random Forests are superior to SVM based on F1-score and recall measures in evaluation 1. However, SVM has outperformed XGBoost and Random Forest in precision, while XGBoost has relatively higher accuracy in evaluation 2. These findings suggest that model selection should be based on the metric selected for evaluation and whether one model's strength overcomes another's weakness."
1745,"caption: Comparison of different models based on the evaluation metricstable: Metric,Model 1,Model 2,Model 3,Model 4, RMSE,0.74,0.62,0.68,0.76, MAE,0.57,0.50,0.54,0.60, R2,0.83,0.89,0.85,0.81, Explained Variance Score,0.84,0.90,0.87,0.83","The table represents the evaluation results of four models, Model 1, Model 2, Model 3 and Model 4, based on different evaluation metrics like RMSE, MAE, R2, and explained variance score. The evaluation metrics are commonly used performance measures for regression tasks. Interestingly, Model 2 achieved the best results for all metrics. It had the lowest RMSE of 0.62, the lowest MAE of 0.50, the highest R2 of 0.89, and also the highest explained variance score of 0.90. It can be concluded that Model 2 outperformed the other models."
1746,"caption: Performance Metrics of Different Modelstable: Model Name,Accuracy,F1 Score,Precision,Recall,ROC-AUC,PR-AUC, Model 1,0.85,0.87,0.90,0.84,0.79,0.88, Model 2,0.82,0.85,0.88,0.83,0.81,0.87, Model 3,0.87,0.88,0.91,0.86,0.84,0.90, Model 4,0.80,0.83,0.89,0.79,0.76,0.85","The table above compares the performance of four different models based on six evaluation metrics. The evaluation metrics include accuracy, F1 score, precision, recall, ROC-AUC, and PR-AUC. Each model was trained and tested on the same dataset. Model 3 outperformed the other models in all metrics except for ROC-AUC, where Model 2 performed slightly better. Interestingly, Model 4 had the highest precision of 0.89 but performed poorly in the recall metric. Model 1 had the highest recall score of 0.84. Overall, the table provides a comprehensive comparison of the models based on multiple evaluation metrics, aiding in determining the best-performing model based on the specific metric requirements."
1747,"caption: Performance metrics of various models in a classification task.table: Model,Precision,Recall,F1-Score,Accuracy, Model A,0.67,0.74,0.70,0.82, Model B,0.75,0.63,0.69,0.83, Model C,0.76,0.77,0.76,0.84, Model D,0.83,0.72,0.77,0.85, Model E,0.79,0.78,0.79,0.84","The presented table compares the performance metrics of different models in a classification task. The models' performance was measured based on precision, recall, F1-Score, and accuracy. Notably, Model D attained the highest precision score of 0.83, while Model C and Model E had the highest recall scores of 0.77 and 0.78, respectively. Further, Model E achieved the best F1-Score of 0.79, and Model D achieved the highest accuracy of 0.85. Overall, the table indicates that each model performed differently across the various evaluation metrics."
1748,"caption: Model evaluation metrics comparison between baseline and five different ML models.table: Model,Accuracy,Precision,Recall,F1-score, Baseline,0.578,0.607,0.498,0.548, Decision Tree,0.750,0.702,0.780,0.738, Naive Bayes,0.651,0.674,0.595,0.631, K-NN (k=5),0.690,0.681,0.677,0.675, Logistic Regression,0.770,0.746,0.796,0.768, Support Vector Machine,0.712,0.689,0.741,0.704","The table above compares the evaluation metrics of six different models, including a baseline model, Decision Tree, Naive Bayes, K-NN (k=5), Logistic Regression, and Support Vector Machine. The evaluation metrics include Accuracy, Precision, Recall, and F1-score.None of the models outperformed the baseline model in all the metrics. Logistic regression and decision trees models exhibit the highest Accuracy with scores of 0.770 and 0.750, respectively. However, Logistic regression achieved the highest Precision, Recall, and F1-score with scores of 0.746, 0.796, and 0.768, respectively. On the contrary, the Decision Tree achieved the lowest Precision. The Naive Bayes model achieved the lowest Recall of 0.595. The Support Vector Machine had the lowest F1-score of 0.704."
1749,"caption: Comparison of Model Performance using different evaluation metrics.table: Models,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.86,0.78,0.85,0.73, Random Forest,0.91,0.83,0.85,0.81, XGBoost,0.90,0.81,0.87,0.76, SVM,0.85,0.75,0.87,0.67, Naive Bayes,0.81,0.68,0.75,0.63","The table above shows a comparison of multiple models using different evaluation metrics. The models listed are Logistic Regression, Random Forest, XGBoost, SVM, and Naive Bayes. The evaluation metrics used are Accuracy, F1 Score, Precision, and Recall. It is interesting to note that the Random Forest Model has the highest scores on all evaluation metrics, with Accuracy score of 0.91, F1 Score of 0.83, Precision of 0.85, and Recall of 0.81. Naive Bayes has the lowest scores on all the evaluation metrics, with Accuracy score of 0.81, F1 Score of 0.68, Precision of 0.75 and Recall of 0.63. Both Logistic Regression and SVM show comparable performance with respect to most metrics."
1750,"caption: Table 4: Performance comparison of different classification models.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.85,0.88,0.82,0.85, Decision Tree,0.80,0.84,0.80,0.81, Random Forest,0.87,0.89,0.85,0.87, K-Nearest Neighbors,0.82,0.85,0.73,0.78, Support Vector Machine (linear),0.84,0.86,0.81,0.83, Support Vector Machine (rbf),0.86,0.88,0.83,0.85","The table displays the comparison of six different classification models based on their accuracy, precision, recall, and F1-score. The Logistic Regression model achieved the highest accuracy (0.85), while the Random Forest model obtained the highest precision (0.89) and F1-score (0.87). The SVM (rbf) model's recall score (0.83) was found to be the highest compared to others. The results suggest that the Random Forest model is the best fit for the classification task, with an accuracy of 0.87, precision of 0.89, recall of 0.85, and an F1-score of 0.87."
1751,"caption: Performance of Different Models Based on Various Metricstable: Model,Accuracy,F1 Score,Precision,Recall, Model 1,0.82,0.79,0.81,0.80, Model 2,0.84,0.82,0.83,0.82, Model 3,0.86,0.84,0.85,0.84, Model 4,0.81,0.78,0.80,0.78, Model 5,0.88,0.86,0.87,0.86","The table compares the performance of different models based on various evaluation metrics, including accuracy, F1 score, precision, and recall. Model 5 demonstrates the best accuracy with a score of 0.88, while Model 3 achieves the highest F1 score, precision, and recall with the scores of 0.84, 0.85, and 0.84, respectively. It is worth noting that Model 2 is the second-best model based on all metrics, except the recall, which is slightly lower than Model 1. Model 4, on the other hand, exhibits the lowest performance results based on all evaluation metrics."
1752,"caption: Table 4: Model performance based on multiple evaluation metrics.table: Model,Precision,Recall,F1 Score,ROC-AUC,PR-AUC, Logistic Regression,0.883,0.901,0.881,0.914,0.812, Decision Trees,0.899,0.867,0.875,0.906,0.803, Naive Bayes,0.839,0.853,0.840,0.895,0.763, Random Forest,0.912,0.927,0.918,0.932,0.878, Support Vector Machine,0.905,0.924,0.916,0.921,0.842","The table 4 presents the performance of different models based on multiple evaluation metrics such as Precision, Recall, F1 Score, ROC-AUC, and PR-AUC. The models include Logistic Regression, Decision Trees, Naive Bayes, Random Forest, and Support Vector Machine. Among these models, Random Forest demonstrates the best Precision score of 0.912 and Recall score of 0.927. On the other hand, the Decision Trees model shows the highest F1 Score of 0.875. Additionally, the Random Forest has the highest area under ROC-AUC curve of 0.932 and PR-AUC score of 0.878, which indicate the best performance in terms of classification ability. Notably, the Support Vector Machine model exhibits the highest Precision-recall F1 score of 0.916, followed by Random Forest (0.918) and Logistic Regression (0.881)."
1753,"caption: Model Evaluation Metrics for Five Different Modelstable: Model,Accuracy,F1 Score,Precision, Logistic Regression,0.85,0.84,0.82, Random Forest,0.89,0.88,0.87, Support Vector Machines,0.86,0.84,0.83, K-Nearest Neighbors,0.82,0.81,0.80, Decision Trees,0.79,0.78,0.77","Table shows the evaluation results of five different models, including Logistic Regression, Random Forest, Support Vector Machines, K-Nearest Neighbors, and Decision Trees. The metrics used to evaluate the models are Accuracy, F1 Score, and Precision. The Random Forest model achieved the highest accuracy score of 0.89, followed by Logistic Regression with an accuracy of 0.85. K-Nearest Neighbors model achieved the lowest accuracy score of 0.82. In terms of F1 Score and Precision, the ranking of models was similar, with Logistic Regression performing best and Decision Trees performing worst. Overall, the Random Forest model performed the best among the models, achieving the highest accuracy score of 0.89."
1754,"caption: Results of Various Modelstable: Model,Accuracy,Balanced Accuracy,F1 Score,Matthew Corr. Coeff., Random Forest,0.82,0.74,0.80,0.47, XGBoost,0.84,0.72,0.81,0.51, Logistic Regression,0.80,0.72,0.79,0.45, Support Vector Machine,0.82,0.70,0.79,0.50","The table summarizes the performance of multiple classification models such as Random Forest, XGBoost, Logistic Regression, and Support Vector Machine (SVM). The evaluation metrics used for measuring the models' performances include Accuracy, Balanced Accuracy, F1 Score, and Matthew Correlation Coefficient (MCC). Each model shows relatively good performance results for some metrics. Based on the Accuracy and F1 Score, XGBoost seems to perform better than other models. In contrast, SVM scores higher in Balanced Accuracy and MCC than other models. The results suggest the importance of using multiple evaluation metrics, along with different models, to gain greater insight into classification performance of the models."
1755,"caption: Comparison of Model Performancetable: ```, Model,Accuracy,Precision,Recall,F1-score, Model 1,0.89,0.91,0.88,0.89, Model 2,0.92,0.88,0.95,0.91, Model 3,0.86,0.85,0.88,0.87","The table above represents the comparison of model performance on different evaluation metrics such as Accuracy, Precision, Recall, and F1-score. The table consists of three different models, Model 1, Model 2, and Model 3. Notably, Model 2 shows the best Accuracy score, achieving 92%, while Model 3 demonstrates the lowest Accuracy score of 86%. Interestingly, Model 1 and Model 2 have relatively the same F1-score of 0.89 and 0.91, respectively, despite having different Accuracy scores. We can observe that Model 2 has the highest Precision and Recall scores, achieving 0.88 and 0.95, respectively, indicating that it is better at identifying positive instances."
1756,"caption: Model Performances based on different evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, A,0.85,0.86,0.88,0.84, B,0.72,0.73,0.77,0.69, C,0.89,0.91,0.92,0.89, D,0.80,0.82,0.85,0.79, E,0.92,0.94,0.95,0.92",
1757,"caption: Table 4: Evaluation metrics across different classification models based on accuracy, precision, recall and F1-score.table: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.86,0.86,0.87,0.86, Decision Trees,0.79,0.78,0.83,0.79, Random Forest,0.89,0.90,0.88,0.89, Gradient Boosting,0.91,0.91,0.91,0.91","Table 4 compares the performance of four different classification models based on their accuracy, precision, recall, and F1-score metrics. The models evaluated were Logistic Regression, Decision Trees, Random Forest and Gradient Boosting, and the scores presented were measured on the same dataset. The Gradient Boosting model achieved the highest scores across all the metrics with an accuracy of 0.91, precision of 0.91, recall of 0.91 and F1-score of 0.91. The Random Forest model also performed well with an accuracy of 0.89 and a high precision score of 0.90. Less accurate models were the Decision Trees with an accuracy of 0.79, and the Logistic Regression with an accuracy of 0.86, falling behind the other two models."
1758,"caption: Performance comparison of different models based on accuracy, F1-score, and recall metrics.table: Model,Accuracy,F1-Score,Recall, Model 1,87.3,0.857,0.890, Model 2,85.9,0.832,0.865, Model 3,88.5,0.869,0.898, Model 4,84.6,0.815,0.845, Model 5,89.1,0.876,0.902","The table presents the accuracy, F1-score, and recall performance metrics of five different models. Model 5 achieved the best performance in all metrics, reaching 89.1% accuracy, 0.876 F1-score, and 0.902 recall. Model 3 performed the second-best with an accuracy of 88.5%, 0.869 F1-score, and 0.898 recall. Model 1 also had relatively good performance with 87.3% accuracy, 0.857 F1-score, and 0.890 recall. In contrast, Model 4 had the worst performance, obtaining 84.6% accuracy, 0.815 F1-score, and 0.845 recall. Interestingly, Model 2 had an accuracy lower than Model 1 or Model 4 but had a better F1-score and recall than both, indicating a trade-off between various performance metrics."
1759,"caption: Table 4: Comparison of performance metrics for different models.table: Model,Accuracy,Precision,Recall,F1 Score, Model A,0.85,0.82,0.87,0.84, Model B,0.81,0.83,0.72,0.77, Model C,0.88,0.85,0.91,0.88, Model D,0.79,0.79,0.84,0.81, Model E,0.90,0.87,0.93,0.90","Table 4 presents a comparison of the performance metrics- Accuracy, Precision, Recall, and F1 Score for different models. The models are labeled as Model A, Model B, Model C, Model D, and Model E. The models with the best score for each metric are as follows: Model E obtained the highest Accuracy of 0.90, Model B achieved the highest Precision of 0.83, Model C achieved the highest Recall of 0.91, and Model E achieved the highest F1 Score of 0.90. It is interesting to note that Model A, which had the second-highest accuracy score, had contradictory Precision and Recall scores. These observations suggest that a single metric may not be sufficient to evaluate model performance and justify the need for a comprehensive metric analysis."
1760,"caption: Performance metrics of different modelstable: Model,Accuracy,F1-score,Precision,Recall, Model A,0.92,0.89,0.91,0.87, Model B,0.91,0.87,0.87,0.88, Model C,0.93,0.91,0.92,0.89, Model D,0.90,0.83,0.85,0.80","Table presents multiple models' performance metrics on several evaluation metrics such as Accuracy, F1-score, Precision, and Recall. Model A outperforms all models with accuracy of 0.92 and F1-score of 0.89. Interestingly, although Model D has the lowest accuracy of 0.90, it attained the highest precision score of 0.85. Model B has the lowest F1-score of 0.87, whereas Model C has the highest F1-score of 0.91. Furthermore, Model C has achieved the second-highest accuracy score of 0.93, while Model A has recorded the highest Recall score of 0.87."
1761,"caption: Evaluation metrics for different models.table: Model,Precision Score,Recall Score,F1-Score,Accuracy Score, Logistic Regression,0.92,0.85,0.88,0.89, K-Nearest Neighbor,0.85,0.80,0.82,0.85, Decision Tree,0.83,0.82,0.83,0.84, Random Forest,0.94,0.91,0.92,0.93, Support Vector Machine,0.88,0.87,0.87,0.88","The table above shows the results of various machine learning models on a classification task. The models evaluated in the table are Logistic Regression, K-Nearest Neighbor, Decision Tree, Random Forest, and Support Vector Machine. The evaluation metrics used to compare the performance of these models are Precision Score, Recall Score, F1-Score, and Accuracy Score. Notably, the Random Forest model performed the best in all the evaluation metrics, achieving precision, recall, F1-score, and accuracy scores of 0.94, 0.91, 0.92, and 0.93, respectively. However, it is interesting to note that the Logistic Regression model performed almost as good as the Random Forest model in terms of accuracy, with a score of 0.89. The Support Vector Machine also performed fairly well with an accuracy score of 0.88."
1762,"caption: Comparison of model performances based on multiple evaluation metrics.table: **Model**,**Accuracy**,**Precision**,**Recall**,**F1 Score**,**ROC-AUC**, Model A,0.85,0.89,0.74,0.81,0.91, Model B,0.82,0.84,0.72,0.77,0.88, Model C,0.87,0.91,0.78,0.84,0.93, Model D,0.89,0.92,0.82,0.86,0.94, Model E,0.84,0.88,0.76,0.81,0.89","Table shows a comparison of the accuracy, precision, recall, F1 score, and ROC-AUC for different models. Model A showed the highest accuracy of 0.85, Model D had the best precision of 0.92, and Model C had the highest recall of 0.78. Interestingly, Model D showed the best F1 score of 0.86 and ROC-AUC of 0.94. Overall, Model C and Model E have good performances across the evaluation metrics. It's important to consider all evaluation metrics while selecting the best model for the task at hand."
1763,"caption: Model Performance Evaluation using multiple metrics.table: Model,Accuracy,Precision,Recall, SVM,84%,0.82,0.88, KNN,79%,0.77,0.73, RF,88%,0.89,0.87, GBM,87%,0.88,0.85","The table above presents the performance evaluation of multiple models using different metrics. The models used are SVM, KNN, RF, and GBM, evaluated using Accuracy, Precision, and Recall. The results indicate that the RF model has the highest accuracy of 88%, while SVM has the highest precision of 0.82 and recall of 0.88. GBM has an accuracy of 87%, which is quite close to RF accuracy results, but its precision and recall scores are lower than RF and SVM. The results suggest that the RF and SVM models could be suitable for this research's purpose, depending on the evaluation metric's focus."
1764,"caption: Model Performances based on Multiple Evaluation Metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic regression,0.91,0.92,0.90,0.91, Random Forest,0.89,0.90,0.87,0.88, Decision Tree,0.88,0.85,0.90,0.86, Naive Bayes,0.86,0.87,0.84,0.86","The table above shows the performance of different models with various evaluation metrics, including accuracy, precision, recall, and F1 Score. Logistic regression outperformed all other models, achieving the highest accuracy of 0.91 and a precision score of 0.92. Random Forest and Decision Tree had closely related performances, with a slight edge in precision from Random Forest and better recall from Decision Tree. The Naive Bayes model had the lowest accuracy score of 0.86, but still managed a relatively high precision and recall score of 0.87 and 0.84, respectively."
1765,"caption: Model evaluation metrics for different classifiers.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.78,0.77,0.81,0.78, Random Forest,0.86,0.84,0.90,0.87, Logistic Regression,0.82,0.82,0.84,0.83, Naive Bayes,0.71,0.68,0.69,0.68, Neural Network,0.85,0.84,0.88,0.86","Table presents the classification performance metrics for five different models; Support Vector Machine (SVM), Random Forest, Logistic Regression, Naive Bayes, and Neural Network. The models were evaluated based on Accuracy, Precision, Recall, and F1-score. The Random Forest model achieved the highest Accuracy (0.86) and Recall (0.90), while the Neural Network model had the highest Precision (0.84) and F1-score(0.86). Interestingly, the SVM model had the second-highest Accuracy (0.78) and F1-score (0.78), but the lowest Precision (0.77) and Recall (0.81) among the evaluated models. Overall, the classification models' results indicate potential suitability for different use cases depending on evaluation criteria."
1766,"caption: Model Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.89,0.92,0.84,0.87, Decision Tree,0.83,0.82,0.81,0.81, Random Forest,0.92,0.93,0.92,0.93, Support Vector Machine,0.90,0.91,0.89,0.90, Multilayer Perceptron,0.94,0.93,0.95,0.94","This table presents the performance evaluation of five different models; Logistic Regression, Decision Tree, Random Forest, Support Vector Machine, and Multilayer Perceptron. The models were evaluated using four metrics: Accuracy, Precision, Recall, and F1 score. Random Forest and Multilayer Perceptron achieved the highest accuracy with 0.92 and 0.94, respectively. Multilayer Perceptron scored the highest Precision and Recall with 0.93 and 0.95. Logistic Regression returned a high Precision of 0.92, while Support Vector Machine achieved a high Recall of 0.89. Decision Tree was the least performing model with 0.81 F1 Score."
1767,"caption: Table 4: Model performance based on different evaluation metrics.table: Model,F1,Recall,Precision,AUC, SVM,0.78,0.64,0.98,0.86, Random Forest,0.81,0.78,0.84,0.89, KNN,0.72,0.81,0.66,0.73, Gradient Boosting,0.83,0.80,0.87,0.91","Table 4 presents the performance of multiple different models based on different evaluation metrics. The table displays F1, Recall, Precision, and AUC scores for SVM, Random Forest, KNN, and Gradient Boosting models. Notably, all models were trained and tested using the same dataset. The best overall performance is achieved by the Gradient Boosting model, which achieved the highest AUC score of 0.91. The Random Forest model also performed well with an AUC score of 0.89. The SVM model had the highest precision score, while the Random Forest model achieved the highest recall score."
1768,"caption: Performance comparison of different models using multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Model 1,0.95,0.93,0.89,0.91, Model 2,0.87,0.79,0.85,0.81, Model 3,0.92,0.91,0.94,0.92, Model 4,0.96,0.94,0.96,0.95, Model 5,0.88,0.76,0.88,0.79",
1769,"caption: Performance comparison of different models based on multiple evaluation metrics.table: Models,Accuracy,F1-score,AUC,Precision,Recall, Logistic regression,0.75,0.742,0.80,0.78,0.75, Decision tree,0.68,0.65,0.62,0.63,0.68, Random Forest,0.83,0.82,0.79,0.84,0.83, Gradient Boosting,0.78,0.76,0.83,0.79,0.78, XGBoost,0.84,0.83,0.88,0.86,0.84, Support Vector Machines,0.71,0.65,0.74,0.68,0.71","The table above presents a comparison of different machine learning models' performances based on multiple evaluation metrics. The different models include logistic regression, decision tree, random forest, gradient boosting, XGBoost, and support vector machines (SVM). The evaluation metrics used in the table are accuracy, F1-score, AUC, precision, and recall. XGBoost outperforms the other models in all evaluation metrics with an accuracy of 0.84, F1-score of 0.83, AUC of 0.88, precision of 0.86, and recall of 0.84. The random forest performs the second-best with an accuracy of 0.83, F1-score of 0.82, AUC of 0.79, precision of 0.84, and recall of 0.83. The performance results indicate that XGBoost and random forest are the most effective models for this specific dataset."
1770,"caption: Table 4: Performance Comparison of Different Modelstable: Model,Accuracy,F1 Score,Precision,Recall, Model A,0.89,0.88,0.90,0.86, Model B,0.90,0.89,0.88,0.91, Model C,0.87,0.86,0.89,0.83, Model D,0.92,0.91,0.93,0.90, Model E,0.88,0.87,0.91,0.84",
1771,"caption: Performance comparison of different models using various evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall,ROC-AUC,PR-AUC, Logistic Regression,0.87,0.84,0.82,0.86,0.93,0.89, SVM,0.88,0.85,0.84,0.86,0.92,0.87, Naive Bayes,0.71,0.45,0.90,0.31,0.62,0.32, Decision Tree,0.81,0.73,0.71,0.78,0.81,0.59","The table shows the accuracy, F1-Score, Precision, Recall, ROC-AUC, and PR-AUC scores for four different models: Logistic Regression, SVM, Naive Bayes, and Decision Tree. The models were evaluated using the corresponding metrics employing the same dataset. The results showed that the SVM model performed the best with an accuracy score of 0.88 and F1-Score of 0.85. The Logistic Regression model closely followed with an accuracy score of 0.87 and F1-Score of 0.84. Naive Bayes showed a strong Precision rate of 0.9 but a relatively poor performance in other metrics. Observably, the tree-based model Decision Tree model showed the weakest performance among all the models."
1772,"caption: Model performances of various machine learning algorithms based on multiple evaluation metrics.table: Model,F1 Score,Accuracy,Precision,Recall, Logistic Regression,0.78,0.82,0.75,0.82, Decision Tree,0.72,0.76,0.81,0.74, Random Forest,0.84,0.88,0.87,0.82, K-Nearest Neighbors (KNN),0.68,0.73,0.71,0.63, Support Vector Machine,0.80,0.85,0.82,0.78","The table presents model performances for various machine learning algorithms, such as Logistic Regression, Decision Tree, Random Forest, K-Nearest Neighbors (KNN), and Support Vector Machine. The table records the F1 Score, Accuracy, Precision, and Recall metrics for thorough evaluation. Among the models presented, Random Forest shows the highest prediction accuracy of 0.88 while achieving an F1 score of 0.84. On the other hand, the Decision Tree model has the highest precision score at 0.81, while the Support Vector Machine produces the highest Recall score of 0.78. Overall, Random Forest provides the best overall performance."
1773,"caption: Performance of different models based on Accuracy, Precision, Recall, and F1-Score evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Model A,0.89,0.90,0.85,0.87, Model B,0.92,0.94,0.89,0.91, Model C,0.85,0.87,0.76,0.81, Model D,0.94,0.93,0.96,0.95","The table provides the comparison of different models based on the accuracy, precision, recall, and F1-score evaluation metrics. Model A has an accuracy of 0.89, precision of 0.90, recall of 0.85, and F1-Score of 0.87. Model B has an accuracy of 0.92, precision of 0.94, recall of 0.89, and F1-Score of 0.91. Model C stands out for having the lowest accuracy of 0.85, precision of 0.87, recall of 0.76, and F1-Score of 0.81. Among all models, Model D shows the best performance with the highest accuracy of 0.94, precision of 0.93, recall of 0.96, and F1-Score of 0.95."
1774,"caption: Comparison of different models based on multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.73,0.68,0.76,0.70, KNN,0.67,0.59,0.63,0.60, Naive Bayes,0.74,0.70,0.71,0.68, Random Forest,0.80,0.76,0.79,0.77, XGBoost,0.81,0.79,0.82,0.80","Table above presents the comparison of SVM, KNN, Naive Bayes, Random Forest, and XGBoost models based on four different evaluation metrics. All models were trained and tested using the same dataset. Based on the table, XGBoost model performs the best in terms of accuracy, precision, recall, and F1-Score, whereas the SVM model gives the least accurate performance. The Random Forest model also performs relatively well, but not as good as XGBoost. Interestingly, despite Naive Bayes model's relatively good performance in accuracy, it has lower precision and recall score than Random Forest and XGBoost models."
1775,"caption: Table 4: Performance comparison of different models using multiple evaluation metrics.table: Model,Precision,Recall,F1-score,AUC-ROC,PR-AUC, Model A,0.85,0.92,0.88,0.93,0.81, Model B,0.87,0.89,0.88,0.92,0.78, Model C,0.81,0.92,0.86,0.94,0.79, Model D,0.89,0.87,0.88,0.91,0.77","Table 4 presents the performance comparison of four different models using multiple evaluation metrics. The models' performance is measured using precision, recall, F1-score, AUC-ROC, and PR-AUC metrics. Notably, each model's AUC-ROC and PR-AUC scores differ, indicating a model's strengths and weaknesses for classification tasks. For instance, Model A achieved the highest PR-AUC score of 0.81, indicating a better performance concerning ranking. Although Model C got a higher precision score of 0.81, Model A had a higher AUC-ROC score of 0.93, indicating a better performance concerning ranking and selecting relevant instances. Model D achieved the highest precision score of 0.89, indicating better performance when minimizing false positives."
1776,"caption: Performance comparison of different classification modelstable: Model,Accuracy,Precision,Recall,F1 Score, SVM,0.92,0.94,0.87,0.90, RF,0.94,0.96,0.92,0.94, Naive Bayes,0.88,0.78,0.93,0.82, MLP,0.93,0.95,0.90,0.92, KNN,0.82,0.84,0.70,0.75, LDA,0.88,0.86,0.80,0.83","The table presents a comparison of six different classification models' performances based on multiple evaluation metrics - Accuracy, Precision, Recall, and F1 Score. The highest optimized values of each metric have been emphasized for each model. Among the six models, Random Forest obtained the highest accuracy of 0.94, the highest Precision score of 0.96, a recall score of 0.92, and an F1 score of 0.94. The SVM model has the highest precision score of 0.94, while Naive Bayes has the highest recall score of 0.93. The MLP model and LDA model achieved accuracy scores of 0.93 and 0.88, respectively. The KNN model achieved the lowest accuracy and the lowest F1 score of 0.82 and 0.75, respectively."
1777,"caption: Table 4: Model performance on different evaluation metricstable: Model,F1-score,Precision,Recall,AUC, SVM,0.83,0.79,0.88,0.92, Logistic Regression,0.82,0.85,0.80,0.89, Decision Tree,0.79,0.82,0.76,0.86, Random Forest,0.85,0.86,0.84,0.93, XGBoost,0.87,0.88,0.87,0.95",
1778,"caption: Performance measures for different models on the test datatable: Model name,Model type,Accuracy,F1 score,Precision,Recall, Logistic,Linear,0.89,0.89,0.87,0.91, Random Forest,Ensemble,0.91,0.91,0.91,0.91, XGBoost,Boosting,0.92,0.92,0.92,0.92, ConvNet,Neural Net,0.90,0.89,0.91,0.87","The table compares the performance of four different models, namely Logistic Regression, Random Forest, XGBoost, and Convolutional Neural Network (ConvNet) on the test data. The evaluation metrics are Accuracy, F1-score, Precision, and Recall. Notably, XGBoost showed the highest accuracy score of 0.92, followed by Random Forest and ConvNet, both having a score of 0.91. Logistic Regression achieved an accuracy score of 0.89. The F1 score for all the models falls between 0.89 and 0.92, indicating good overall performance. Among all models, XGBoost achieved the highest Precision, Recall, and F1 score. In contrast, the ConvNet model has a lower precision score despite having the same accuracy score as Random Forest."
1779,"caption: Comparison of different machine learning models' accuracy, F1-score, precision, and recall on the sentiment analysis task.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.89,0.92,0.95,0.89, Naive Bayes,0.81,0.84,0.78,0.82, Random forest,0.92,0.93,0.93,0.94, K-NN,0.85,0.86,0.88,0.84, Deep neural network,0.93,0.94,0.95,0.94","The table compares the performance of five different machine learning models on the sentiment analysis task. The models evaluated include Support Vector Machines (SVM), Naive Bayes, Random Forest, K-Nearest Neighbors (K-NN), and Deep Neural Network (DNN). The evaluation metrics considered in the table are accuracy, F1-score, precision, and recall. Among the models, the DNN model performs the best on all metrics, achieving an accuracy of 0.93, F1-score of 0.94, precision of 0.95, and recall of 0.94. Random forest also performs relatively well, achieving the second highest results across all metrics. On the other hand, Naive Bayes achieves the lowest scores for all metrics."
1780,"caption: Performance comparison of different models using multiple evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.83,0.84,0.86,0.83, Decision Tree,0.75,0.74,0.76,0.75, Random Forest,0.85,0.86,0.87,0.85, XGBoost,0.87,0.88,0.88,0.87, SVM,0.81,0.81,0.83,0.81","The table exhibits the performance of five different models, namely Logistic Regression, Decision Tree, Random Forest, XGBoost, and SVM. The evaluation metrics used to compare the performance of the models are accuracy, F1-Score, precision, and recall. From the table, XGBoost obtained the highest accuracy of 0.87, while Random Forest and Logistic Regression obtained the highest F1-score of 0.86 and 0.84, respectively. All models showed excellent precision values over 0.76, with Random Forest achieving the highest precision of 0.87. Recall for all the models was over 0.75, with XGBoost and SVM both achieving recall of 0.87. Overall, the table suggests Random forest and XGBoost may be the better models for the chosen evaluation metrics, considering the high performance across all metrics."
1781,"caption: Performance results of various models using different evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.87,0.85,0.88,0.83, Random Forest,0.78,0.76,0.81,0.72, Logistic Reg,0.85,0.81,0.83,0.82, Naive Bayes,0.76,0.71,0.74,0.68, K-NN,0.65,0.58,0.6,0.57","The table presents the comparison of multiple models' performance metrics. The models' accuracy, F1-score, precision, and recall are presented, which were calculated using the same dataset. It is important to note that the SVM model produced the highest accuracy score, achieving 0.87. Whereas, the Random Forest model had the lowest accuracy score of 0.78, however, it had the highest Precision score of 0.81. In contrast, the K-NN algorithm had the lowest score on all evaluation metrics. Therefore, based on these results, we can conclude that the SVM and Random Forest models may be the best performing models for this dataset, depending on the emphasis of the performance metric."
1782,"caption: Comparison of model performance using multiple evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.82,0.77,0.78,0.77, Decision Tree,0.79,0.67,0.72,0.67, Random Forest,0.89,0.88,0.88,0.89, Gradient Boost,0.91,0.90,0.91,0.90","The table provides a comparison of different model performances using accuracy, F1-score, precision, and recall as evaluation metrics. Logistic Regression has an accuracy of 0.82 and an F1-score, precision, and recall of 0.77. Whereas, Decision Tree has an accuracy of 0.79 and an F1-score, precision, and recall of 0.67. Random Forest has an accuracy of 0.89 and an F1-score, precision, and recall of 0.88 and 0.89, respectively. Gradient Boost model shows the highest accuracy 0.91 and F1-score 0.90, and highest precision and recall values of 0.91 and 0.90, respectively. Overall, the Gradient Boost model performs the best, indicating that it may be the most appropriate model for this dataset."
1783,"caption: Table 4: Comparison of different machine learning modelstable: Model,Accuracy,F1-score,Precision,Recall, SVM,0.912,0.914,0.920,0.908, Logistic,0.902,0.899,0.904,0.895, Random Forest,0.917,0.916,0.922,0.910, Gradient Boost,0.921,0.922,0.925,0.919","This table presents a comparison of four machine learning models' performance using multiple evaluation metrics. The models include SVM, Logistic, Random Forest, and Gradient Boost. The evaluation metrics include Accuracy, F1-score, Precision, and Recall. Random Forest performed the best in Accuracy with a score of 0.917 and an F1-score of 0.916. The Gradient Boost model yielded the highest F1-score of 0.922 and the best Precision of 0.925. SVM showed the highest Recall of 0.908 and an Accuracy of 0.912. Meanwhile, Logistic Regression produced a relatively lower Accuracy of 0.902 and F1-score of 0.899, but it had a higher Precision of 0.904 and Recall of 0.895."
1784,"caption: Performance metrics for different classification modelstable: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.91,0.92,0.93,0.92, Random Forest,0.88,0.90,0.89,0.89, Support Vector Machine,0.79,0.84,0.80,0.82, Multinomial Naive Bayes,0.85,0.89,0.85,0.87, k-Nearest Neighbours,0.83,0.88,0.83,0.85",
1785,"caption: Table 4: Model performance based on different evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.842,0.844,0.846,0.844, RF,0.859,0.856,0.867,0.845, XGB,0.849,0.846,0.853,0.841, Ada,0.838,0.836,0.843,0.830, GB,0.857,0.854,0.865,0.844","Table 4 shows the comparison of different models based on various evaluation metrics, i.e., Accuracy, F1 Score, Precision, and Recall. The table includes models such as SVM, Random Forest (RF), XGBoost (XGB), AdaBoost (Ada), and Gradient Boosting (GB). The highest accuracy is shown by RF with a score of 0.859, followed by GB with a score of 0.857. Interestingly, the highest F1 score is obtained by SVM with a score of 0.844, while the highest Precision and Recall are shown by RF with scores of 0.867 and 0.845, respectively. Overall, the results indicate that RF is the best fit among the models in terms of overall performance."
1786,"caption: Table 4: Performance evaluation of different classifierstable: Model,Precision,Recall,F1-score,Accuracy, Logistic Regression,0.85,0.80,0.82,0.87, Random Forest,0.82,0.89,0.85,0.86, Support Vector Machine,0.86,0.83,0.84,0.88, Multilayer Perceptron,0.81,0.88,0.84,0.85, Gradient Boosting,0.87,0.79,0.82,0.88","Table 4 presents the performance evaluation of five different classifiers based on multiple metrics. The models tested include Logistic Regression, Random Forest, Support Vector Machine, Multilayer Perceptron, and Gradient Boosting. The evaluation metrics include Precision, Recall, F1-score, and Accuracy. The results reveal that the models vary in their performance depending on the evaluation metric. Support Vector Machine achieved the highest Precision score of 0.86. However, Random Forest attained the best Recall score of 0.89, while Gradient Boosting achieved the highest Accuracy score of 0.88. Overall, the results suggest that different classifiers produce different results, emphasizing the need to choose a classifier based on the evaluation metric of interest."
1787,"caption: Model performance scores based on multiple evaluation metricstable: Model,Precision,Recall,F1-score,Accuracy, SVM,0.74,0.81,0.77,0.70, Random Forest,0.80,0.83,0.81,0.75, Gradient Boosting,0.78,0.85,0.81,0.76, Logistic Regression,0.75,0.80,0.77,0.71, Neural Network,0.81,0.84,0.82,0.76",
1788,"caption: Table 4: Model performances based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.87,0.86,0.80,0.83, Random Forest,0.91,0.91,0.85,0.88, Decision Tree,0.78,0.74,0.69,0.71, Naive Bayes,0.66,0.67,0.80,0.72, Support Vector Machines,0.89,0.89,0.86,0.87","Table 4 presents model performances based on different evaluation metrics, namely Accuracy, Precision, Recall, and F1 Score. The table compares the performances of five different models, Logistic Regression, Random Forest, Decision Tree, Naive Bayes, and SVM. Interestingly, the Random Forest model shows the best performance across all metrics with an accuracy of 0.91, precision of 0.91, recall of 0.85, and F1 score of 0.88. The Logistic Regression and SVM models also exhibit good performances with overall scores of over 0.87 in all metrics. In contrast, the Naive Bayes and Decision Tree models show relatively lower performance with accuracy scores of 0.66 and 0.78, respectively."
1789,"caption: Table 4: Comparison of different models based on multiple evaluation metricstable: Model,Metric 1,Metric 2,Metric 3, Model A,0.82,0.73,0.87, Model B,0.91,0.61,0.94, Model C,0.85,0.76,0.91, Model D,0.94,0.58,0.88, Model E,0.88,0.81,0.92","Table 4 presents a comparison of different models' performances based on multiple evaluation metrics. The table exhibits Model A, Model B, Model C, Model D, and Model E's Metric 1, Metric 2, and Metric 3 scores. Notably, all models were trained and tested using the same dataset. Model D shows the best performance in Metrics 1 and 3 with scores of 0.94 and 0.88, respectively. Meanwhile, Model B achieved the highest score in Metric 2 with a score of 0.61. Interestingly, Model E showed consistent performance across all three metrics with scores of 0.88, 0.81, and 0.92."
1790,"caption: Model Performance on Test Set with Multiple Metricstable: Model,Accuracy,Precision,Recall,F1-Score, KNN,0.84,0.82,0.86,0.84, Logistic Regression,0.87,0.86,0.88,0.87, Naive Bayes,0.76,0.72,0.83,0.77, Decision Tree,0.81,0.79,0.84,0.81, Random Forest,0.88,0.87,0.89,0.88, XGBoost,0.90,0.89,0.91,0.90",
1791,"caption: Performance Comparison of Different Machine Learning Modelstable: Model,Accuracy,F1-score,Area Under PR-Curve, SVM,0.89,0.88,0.87, RF,0.91,0.89,0.90, XGBoost,0.92,0.90,0.90, ANN,0.88,0.87,0.86","The table presents a performance comparison of different machine learning models based on accuracy, F1-score, and area under PR-curve metrics. The models evaluated in this study include Support Vector Machine (SVM), Random Forest (RF), XGBoost, and Artificial Neural Network (ANN). The table shows that the XGBoost achieved the highest accuracy of 0.92, followed by RF (0.91), SVM (0.89), and ANN (0.88). In terms of F1-score, the XGBoost model outperformed all the other models with a score of 0.90, whereas RF and SVM had a close score of 0.89 and 0.88, respectively. Interestingly, the ANN model achieved the highest area under PR-curve of 0.86, while XGBoost and RF models had similar scores of 0.90. Therefore, the relative performance of different models may depend on the choice of evaluation metrics."
1792,"caption: Comparison of Model Performance with Various Evaluation Metrics.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.75,0.70,0.79,0.63, Random Forest,0.80,0.77,0.81,0.75, XGBoost,0.82,0.80,0.84,0.77, Naive Bayes,0.68,0.62,0.73,0.53, KNN,0.72,0.68,0.72,0.68","The table above presents the performance of multiple models with various evaluation metrics, including accuracy, F1 score, precision, and recall. The evaluated models include SVM, Random Forest, XGBoost, Naive Bayes, and KNN. Notably, XGBoost obtained the highest scores with accuracy of 0.82, F1 score of 0.80, precision of 0.84, and recall of 0.77.  Random forest attained the second-highest scores with 0.80 accuracy, 0.77 F1 score, 0.81 precision, and 0.75 recall score. The SVM model achieved the lowest recall result of 0.63, whereas Naive Bayes got the lowest accuracy and F1 score of 0.68 and 0.62, respectively."
1793,"caption: Table 4: Performance metrics for different models evaluated on the classification task.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.89,0.88,0.92,0.90, KNN,0.85,0.88,0.84,0.86, Naive Bayes,0.80,0.72,0.92,0.80, Random Forest,0.92,0.92,0.93,0.92, XGBoost,0.93,0.93,0.94,0.93","Table 4 presents a comparison of different models' performances based on evaluation metrics, including accuracy, precision, recall, and F1-score. The table consists of SVM, KNN, Naive Bayes, Random Forest, and XGBoost models. The Random Forest and XGBoost models have the highest accuracy with scores of 0.92 and 0.93, respectively. Similarly, both models have the highest Precision score of 0.92 and 0.93, respectively. Naive Bayes shows the highest Recall score with a value of 0.92, and the XGBoost model exhibits the highest F1-Score with a score of 0.93. Overall, the Random Forest and XGBoost models perform the best in this classification task, with the XGBoost model being the best in F1-Score and accuracy."
1794,"caption: Table 4: Model comparison based on evaluation metrics.table: Models,Precision,Accuracy,Recall,F1-score, SVM,0.84,0.89,0.76,0.80, Logistic Regression,0.81,0.82,0.79,0.80, KNN,0.77,0.76,0.71,0.74, Naïve Bayes,0.68,0.59,0.62,0.65, Decision tree,0.81,0.82,0.79,0.80, Random Forest,0.90,0.94,0.86,0.88","Table 4 presents a comparison of different models based on evaluation metrics including precision, accuracy, recall and F1-score. The table comprises SVM, Logistic Regression, KNN, Naïve Bayes, Decision tree, and Random Forest models. The Random Forest model showed the best overall performance in the different metrics – with a precision score of 0.90, accuracy score of 0.94, recall score of 0.86 and F1-score of 0.88. The Naïve Bayes model demonstrated the lowest performance with scores of 0.68, 0.59, 0.62, and 0.65 for precision, accuracy, recall, and F1-score, respectively. The table's results can assist in selecting suitable models for achieving the desired performance under different evaluation metrics."
1795,"caption: Table 4: Model comparison based on accuracy, balanced accuracy, and F1-Score.table: Model,Accuracy,Balanced Accuracy,F1-Score, SVM,0.837,0.785,0.845, KNN,0.817,0.753,0.819, RF,0.853,0.799,0.855, XGB,0.868,0.802,0.872","Table 4 shows the comparison of four different models: SVM, KNN, RF, and XGB based on three performance evaluation metrics: accuracy, balanced accuracy, and F1-Score. The highest accuracy score of 0.868 was achieved by the XGB model. While all models have comparable performances, the Random Forest model achieved the highest balanced accuracy score of 0.799. Interestingly, the SVM model achieved the highest F1-Score with a score of 0.845, while the XGB model had the highest F1-Score of 0.872. Overall, the table demonstrates that the XGB model performs the best in terms of accuracy, and the Random Forest model performs the best in terms of balanced accuracy, but the choice of a particular model depends on the evaluation metric being considered."
1796,"caption: Table 4: Comparison of accuracy, F1-Score, precision and recall among different models.table: Models,Accuracy,F1-Score,Precision,Recall, Model A,0.85,0.83,0.87,0.81, Model B,0.81,0.82,0.79,0.85, Model C,0.89,0.91,0.84,1.00, Model D,0.83,0.84,0.80,0.89","Table 4 presents the comparison of different models based on four different evaluation metrics. The models, Model A, Model B, Model C, and Model D, achieved varying performances in terms of accuracy, F1-Score, precision, and recall. Model C shows the highest accuracy of 0.89, and has a perfect recall score of 1.00. Model D has the highest F1-Score of 0.84, and Model A demonstrates the highest precision of 0.87. Interesting to note that while Model C has the highest accuracy, it isn't the best in F1-Score or precision, which suggests that it lacks generalization, highlighting the importance of evaluating models with more than one metric."
1797,"caption: Performance of different models on a binary classification tasktable: Model,Accuracy,Precision,Recall,F1-score, CNN,0.87,0.89,0.84,0.86, SVM,0.89,0.87,0.91,0.89, NB,0.82,0.81,0.83,0.82, LR,0.85,0.84,0.86,0.85","Table shows the performance of four different models based on various evaluation metrics on a binary classification task. The models include CNN, SVM, NB, and LR. The evaluation metrics incorporated in the table include Accuracy, Precision, Recall, and F1-score. Notably, SVM achieves the highest accuracy of 0.89 with a precision of 0.87 and recall of 0.91, which is the best value for Recall. Meanwhile, CNN produced the second-best performance result with an accuracy of 0.87 and a precision score of 0.89. The findings in this table suggest that SVM may be the best-fit model for this specific binary classification task."
1798,"caption: Performance comparison of different models using various evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall,AUC, Model 1,0.83,0.78,0.82,0.75,0.89, Model 2,0.87,0.81,0.86,0.77,0.93, Model 3,0.84,0.77,0.83,0.73,0.88, Model 4,0.92,0.89,0.90,0.89,0.95","The table exhibits the comparison of performance results of four different models using various evaluation metrics, including accuracy, F1 score, precision, recall, and AUC. Model 4 shows the best performance across all metrics, with an accuracy score of 0.92, F1 score of 0.89, precision score of 0.90, recall score of 0.89, and AUC of 0.95. Notably, Model 2 scored high across all metrics, except for accuracy, with an F1 score of 0.81, precision score of 0.86, recall score of 0.77, and AUC of 0.93. Model 1 and Model 3 performed comparatively poorer than Model 2 and Model 4, with Model 3 having the lowest scores among the models in all metrics. Overall, the table shows varying performance results for different models across multiple evaluation metrics."
1799,"caption: Table 4: Classification Model Performance.table: Model,Accuracy,F1-score,Precision,Recall,AUC, Decision Tree,0.80,0.80,0.79,0.81,0.73, Random Forest,0.86,0.86,0.87,0.84,0.89, KNN,0.75,0.74,0.73,0.75,0.64, SVM,0.83,0.83,0.84,0.82,0.87, Gradient Boosting,0.87,0.87,0.88,0.85,0.90, XGBoost,0.89,0.89,0.91,0.86,0.93","Table 4 shows the performance results of six classification models, including Decision Tree, Random Forest, KNN, SVM, Gradient Boosting, and XGBoost. The table presents the accuracy, F1-score, precision, recall, and AUC for each model. The best performance is achieved by the XGBoost model, with the highest accuracy of 0.89 and AUC of 0.93. The Random Forest model also performs well with accuracy of 0.86, F1-score of 0.86, precision of 0.87, recall of 0.84, and AUC of 0.89. Interestingly, the Gradient Boosting model has the highest precision of 0.88 while the SVM model has the highest recall of 0.82."
1800,"caption: Table 4: Evaluation of Machine Learning Modelstable: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.82,0.80,0.76,0.84, Naive Bayes,0.77,0.73,0.69,0.78, Decision Tree,0.71,0.67,0.70,0.64, Random Forest,0.86,0.83,0.82,0.84, K-NN,0.79,0.77,0.72,0.82","Table 4 presents a comparison of five different machine learning models based on various evaluation metrics such as accuracy, F1 score, precision, and recall. The models include SVM, Naive Bayes, Decision Tree, Random Forest, and K-NN. The highest accuracy is exhibited by the Random Forest model, which scored 0.86, while the Decision Tree model presented the lowest result for accuracy with 0.71. For F1 score, the best performance comes from the Random Forest model, followed by SVM and K-NN. Precision and Recall are presented similarly, with Random Forest and SVM obtaining the highest score for precision and recall, respectively. Overall, the Random Forest model displays an outstanding all-around performance in the evaluated metrics in this study."
1801,"caption: Model performance comparison using multiple evaluation metrics.table: Model,Accuracy,Recall,Precision,F1-score,AUC, SVM,0.85,0.81,0.90,0.85,0.91, KNN,0.72,0.71,0.75,0.73,0.80, RF,0.89,0.87,0.91,0.89,0.93, LR,0.80,0.78,0.82,0.80,0.85","The table compares the accuracy, recall, precision, F1-score, and AUC of four different models: SVM, KNN, RF, and LR. The models were tested on the same dataset, and the results show that RF has the highest accuracy, recall, precision, F1-score, and AUC. SVM has the second-best performance, with the highest AUC score. KNN has the lowest accuracy, recall, precision, and F1-score, but still achieved a respectable AUC score. LR has a moderate overall performance but is outperformed by SVM, KNN, and RF in terms of AUC. Overall, these results suggest that RF is the best performer across the different evaluation metrics."
1802,"caption: Comparison of Different Models' Performance Scores based on Accuracy, F1 Score, Precision, and Recall.table: Model,Accuracy,F1 Score,Precision,Recall, Random Forest,0.87,0.85,0.88,0.83, XGBoost,0.84,0.82,0.79,0.86, SVM (Linear Kernel),0.82,0.76,0.79,0.74, Logistic Regression,0.76,0.80,0.69,0.94, Neural Network,0.78,0.77,0.75,0.79","Table presents a comparison of different models based on four evaluation metrics, namely Accuracy, F1 Score, Precision, and Recall. The models selected for comparison are Random Forest, XGBoost, SVM (Linear Kernel), Logistic Regression, and Neural Network, evaluated on the same dataset. From the table, the Random Forest model shows the highest accuracy score of 0.87, followed by XGBoost scoring 0.84. The Logistic Regression model has the highest F1 Score of 0.80, while the SVM (Linear Kernel) has the lowest F1 Score of 0.76. For the Precision metric, Random Forest performs the best with a score of 0.88, while Logistic Regression has the least score of 0.69. Finally, for Recall, Neural Network shows the highest value of 0.79, while Logistic Regression once again trails with the least score of 0.94."
1803,"caption: Performance of Five Different Models on Classification Tasktable: Model,F1-Score,Precision,Recall,Accuracy, Model A,0.82,0.84,0.80,0.87, Model B,0.80,0.86,0.75,0.86, Model C,0.83,0.89,0.78,0.89, Model D,0.78,0.82,0.75,0.83, Model E,0.85,0.85,0.85,0.85","The table compares the performance of five different models based on multiple evaluation metrics on a classification task. The evaluation metrics included are F1-Score, precision, recall, and accuracy. Model C performed the best with an F1-Score of 0.83 and accuracy of 0.89, while model D had the lowest F1-Score of 0.78 and accuracy of 0.83. Interestingly, model E had the highest precision, recall, and F1-Score, all of which are equal to 0.85. This suggests that the model E performed consistently across all evaluation metrics."
1804,"caption: Table 4: Model performance comparison based on different evaluation metrics.table: ```, Model,F1 Score Micro,F1 Score Macro,Accuracy,Precision,Recall, Model A,0.65,0.62,0.67,0.73,0.58, Model B,0.72,0.69,0.74,0.77,0.65, Model C,0.53,0.49,0.55,0.60,0.45, Model D,0.78,0.75,0.80,0.81,0.70","Table 4 shows the comparison of different models based on multiple evaluation metrics. The models were evaluated on F1 Score (micro), F1 Score (macro), accuracy, precision, and recall. Model B shows the highest F1 Score (micro), F1 Score (macro), and accuracy with score of 0.72, 0.69, and 0.74, respectively. Model D shows the highest precision and recall with scores of 0.81 and 0.70, respectively. Interestingly, Model A and Model C have relatively lower model performance scores across all evaluation metrics."
1805,"caption: Table 4: Evaluation metrics comparison of four models.table: Model name,Accuracy,F1-score,AUC-ROC, Model 1,0.82,0.80,0.92, Model 2,0.85,0.83,0.90, Model 3,0.78,0.75,0.95, Model 4,0.80,0.78,0.88","Table 4 presents a comparison of four different models based on three evaluation metrics - accuracy, F1-score, and AUC-ROC. Notably, Model 3 has the highest AUC-ROC of 0.95, indicating that it performed exceptionally well in the dataset's classification performance. Model 1 and Model 2 have similar accuracy and F1-score, with Model 2 slightly outperforming Model 1 in both metrics. However, Model 4 seems to underperform relative to the other models in all three metrics. The results suggest that Models 1, 2, and 3 are potentially better models for this dataset than Model 4."
1806,"caption: Table 4: Model performances of different supervised learning algorithms based on multiple evaluation metrics.table: Model,Accuracy,F1 score,Precision,Recall, Logistic Reg.,0.8,0.82,0.84,0.84, SVM,0.78,0.81,0.83,0.82, Decision Tree,0.75,0.75,0.76,0.76, Random Forest,0.85,0.87,0.88,0.88, XGBoost,0.87,0.89,0.90,0.90","Table 4 presents a comparison of different supervised learning algorithms' model performances based on multiple evaluation metrics, including Accuracy, F1 score, Precision, and Recall. The table exhibits Logistic Regression, SVM, Decision Tree, Random Forest, and XGBoost models' performance metrics. Interestingly, the Random Forest model achieved the highest Accuracy, F1 score, Precision, and Recall scores of 0.85, 0.87, 0.88, and 0.88, respectively. The XGBoost model performed the next best with an Accuracy of 0.87 and F1 score, Precision, and Recall scores of 0.89, 0.90, and 0.90, respectively. In contrast, the Decision Tree model performed the worst among other models for all evaluation metrics presented here."
1807,"caption: Table 4: Comparison of different models' performance using different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, SVM,0.87,0.90,0.86,0.88, Decision Tree,0.82,0.82,0.87,0.84, Random Forest,0.89,0.92,0.85,0.88, Naive Bayes,0.73,0.77,0.68,0.72, Logistic Regression,0.92,0.94,0.93,0.93","Table 4 presents a comparison of different machine learning models' performance measured by various evaluation metrics: Accuracy, Precision, Recall, and F1 Score. The models evaluated include SVM, Decision Tree, Random Forest, Naive Bayes, and Logistic Regression. The Accuracy score reflects the percentage of the correct predictions made by each model. The Logistics Regression model's performance stands out as it achieved the highest score in all evaluated metrics: Accuracy (0.92), Precision (0.94), Recall (0.93), and F1 Score (0.93). Interestingly, the Decision Tree model achieved the highest Recall (0.87) score, while the Naive Bayes model had the lowest scores in all evaluated metrics."
1808,"caption: Table 4: Evaluation metrics for various machine learning modelstable: Model,Accuracy,F1-Score,Precision,Recall, Naive Bayes,0.78,0.75,0.61,0.93, Logistic Regression,0.85,0.84,0.77,0.92, Random Forest,0.90,0.89,0.84,0.94, Support Vector Machine,0.82,0.81,0.72,0.94","Table 4 displays multiple evaluation metrics for various machine learning models, including Naive Bayes, Logistic Regression, Random Forest, and Support Vector Machine (SVM). The evaluation metrics include Accuracy, F1-Score, Precision, and Recall. Notably, Random Forest achieves the highest accuracy with a score of 0.90, while Naive Bayes achieved the lowest accuracy of 0.78. The highest F1-Score is achieved by Random Forest with a score of 0.89, followed by Logistic Regression with 0.84. Moreover, Random Forest has the highest precision 0.84, while Naive Bayes has the lowest precision 0.61. Finally, Recall scores range from a low of 0.92 by Logistic Regression to a high of 0.94 by Random Forest and SVM models."
1809,"caption: Evaluation metrics for multiple modelstable: Model,F1-Score (Class 0),F1-Score (Class 1),Precision (Class 0),Precision (Class 1),Recall (Class 0),Recall (Class 1), A,0.85,0.78,0.92,0.65,0.80,0.90, B,0.82,0.85,0.75,0.93,0.91,0.77, C,0.90,0.73,0.84,0.80,0.96,0.66, D,0.78,0.88,0.98,0.54,0.65,0.97","The presented table showcases the evaluation metrics for four different models, A, B, C, and D. The table includes F1-scores, precision, and recall separated by class. The models' results vary significantly across the evaluation metrics. Model A achieved the highest F1-Score in class 0 at 0.85, while model D had the highest F1-score in class 1 at 0.88. Overall, model C consistently showed excellent results, particularly with a precision of 0.84 in class 0, a recall of 0.96 in class 0, and an F1-score of 0.90. Model B's precision in class 1 was the highest, scoring 0.93, while recall in class 0 was 0.91."
1810,"caption: Table 4: Comparison of different models using various evaluation metrics.table: Model,Precision,Recall,F1-score,AUC, Logistic Regression,0.89,0.75,0.81,0.94, Random Forest,0.92,0.83,0.86,0.96, Gradient Boosting,0.93,0.81,0.86,0.95, Multi-Layer Perceptron,0.90,0.79,0.83,0.93, Support Vector Machine,0.88,0.68,0.75,0.90","Table 4 depicts the comparison of different machine learning models' performances, including Logistic Regression, Random Forest, Gradient Boosting, Multi-Layer Perceptron, and Support Vector Machine. These models were evaluated using four different metrics, such as Precision, Recall, F1-Score, and AUC. Based on the table, Random Forest performs the best in terms of precision, recall, and F1-score with 0.92, 0.83, and 0.86, respectively. However, Gradient Boosting produces the highest AUC of 0.95. Interestingly, Support Vector Machine has the lowest AUC compared to other models, while Multi-Layer Perceptron reveals the lowest score in F1. Overall, the table suggests that Random Forest and Gradient Boosting are the leading models in the given context."
1811,"caption: Performance metrics of different models based on accuracy, F1-Score, Precision, and Recall.table: Model Name,Accuracy,F1-Score,Precision,Recall, Model A,0.92,0.91,0.95,0.87, Model B,0.78,0.76,0.72,0.81, Model C,0.81,0.75,0.88,0.65, Model D,0.89,0.88,0.93,0.83","The above table provides a comparison of multiple models based on their accuracy, F1-Score, Precision, and Recall metrics. Model A achieved the highest accuracy of 0.92, while Model D had an accuracy of 0.89. Model A also had the highest F1-Score of 0.91, with Model D close behind with a score of 0.88. In contrast, Model B had the lowest accuracy of 0.78 and F1-Score of 0.76. Additionally, Model C had the highest Precision score with a value of 0.88, and Model B had the lowest Precision score of 0.72. Finally, Model B had the highest Recall score at 0.81, with Model C having the lowest Recall score at 0.65. Overall, Model A had the best performance based on the analyzed metrics."
1812,"caption: Table 4: Performance comparison of different regression models in predicting house prices.table: Model,RMSE,MAE,r2, Linear Regression,0.452,0.343,0.560, Support Vector Machine,0.324,0.287,0.776, Random Forest,0.308,0.261,0.809, Gradient Boosting,0.291,0.238,0.834, XGBoost,0.300,0.244,0.827","Table 4 shows the performance comparison of different regression models in predicting house prices using multiple evaluation metrics, specifically Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), and R-squared (r2). The linear regression model is the least performing model, achieving the highest RMSE of 0.452 and the lowest r2 of 0.56 among other models. While the Support Vector Machine model performs better with an RMSE of 0.324 and a better r2 of 0.776. The Random Forest model is the best-performing model in terms of both RMSE and r2 with 0.308 and 0.809, respectively. Interestingly, the Gradient Boosting model and XGBoost models have lower RMSE and higher r2 compared to the Random Forest model, but they are not better for all three evaluation metrics."
1813,"caption: Model performances based on different evaluation metrics.table: Model,F1-score,Precision,Recall, Logistic Regression (C=0.1),0.83±0.02,0.86±0.03,0.80±0.04, Support Vector Machine (C=1),0.80±0.01,0.84±0.02,0.77±0.03, Decision Tree Classifier (max-depth=6),0.75±0.02,0.82±0.03,0.70±0.04, Random Forest Classifier,0.88±0.01,0.89±0.02,0.87±0.03, XGBoost Classifier,0.88±0.02,0.88±0.03,0.87±0.04","Table 4 presents the performance of different models based on multiple evaluation metrics such as F1-score, precision, and recall. The table includes five models - Logistic Regression, Support Vector Machine, Decision Tree Classifier, Random Forest, and XGBoost Classifier. The models were trained and tested using the same dataset. The Random Forest Classifier recorded the highest F1-score of 0.88±0.01, closely followed by the XGBoost Classifier with a score of 0.88±0.02. Moreover, the Logistic Regression and SVM models performed relatively well, while the Decision Tree Classifier attained a lower F1-score of 0.75±0.02. On the other hand, all models demonstrated a high level of precision, with Random Forest achieving the highest precision of 0.89±0.02. Additionally, all models yielded comparable recall scores, with Logistic Regression creating the most optimal result and Decision Tree Classifier producing the least."
1814,"caption: Table 2: Model performance evaluation using different evaluation metrics.table: Model,F1-score,Precision,Recall, LogReg,0.73,0.68,0.79, SVM,0.76,0.72,0.81, KNN,0.63,0.71,0.57, RF,0.81,0.76,0.87, XGB,0.83,0.79,0.88","Table 2 showcases multiple models' performances based on different evaluation metrics like F1-score, Precision, and Recall. The models in consideration are LogReg, SVM, KNN, RF, and XGB. The highest F1-score is shown by XGB (0.83), followed by RF (0.81); KNN has the lowest F1-score of 0.63. In terms of Precision, XGB and RF have the highest Precision score (0.79 and 0.76, respectively). Also, SVM produced a slightly higher Precision score (0.72), but LogReg had the lowest score (0.68). Comparing the highest Recall score, RF and XGB got the highest values of 0.87 and 0.88, respectively. Meanwhile, KNN got the lowest score of 0.57. Overall, XGB and RF performed better than other models in most metrics, while KNN had the poorest performance."
1815,"caption: Table 4: Performance of Different Models Based on Various Evaluation Metrics.table: Model,F1 Score,Accuracy,Precision,Recall, Model A,0.68,0.74,0.72,0.64, Model B,0.74,0.79,0.78,0.71, Model C,0.76,0.81,0.80,0.73, Model D,0.72,0.77,0.75,0.70, Model E,0.80,0.83,0.82,0.78","Table 4 presents the performance of five models based on different evaluation metrics. The evaluation metrics are F1 Score, Accuracy, Precision, and Recall. The models are labeled from A to E, with each model's corresponding F1 Score, Accuracy, Precision, and Recall presented in the table. Model E demonstrates the best performance across all metrics, with an F1 Score of 0.80, Accuracy of 0.83, Precision of 0.82, and Recall of 0.78. Interestingly, Model B has the second-highest performance, even though it has the lowest F1 Score. This result suggests the importance of considering multiple evaluation metrics when comparing model performance."
1816,"caption: Table 4: Model performance using different evaluation metrics.table: Model,Precision,Recall,F1-score,AUC, Naive Bayes,0.84,0.78,0.81,0.87, Random Forest,0.91,0.88,0.89,0.93, Gradient Boost,0.92,0.90,0.91,0.94, SVM,0.89,0.81,0.84,0.91, Logistic,0.85,0.89,0.86,0.92","Table 4 represents a comparison of different models' performances evaluated using various metrics. The models compared are Naive Bayes, Random Forest, Gradient Boost, SVM, and Logistic. The evaluation metrics used are Precision, Recall, F1-score, and AUC. This table shows that the highest Precision is obtained by Gradient Boost, with a score of 0.92. Random Forest has the highest Recall and F1-score performance, with both scores at 0.88 and 0.89, respectively. For AUC, Gradient Boost outperformed other models, with a score of 0.94. SVM and Logistic models also displayed good performances in all metrics."
1817,"caption: Comparison of different machine learning models based on various evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, Logistic regression,0.89,0.87,0.91,0.85, SVM,0.88,0.86,0.9,0.82, Random forest,0.92,0.90,0.93,0.88, XGBoost,0.93,0.92,0.94,0.89","Table 1 demonstrates the results of multiple machine learning models, namely Logistic regression, SVM, Random forest, and XGBoost trained on the same dataset. The models' evaluation metrics, including Accuracy, F1-Score, Precision, and Recall, are juxtaposed in the table, with XGBoost achieving the highest performance among the models, with an Accuracy of 0.93, F1-Score of 0.92, Precision of 0.94, and Recall of 0.89. Meanwhile, Random forest has the second-best performance with an Accuracy of 0.92 and an F1-Score of 0.90. Interestingly, both Logistic Regression and SVM models perform similarly with an Accuracy of 0.89 and 0.88, respectively."
1818,"caption: Model Performance Metricstable: Model,Accuracy,Precision,Recall,F1 score, Logistic regression,0.85,0.70,0.95,0.80, Random forest,0.92,0.86,0.97,0.91, MLP,0.89,0.78,0.93,0.84, SVM,0.84,0.69,0.96,0.79","Table presents the accuracy, precision, recall, and F1 score for logistic regression, random forest, MLP, and SVM models. The best performing model varies across the evaluation metric. The random forest model has the highest accuracy of 0.92, while the logistic regression model scored the lowest accuracy with 0.85. For precision and recall metrics, the random forest model obtained the highest values of 0.86 and 0.97, respectively. MLP outperformed other models in the F1 score metric with a score of 0.84. SVM had the highest precision value of 0.69 and a comparatively low recall value of 0.96."
1819,"caption: Table 4: Model evaluation results on binary classification task using multiple metrics.table: Model,Precision,Recall,F1-score,Accuracy, Logistic Regression,0.84,0.92,0.88,0.83, Random Forest,0.89,0.88,0.88,0.88, XGBoost,0.93,0.92,0.91,0.92, SVM,0.78,0.84,0.81,0.73","Table 4 compares the performances of different models on a binary classification task, where four models, namely Logistic Regression, Random Forest, XGBoost, and SVM were evaluated using multiple metrics such as Precision, Recall, F1-score, and Accuracy. Notably, all models were trained and tested on the same dataset. The results show that XGBoost has the highest Precision, Recall, and F1-score values of 0.93, 0.92, and 0.91, respectively. While Logistic Regression has the lowest values of Precision, Recall, and F1-score, it has the highest Accuracy score of 0.83. Random Forest has identical F1-scores with XGBoost, while the SVM has the lowest average performance results."
1820,"caption: Performance comparison of different models using various evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.92,0.93,0.94,0.92, RF,0.89,0.87,0.86,0.90, LR,0.78,0.79,0.71,0.89, MLP,0.85,0.83,0.85,0.81","Table presented clearly illustrates the performances of four different models: SVM, Random Forest (RF), Logistic Regression (LR), and Multi-layer Perceptron (MLP) using various evaluation metrics, including accuracy, F1-score, precision, and recall. Based on the accuracy scores, SVM ranks first with a score of 0.92, while the RF model ranks second with accuracy of 0.89. Although the SVM and RF models have nearly the same F1-score and recall scores, the SVM model has significantly higher precision score than RF and MLP models. While MLP has the highest precision score in all models, it has the lowest recall score. These results indicate that SVM is better suited for overall accuracy, RF is better suited for recall, and MLP is better suited for precision."
1821,"caption: Comparison of model performance based on evaluation metricstable: Model,F1-Score,Matthews Correlation Coefficient,Accuracy, Model 1,0.78,0.68,0.80, Model 2,0.84,0.77,0.86, Model 3,0.79,0.64,0.82, Model 4,0.88,0.81,0.88, Model 5,0.81,0.71,0.84","Table 1 compares different models based on their evaluation metrics. The table shows the models' F1-Score, Matthews Correlation Coefficient, and Accuracy. Notably, Model 4 achieved the highest F1-Score of 0.88 and the highest Matthews Correlation Coefficient score of 0.81, indicating excellent performance. Model 2 attains the highest Accuracy with a score of 0.86. Model 1 achieved the lowest scores in all three metrics, with F1-Score, Matthews Correlation Coefficient, and Accuracy of 0.78, 0.68, and 0.80, respectively. Interestingly, Model 3 attained a lower score in F1-Score and Matthews Correlation Coefficient but a relatively higher Accuracy score of 0.82."
1822,"caption: Model performances in different evaluation metricstable: Model,Accuracy,F1-Score,Precision,Recall, Decision Tree,0.75,0.72,0.73,0.74, Random Forest,0.83,0.81,0.84,0.80, Support Vector Machine,0.79,0.76,0.77,0.78, Logistic Regression,0.81,0.80,0.83,0.77, Multilayer Perceptron,0.85,0.82,0.84,0.81","Model performances in terms of evaluation metrics such as Accuracy, F1-Score, Precision, and Recall are shown in Table X. The table presents the performance result of five different models: Decision Tree, Random Forest, Support Vector Machine, Logistic Regression, and Multilayer Perceptron. The highest performing model for Accuracy and F1-score is Multilayer Perceptron, achieving 0.85 and 0.82, respectively. The highest-performing models for Precision and Recall are Random Forest and Logistic Regression, respectively. By analyzing the table, it can be observed that Multilayer Perceptron is the most balanced of models, scoring well across all evaluation metrics."
1823,"caption: Table 4: Model performance based on different evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score, Decision Tree,0.85,0.72,0.85,0.78, Random Forest,0.92,0.89,0.92,0.91, Support Vector Machine,0.89,0.82,0.89,0.85, Logistic Regression,0.91,0.87,0.91,0.89, Naive Bayes,0.87,0.76,0.87,0.81","Table 4 illustrates the model performances based on different evaluation metrics such as Accuracy, Precision, Recall, and F1-Score. The table includes five models, namely Decision Tree, Random Forest, Support Vector Machine, Logistic Regression, and Naive Bayes. From the table, the Random Forest model produces the highest Accuracy, Precision, and F1-Score scores of 0.92, 0.89, and 0.91, respectively. However, the Support Vector Machine model generates the highest Recall score of 0.89, indicating that this model is more suitable for identifying true positives. It can be observed that all models perform reasonably well, with Accuracy ranging from 0.85 to 0.91."
1824,"caption: Table 4: Performance comparison of multiple models using different evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.947,0.947,0.948,0.947, Decision Tree,0.900,0.899,0.902,0.900, Random Forest,0.964,0.963,0.964,0.964, Gradient Boosting,0.945,0.944,0.945,0.945, Support Vector Machine,0.935,0.935,0.937,0.935","Table 4 presents a comparison of multiple machine learning models based on different evaluation metrics, including accuracy, F1-score, precision, and recall. The table contains five models: Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Support Vector Machine. Interestingly, Random Forest achieved the highest accuracy, F1-score, and recall results, with 0.964, 0.963, and 0.964, respectively. In contrast, Decision Tree had the lowest performance in terms of accuracy, F1-score, and recall among all the models. Logistic Regression, Gradient Boosting, and Support Vector Machine achieved moderate performance results from all evaluation metrics."
1825,"caption: The performance comparison of different machine learning classifiers.table: Model Name,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.85,0.87,0.82,0.84, KNN,0.78,0.69,0.74,0.71, Decision Tree,0.82,0.86,0.82,0.82, Random Forest,0.89,0.90,0.87,0.89, SVM,0.84,0.86,0.82,0.84","The table displays a performance comparison of different machine learning classifiers based on evaluation metrics such as accuracy, precision, recall, and F1 score. Logistic regression, KNN, decision tree, random forest, and SVM models are evaluated on a dataset, and respective performances are reported. Random forest has the highest accuracy score of 0.89, whereas, in precision and recall, all models have close scores. In terms of the F1 score, random forest outperforms other models obtaining the highest score of 0.89, while KNN has the lowest score of 0.71. The table will assist in selecting a suitable algorithm based on the specific evaluation metric requirement."
1826,"caption: A comparison of different models based on evaluation metrics.table: Model Type,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.75,0.74,0.73,0.77, Support Vector Machine,0.72,0.73,0.70,0.76, Naive Bayes,0.68,0.63,0.70,0.56, Random Forest,0.81,0.80,0.82,0.79, Neural Network,0.77,0.75,0.78,0.73","Table above presents a comparison of five different classification models based on evaluation metrics such as Accuracy, F1-Score, Precision, and Recall. The models' performances were tested and compared on the same dataset. The Random Forest model shows the best performance with an accuracy score of 0.81, an F1-score of 0.80, a precision score of 0.82, and a recall score of 0.79. Overall, the table shows that the random forest and neural network models outperformed the other models, while the Naive Bayes model exhibited the lowest performance."
1827,"caption: Table 4: Comparison of different models using multiple evaluation metricstable: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.85,0.82,0.85,0.80, Random Forest,0.87,0.84,0.87,0.81, XGBoost,0.88,0.85,0.89,0.83, Support Vector Machine,0.81,0.78,0.81,0.77, Multilayer Perceptron,0.84,0.81,0.84,0.77","Table 4 provides performance comparison of five different models using multiple evaluation metrics, namely Accuracy, F1 Score, Precision, and Recall. From this table, we can observe that XGBoost achieved the highest Accuracy of 0.88. Random Forest got the best F1 Score of 0.84 and Precision score of 0.87. All models’ recall scores are over 0.75, indicating that they are good at correctly predicting positive instances. However, Support Vector Machine performed the worst, with accuracy, F1 score, precision, and recall scores of 0.81, 0.78, 0.81, and 0.77, respectively."
1828,"caption: Comparison of Model Performance based on Multiple Evaluation Metricstable: Model,Accuracy (%),Precision (%),Recall (%),F1 Score (%), SVM,78.9,80.5,75.3,77.7, Random Forest,83.2,86.1,78.3,82.0, Neural Network,85.6,87.4,83.5,85.4, Logistic Regression,76.8,81.2,70.3,75.3","Table 4 presents a comparison of different machine learning models in terms of accuracy, precision, recall, and F1 score evaluation metrics. The SVM, Random Forest, Neural Network, and Logistic Regression models achieved accuracy scores of 78.9%, 83.2%, 85.6%, and 76.8%, respectively. Interestingly, the Neural Network model showed the highest scores for precision, recall, and F1 score with 87.4%, 83.5%, and 85.4%, respectively. In contrast, the SVM model obtained the lowest recall score at 75.3%. Overall, the results show that the Neural Network model performed best among the models considered in this study, while the SVM model underperformed."
1829,"caption: Table 4: Model Performance Comparisons Based on Various Evaluation Metricstable: Model,MAE,MSE,R2 Score,Explained Variance Score, Random Forest,0.138,0.028,0.921,0.925, XGBoost,0.145,0.030,0.914,0.918, SVR[linear],0.155,0.036,0.898,0.902, SVR[rbf],0.186,0.047,0.852,0.859, Decision Tree,0.159,0.038,0.882,0.887","Table 4 provides the MAE, MSE, R2 Score, and Explained Variance Score comparison of different models, including Random Forest, XGBoost, Decision Tree, and Support Vector Regression with Linear and RBF kernels. Based on the MAE and MSE, the Random Forest and XGBoost models have the closest performance, followed by the Decision Tree.  However, the Random Forest model has the highest R2 score of 0.921 and explained variance score of 0.925. The XGBoost model also has a close R2 score of 0.914 and an explained variance score of 0.918. The Support Vector Regression model with a linear kernel has the lowest MAE and MSE values, while the model with an RBF kernel has the worst performance."
1830,"caption: Various models' evaluation metrics resultstable: Model,Accuracy,Precision,Recall,F1-Score,AUC, Logistic Regression,0.75,0.74,0.78,0.76,0.83, Decision Tree,0.72,0.71,0.74,0.73,0.79, Random Forest,0.78,0.77,0.80,0.78,0.85, XGBoost,0.80,0.79,0.82,0.80,0.87, Neural Network,0.82,0.81,0.84,0.82,0.89","In this table, we present a comparison of different machine learning models' performance based on multiple evaluation metrics in a binary classification problem. The evaluated models are Logistic Regression, Decision Tree, Random Forest, XGBoost, and Neural Network. The table shows that the best accuracy is achieved by the Neural Network model with a score of 0.82. Interestingly, the XGBoost model achieved the highest AUC with a score of 0.87. The Random Forest model shows the highest recall and precision with scores of 0.80 and 0.77, respectively. Overall, this table provides insights into the strengths of different models for the given classification problem and can be used to guide model selection for future data classification tasks."
1831,"caption: Model performance from different algorithms based on various evaluation metrics.table: Model,F1-score,Precision,Recall,Accuracy, SVM,0.78,0.86,0.72,0.81, Random Forest,0.82,0.81,0.84,0.83, XGBoost,0.86,0.87,0.85,0.85, Logistic Regression,0.80,0.83,0.77,0.81, Naive Bayes,0.75,0.62,0.92,0.76","The table above displays the results of the performance evaluation of five different models, including SVM, Random Forest, XGBoost, Logistic Regression, and Naive Bayes. Each model's performance was evaluated based on four different evaluation metrics: F1-score, Precision, Recall, and Accuracy. Interestingly, the XGBoost model shows the best F1-score of 0.86, while the SVM model achieved the highest Precision with a score of 0.86. Naive Bayes achieved the best Recall with a score of 0.92. Moreover, the Random Forest model reaches balanced performance across all evaluation metrics."
1832,"caption: Table 4: Model performance based on different evaluation metricstable: Model,Accuracy Score,F1 Score,Precision Score,Recall Score, Logistic Regression,0.93,0.89,0.91,0.88, Decision Tree,0.85,0.81,0.83,0.82, Random Forest,0.95,0.92,0.94,0.91, Naive Bayes,0.88,0.82,0.89,0.76, Support Vector Machine,0.94,0.91,0.94,0.88","Table 4 presents a comparison of different machine learning models based on multiple evaluation metrics. The table includes the models' accuracy score, F1 score, precision score, and recall score. The models compared in this table are Logistic Regression, Decision Tree, Random Forest, Naive Bayes, and Support Vector Machine. Notably, the Random Forest model shows the best performance across all metrics with the highest accuracy score of 0.95, F1 score of 0.92, precision score of 0.94, and recall score of 0.91. However, the Logistic Regression model performs best on the precision score at 0.91, while the Naive Bayes model's recall score is the lowest at 0.76. Overall, this table provides an overview of the models' performances based on a range of measures."
1833,"caption: Table 4: Model performance across multiple evaluation metrics.table: Model,Precision,Recall,F1-score,Accuracy, LogReg,0.87,0.81,0.84,0.86, SVM,0.80,0.83,0.81,0.86, Naive Bayes,0.82,0.78,0.80,0.84, Random Forest,0.88,0.86,0.87,0.88, XGBoost,0.87,0.88,0.87,0.88, Neural Network,0.89,0.91,0.89,0.90","Table 4 presents a comparison of multiple models' performance across multiple evaluation metrics, such as precision, recall, F1-score, and accuracy. The LogReg and XGBoost models both achieved the highest precision scores of 0.87 and 0.87, respectively. On the other hand, Neural Network model achieved the highest recall and F1-score of 0.91 and 0.89. Moreover, Random Forest model obtained the highest accuracy score of 0.88. Interestingly, SVM model presented the most balanced performance in terms of precision and recall, achieving scores of 0.80 and 0.83, respectively. Overall, considering multiple evaluation metrics, the Neural Network model shows exceptional performance, with high recall score of 0.91, and a balanced F1-score of 0.89."
1834,"caption: Model evaluation metrics comparisontable: Model,Precision,Recall,F1-score,AUC-ROC, Logistic,0.81,0.83,0.82,0.71, Decision Tree,0.75,0.65,0.68,0.80, Naïve Bayes,0.77,0.71,0.72,0.70, Random Forest,0.91,0.84,0.87,0.95, XGBoost,0.94,0.89,0.91,0.98",
1835,"caption: Model performances of various classification models on the dataset.table: Model,Accuracy (±std),F1-score (±std),AUC-ROC (±std), MLP,0.87±0.03,0.83±0.02,0.92±0.01, SVM,0.83±0.02,0.80±0.03,0.91±0.02, LR,0.86±0.02,0.82±0.01,0.92±0.01, DT,0.75±0.03,0.71±0.02,0.78±0.04, RF,0.88±0.02,0.85±0.01,0.95±0.01","Table presents the comparison of multiple classification models on the dataset based on accuracy, F1-score, and AUC-ROC evaluation metrics. The models considered in the comparison are MLP, SVM, LR, DT, and RF. The table demonstrates that the RF model outperforms others with the highest Accuracy (0.88±0.02), F1-score (0.85±0.01), and AUC-ROC (0.95±0.01). Notably, the MLP model also performs well in terms of Accuracy and F1-score with scores of 0.87±0.03 and 0.83±0.02, respectively. However, the DT model performs poorly with the lowest scores of all metrics. Overall, the results suggest that the RF model is the best-performing model among the considered models, while DT is the least performing model."
1836,"caption: Model performance evaluation using various metrics.table: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.89,0.90,0.88,0.89, Decision Tree,0.87,0.84,0.88,0.86, Random Forest,0.94,0.95,0.93,0.94, K-Nearest Neighbor,0.83,0.82,0.85,0.83, Support Vector Machine,0.91,0.91,0.90,0.91","The table presents a model performance evaluation based on different evaluation metrics. The models evaluated are Logistic Regression, Decision Tree, Random Forest, K-Nearest Neighbor, and Support Vector Machine. The models' evaluation metrics include Accuracy, Precision, Recall, and F1-score. The Random Forest model performs the best in all the evaluation metrics, having achieved an Accuracy score of 0.94, Precision score of 0.95, Recall score of 0.93, and F1-score of 0.94. Logistic Regression and Support Vector Machine also performed impressively, having achieved above 0.9 in all evaluation metrics. K-Nearest Neighbor had the lowest performance, achieving the lowest F1-score of 0.83 among the models evaluated."
1837,"caption: Comparison of different models using multiple evaluation metrics.table: Model Name,F1 Score,Matthews Correlation Coefficient (MCC),Precision,Recall, Model A,0.75,0.50,0.80,0.71, Model B,0.62,0.27,0.60,0.64, Model C,0.81,0.61,0.75,0.89, Model D,0.69,0.38,0.62,0.77, Model E,0.73,0.50,0.70,0.76","Table presents a comparison of different models used for a specific task based on multiple evaluation metrics - F1 Score, Matthews Correlation Coefficient (MCC), Precision, and Recall. The models listed in the table are Model A, Model B, Model C, Model D, and Model E. The F1 score is a harmonic mean of Precision and Recall. Matthews's Correlation Coefficient (MCC) is a correlation coefficient used for binary classification tasks. The table shows that Model C has the highest F1 score and MCC among the listed models. Furthermore, Model C and Model E have higher Precision scores, whereas Model C has the highest recall score. The evaluation metrics' difference emphasizes the importance of performing different evaluations when selecting a model."
1838,"caption: Performance of different models on classification tasktable: Model,Accuracy,Recall,Precision,F1 Score, Random Forest,0.756,0.713,0.781,0.745, Decision Tree,0.698,0.618,0.678,0.647, Support Vector Machine,0.702,0.648,0.664,0.642, Naive Bayes,0.622,0.418,0.513,0.421, Logistic Regression,0.725,0.652,0.715,0.674","The table above shows the performance of different machine learning models in a classification task. The models were evaluated using four different metrics, i.e., accuracy, recall, precision, and F1 score. It's interesting to note that the Random Forest model achieved the highest accuracy with a score of 0.756, however, it had a relatively lower recall compared to Decision Tree, Support Vector Machine, and Logistic Regression models. Naive Bayes performed poorly on all metrics with the lowest score on the F1 score at 0.421. Overall, the Logistic Regression model showed a relatively balanced performance on all metrics compared to other models."
1839,"caption: Performance comparison of multiple classification models using different evaluation metrics.table: Model,F1-score,Precision,Recall,Accuracy, SVM,0.89,0.91,0.87,0.93, Naive Bayes,0.84,0.78,0.92,0.90, Decision Tree,0.80,0.82,0.78,0.86, Random Forest,0.95,0.92,0.98,0.96, Boosting,0.93,0.91,0.96,0.95","The presented table showcases the performance results of multiple classification models based on different evaluation metrics, including F1-score, precision, recall, and accuracy. The SVM model shows the highest F1-score of 0.89, while the Random Forest model performed best in other metrics, such as precision (0.92), recall (0.98) and accuracy (0.96). The boosting model had a high F1-score of 0.93 and excellent precision (0.91) and recall (0.96). Interestingly, Naive-Bayes had a reasonable F1-score, while Decision Tree's performance was the lowest among the models. Overall, Random Forest and Boosting models were the top performers based on the evaluation metrics."
1840,"caption: Comparison of different models based on evaluation metricstable: Models,Accuracy,Precision,Recall,F1-Score, Model A,0.86,0.68,0.93,0.79, Model B,0.78,0.54,0.92,0.68, Model C,0.91,0.73,0.89,0.80, Model D,0.80,0.63,0.78,0.69, Model E,0.87,0.71,0.90,0.79","Table: Comparison of different models based on evaluation metrics. The table presents the accuracy, precision, recall, and F1-score of five different models. Model C shows the highest accuracy of 0.91, with a corresponding precision of 0.73 and recall of 0.89. Alternatively, Model B has the lowest accuracy (0.78) but achieves a high recall score of 0.92. Interestingly, Model D and Model E report similar accuracy results, 0.80 and 0.87, respectively. However, Model E outperforms Model D in all other evaluation metrics, including precision, recall, and F1-score. Overall, this table could help in deciding which model performs the best in specific evaluation metrics."
1841,"caption: Table 4: Model performance on different evaluation metrics.table: Model,F1 Score,Precision,Recall,Accuracy, SVM,0.897,0.910,0.885,0.908, KNN,0.887,0.879,0.895,0.890, RF,0.906,0.915,0.898,0.910, XGB,0.900,0.898,0.902,0.898, ANN,0.903,0.889,0.917,0.890","Table 4 demonstrates a performance comparison of five different models using various evaluation metrics, including F1 Score, Precision, Recall, and Accuracy. The table reveals that the Random Forest (RF) model achieved the highest F1 Score and Precision score with 0.906 and 0.915, respectively. On the other hand, SVM showed the highest Recall score with 0.885, while ANN had the highest Accuracy score of 0.890. These results indicate that no single model performed best in all evaluation metrics, suggesting the need for a trade-off between these metrics to select the best model based on the specific needs and applications."
1842,"caption: Table 4: Evaluation metrics for different machine learning models applied to a binary classification problem.table: Model,Precision,Recall,F1-score,ROC-AUC, Random Forest,0.90,0.85,0.87,0.78, Support Vector Machine,0.88,0.90,0.89,0.85, Logistic Regression,0.82,0.81,0.81,0.71, Gradient Boosting,0.87,0.88,0.87,0.83, CatBoost,0.91,0.92,0.91,0.88","The table shows the evaluation metrics, such as Precision, Recall, F1-score, and ROC-AUC, for five different machine learning models applied to a binary classification problem. The Random Forest model performed the best with a high Precision score of 0.90 and an F1-score of 0.87. The CatBoost model had the best Recall score of 0.92 and ROC-AUC of 0.88. The Support Vector Machine performed well in terms of both Precision and Recall, achieving scores of 0.88 and 0.90, respectively. The Logistic Regression model had the lowest performance of all, achieving a Precision score of only 0.82 and an ROC-AUC of 0.71. Overall, the Random Forest and CatBoost models show the most promising results based on the evaluation metrics."
1843,"caption: Model performance comparison of different algorithms based on multiple evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.75,0.70,0.68,0.72, Random Forest,0.83,0.80,0.85,0.76, Decision Tree,0.80,0.74,0.77,0.71, Gradient Boosting,0.85,0.82,0.81,0.83, Neural Network (1HL),0.79,0.72,0.75,0.70, Neural Network (2HL),0.87,0.85,0.88,0.83","Table 4 displays the performance of six different models, namely SVM, Random Forest, Decision Tree, Gradient Boosting, Neural Network (1HL), and Neural Network (2HL). The models are compared based on four evaluation metrics: Accuracy, F1-score, Precision, and Recall. From the table, we observe that the Gradient Boosting model performs the best across all metrics, achieving an accuracy of 0.85, F1-score of 0.82, Precision of 0.81, and Recall of 0.83. The Neural Network (2HL) model follows closely, with an accuracy of 0.87, F1-score of 0.85, Precision of 0.88, and Recall of 0.83. Interestingly, the Random Forest model has a higher precision of 0.85 but a lower recall of 0.76. In contrast, the Decision Tree model performs well in recall (0.71) but has a lower precision score (0.77)."
1844,"caption: Model Performance Evaluation Metricstable: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.89,0.88,0.87,0.89, Decision Tree,0.86,0.85,0.82,0.88, Random Forest,0.92,0.92,0.93,0.91, Support Vector Machine,0.88,0.87,0.86,0.89, Multi-Layer Perceptron,0.91,0.91,0.92,0.90","This table presents the evaluation metrics for multiple models. The models include Logistic Regression, Decision Tree, Random Forest, Support Vector Machine, and Multi-Layer Perceptron. Each model's performance is evaluated using different metrics, including Accuracy, F1-score, Precision, and Recall. The Random Forest model outperformed all other models, achieving the highest accuracy, F1-score, and recall, with a Precision score only slightly lower than the Multi-Layer Perceptron. The Logistic Regression and Support Vector Machine models had comparable performance, though the Multi-Layer Perceptron outperformed both in terms of precision and recall. Meanwhile, the Decision Tree model had the lowest performance among the models evaluated."
1845,"caption: Table 4: Model evaluation results for multiple evaluation metricstable: Model,Precision (P),Recall (R),F1-Score (F1),Accuracy (Acc), Logistic,0.87,0.73,0.79,0.85, Decision Trees,0.78,0.80,0.79,0.81, SVM,0.92,0.60,0.72,0.89, Naive Bayes,0.66,0.87,0.75,0.73, Random Forest,0.90,0.83,0.86,0.89","Table 4 reports the evaluation results of five different models, i.e., Logistic, Decision Trees, SVM, Naive Bayes, and Random Forest. The models' performances are measured in terms of multiple evaluation metrics such as Precision, Recall, F1-Score, and Accuracy. The results reveal that the SVM classifier achieved the highest Precision of 0.92, while the Naive Bayes classifier achieved the highest Recall of 0.87. Interestingly, Random Forest classifier achieved the highest F1-Score of 0.86 and second-best Precision of 0.90, implying that it can successfully classify and balance the trade-off between Precision and Recall. Among all the models, Logistic classifier achieved the highest Accuracy of 0.85. These results provide useful insights into the performance of different classifiers in this particular dataset."
1846,"caption: Table 4: Performance comparison of different models based on various evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.85,0.81,0.86,0.76, Decision Tree,0.75,0.68,0.70,0.67, Random Forest,0.90,0.88,0.91,0.86, Gradient Boosting,0.92,0.91,0.93,0.89, Support Vector Machine,0.87,0.85,0.87,0.84, Neural Network,0.91,0.90,0.92,0.89","Table 4 presents the model performance comparison in terms of Accuracy, F1 Score, Precision, and Recall based on various evaluation metrics. The table comprises six models: Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, Support Vector Machine, and Neural Network. The Neural Network model achieves the highest Accuracy, F1 Score, Precision, and Recall of 0.91, 0.90, 0.92, and 0.89, respectively, among all models. Interestingly, the Gradient Boosting model also shows excellent performance with Accuracy of 0.92, F1 Score of 0.91, Precision of 0.93, and Recall of 0.89. The Decision Tree model exhibits the lowest scores for all the evaluation metrics."
1847,"caption: Performance of different models using multiple evaluation metrics.table: Model,Precision,Recall,F1 Score,AUC-ROC,Accuracy, Model A,0.86,0.92,0.89,0.94,0.88, Model B,0.84,0.91,0.87,0.92,0.87, Model C,0.79,0.85,0.80,0.88,0.81, Model D,0.88,0.89,0.88,0.91,0.87, Model E,0.92,0.87,0.89,0.93,0.88","The table displays the performance of five models, namely Model A, Model B, Model C, Model D, and Model E. The evaluation metrics used to measure the models' performances include precision, recall, F1 score, area under the receiver operating characteristic curve (AUC-ROC), and accuracy. Model A shows the highest precision score of 0.86, while Model E shows the highest recall score of 0.87. Model D exhibits the highest F1 score of 0.88, and Model A has the highest AUC-ROC of 0.94. All models show a high accuracy score, indicating that they are effective in correctly classifying the data. However, selecting the best model requires considering all evaluation metrics simultaneously."
1848,"caption: Comparison of different classification models based on accuracy, F1-Score, Recall, and Precision.table: Model,Accuracy,F1-Score,Recall,Precision, SVM,0.80,0.78,0.75,0.82, Random Forest,0.85,0.82,0.86,0.81, KNN,0.70,0.67,0.74,0.62, Decision Tree,0.82,0.80,0.79,0.81","Table 1 presents a comparison of multiple classification models based on accuracy, F1-Score, Recall, and Precision. The table lists SVM, Random forest, KNN, and Decision Tree models along with their corresponding evaluation metrics performances. Among models, the Random Forest model displayed the best overall score across all the metrics. The KNN model had the lowest score across all the metrics, highlighted that it may not be the appropriate model for this classification problem. This table demonstrates the importance of evaluating models from different metrics as the results may not be consistent across different metrics."
1849,"caption: Comparison of F1-score, accuracy, precision, and recall of different classification models on the test set.table: Model,F1-score,Accuracy,Precision,Recall, Logistic Regression,0.91,0.87,0.89,0.93, Decision Tree,0.81,0.76,0.78,0.84, Random Forest,0.93,0.89,0.91,0.96, Gradient Boosting,0.88,0.84,0.82,0.95, Support Vector Machine,0.90,0.86,0.87,0.93","The table displays the performance of five different classification models, namely, Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Support Vector Machine. F1-score, accuracy, precision, and recall of each model on the test set are reported. Among the models, Random Forest shows the highest F1-score of 0.93 and accuracy of 0.89. Logistic Regression has the highest precision of 0.89 with a high recall of 0.93. Interestingly, Gradient Boosting has comparatively lower performance in achieving precision and recall, but its F1-score and accuracy performance are competitive with other models."
1850,"caption: Comparison of Model Performances based on Multiple Metricstable: Model,Accuracy,F1-score,Precision,Recall, Model A,0.89,0.85,0.90,0.80, Model B,0.85,0.82,0.88,0.76, Model C,0.87,0.84,0.85,0.83, Model D,0.92,0.89,0.94,0.84, Model E,0.94,0.91,0.91,0.93",
1851,"caption: Performance results of different models on various evaluation metrics.table: Model,F1 Score,Accuracy,Precision,Recall, Model A,0.85,0.78,0.86,0.84, Model B,0.80,0.72,0.82,0.78, Model C,0.87,0.81,0.84,0.91, Model D,0.75,0.69,0.72,0.78, Model E,0.89,0.82,0.92,0.87","The table presents the performance results of five models based on multiple evaluation metrics for a given dataset. The models are Model A, Model B, Model C, Model D, and Model E. The metrics include F1 Score, Accuracy, Precision, and Recall. It is interesting to observe that Model E shows the highest F1 Score (0.89) and Accuracy (0.82) among all models. In contrast, Model D has the lowest F1 Score (0.75) and Accuracy (0.69). Additionally, it is noteworthy that Model A displays the best Precision result of 0.86, while Model C achieved the highest Recall score of 0.91. Overall, the table provides a comprehensive overview of different models' performance on multiple evaluation metrics."
1852,"caption: Model performance comparison using different evaluation metrics.table: Model,F1-Score,Accuracy,Precision,Recall, SVM,0.85,0.82,0.83,0.87, RF,0.86,0.81,0.84,0.89, KNN,0.82,0.79,0.81,0.83, LR,0.83,0.80,0.82,0.85, NB,0.78,0.77,0.76,0.81","Table above shows the performances of five models, SVM, RF, KNN, LR, and NB, in terms of F1-Score, Accuracy, Precision and Recall. SVM and RF have the highest F1-Score of 0.85 and 0.86, respectively, while KNN has the lowest F1-Score of 0.82. NB has the lowest Accuracy, Precision, and Recall among the five models. Interestingly, SVM has the highest Recall and the lowest Precision. Meanwhile, RF has the highest Precision and the second-highest Recall. The table suggests that different models perform differently based on different evaluation metrics."
1853,"caption: Table 4: Performance comparison of five classification models based on accuracy, F1-Score, precision, and recall.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.90,0.91,0.91,0.91, KNN,0.85,0.87,0.85,0.91, LR,0.92,0.89,0.93,0.86, RF,0.94,0.93,0.95,0.92, XGB,0.93,0.92,0.92,0.93","Table 4 shows a performance comparison of five classification models based on four evaluation metrics: accuracy, F1-Score, precision, and recall. The SVM model demonstrated the highest accuracy score of 0.90. Random Forest (RF) scored the highest F1-Score of 0.93. Complementing RF, SVM and XGB exhibited the highest precision scores of 0.91 and 0.92, respectively, while LR showed the highest recall score of 0.86. Overall, the table presents an overview of the models' performance based on multiple evaluation metrics, highlighting the models' different strengths and weaknesses."
1854,"caption: Model Performances Based on Different Evaluation Metricstable: Model Name,Accuracy,F1-Score,Recall,Precision, Random Forest,0.92,0.91,0.91,0.91, Naive Bayes,0.80,0.76,0.88,0.67, Logistic Regression,0.85,0.84,0.84,0.85, Decision Tree,0.85,0.83,0.83,0.83, Support Vector Machine,0.89,0.88,0.88,0.89","Table above shows the performance of different classification models, including Random Forest, Naive Bayes, Logistic Regression, Decision Tree, and Support Vector Machine. Each model's accuracy, F1-Score, recall, and precision evaluation metrics are reported. The Random Forest model achieved the highest accuracy score of 0.92, demonstrating the highest level of correct predictions among the models. Meanwhile, the Naive Bayes model recorded the lowest performance among the models in all evaluation metrics, highlighting its inefficiency in correctly classifying the data."
1855,"caption: Model performances based on evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Model A,0.894,0.856,0.809,0.832, Model B,0.887,0.863,0.800,0.824, Model C,0.900,0.872,0.823,0.844, Model D,0.902,0.878,0.809,0.835, Model E,0.892,0.858,0.831,0.840","The table presents a comparison of different models' performance based on evaluation metrics such as accuracy, precision, recall, and F1-score. Model A gives the highest accuracy score of 0.894, while Model D attains the highest precision score of 0.878 closely followed by Model C. Model E shows the highest recall score of 0.831, which is higher than the other models. Model C outperforms other models in the F1-score measure with 0.844, followed by Model E with 0.840. Thus, depending on the evaluation metric and application, one can choose the suitable model."
1856,"caption: Evaluation results of different models based on several evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score, Random Forest,0.934,0.938,0.889,0.913, KNN,0.886,0.854,0.822,0.838, SVM,0.902,0.895,0.832,0.858, Naive Bayes,0.837,0.777,0.755,0.759, Decision Tree,0.899,0.888,0.883,0.884","The table compares the performance of five different models using multiple evaluation metrics, including accuracy, precision, recall, and F1-Score. The models evaluated in the table are Random Forest, K-Nearest Neighbors (KNN), Support Vector Machine (SVM), Naive Bayes, and Decision Tree. The best-performing model according to accuracy is Random Forest with a score of 0.934. The model with the highest precision is Random Forest with a score of 0.938, and for recall, the Random Forest scored the lowest at 0.889. The average F1-score of the model evaluation for each model is around 0.85, with the highest score of 0.913 achieved by Random Forest. Overall, the results suggest that Random Forest model outperformed the other models in terms of accuracy, precision, and F1-score, while SVM had the highest recall among all the models."
1857,"caption: Performance comparison of different models using various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.92,0.93,0.86,0.89, Decision Tree,0.81,0.75,0.72,0.74, Random Forest,0.94,0.96,0.90,0.92, Support Vector Machine,0.91,0.92,0.85,0.87","Table 1 compares different models' performance using various evaluation metrics such as accuracy, precision, recall, and F1-score. The models evaluated are Logistic Regression, Decision Tree, Random Forest, and Support Vector Machine. The Random Forest model exhibited the best overall performance with an accuracy score of 0.94, precision of 0.96, recall of 0.90, and F1 score of 0.92. In comparison, the Decision Tree model had the least accurate results across all evaluation metrics."
1858,"caption: Performance metrics of various modelstable: Model,Accuracy,Precision,Recall,F1-Score,AUC, Model A,0.87,0.76,0.89,0.81,0.92, Model B,0.84,0.70,0.86,0.77,0.90, Model C,0.85,0.72,0.88,0.79,0.89, Model D,0.83,0.68,0.85,0.76,0.87, Model E,0.86,0.74,0.87,0.80,0.91","The table shows a comparison of performance metrics of five different models, including accuracy, precision, recall, F1-score, and AUC. The highest accuracy is achieved by Model A with a score of 0.87, followed by Model E with a score of 0.86. However, Model E outperforms the other models in precision, recall, F1-score, and AUC with scores of 0.74, 0.87, 0.80, and 0.91, respectively. Model B, C, and D obtained relatively lower scores in all metrics. It is interesting to note the trade-offs between different models' performance in different metrics, and these results can be useful to select a model depending on specific requirements of a project."
1859,"caption: Performance comparison of different models using multiple metrics.table: Model 1,Model 2,Model 3,Model 4,Model 5, Metric 1,0.95,0.74,0.88,0.82,0.79, Metric 2,0.84,0.91,0.63,0.77,0.81, Metric 3,0.65,0.75,0.89,0.92,0.81, Metric 4,0.71,0.48,0.72,0.83,0.90, Metric 5,0.92,0.99,0.76,0.43,0.85","The table compares the performance of five different models using five different evaluation metrics. Metrics 1, 2, 3, 4, and 5 represent the performance scores of the models for different evaluation criteria. Model 2 achieved the highest score for metric 2 with a score of 0.91. In contrast, model 4 had the highest score for metric 5, with a 0.90 score. Interestingly, model 1 performed the best for metric 1, obtaining a score of 0.95. The results suggest that each model performs differently for different evaluation metrics and may offer insights to select the best suited model for optimum results."
1860,"caption: Performance comparison of different classification models on the test dataset.table: Model Name,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.86,0.87,0.79,0.83, Random Forest,0.89,0.91,0.80,0.85, K-NN,0.82,0.75,0.84,0.79, Naive Bayes,0.81,0.81,0.77,0.78","The table presents the performance comparison of different classification models on the test dataset. The models selected for the comparison are Logistic Regression, Random Forest, K-NN, and Naive Bayes. The table shows the accuracy, precision, recall, and F1 scores of each model. Interestingly, the Random Forest model achieved the highest accuracy score of 0.89. On the other hand, the Logistic Regression model showed the highest precision score of 0.87. Similarly, the K-NN model showed the highest recall score of 0.84, while the Naive Bayes model achieved the lowest score across all metrics. Overall, the table highlights the need to consider multiple metrics when comparing classification models' performance."
1861,"caption: Model performances measured by multiple evaluation metrics.table: Model,Metric,Accuracy,Precision,Recall,F1 Score,AUC, SVM,Micro,0.87,0.79,0.91,0.85,0.89, KNN,Micro,0.79,0.73,0.84,0.78,0.81, Random Forest,Micro,0.92,0.90,0.96,0.93,0.92, Logistic Regression,Micro,0.81,0.68,0.91,0.78,0.86, Neural Network,Micro,0.85,0.75,0.89,0.81,0.87","The table presents the performances of different models measured by multiple evaluation metrics such as Accuracy, Precision, Recall, F1 Score, and AUC. The models include SVM, KNN, Random Forest, Logistic Regression, and Neural Network. These models were evaluated using the Micro-average metric. The Random Forest model demonstrates the highest Accuracy of 0.92, Precision of 0.90, Recall of 0.96, F1 score of 0.93, and AUC of 0.92. The KNN model shows the lowest performance compared to other models, with an Accuracy of 0.79, Precision of 0.73, Recall of 0.84, F1 score of 0.78, and AUC of 0.81. The table provides an overview of the models' performance based on various evaluation metrics to assist in decision-making regarding which algorithms to use."
1862,"caption: Table 4: Performance Metrics of Different Modelstable: Model,Precision,Recall,F1-Score,Accuracy, Model A,0.85,0.61,0.71,0.90, Model B,0.79,0.72,0.75,0.88, Model C,0.76,0.84,0.80,0.89, Model D,0.91,0.68,0.77,0.91, Model E,0.82,0.74,0.78,0.88","Table 4 summarizes the performance metrics of five different models based on precision, recall, F1-score, and accuracy. Model A has the highest precision score of 0.85, but lower recall than some models, achieving an F1-score of 0.71 and accuracy of 0.90. Model D has the highest precision-recall balance of 0.91 and 0.68 scores, respectively, and the highest accuracy of 0.91, leading to an F1-score of 0.77. Model E stands out in recall with a score of 0.74, resulting in an F1-score of 0.78 and accuracy of 0.88. These results indicate that Model D performed the best overall, achieving a good balance between precision and recall, and yielding the highest accuracy score."
1863,"caption: Model performance for different models based on evaluation metrics.table: Model,F1-Score,Accuracy,Precision,Recall, Model A,0.85,0.91,0.87,0.83, Model B,0.82,0.88,0.86,0.79, Model C,0.90,0.94,0.93,0.87, Model D,0.86,0.92,0.89,0.83, Model E,0.80,0.87,0.85,0.77","The table presents the performance of five different models based on F1-score, Accuracy, Precision, and Recall evaluation metrics. Model A shows the highest F1-score of 0.85 and Accuracy of 0.91, while Model C has the highest Precision score of 0.93 and Model D has the highest Recall score of 0.83. Remarkably, Model E has the lowest performance among all models in terms of all evaluation metrics. Overall, the table highlights that each of the different models has different strengths and weaknesses based on the evaluation metrics."
1864,"caption: Table 4. Comparison of model performances based on multiple evaluation metrics.table: Model,Accuracy,F1 Score,Precision,ROC-AUC, Model A,0.82,0.85,0.87,0.92, Model B,0.78,0.83,0.74,0.89, Model C,0.79,0.82,0.81,0.91, Model D,0.86,0.87,0.86,0.93","Table 4 presents a comparison of different models based on multiple evaluation metrics. The table displays the accuracy, F1 score, precision, and ROC-AUC for each model, with Model A, B, C, and D being compared. The accuracy and F1 scores suggest that Model D performed the best, with values of 0.86 and 0.87, respectively. However, when evaluating precision, Model A achieved the best score with 0.87. Interestingly, Model D also attained the highest ROC-AUC score of 0.93, while Model B received the lowest score of 0.89. The table exhibits the variations in performance metrics across different models, which is crucial in determining the most suitable model for the task at hand."
1865,"caption: Table 4: Evaluation metrics results from different classification modelstable: Model name,Accuracy,F1-score,Sensitivity,Specificity, Logistic regression,0.82,0.84,0.71,0.87, Decision tree,0.73,0.77,0.50,0.85, Random forest,0.89,0.91,0.80,0.94, K-nearest neighbor,0.76,0.79,0.56,0.87, Support vector machine,0.84,0.86,0.71,0.92","Table 4 shows the evaluation metrics results of different classification models. The models compared are Logistic Regression, Decision Tree, Random Forest, K-Nearest Neighbor, and Support Vector Machine. The evaluation metrics used in the comparison are Accuracy, F1-score, Sensitivity, and Specificity. Interestingly, the Random Forest model outperformed other models in accuracy and F1-score with the values of 0.89 and 0.91, respectively. Additionally, it exhibited good sensitivity and specificity scores of 0.80 and 0.94, respectively. Logistic Regression and Support Vector Machine showed better sensitivity and specificity scores, while Decision Tree outperformed other models in sensitivity. The K-Nearest Neighbor model depicts the lowest scores for all evaluation metrics."
1866,"caption: Table 4. Model performances based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.85,0.87,0.83,0.85, Random Forest,0.83,0.80,0.88,0.84, Decision Trees,0.81,0.83,0.80,0.81, KNN,0.77,0.78,0.75,0.76","Table 4 presents the performance of different models based on various evaluation metrics. The models include Support Vector Machine (SVM), Random Forest, Decision Trees, and K-Nearest Neighbors (KNN). The evaluation metrics include accuracy, precision, recall, and F1-score. Based on the accuracy score, SVM and Random Forest have the most reliable performance with 0.85 and 0.83 scores, respectively. However, based on precision, SVM and Decision Tree models show higher scores of 0.87 and 0.83, respectively. Among the models, Random Forest has the highest recall score of 0.88, while F1-Score suggests Decision Tree has the best performance with a 0.81 score."
1867,"caption: Comparison of multiple models' performance based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Model A,0.72,0.75,0.68,0.71, Model B,0.69,0.59,0.82,0.69, Model C,0.81,0.80,0.86,0.82, Model D,0.65,0.69,0.62,0.65, Model E,0.84,0.83,0.89,0.86, Model F,0.76,0.73,0.82,0.77","Table presents a comparison of six different models' performances based on various evaluation metrics. The metrics include Accuracy, Precision, Recall, and F1 Score. Notably, Model C demonstrated the highest accuracy and a relatively high Precision, Recall, and F1 Score with 0.81 and 0.8, 0.86, and 0.82, respectively. In contrast, Model D provided the lowest performance in all the four metrics. Model E showed exceptional performance in all the evaluation metrics with Precision, Recall, and F1 Score of 0.83, 0.89, and 0.86, respectively, and an accuracy of 0.84. Finally, Model B displayed the lowest Precision of 0.59 but the highest recall of 0.82, leading to an F1 Score of 0.69, the lowest F1 Score amongst all models."
1868,"caption: Comparison of model performance using different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, Model A,0.87,0.80,0.85,0.82, Model B,0.91,0.89,0.92,0.87, Model C,0.89,0.85,0.88,0.86, Model D,0.94,0.91,0.95,0.93, Model E,0.85,0.81,0.87,0.83","The table compares the performance of five different models based on various evaluation metrics. The evaluation metrics include Accuracy, Precision, Recall, and F1-score. Model D shows the highest performance across all evaluation metrics, achieving an accuracy of 0.94, precision of 0.91, recall of 0.95, and an F1-score of 0.93. Model B also shows good performance, achieving an accuracy of 0.91, precision of 0.89, recall of 0.92, and an F1-score of 0.87. Model A and Model C also exhibit reasonable performance across all the metrics, while Model E has the least performance across the board."
1869,"caption: Model performance using different evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.85,-,-,0.89, RFC,0.79,0.87,0.75,0.8, KNN,0.81,0.9,0.7,0.78, NB,0.71,0.6,0.85,0.7, LR,0.87,0.89,0.78,0.83","The table above shows the various models' performances using different evaluation metrics like Accuracy, Precision, Recall, and F1-Score. From the table's listing, it's clear that Support Vector Machine (SVM) and Logistic Regression (LR) have the highest accuracy scores among the models. SVM does not have values for Precision and Recall, while the Naive Bayes (NB) model has the lowest accuracy score, indicating that it was not a good model for this dataset. The Random Forest Classifier (RFC) shows a high Precision score but a slightly lower Recall score, resulting in an F1-score of 0.8. K-Nearest Neighbor (KNN) shows a higher Precision score but a lower Recall score, resulting in a lower F1-score of 0.78. Overall, from the table, we can say that SVM and LR are the best performing models."
1870,"caption: Table 4: Evaluation metrics for different modelstable: Model,F1-score,Accuracy,AUC,Precision,Recall, SVM,0.89,0.92,0.95,0.93,0.85, MLP,0.91,0.93,0.96,0.92,0.90, Random Forest,0.93,0.93,0.98,0.94,0.93, Naive Bayes,0.80,0.87,0.91,0.82,0.78, Logistic Regression,0.88,0.91,0.94,0.91,0.85","Table 4 exhibits the evaluation metrics (F1-score, accuracy, AUC, precision, and recall) for different models. The table presents SVM, MLP, Random Forest, Naive Bayes, and Logistic Regression models' performances. Notably, the Random Forest model shows the best performance in terms of F1-score (0.93), accuracy (0.93), and AUC (0.98). The Naive Bayes model had the lowest F1-score and recall, although it had decent precision. In contrast, MLP had the best F1-score (0.91) and precision (0.92) but a slightly lower AUC (0.96) than the Random Forest model. Overall, the Random Forest model has the highest average performance across all metrics among the models in the table."
1871,"caption: Performance of Different Machine Learning Modelstable: Model,F1-Score,Balanced Accuracy,AUC-ROC, SVM with RBF kernel,0.71,0.63,0.78, Gradient Boosting,0.74,0.67,0.81, Random Forest,0.76,0.68,0.82, Multi-Layer Perceptron,0.72,0.64,0.80, K-Nearest Neighbors,0.63,0.58,0.75","The table above shows the comparison of five machine learning models' performance based on three different evaluation metrics: F1-score, balanced accuracy, and AUC-ROC. The models included in the table are SVM with RBF kernel, Gradient Boosting, Random Forest, Multi-Layer Perceptron, and K-Nearest Neighbors. According to the results, the Random Forest model shows the best performance with an F1-score, balanced accuracy, and AUC-ROC of 0.76, 0.68, and 0.82, respectively. Interestingly, the K-Nearest Neighbors had the worst AUC-ROC score of 0.75, which is much lower than the best AUC-ROC score of 0.82 obtained by Random Forest. Overall, the table suggests that Random Forest is the best model for the given classification task."
1872,"caption: Model performances across various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.87,0.89,0.93,0.91, Random Forest,0.85,0.84,0.88,0.86, KNN,0.79,0.81,0.82,0.82, Logistic Reg.,0.90,0.92,0.94,0.93","Table 1 compares the performances of different machine learning models across four evaluation metrics: Accuracy, Precision, Recall, and F1-score. The table includes the results of the SVM, Random Forest, KNN, and Logistic Regression models. The SVM model achieved the highest accuracy of 0.87. The Logistic Regression model achieved the best performance across all evaluation metrics with an accuracy of 0.90, precision of 0.92, recall of 0.94, and F1-score of 0.93. Interestingly, Random Forest model and KNN model obtained similar F1-scores of 0.86 and 0.82, respectively."
1873,"caption: Table 4: Evaluation metrics and performance results of different models.table: Model,Accuracy,F1-score,Precision,Recall,AUC,PR-AUC, Model A,0.94,0.93,0.96,0.90,0.96,0.97, Model B,0.95,0.94,0.95,0.94,0.97,0.96, Model C,0.93,0.92,0.93,0.91,0.94,0.93, Model D,0.96,0.95,0.97,0.93,0.98,0.96, Model E,0.92,0.91,0.94,0.88,0.95,0.92","Table 4 presents a comparative analysis of different models' performances based on multiple evaluation metrics, including accuracy, F1-score, precision, recall, AUC, and PR-AUC. From this table, it can be observed that Model D shows the best performance in terms of accuracy (0.96), F1-score (0.95), Precision (0.97), Recall (0.93), and AUC (0.98). Conversely, Model E has the lowest performance in all evaluation metrics. Additionally, for the PR-AUC metric, Model A and Model B perform best with the highest scores of 0.97 and 0.96, respectively, whereas Model E has the lowest PR-AUC score of 0.92."
1874,"caption: Different models' performances using different evaluation metricstable: Model,Accuracy,F1-score,Precision,Recall, SVM,0.844,0.856,0.864,0.824, LR,0.832,0.844,0.857,0.832, RF,0.805,0.807,0.815,0.809, MLP,0.849,0.861,0.874,0.842, KNN,0.773,0.751,0.758,0.753","Table above conducts a comparative evaluation of multiple models' performances using various evaluation metrics like Accuracy, F1-score, Precision, and Recall. The models evaluated were Support Vector Machines (SVM), Logistic Regression (LR), Random Forest, Multi-Layer Perceptron (MLP), and K-Nearest Neighbors (KNN). Interestingly, the MLP model has the highest Accuracy (0.849), F1-score (0.861) and Precision (0.874) of all the models. In contrast, the KNN model has the lowest Accuracy score (0.773) relative to all other models. However, the SVM model seems to have the most balanced results across all the evaluation metrics."
1875,"caption: Table 4: Model performance evaluation using different evaluation metricstable: Model,Accuracy,Precision,Recall,F1-score, Naive Bayes,0.82,0.70,0.90,0.79, Logistic Regression,0.86,0.80,0.92,0.85, Decision Tree,0.83,0.71,0.88,0.79, Random Forest,0.89,0.85,0.92,0.88, XGBoost,0.90,0.87,0.92,0.89","Table 4 presents the comparison of several models based on different evaluation metrics such as accuracy, precision, recall, and F1-score. The dataset used to train and test the models is the same, ensuring a fair comparison. The table includes five different models, namely Naive Bayes, Logistic Regression, Decision Tree, Random Forest, and XGBoost. Observing the results, XGBoost shows the best performance in all metrics, achieving an accuracy of 0.90, precision of 0.87, recall of 0.92, and F1-score of 0.89. However, other models like Random Forest and Logistic Regression also produce good results in all evaluation metrics, indicating they are viable performance models too."
1876,"caption: Table 4: Performance of different models based on multiple evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.85,0.80,0.88,0.75, SVM,0.82,0.77,0.85,0.70, Random Forest,0.89,0.83,0.90,0.79, XGBoost,0.91,0.88,0.89,0.87","Table 4 displays the results of four different machine learning models used for classification, evaluated through multiple metrics, including accuracy, F1 score, precision, and recall. The Logistic Regression, SVM, Random Forest, and XGBoost models achieved 0.85, 0.82, 0.89, and 0.91 accuracy scores, respectively. The highest F1 score of 0.88 was achieved by XGBoost, followed closely by Random Forest with a score of 0.83. The Random Forest and Logistic Regression models achieved the best precision scores of 0.90 and 0.88, respectively, while the XGBoost model achieved the best recall score of 0.87. Overall, the XGBoost model appears to have the best performance across all metrics, with Random Forest also showing strong results."
1877,"caption: Table 4: Model Performance Comparison by Multiple Evaluation Metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.83,0.82,0.78,0.87, Naive Bayes,0.77,0.74,0.65,0.86, Random Forest,0.94,0.94,0.93,0.94, Support Vector Machine,0.87,0.86,0.83,0.89","Table 4 displays the performance comparison of different models based on multiple evaluation metrics, including accuracy, F1 score, precision, and recall. The models under comparison are logistic regression, Naive Bayes, random forest, and support vector machine, with their corresponding evaluation metrics' values. Notably, the random forest model achieved the highest accuracy of 0.94, F1 score of 0.94, and Recall of 0.94, indicating high overall performance. Furthermore, the logistic regression and support vector machines models had moderate performances on all metrics. Interestingly, the Naive Bayes model had a precision score of 0.65, indicating a limited ability to label positives accurately."
1878,"caption: Evaluation metrics of different modelstable: Model,Accuracy,Precision,Recall,F1-score, Model1,0.85,0.88,0.83,0.85, Model2,0.82,0.80,0.90,0.85, Model3,0.87,0.89,0.82,0.85, Model4,0.89,0.93,0.85,0.89, Model5,0.90,0.91,0.87,0.89",
1879,"caption: Performance comparison of various classification models based on different evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.87,0.89,0.90,0.89, Random Forest,0.92,0.93,0.91,0.96, Decision Tree,0.75,0.78,0.80,0.76, SVM,0.84,0.85,0.89,0.81, Naive Bayes,0.76,0.77,0.74,0.81","The table above presents a comparison of the accuracy, F1 score, precision, and recall of different classification models, including Logistic Regression, Random Forest, Decision Tree, SVM, and Naive Bayes. The best model performance is achieved by Random Forest with an accuracy of 0.92, followed by Logistic Regression with an accuracy of 0.87. Interestingly, Naive Bayes shows the lowest accuracy, F1 score, and precision while achieving the highest recall score. This table provides valuable insights into the comparative performance of different classification models based on different evaluation metrics."
1880,"caption: Comparison of different models based on Accuracy, F1 score, and Brier score.table: Model,Accuracy,F1 score,Brier Score, SVM,0.821,0.812,0.138, RF,0.805,0.791,0.157, KNN,0.750,0.723,0.212, LR,0.780,0.771,0.187, DT,0.705,0.681,0.266","Table 1 presents a comparison of the performance of various models based on Accuracy, F1 score, and Brier Score. The table shows five different models: SVM, RF, KNN, LR, and DT. Each model has an evaluation score for Accuracy, F1 score, and Brier Score. The SVM and RF models achieved the highest and lowest accuracy scores with 0.821 and 0.805, respectively. Moreover, the SVM and RF models attained the highest and lowest F1 scores with 0.812 and 0.791, respectively. Strikingly, SVM and LR models achieved the lowest and highest Brier scores of 0.138 and 0.187, respectively. These performances show that SVM is the best classifier based on Accuracy and F1 score, while LR is the best based on the Brier score."
1881,"caption: Evaluation metrics for different classification models.table: Model,Accuracy,Precision,Recall,F1 score, Logistic Regression,0.93,0.93,0.87,0.90, Decision Tree,0.86,0.85,0.84,0.84, Random Forest,0.92,0.91,0.89,0.89, Gradient Boosting,0.95,0.94,0.92,0.93, Support Vector Machine,0.94,0.92,0.93,0.93","The table presents the evaluation metrics for different classification models, including Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Support Vector Machine. The evaluation metrics include Accuracy, Precision, Recall, and F1 Score. Among the evaluation metrics, Random Forest and Gradient Boosting models show relatively higher scores in all metrics. However, it is essential to note that the Gradient Boosting model provides the best F1 score, precision and accuracy score with 0.93, 0.94, 0.95, respectively. On the other hand, the Logistic Regression model delivers high precision, accuracy, and recall scores with 0.93. The Decision Tree model produced the lowest accuracy (0.86) and F1 score (0.84) among the models."
1882,"caption: Table 4: Comparison of model performances based on different evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.87,0.86,0.88,0.84, MLP,0.85,0.85,0.84,0.87, KNN,0.81,0.78,0.82,0.75, RF,0.89,0.88,0.90,0.86, XGB,0.88,0.86,0.87,0.86","Table 4 presents a comparison of different models' performances based on various evaluation metrics. The table exhibits SVM, MLP, KNN, RF, and XGB models' accuracy, precision, recall, and F1 score. Notably, the highest accuracy is achieved by the RF model with a score of 0.89, and it also achieves the highest precision and F1 score of 0.90 and 0.88, respectively. The MLP model achieved the highest recall score with a value of 0.87. Interestingly, the SVM model had the lowest recall score of 0.84, whereas the KNN model performed poorly in all the evaluation metrics compared to the other models tested."
1883,"caption: Model performance using different evaluation metrics.table: Models,Accuracy,F1-score,Precision,Recall, Random Forest,0.81,0.78,0.82,0.74, Support Vector Machine,0.72,0.67,0.75,0.61, K-Nearest Neighbors,0.65,0.57,0.64,0.51, Logistic Regression,0.76,0.73,0.79,0.68","Table presents the comparison of different machine learning models' performance based on multiple evaluation metrics. The models included in the table are Random Forest, Support Vector Machine, K-Nearest Neighbors, and Logistic Regression. The evaluation metrics used in the comparison are Accuracy, F1-score, Precision, and Recall. The table demonstrates that the Random Forest model performed the best in all evaluation metrics considered, having an accuracy score of 0.81, F1-score of 0.78, Precision of 0.82, and Recall of 0.74. Logistic Regression had the second-best performance, while the K-Nearest Neighbors had the poorest performance across all the evaluation metrics."
1884,"caption: Table 4: Model performance comparison based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.85,0.86,0.84,0.85, Decision Trees,0.78,0.77,0.76,0.77, Random Forest,0.91,0.93,0.90,0.91, Support Vector Machine,0.88,0.89,0.87,0.88","Table 4 shows the performance comparison of four different models, namely Logistic Regression, Decision Trees, Random Forest, and Support Vector Machine, based on different evaluation metrics such as Accuracy, precision, recall, and F1-score. Among all the models, the Random Forest model displayed the best performance across all metrics, achieving the highest accuracy, precision, recall, and F1-score of 0.91, 0.93, 0.9 and 0.91, respectively. Logistic Regression also demonstrated a reasonable performance with 0.85 accuracy, 0.86 precision, 0.84 recall, and 0.85 F1-Score. The Decision Trees model had the poorest performance with an accuracy of 0.78, and 0.77 precision, 0.76 recall, and 0.77 F1-Score."
1885,"caption: A comparison of different models' performance based on multiple evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.762,0.785,0.805,0.767, KNN,0.702,0.722,0.680,0.773, RF,0.830,0.848,0.894,0.807, XGB,0.820,0.840,0.854,0.826, MLP,0.744,0.766,0.780,0.754","The table above presents a comparison of five different machine learning models' performance based on multiple evaluation metrics. The models were evaluated based on their accuracy, F1 score, precision, and recall. The results show that the Random Forest (RF) model achieved the highest accuracy and F1 score of 0.830 and 0.848, respectively. Additionally, the RF model also achieved the best precision score compared to the other models with a score of 0.894, albeit the recall score of the RF model is lower than the KNN, XGB, and MLP models. It is worth noting that the MLP model achieved the lowest accuracy score of 0.744."
1886,"caption: Model Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1 Score, Random Forest,0.95,0.96,0.90,0.93, XGBoost,0.93,0.90,0.94,0.92, SVM,0.89,0.83,0.90,0.86, Multilayer Perceptron (MLP),0.92,0.89,0.93,0.91",
1887,"caption: Model performance based on Accuracy, F1-Score, Precision, and Recall.table: Model,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.82,0.80,0.82,0.78, Random Forest,0.84,0.83,0.85,0.82, Support Vector Machine,0.81,0.79,0.81,0.77, Multilayer Perceptron,0.85,0.84,0.86,0.82, Naive Bayes,0.75,0.74,0.76,0.72","The table reports the evaluation results of five different machine learning models. The models' evaluation metrics, including the Accuracy, F1-Score, Precision, and Recall classification measures, have been presented. The results showed that the Multilayer Perceptron model had the highest accuracy of 0.85 and F1-Score of 0.84 among all models. The Random Forest model has also shown a good performance on all metrics with the highest Precision and Recall scores of 0.85 and 0.82, respectively. Notably, the Naive Bayes model had the lowest performance across all metrics with an Accuracy and F1-Score of 0.75 and 0.74, respectively."
1888,"caption: Table 4: Model performance based on multiple evaluation metricstable: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.89,0.88,0.92,0.85, Random Forest,0.93,0.92,0.95,0.90, XGBoost,0.92,0.91,0.94,0.88, Support Vector,0.88,0.87,0.91,0.83, Neural Network,0.94,0.93,0.96,0.90","Table 4 compares multiple models' performances with four evaluation metrics; Accuracy, F1 Score, Precision, and Recall. The table presents the accuracy, F1 Score, precision and recall score of different models. Notably, the Random Forest model achieves the highest accuracy (0.93) and is the best in F1 Score (0.92), precision (0.95), and recall (0.90). Interestingly, the Neural Network model achieves the highest accuracy of 0.94. Nonetheless, the model has a slightly lower performance in F1 Score (0.93), precision (0.96), and recall (0.90) compared to the Random Forest. The Support Vector model performs relatively lower across all metrics, with accuracy, F1 Score, precision, and recall scores of 0.88, 0.87, 0.91, and 0.83, respectively."
1889,"caption: Table 4: Model performance based on multiple evaluation metrics.table: Model Name,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.87,0.89,0.84,0.86, Support Vector Machines,0.89,0.91,0.86,0.88, Random Forest,0.91,0.90,0.94,0.92, Gradient Boosting,0.92,0.93,0.91,0.92, Multilayer Perceptron Neural Network,0.87,0.85,0.91,0.88","Table 4 lists the performance scores of multiple models with respect to accuracy, precision, recall, and F1 scores. Each model was trained and tested using the same dataset. The table exhibits five models, including Logistic Regression, Support Vector Machines, Random Forest, Gradient Boosting, and Multilayer Perceptron Neural Network. Interestingly, the Random Forest model achieved the highest Accuracy and Recall, achieving scores of 0.91 and 0.94, respectively. The Gradient Boosting model achieved the highest Precision score of 0.93, while the F1 score was similar across all models but highest for the Random Forest with a score of 0.92."
1890,"caption: Comparison of model performances using different evaluation metrics.table: Model A,Model B,Model C, Metric 1,0.85,0.92,0.78, Metric 2,0.74,0.81,0.91, Metric 3,0.65,0.77,0.83","The above table shows the performance of Model A, Model B, and Model C when evaluated using various evaluation metrics, Metric 1, Metric 2, and Metric 3. Model B consistently shows the highest performance across all metrics, with the highest score being 0.92 in Metric 1. Model C shows the highest score in Metric 3 with a value of 0.83. Model A has the lowest scores in all metrics with the value ranging between 0.65 and 0.85. The table provides a comprehensive view, which can be useful while selecting a model for a specific task according to the significant evaluation metrics."
1891,"caption: Model performance on binary classification tasktable: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.85,0.86,0.87,0.85, Logistic regression,0.77,0.78,0.80,0.76, Random Forest,0.91,0.92,0.93,0.91, Naive Bayes,0.69,0.72,0.65,0.68, KNN,0.80,0.81,0.81,0.79","The table compares the performance of five different machine learning models on a binary classification task. The evaluation metrics include accuracy, precision, recall, and F1-score. Random Forest model achieved the highest accuracy with a score of 0.91. SVM, Logistic Regression, and KNN also show strong performance with accuracy scores of 0.85, 0.77, and 0.80 respectively. Moreover, the Random Forest model achieved the highest precision, recall, and F1-score with 0.92, 0.93, and 0.91, respectively, while Naive Bayes showed poor performance in all metrics with only 0.69 accuracy, 0.72 precision, 0.65 recall, and 0.68 F1-score."
1892,"caption: Model performance comparison based on multiple evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic,0.89,0.91,0.88,0.94, SVM,0.93,0.92,0.91,0.94, Decision-Tree,0.78,0.79,0.77,0.83, Naive Bayes,0.85,0.87,0.82,0.92","Table 4 above shows the comparison of multiple models based on several evaluation metrics that include accuracy, F1 score, precision, and recall. The table presents four models; Logistic, SVM, Decision-Tree, and Naive Bayes, and their respective performances using the different metrics. Notably, the SVM model achieved the highest accuracy of 0.93, closely followed by the Logistic model with 0.89. On the other hand, the Decision-Tree model shows the lowest accuracy with 0.78. The Naive Bayes model recorded the highest F1 score of 0.87, while the SVM model recorded the best precision and recall scores of 0.91 and 0.94, respectively. Overall, the table shows that the SVM model performs best based on multiple metrics."
1893,"caption: Table 1: Model performance based on Multiple Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1 Score, Model 1,0.87,0.89,0.83,0.86, Model 2,0.82,0.86,0.78,0.82, Model 3,0.91,0.93,0.87,0.90, Model 4,0.90,0.89,0.94,0.91, Model 5,0.86,0.82,0.90,0.86","The table presents the performance of five models based on multiple evaluation metrics, including accuracy, precision, recall, and F1 score. The model's name, along with the score of each metric, is presented in the respective columns. Interestingly, Model 3 performed the best overall with 0.91 accuracy and the highest scores in all metrics except recall. Model 4 performed the best in recall with a score of 0.94. Furthermore, Model 1 and Model 3 performed similarly in accuracy, but Model 3 scored higher in precision, recall, and F1 score. Overall, Model 3 seems to be the best performer based on the presented metrics."
1894,"caption: Model Evaluation Metrics for Different Algorithms.table: Model Name,Accuracy,Precision,Recall,F1 Score, Support Vector Classifier,0.8964,0.9044,0.8919,0.8980, Random Forest,0.9045,0.9125,0.9002,0.9064, Naive Bayes,0.8732,0.8832,0.8671,0.8753, K-Nearest Neighbors,0.8856,0.8941,0.8800,0.8839, Neural Network,0.9121,0.9175,0.9100,0.9134","Table presents model evaluation metrics for different algorithms, including Support Vector Classifier, Random Forest, Naive Bayes, K-Nearest Neighbors, and Neural Network. The evaluation metrics for each model include Accuracy, Precision, Recall, and F1 Score. Interestingly, all models showed high precision, recall, and F1 scores, and the Neural Network showed the best Accuracy score of 0.9121. Random Forest showed the second-best results with an Accuracy of 0.9045 and the highest Precision Score of 0.9125. Naive Bayes demonstrated the lowest model performance among models, with an Accuracy of 0.8732. Overall, the models showed promising results, with the Neural network and Random forest providing the most promising algorithmic solutions."
1895,"caption: Table 4: Model evaluation metrics for classifiers trained on the sample dataset.table: Model,F1 Score,Precision,Recall,Accuracy, Logistic Regression,0.85,0.89,0.82,0.83, Random Forest,0.87,0.88,0.88,0.85, XGBoost,0.88,0.90,0.87,0.86, Support Vector Machine,0.82,0.87,0.79,0.81, Naive Bayes,0.78,0.81,0.76,0.77","In Table 4, we present a comparison of the performance metrics of five different classifiers: Logistic Regression, Random Forest, XGBoost, Support Vector Machine, and Naive Bayes. Each model is evaluated on the same sample dataset that contains features of multiple patients. The evaluation metrics include accuracy, F1-Score, precision, and recall. Among the models, the best F1-score (0.88) is obtained by XGBoost with an accuracy of 0.86. Interestingly, Random Forest achieves the highest precision score of 0.88, while Logistic Regression shows the highest recall score of 0.82. Support Vector Machine and Naive Bayes models appear to be underperforming on this dataset, with F1-Scores of 0.82 and 0.78, respectively."
1896,"caption: Model performance comparison on the regression task based on different models and evaluation metrics.table: Model,MAE,RMSE,R-squared, Linear,0.23,0.50,0.87, SVM,0.15,0.45,0.92, Random Forest,0.12,0.41,0.94, XGBoost,0.14,0.43,0.93, Neural Net,0.13,0.42,0.93","This table compares the performance of different models based on multiple evaluation metrics in the context of a regression task. The models included in the table are Linear Regression, Support Vector Machine (SVM), Random Forest, XGBoost, and a Neural Network. The evaluation metrics used in the table to compare the performance of the models are Mean Absolute Error (MAE), Root-Mean-Square Error (RMSE), and R-squared (R2). Notably, Random Forest demonstrates the best performance in terms of MAE (0.12) and RMSE (0.41) metrics, with a corresponding R2 score of 0.94. In contrast, SVM delivers an R2 score of 0.92, which is the highest among all the models. However, Neural Network yields the lowest MAE of 0.13 and RMSE of 0.42, making it a close contender for the best model."
1897,"caption: Model performance using different evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, Decision Tree,0.85,0.84,0.86,0.83, Naive Bayes,0.72,0.68,0.71,0.66, Random Forests,0.91,0.91,0.92,0.91, Support Vector Machines,0.87,0.86,0.88,0.85","Table X shows the comparison of different machine learning models' performances concerning accuracy, F1-score, precision, and recall. The models included in the experiment are Decision Tree, Naive Bayes, Random Forests, and Support Vector Machines. The table exhibits the numerical results obtained from evaluating the models using each of the stated evaluation metrics. As can be seen in the table, Random Forests achieved the highest scores in all four metrics, indicating that it is the best-performing model among the four algorithms. In contrast, Naive Bayes had the lowest performance across the measures, implying that it is the worst-performing model."
1898,"caption: Model performance on the test set based on multiple evaluation metricstable: Models,Accuracy,F1-Score,Precision,Recall, Random Forest,0.89,0.81,0.73,0.91, Logistic Regression,0.85,0.75,0.66,0.87, Naive Bayes,0.75,0.62,0.58,0.67, Decision Tree,0.81,0.73,0.69,0.78, Gradient Boost,0.88,0.80,0.72,0.89",
1899,"caption: Comparison of Different Classification Modelstable: Model,Accuracy,Precision,Recall,F1-Score,ROC-AUC, Random Forest,0.95,0.96,0.89,0.92,0.98, Logistic Regression,0.90,0.87,0.86,0.86,0.95, Multilayer Perceptron (MLP),0.93,0.92,0.83,0.87,0.97, Gradient Boosting,0.94,0.95,0.87,0.90,0.98","Table presents a comparison of four different classification models in terms of their accuracy, precision, recall, F1-score, and ROC-AUC. The models evaluated in the table are Random Forest, Logistic Regression, Multilayer Perceptron (MLP), and Gradient Boosting. The highest accuracy (0.95) is achieved by Random Forest model, while the best F1-score of 0.92 is obtained by this model and Gradient Boosting with 0.90 score. The MLP model demonstrates the best precision (0.92), and the Logistic Regression model has the best recall (0.86). The highest ROC-AUC score is observed for the Gradient Boosting model, with 0.98. Overall, the results indicate a strong performance by all models, demonstrating their potential in a classification task."
1900,"caption: Table 4: Evaluation metrics of different machine learning models.table: Model,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.89,0.85,0.89,0.82, Decision Tree,0.83,0.78,0.76,0.79, Random Forest,0.93,0.92,0.90,0.94, Gradient Boosting Trees,0.91,0.89,0.92,0.86","Table 4 shows the evaluation metrics of different machine learning models - Logistic Regression, Decision Tree, Random Forest, and Gradient Boosting Trees. The models were evaluated based on their accuracy, F1-score, precision, and recall. The Random Forest model exhibits the highest accuracy of 0.93. On the other hand, the highest F1-score of 0.92 was achieved by both Random Forest and Logistic Regression models. Particularly, the Decision Tree model performs poorly in all evaluation metrics, having the lowest accuracy and F1-score. Overall, the Random Forest and Gradient Boosting Trees models show better performance than Logistic Regression and Decision Trees."
1901,"caption: Table 4: Model Performance on Multiple Metricstable: Model,Accuracy,Precision,Recall,F1 Score, SVM,0.80,0.85,0.70,0.76, Decision Tree,0.82,0.81,0.85,0.83, Random Forest,0.87,0.93,0.82,0.87, KNN,0.77,0.82,0.69,0.75","The table presents the performance of various supervised learning models: SVM, Decision Tree, Random Forest, and KNN. Multiple evaluation metrics such as accuracy, precision, recall, and F1 score are shown for each model. Notably, the Random Forest model achieves the highest accuracy of 0.87 with a precision of 0.93 and recall of 0.82. In contrast, the SVM model shows the second-best accuracy of 0.80 and highest precision of 0.85. Moreover, Decision Tree performs consistently well across all evaluation metrics with an accuracy of 0.82, precision of 0.81, recall of 0.85, and F1 score of 0.83. However, the KNN model appears to have the lowest performance across all metrics."
1902,"caption: Model Performance on Binary Classification Tasktable: Model,Accuracy,Precision,Recall, SVM,0.85,0.82,0.78, KNN,0.80,0.75,0.81, DT,0.75,0.73,0.71, RF,0.90,0.91,0.87, MLP,0.88,0.87,0.85","Table presents a comparison of five different models' performances on the binary classification task. The model's evaluation metrics of accuracy, precision, and recall are listed to measure performance. SVM, KNN, DT, RF, and MLP were trained and tested using the same dataset. The best performance model is observed to be the Random forest model with an accuracy measure of 0.90, a precision score of 0.91, and a recall of 0.87. Interestingly, MLP had the second-best performance score in all evaluation metrics. SVM, KNN, and DT models recorded lower values for all performance measures."
1903,"caption: Table 4: Performance comparison of different models using various metrics.table: Model,Accuracy,F1-Score,Matthew Corr,AUC, Model A,0.91,0.91,0.89,0.87, Model B,0.92,0.89,0.87,0.92, Model C,0.90,0.86,0.84,0.88, Model D,0.91,0.92,0.90,0.89, Model E,0.92,0.87,0.85,0.91","Table 4 compares the performance of different models using various metrics, including Accuracy, F1-Score, Matthew Corr, and AUC. Model A has an accuracy rate of 0.91, which is the highest among all the models. Model B has an F1-Score of 0.89, which is the second-highest value in the table. Model D has the highest F1-Score of 0.92, which is the best performing model in terms of F1-Score. Additionally, Model E shows the highest AUC of 0.91, whereas Model B has the highest Matthew Corr value of 0.87. Overall, the table shows that all models have their strengths and weaknesses when evaluated with various metrics. Among the models, Model A and D appear to be the best-performing models with high accuracy and F1-Score values."
1904,"caption: Table 4: Different models' performance based on their accuracy, precision, recall, and f1-score.table: Model Name,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.86,0.85,0.87,0.86, Decision Tree,0.83,0.82,0.82,0.82, SVM(Linear),0.91,0.92,0.90,0.91, SVM(Poly),0.90,0.88,0.91,0.89, Random Forest,0.94,0.92,0.95,0.93, XGBoost,0.93,0.91,0.94,0.92","Table 4 presents a comparison of different models' performances based on their accuracy, precision, recall, and f1-score. The table includes Logistic Regression, Decision Tree, SVM(Linear), SVM(Poly), Random Forest, and XGBoost models. Notably, the Random Forest model shows the highest accuracy, precision, and recall, achieving 0.94, 0.92, and 0.95 scores, respectively. XGBoost has the second-highest scores on accuracy, precision, and recall. However, SVM(Linear) performed the best based on the F1-score with a score of 0.91, which is higher than that of other models. The decision tree model had the lowest performance among all the models."
1905,"caption: Performance of classifiers based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Decision Tree,0.872,0.857,0.879,0.866, Naïve Bayes,0.863,0.834,0.896,0.855, Random Forest,0.901,0.886,0.912,0.899, Support Vector Machines(SVM),0.887,0.872,0.892,0.879, Neural Network (NN),0.903,0.878,0.917,0.895","The table above presents a comparison of the performance of five different machine learning models based on four evaluation metrics including Accuracy, Precision, Recall, and F1 Score. The models analyzed are Decision Tree, Naïve Bayes, Random Forest, Support Vector Machines (SVM), and Neural Network (NN). Results show that Random Forest outperforms other models for all the evaluation metrics except for Precision and Recall in which the NN model achieved higher scores. The SVM model also demonstrated a good performance with scores close to the top performers in all the evaluation metrics. These results may reveal the potential of these classifiers for the early diagnosis of the targeted disease."
1906,"caption: Model performances for various classifiers on the test data.table: Model,F1-score,Precision,Recall,AUC-PR,AUC-ROC, SVM,0.81,0.84,0.79,0.85,0.92, Random Forest,0.78,0.80,0.77,0.80,0.87, Multi-layer Perceptron,0.77,0.83,0.75,0.82,0.89, XGBoost,0.83,0.82,0.84,0.86,0.92, Decision Tree,0.62,0.64,0.63,0.63,0.69","The table shows the performance metrics for five different classifiers - SVM, Random Forest, Multi-layer Perceptron, XGBoost, and Decision Tree - evaluated on test data. The performance was evaluated using five metrics - F1-score, Precision, Recall, AUC-PR, and AUC-ROC. Notably, XGBoost achieved the highest F1-score of 0.83, with SVM and Random Forest coming in second and third, respectively. Interestingly, SVM achieved the highest AUC-ROC of 0.92, while XGBoost had the highest AUC-PR of 0.86. Decision Tree's performance was lower than the other classifiers across all the metrics."
1907,"caption: Model performances based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score,Specificity, SVM,0.85,0.81,0.86,0.83,0.79, RF,0.83,0.76,0.87,0.81,0.73, LR,0.81,0.79,0.81,0.79,0.78, NB,0.72,0.81,0.60,0.69,0.83","The table displays a comparison of different models based on various evaluation metrics such as accuracy, precision, recall, F1-score, and specificity. The presented models are Support Vector Machine (SVM), Random Forest (RF), Logistic Regression (LR), and Naive Bayes (NB). The RF model shows the highest recall score of 0.87, whereas the SVM model has the highest precision score of 0.81. The LR model has the highest accuracy score of 0.81, while NB has the lowest overall performance among these models, specifically in recall. Notably, these performance differences in the models suggest that selecting the right model for specific tasks is crucial to achieve the best results."
1908,"caption: Performance Metrics of Different Modelstable: Model,Accuracy,Precision,Recall,F1-score,AUC-ROC, Logistic Regression,0.89,0.92,0.87,0.89,0.95, Random Forest,0.94,0.96,0.93,0.94,0.98, K-Nearest Neighbors,0.91,0.91,0.91,0.91,0.96, Decision Tree,0.89,0.90,0.89,0.88,0.93, Gradient Boosting,0.95,0.96,0.94,0.95,0.99","The table presents performance metrics of distinct models evaluated using various metrics, namely accuracy, precision, recall, F1-score, and AUC-ROC. The table contains information on five models, Logistic Regression, Random Forest, K-Nearest Neighbors, Decision Tree, and Gradient Boosting. Random Forest exhibits the best overall performance across all the presented metrics, scoring highest in accuracy (0.94), precision (0.96), recall (0.93), F1-score (0.94), and AUC-ROC (0.98). Gradient Boosting also shows excellent performance with a high AUC-ROC score of 0.99. Interestingly, although Logistic Regression has the lowest accuracy score of 0.89, it shows the highest precision score of 0.92. K-Nearest Neighbors and Decision Tree models yield a moderate performance with an overall accuracy score of 0.91 and 0.89, respectively."
1909,"caption: Model performances on various evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.85,0.84,0.84,0.85, Logistic Regression,0.83,0.80,0.80,0.81, Decision Tree,0.78,0.75,0.75,0.75, Random Forest,0.90,0.88,0.87,0.89, Gradient Boosting,0.87,0.85,0.84,0.86","The table displays the performances of SVM, Logistic Regression, Decision Tree, Random Forest, and Gradient Boosting models on different evaluation metrics, such as Accuracy, F1-Score, Precision, and Recall. Interestingly, the Random Forest model demonstrated the highest accuracy score of 0.9, followed closely by the Gradient Boosting model, which achieved a score of 0.87. On the other hand, Decision Tree, Logistic Regression, and SVM scored lower in comparison to the above two models. The F1-Score, Precision, and Recall metrics also reported similar results, with Random Forest and Gradient Boosting exhibiting better performances than the other models. Overall, the Random Forest and Gradient Boosting models showed the best performances across the various evaluated metrics."
1910,"caption: Table 4: Model performance based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Random Forest,0.89,0.90,0.87,0.87, Decision Tree,0.76,0.72,0.81,0.75, Logistic Regression,0.80,0.75,0.86,0.78, K-Nearest Neighbor,0.84,0.87,0.80,0.83, Support Vector,0.86,0.82,0.90,0.85","Table 4 presents the performance of five different models based on multiple evaluation metrics, including Accuracy, Precision, Recall, and F1-Score. The Random Forest model achieved the highest Accuracy with a score of 0.89, while the Decision Tree model had the lowest Accuracy of 0.76. In contrast, the Decision Tree model achieved the highest Precision score of 0.72, while the Random Forest had the highest Recall and F1-Score of 0.87 and 0.87, correspondingly. The Logistic Regression model had a relatively balanced performance compared to the other models. Interestingly, the Support Vector model scored the highest Recall with 0.90, but its F1-Score was lower than the Random Forest and K-Nearest Neighbor models."
1911,"caption: A comparison of different models' performance results using different evaluation metrics (Accuracy, F1 Score, Precision, and Recall).table: Models,Accuracy,F1 Score,Precision,Recall, SVM,0.78,0.77,0.76,0.78, Decision Tree,0.72,0.73,0.70,0.75, Logistic Regression,0.79,0.77,0.77,0.78, MLP,0.81,0.80,0.81,0.80, Random Forest,0.84,0.83,0.82,0.85","Table presents a comparison of different machine learning models' performance results using four evaluation metrics, namely, Accuracy, F1 Score, Precision, and Recall. The table exhibits five models, such as SVM, Decision Tree, Logistic Regression, MLP, and Random Forest, with their respective performance scores. Overall, the Random Forest model shows the highest accuracy score of 0.84, followed by the MLP model of 0.81. However, note that the Decision Tree model has the lowest accuracy of 0.72 with F1 Score, Precision, and Recall metrics of 0.73, 0.70, and 0.75, respectively. The Logistic Regression model shows balanced results with a score range of 0.77-0.79 for all evaluation metrics."
1912,"caption: Table 4: Model performance based on different evaluation metrics.table: Model,F1-score,Precision,Accuracy,AUC, Logistic Regression,0.84,0.85,0.81,0.90, Decision Tree,0.79,0.87,0.77,0.87, Random Forest,0.90,0.92,0.86,0.95, Gradient Boosting,0.88,0.91,0.86,0.94, Support Vector,0.87,0.88,0.84,0.91","Table 4 illustrates the performance of five distinct models based on various evaluation metrics including F1 score, precision, accuracy, and AUC. The models in the table include Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Support Vector. It is important to note that each model was trained and tested on the same dataset. Among the models, Random Forest yielded the highest F1-score of 0.90, the highest precision value of 0.92, and the highest AUC score of 0.95. Gradient Boosting model had the second highest F1-score of 0.88, and performed similarly in precision and AUC. Meanwhile, Logistic regression proved to have the highest accuracy of 0.81."
1913,"caption: Table 4: Performance Metrics of Multiple Modelstable: Model,Accuracy,F1 Score,Precision,Recall, Model A,0.85,0.78,0.92,0.68, Model B,0.81,0.76,0.88,0.67, Model C,0.86,0.81,0.90,0.75, Model D,0.87,0.82,0.92,0.74, Model E,0.83,0.79,0.84,0.74","Table 4 compares the performance metrics of five different models, Model A, B, C, D, and E. The four evaluation metrics, Accuracy, F1 Score, Precision, and Recall, of all models were measured by the same dataset, with a higher score indicating a better model. Model C had the best accuracy of 0.86, while Model D had the best F1 Score and Precision, with scores of 0.82 and 0.92, respectively. On the other hand, Model A had the best Recall score with 0.68. The models' overall performance suggests that Model C and Model D are more efficient, with scores above 0.80 for all the evaluated metrics."
1914,"caption: Table 4: Performance comparison of different models based on multiple evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Model A,0.89,0.91,0.87,0.95, Model B,0.92,0.94,0.93,0.95, Model C,0.88,0.91,0.85,0.97, Model D,0.94,0.95,0.93,0.96",
1915,"caption: Model evaluation metrics for different modelstable: Model,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.86 (+-0.02),0.81 (+-0.01),0.83 (+-0.02),0.83 (+-0.01), Decision Tree,0.77 (+-0.04),0.72 (+-0.03),0.76 (+-0.05),0.7 (+-0.04), Random Forest,0.85 (+-0.01),0.80 (+-0.01),0.81 (+-0.03),0.83 (+-0.01), Multilayer Perceptron,0.87 (+-0.02),0.81 (+-0.01),0.83 (+-0.02),0.84 (+-0.02)","The table above summarizes the performance evaluation of four machine learning models: Logistic Regression, Decision Tree, Random Forest, and Multilayer Perceptron. The models were trained and tested on a single dataset, and their performance was evaluated using four different metrics: Accuracy, F1-Score, Precision, and Recall. The evaluation results reveal that the Multilayer Perceptron model has the highest Accuracy, F1-Score, and Recall scores with a mean score of 0.87 (+-0.02), 0.81 (+-0.01), and 0.84 (+-0.02), respectively. The Logistic Regression and Random Forest models produced similar results, and all models outperformed the Decision Tree model in all evaluation metrics."
1916,"caption: Table 4: Evaluation metrics for different modelstable: Algorithm,F1-score,Accuracy,Precision,Recall, Decision Tree,0.72,0.80,0.69,0.76, Support Vector Machine,0.82,0.85,0.80,0.85, Naive Bayes,0.77,0.81,0.75,0.81, Random Forest,0.89,0.91,0.88,0.91, Artificial Neural Network,0.91,0.93,0.91,0.92","Table 4 presents the evaluation metrics for various classification models. These models were implemented and trained using the same dataset and evaluated using four standard metrics: F1-score, accuracy, precision, and recall. The algorithms compared are Decision Trees, Support Vector Machine, Naive Bayes, Random Forest, and Artificial Neural Network. According to the table, the Artificial Neural Network algorithm showed the best performance in terms of F1-score, accuracy, precision, and recall with 0.91, 0.93, 0.91 and 0.92, respectively. Random Forest also showed notable performance with an F1-score of 0.89 and accuracy of 0.91."
1917,"caption: Model Evaluation Metrics Comparisontable: Model,Precision,Recall,F1-score,ROC-AUC,PR-AUC, Random Forest,0.92,0.85,0.88,0.90,0.91, SVM,0.85,0.92,0.88,0.89,0.87, Logistic Regr.,0.88,0.74,0.80,0.82,0.83, MLP,0.90,0.82,0.86,0.85,0.88","The table illustrates a comparison between different models' evaluation metrics, namely Precision, Recall, F1-Score, ROC-AUC, and PR-AUC. The Random Forest model achieved the highest precision score of 0.92, while the SVM model achieved the highest recall score of 0.92. The Random forest model outperformed all other models in terms of F1-score, ROC-AUC, and PR-AUC, gaining 0.88, 0.90, and 0.91, respectively. Interestingly, the MLP model shows relatively high performance across all metrics but underperformed when compared to the Random forest model. Overall, the table demonstrates that the Random forest model is the most effective among the models tested."
1918,"caption: Table 4: Comparison of model performance based on multiple evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.79,0.73,0.76,0.70, Random Forest,0.81,0.75,0.80,0.70, XGBoost,0.83,0.79,0.81,0.77, SVM,0.75,0.67,0.72,0.62, Neural Network,0.82,0.78,0.81,0.75","Table 4 provides a comparison of model performance based on multiple evaluation metrics, including accuracy, F1 score, precision, and recall. The table includes five different models: Logistic Regression, Random Forest, XGBoost, SVM, and Neural Network. Results show that the XGBoost model achieved the highest accuracy of 0.83 and F1 score of 0.79 among the models, while the SVM model had the lowest scores in all evaluation metrics. Interestingly, all models except for SVM exhibit relatively similar performance across all evaluation metrics, implying that multiple models are suitable for this task. However, further investigation is necessary to determine the optimal model for a specific purpose."
1919,"caption: Model evaluation metrics for various models.table: Model,Accuracy,F1 Score,Precision,Recall, Model A,0.85,0.84,0.87,0.81, Model B,0.77,0.79,0.82,0.76, Model C,0.92,0.93,0.91,0.95, Model D,0.63,0.71,0.66,0.76, Model E,0.79,0.81,0.79,0.84","The table presents evaluation metrics for multiple models. The models are evaluated on four different metrics, namely Accuracy, F1 Score, Precision, and Recall. Model C has the best performance across all metrics, achieving an accuracy of 0.92, an F1 score of 0.93, precision of 0.91, and recall of 0.95. Model A and Model E also achieve good performance across all metrics, while Model B has moderate performance, and Model D shows the weakest performance across all the measures. Overall, this table provides a quick comparison of model performance based on different evaluation metrics."
1920,"caption: Evaluation metrics for different modelstable: Model,Accuracy (%),F1 Score,Precision,Recall, Model A,78.5,0.76,0.85,0.70, Model B,83.2,0.84,0.78,0.91, Model C,70.4,0.62,0.81,0.50, Model D,89.1,0.90,0.92,0.88, Model E,79.9,0.79,0.71,0.89","Table presents the evaluation metrics for five different models, where the evaluation metrics include Accuracy, F1 Score, Precision, and Recall. Model D shows the highest Accuracy of 89.1% and F1 Score of 0.90. Model C has the lowest Accuracy of 70.4% and F1 Score of 0.62. Model D also has high Precision (0.92) and Recall (0.88), while Model C has low Precision (0.81) and Recall (0.50). The F1 Scores of Model B and E are 0.84 and 0.79, respectively, with the former showing the highest Precision at 0.78 and the later showing the highest Recall at 0.89. Overall, Model D shows the best performance across all four evaluation metrics."
1921,"caption: Model performances based on different evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Model 1,0.88,0.87,0.90,0.84, Model 2,0.92,0.84,0.96,0.76, Model 3,0.95,0.91,0.88,0.94, Model 4,0.89,0.88,0.91,0.85, Model 5,0.93,0.87,0.93,0.82","Table presents the results of five different models evaluating their performance based on accuracy, F1 score, precision, and recall metrics. Each model's accuracy ranges from 0.88 to 0.95, with Model 3 being the most accurate model. Interestingly, Model 1 and Model 4 have similar accuracy, but the precision and recall values for Model 1 are higher. Model 5 has the highest precision value of 0.93, while Model 2 has the highest F1 score value of 0.84. Model 3 has the highest recall value of 0.94, indicating its success in predicting the positive cases. The obtained results provide insights into each model's strengths and weaknesses and can be used in selecting the appropriate model based on the evaluation metric of interest."
1922,"caption: Table showing the performance of different models based on evaluation metrics.table: Model,Precision,Recall,F1 Score,Accuracy, SVM,0.89,0.65,0.74,0.83, KNN,0.78,0.70,0.74,0.79, Decision Tree,0.79,0.88,0.83,0.81, Random Forest,0.85,0.90,0.87,0.86, XGBoost,0.88,0.91,0.89,0.89","The table presents the performance of several learning models: SVM, KNN, Decision Tree, Random Forest, and XGBoost. The evaluation metrics include precision, recall, F1 score, and accuracy. According to the table, the XGBoost model outperforms the other models in terms of precision, recall, F1 score, and accuracy. It produced a precision of 0.88, recall of 0.91, F1 score of 0.89, and accuracy of 0.89. Interestingly, the Random Forest had the second-best performance with a precision of 0.85, recall of 0.90, F1 score of 0.87, and accuracy of 0.86. The SVM, KNN, and Decision Tree models are slightly behind, but they still produce decent results."
1923,"caption: Table 4: Comparison of different models based on accuracy, precision, recall and F1 Score.table: Model,Accuracy,Precision,Recall,F1 Score, Model A,0.925,0.908,0.876,0.891, Model B,0.907,0.902,0.864,0.885, Model C,0.922,0.881,0.908,0.894, Model D,0.909,0.898,0.889,0.893","Table 4 displays the comparative performances of different models, including Model A, Model B, Model C, and Model D, in terms of accuracy, precision, recall, and F1 score. The table demonstrates that Model A has the highest accuracy of 0.925. In contrast, Model B has the highest precision of 0.902, while Model C has the highest recall of 0.908, and Model A has the highest F1 score of 0.891. Interestingly, Model D seems to have a moderate performance in all the metrics, with a reasonable accuracy of 0.909, precision of 0.898, recall of 0.889 and F1 score of 0.893."
1924,"caption: Comparison of different classification models' performances based on different evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.85,0.86,0.89,0.85, Random Forest,0.87,0.88,0.91,0.87, Support Vector Machine,0.83,0.84,0.87,0.83, Multilayer Perceptron,0.84,0.85,0.89,0.84","The table compares four distinct classification models' performances based on multiple evaluation metrics - accuracy, F1-score, precision, and recall. The models Logistic Regression, Random Forest, Support Vector Machine, and Multilayer Perceptron's evaluation metrics are presented in the table. By analyzing the metrics, the models' performances can be compared against each other. Random Forest was the best-performing model for all metrics, achieving 0.87 accuracy, 0.88 F1-score, 0.91 precision, and 0.87 recall. Logistic Regression also produced an impressive performance with 0.85 accuracy, 0.86 F1-score, 0.89 precision, and 0.85 recall."
1925,"caption: Performance comparison of various models based on accuracy, precision, recall, F1-Sscore, and AUC.table: Model,Accuracy,Precision,Recall,F1-Score,AUC, SVM,0.926,0.925,0.928,0.925,0.956, Random Forest,0.891,0.888,0.880,0.883,0.931, Decision Tree,0.851,0.848,0.846,0.845,0.904, Naive Bayes,0.796,0.690,0.738,0.674,0.823, Multi-Layer Perceptron,0.912,0.912,0.912,0.911,0.943",
1926,"caption: Model comparison based on different evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, A,0.80,0.72,0.78,0.74, B,0.85,0.75,0.82,0.69, C,0.82,0.79,0.75,0.83, D,0.90,0.83,0.88,0.79, E,0.88,0.81,0.84,0.78","The table displays the model performances across multiple evaluation metrics, including Accuracy, F1-Score, Precision, and Recall. Model A exhibits an accuracy of 0.80 and F1-Score of 0.72, while Model E has an accuracy of 0.88 and F1-Score of 0.81. Interestingly, Model D performed the best across all metrics, with the highest accuracy and F1-Score scores of 0.90 and 0.83, respectively. While Models A and B have similar accuracy scores, Model B has a slightly higher F1-Score than Model A, indicating better overall performance. Model C has a higher recall score than Models B and E but has a lower precision score, indicating its classification relies on stricter criteria."
1927,"caption: Model performance comparison based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.89,0.89,0.90,0.89, Naive Bayes,0.72,0.81,0.60,0.68, Random Forest,0.92,0.92,0.83,0.87, Gradient Boosting,0.94,0.96,0.89,0.92",
1928,"caption: Comparison of Five Different Models' Performance using Multiple Evaluation Metricstable: Model,F1 Score,Accuracy,Precision,Recall, Model 1,0.83,0.92,0.80,0.87, Model 2,0.88,0.95,0.90,0.85, Model 3,0.91,0.94,0.87,0.95, Model 4,0.86,0.91,0.92,0.80, Model 5,0.89,0.93,0.88,0.91","Table above presents a comparison of the performance of five different models regarding different evaluation metrics, including F1 Score, Accuracy, Precision, and Recall. Model 3 exhibits the highest F1 Score and Recall of 0.91 and 0.95, respectively. Similarly, Model 2 achieved outstanding accuracy and precision of 0.95 and 0.90, respectively. Notably, Model 4 shows the highest precision among five models with a score of 0.92. Overall, these metrics indicate that while all models did well, Model 2 and Model 3 outperform the other models in various ways, depending on which metric is considered most important."
1929,"caption: Table 4: Model Evaluation Metrics Scores for Different Modelstable: Model Name,Accuracy,F1 Score,AUC Score, Model 1,0.90,0.89,0.92, Model 2,0.91,0.88,0.93, Model 3,0.89,0.84,0.91, Model 4,0.88,0.83,0.89, Model 5,0.93,0.94,0.91","Table 4 outlines the evaluation metrics scores such as Accuracy, F1 Score, and AUC Score for different models. The table displays the scores for five models, namely, Model 1, Model 2, Model 3, Model 4 and Model 5. It is observed that Model 5 achieved the highest scores for Accuracy (0.93) and F1 Score (0.94). Conversely, Model 4 and Model 3 obtained the lowest scores for all three metrics. It is interesting to note that while Model 5 attained the highest accuracy, it had a lower AUC Score of 0.91 compared to Model 1 and Model 2. Overall, it can be noted that the performance of each model varies based on the evaluation metric used."
1930,"caption: Table 4: Model performance on different evaluation metrics.table: Model,Accuracy,F-1 score,Precision,Recall, SVM,0.95,0.91,0.94,0.91, RF,0.92,0.88,0.83,0.93, KNN,0.87,0.82,0.77,0.88, MLP,0.94,0.90,0.94,0.86, Naive Bayes,0.89,0.79,0.81,0.76","Table 4 displays a comparison of different models' performances based on multiple evaluation metrics, specifically accuracy, F-1 score, precision, and recall. The table includes five models, SVM, RF, KNN, MLP, and Naive Bayes. Notably, SVM has the highest accuracy score of 0.95. The MLP model achieved the highest F-1 score with a score of 0.90. Furthermore, the highest precision score was obtained by the SVM model of 0.94, and the highest recall score was obtained by the RF model of 0.93. Interestingly, the Naive Bayes model had the lowest performance compared to the other models on all the evaluation metrics."
1931,"caption: Model performance comparison based on evaluation metricstable: Model,Accuracy,F1-score,AUC-ROC,Precision,Recall, Logistic Regression,0.92,0.94,0.87,0.91,0.97, SVM,0.91,0.93,0.86,0.89,0.98, Decision Tree,0.85,0.90,0.75,0.83,0.96, Random Forest,0.89,0.92,0.83,0.90,0.94, XGBoost,0.94,0.96,0.91,0.97,0.95","The table presents a comparison of various models' performances based on five evaluation metrics-- Accuracy, F1-score, AUC-ROC, Precision, and Recall. The table includes Logistic Regression, SVM, Decision Tree, Random Forest, and XGBoost models. Notably, XGBoost model demonstrated the best performance in terms of Accuracy, F1-score, and AUC-ROC, while Logistic Regression exhibited the highest Precision and Recall scores. Additionally, the Decision Tree model showed the lowest performance scores across all metrics. The table provides useful insights for selecting the best suitable model based on given evaluation metrics."
1932,"caption: Performance of different models based on various evaluation metrics.table: Model Name,Precision,Recall,F1-score,Accuracy, Logistic Regression,0.81,0.68,0.74,0.89, Decision Tree,0.76,0.69,0.72,0.86, Naive Bayes,0.70,0.85,0.76,0.84, Random Forest,0.79,0.75,0.77,0.88","Table 1 showcases the performance of four different models, namely Logistic Regression, Decision Tree, Naive Bayes, and Random Forest, based on various evaluation metrics, including precision, recall, F1-score, and accuracy. The models were tested on the same data and are evaluated on these metrics. Interestingly, Logistic Regression has the best precision of 0.81 while Naive Bayes has the best recall of 0.85. Meanwhile, the highest F1-score is achieved by Naive Bayes with a score of 0.76. Random Forest has the best accuracy of 0.88, although other models showed a competitive score with a difference of 0.02 or less."
1933,"caption: Model performance comparison of four different models based on Accuracy, Precision, Recall and F1.table: Model Name,Accuracy,Precision,Recall,F1, Model A,0.86,0.91,0.84,0.87, Model B,0.91,0.88,0.93,0.9, Model C,0.78,0.82,0.79,0.8, Model D,0.92,0.87,0.94,0.90","Table above compares the performances of four different models based on Accuracy, Precision, Recall, and F1 metrics. The table demonstrates that Model D has the highest Accuracy score (0.92), while Model B has the highest Recall score (0.93), and Model A has the highest Precision score (0.91). Interestingly, Model B also has the highest F1 score (0.9), indicating that it has the best balance between Precision and Recall. Conversely, Model C has the lowest scores in all metrics, suggesting that it is the poorest model for the given problem. Overall, the table illustrates that no single model excels in all the evaluation metrics, and different models perform better in different metrics."
1934,"caption: Comparison of model performances using various evaluation metrics.table: Model,Accuracy,F1_score,Recall,Precision,AUC_ROC,AUC_PR, Model 1,0.9,0.89,0.87,0.91,0.92,0.87, Model 2,0.87,0.86,0.84,0.89,0.9,0.86, Model 3,0.92,0.91,0.89,0.93,0.94,0.9, Model 4,0.88,0.86,0.85,0.87,0.92,0.85, Model 5,0.83,0.82,0.8,0.85,0.88,0.81",
1935,"caption: Table 4 - Model performance summary based on different evaluation metrics.table: Model Name,Accuracy,F1 score,Precision,Recall, Model 1,0.89,0.83,0.91,0.76, Model 2,0.92,0.87,0.90,0.84, Model 3,0.85,0.78,0.88,0.70, Model 4,0.91,0.85,0.92,0.79, Model 5,0.90,0.84,0.88,0.82","Table 4 provides a comparison of five different models' performance summary evaluated through four different metrics, namely Accuracy, F1 score, Precision, and Recall. The table shows that Model 2 exhibits the highest Accuracy result of 0.92. Model 4 has the highest Precision of 0.92, whereas Model 2 has the highest Recall result of 0.84. F1 score, representing the harmonic mean of Precision and Recall, shows that Model 2 has the highest F1 score at 0.87. However, interestingly, Model 1 exhibits a slightly lower F1 score of 0.83 with the highest Precision of 0.91. Therefore, the trade-off between Precision and Recall must be taken into account while choosing the best model."
1936,"caption: Table 4: Model evaluation metrics comparison of different classification modelstable: Metric,Model 1,Model 2,Model 3,Model 4, Recall,0.69,0.87,0.92,0.78, Precision,0.78,0.91,0.82,0.69, F1-score,0.73,0.89,0.86,0.73, Accuracy,0.80,0.92,0.81,0.76","Table 4 presents the results of the evaluation metrics of four different classification models. The table includes recall, precision, F1-score, and accuracy measures. Model 2 performs the best for the F1-score and accuracy measures with scores of 0.89 and 0.92, respectively. On the other hand, Model 3 has the highest recall and precision values of 0.92 and 0.82, respectively. Notably, Model 4 has the least performance with the lowest scores across all metrics. These results suggest that Model 2 and Model 3 are the top-performing models for this classification task, depending on the evaluation metric."
1937,"caption: Model performances based on accuracy, F1-score, precision, and recall.table: Model name,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.89,0.88,0.90,0.87, K-Nearest Neighbors,0.92,0.91,0.94,0.89, Decision Tree,0.85,0.83,0.86,0.80, Random Forest,0.94,0.94,0.95,0.93, XGBoost,0.93,0.92,0.94,0.91, Support Vector Machine,0.91,0.90,0.92,0.89","Table shows the performance comparison of six different classification models, including Logistic Regression, K-Nearest Neighbors (KNN), Decision Tree, Random Forest, XGBoost, and Support Vector Machine (SVM). The evaluation metrics used in the table are accuracy, F1-score, precision, and recall. Notably, The Random Forest model shows the best performance results with an accuracy of 0.94, F1-score of 0.94, precision of 0.95, and recall of 0.93. SVM shows the second-best accuracy of 0.91 and KNN had the highest accuracy of 0.92. Interestingly, Decision Tree showed the lowest scores on all evaluation metrics."
1938,"caption: Performance metrics of different models on a binary classification task.table: Model,AUC,F1 Score,Accuracy, Logistic Regression,0.76,0.45,0.60, Random Forest,0.87,0.53,0.72, XGBoost,0.8,0.47,0.63, Support Vector Machine,0.74,0.42,0.59, Artificial Neural Network,0.83,0.52,0.70","The table shows the performance comparison of five different models used for the binary classification task using three evaluation metrics: AUC, F1 Score, and Accuracy. The Random Forest model outperforms all other models with a maximum AUC of 0.87, F1 Score of 0.53, and Accuracy of 0.72. The Artificial Neural Network model follows closely with an AUC of 0.83, F1 Score of 0.52, and accuracy of 0.70. Surprisingly Logistic Regression has produced significantly lower performance scores for all three metrics, with an AUC of 0.76, F1 Score of 0.45, and Accuracy of 0.60. Interestingly, XGBoost has performed better in F1 Score despite its low accuracy score of 0.63 compared to other models. The Support Vector Machine model achieved the least performance results compared to the other models."
1939,"caption: Table 4: Model evaluation metrics comparisontable: Model,Accuracy,Precision,Recall,F1-score, Model 1,0.85,0.83,0.83,0.83, Model 2,0.79,0.81,0.71,0.76, Model 3,0.92,0.93,0.89,0.91, Model 4,0.77,0.72,0.86,0.79, Model 5,0.91,0.88,0.92,0.90","Table 4 presents model evaluation metrics comparison using multiple different models. The table includes accuracy, precision, recall, and F1-score for each model. It can be observed that Model 3 achieved the highest scores for accuracy (0.92), precision (0.93), recall (0.89), and F1-score (0.91) among all models presented. On the contrary, Model 4 obtained the lowest F1-score of 0.79, caused by its relatively lower recall value of 0.86. Overall, Table 4 offers a comprehensive performance comparison of different models and evaluation metrics, which can help researchers and practitioners to make well-informed decisions."
1940,"caption: Comparison of different classifiers' performance using multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.93,0.92,0.95,0.93, KNN,0.84,0.81,0.86,0.83, Naive Bayes,0.78,0.75,0.89,0.81, Decision Tree,0.88,0.88,0.87,0.87, Random Forest,0.94,0.93,0.95,0.94","The table presents a comparison of five different classification models based on their performance results using different evaluation metrics, namely Accuracy, Precision, Recall, and F1-Score. The models evaluated are SVM, KNN, Naive Bayes, Decision Tree, and Random Forest. Notably, Random Forest shows the best performance having achieved an Accuracy, Precision, Recall, and F1-score of 0.94. SVM has also performed well with an Accuracy of 0.93. However, Naive Bayes achieved high Recall of 0.89, and Decision Tree and Random Forest show high Precision of 0.88 and 0.93, respectively. KNN, on the other hand, demonstrates the lowest performance among all the models."
1941,"caption: Table 4: Model Performance Comparisontable: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.89,0.88,0.91,0.89, Decision Tree,0.78,0.76,0.84,0.80, Random Forest,0.94,0.92,0.96,0.94, Gradient Boosting,0.93,0.91,0.95,0.93","Table 4 compares the performances of four different models, Logistic Regression, Decision Tree, Random Forest, and Gradient Boosting. The table presents their performance evaluation metrics such as accuracy, precision, recall, and F1-score. The Random Forest model shows the highest accuracy score of 0.94, followed by Gradient Boosting with an accuracy score of 0.93. In terms of precision, the Random Forest and Gradient Boosting models performed similarly, achieving precision scores of 0.92 and 0.91, respectively. The Decision Tree model, however, had a significantly lower precision score of 0.76. Furthermore, for recall values, the Logistic Regression model had the lowest value of 0.91, while Random Forest achieved the highest score of 0.96. Finally, the F1-score comparison shows that the Random Forest model performed the best with a score of 0.94, followed by Gradient Boosting with a score of 0.93."
1942,"caption: Performance of different models on evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, Model A,0.87,0.85,0.88,0.82, Model B,0.89,0.87,0.86,0.88, Model C,0.81,0.79,0.84,0.75, Model D,0.92,0.91,0.93,0.89","Table depicts the performance of four different models by measuring accuracy, F1-score, Precision, and Recall. Model A achieved an accuracy of 0.87 with a precision score of 0.88 and lower recall of 0.82. Model B showed better accuracy with 0.89 and consistent F1-score of 0.87. It has a high recall of 0.88 but a relatively lower precision of 0.86. Conversely, Model C had a lower overall performance than Model A and B, with an  accuracy of 0.81. Despite having the highest precision of 0.84, Model C's lower recall of 0.75 contributed to its poorer performance. Model D displayed the best performance, achieving a high accuracy of 0.92 and consistent F1-score of 0.91. It had the highest precision of 0.93 and recall of 0.89, indicating a balanced trade-off between precision and recall."
1943,"caption: Table 4: Comparison of model performance over different evaluation metrics.table: Model name,Accuracy,Precision,Recall,F1 Score, Random Forest,0.987,0.985,0.973,0.979, Logistic Regression,0.978,0.984,0.951,0.967, Decision Tree,0.945,0.930,0.946,0.938, Multi-layer Perceptron,0.980,0.982,0.963,0.972, Naive Bayes,0.925,0.952,0.853,0.904","Table 4 presents the evaluation metrics' comparison of five machine learning models: Random Forest, Logistic Regression, Decision Tree, Multi-layer Perceptron, and Naive Bayes. The evaluation metrics included in the table are Accuracy, Precision, Recall, and F1 Score. The Random Forest model achieved the highest scores in all four metrics. The model's best-performing metric is Accuracy, with a score of 0.987, followed closely by Multi-layer Perceptron with 0.980. Logistic Regression model performed second best, with a score of 0.978 in Accuracy metric, while Naive Bayes had the least scores in all the metrics. These results suggest that Random Forest and Multi-layer Perceptron models are promising to achieve better results, given their higher scores in all evaluation metrics."
1944,"caption: Model Evaluation Results for Different Classifierstable: Model,Accuracy,F1-Score,AUC, Logistic Regression,0.87,0.89,0.93, Support Vector Machine,0.84,0.86,0.91, Decision Tree,0.78,0.81,0.86, Random Forest,0.89,0.91,0.94, XGBoost,0.91,0.92,0.95","The table exhibits the evaluation results of five classification models, which are Logistic Regression, Support Vector Machine, Decision Tree, Random Forest, and XGBoost. The evaluation metrics include Accuracy, F1-Score, and AUC. The AUC metric is a significant indicator of the model's classification performance in a binary classification problem. The Random Forest model achieved the highest accuracy score of 0.89, while the XGBoost model had the highest AUC score of 0.95. In terms of F1-Score, XGBoost had the best score of 0.92. Logistic Regression gained good performance over all three evaluation metrics, prompting it as a potential candidate for further analysis as well. Decision Tree has the lowest scores for all three evaluation metrics, indicating inadequate performance compared to other models."
1945,"caption: Comparison of different models based on accuracy, precision, recall, F1-score, and AUC.table: Model,Accuracy,Precision,Recall,F1-Score,AUC, Model A,0.89,0.83,0.76,0.79,0.92, Model B,0.91,0.85,0.80,0.82,0.94, Model C,0.88,0.80,0.72,0.75,0.90, Model D,0.87,0.82,0.74,0.77,0.90, Model E,0.85,0.78,0.67,0.70,0.88","The table above provides a comparison across multiple models of various evaluation metrics, including accuracy, precision, recall, F1-Score, and AUC. Model B has the best overall performance with an accuracy of 0.91, precision at 0.85, and recall at 0.80. However, Model A has the highest AUC at 0.92. Model E shows the lowest performance across all metrics, suggesting it may not perform well for the given task. These results demonstrate the importance of evaluating models based on multiple metrics to assess their generalizability and robustness."
1946,"caption: The performance of different models based on multiple evaluation metrics.table: Model,Accuracy,Recall,Precision,F1 Score, Model 1,0.85,0.93,0.78,0.85, Model 2,0.82,0.89,0.76,0.82, Model 3,0.86,0.91,0.81,0.85, Model 4,0.82,0.87,0.77,0.82","The table presents a comparison of multiple models based on different evaluation metrics, including Accuracy, Recall, Precision, and F1 Score. Model 1 has the highest Accuracy score of 0.85, and Model 3 has the highest recall score of 0.91. Model 3 also has the highest precision of 0.81, resulting in the highest F1 score of 0.85 among all models. On the other hand, Model 2 has the lowest accuracy and F1 score among all models. Overall, Model 3 is the best performer in this evaluation, with relatively high scores in all metrics."
1947,"caption: Model performance based on different evaluation metricstable: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.85,0.83,0.88,0.84, Naive Bayes,0.77,0.67,0.76,0.72, Random Forest,0.89,0.87,0.91,0.88, Gradient Boosting,0.91,0.89,0.93,0.90, Support Vector Machine,0.87,0.85,0.90,0.86","The presented table showcases the performance of different models based on several evaluation metrics, namely accuracy, F1 score, precision, and recall. The table compares the logistic regression, naive bayes, random forest, gradient boosting, and support vector machine models based on these metrics. The results demonstrate that the Gradient Boosting model outperforms other models on all metrics, achieving a high accuracy of 0.91, F1 score of 0.89, precision of 0.93, and recall of 0.90. The Random Forest model ranks second with high scores across all metrics. The Logistic Regression and Support Vector Machine also perform reasonably well, achieving high scores for accuracy, precision and recall, but with relatively lower F1 scores. The Naive Bayes model shows the lowest performance for all metrics."
1948,"caption: Table 4: Model Comparison based on Different Evaluation Metricstable: Model,Precision,Recall,F1-Score, SVM,0.88,0.79,0.83, RF,0.90,0.80,0.84, LR,0.85,0.75,0.77","Table 4 presents a comparison of different models based on multiple evaluation metrics. The table displays Precision, Recall, and F1-Score for the SVM, Random Forest, and Logistic Regression models. The results demonstrate that the RF model had the highest Precision value of 0.90, followed by SVM and LR, with 0.88 and 0.85, respectively. The Recall values for SVM and RF are identical at 0.80, while LR achieved the lowest Recall value of 0.75. Finally, the F1-Score results show that RF model performed the best with a score of 0.84, followed by SVM and LR, with scores of 0.83 and 0.77, respectively."
1949,"caption: Performance evaluation of different classification models.table: Models,F1-Score,Precision,Recall,Accuracy,Specificity, SVM,0.87,0.92,0.83,0.89,0.93, Logistic Regression,0.85,0.91,0.81,0.87,0.91, Decision Tree,0.76,0.78,0.75,0.76,0.77, Random Forest,0.91,0.93,0.91,0.92,0.92, XGBoost,0.89,0.90,0.89,0.90,0.91",
1950,"caption: Model comparison based on multiple evaluation metricstable: Model,Accuracy,F1-score,Precision,Recall, LSTM,0.85,0.87,0.84,0.91, Random Forest,0.92,0.91,0.93,0.89, SVM,0.84,0.89,0.83,0.96, Naive Bayes,0.79,0.78,0.81,0.76",
1951,"caption: Table 4: Performance comparison of multiple models using different evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score, Model 1,0.92,0.90,0.93,0.91, Model 2,0.94,0.93,0.92,0.93, Model 3,0.89,0.87,0.91,0.89, Model 4,0.93,0.94,0.92,0.93","The table exhibits a comparison of four different models' performance metrics, including Accuracy, Precision, Recall, and F1-Score. Model 2 shows the highest Accuracy of 0.94, followed by Model 4 with a score of 0.93. In terms of Precision, Model 4 performs the best with a score of 0.94, while Model 2 achieves the best Recall score of 0.92. Interestingly, Model 1 had the highest F1-Score of 0.91, while Model 2 comes in strong with a close score of 0.93. The results showcase varying performance levels for each model, highlighting the importance of evaluating multiple metrics simultaneously when comparing the models."
1952,"caption: Table 4. Model performances based on Accuracy, F1 Score, Precision, and Recall evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Model A,0.92,0.89,0.92,0.87, Model B,0.89,0.86,0.82,0.87, Model C,0.88,0.87,0.84,0.88, Model D,0.86,0.85,0.8,0.87, Model E,0.84,0.81,0.75,0.8","Table 4 shows the model performances based on accuracy, F1 Score, precision, and recall evaluation metrics. The table presents five different models, and their corresponding performance results are shown in the table. Model A achieved the highest accuracy of 0.92, while Model D had the lowest accuracy of 0.86. In terms of F1 Score, Model A achieved the highest score of 0.89, while Model E had the lowest score of 0.81. Model A also had the highest precision score of 0.92, while Model E had the lowest precision score of 0.75. Furthermore, Model A also achieved the highest recall score of 0.87, while Model E had the lowest recall score of 0.8. Based on the results, it can be concluded that Model A performed the best overall among the models."
1953,"caption: Performance comparison of different machine learning models on the given dataset using different evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall,ROC-AUC,PR-AUC, Logistic Regression,0.734,0.738,0.744,0.733,0.750,0.748, Random Forest,0.843,0.848,0.861,0.837,0.891,0.862, Gradient Boosting,0.826,0.830,0.837,0.825,0.874,0.824, Naive Bayes,0.684,0.689,0.712,0.674,0.606,0.596, K-Nearest Neighbor,0.741,0.742,0.746,0.739,0.726,0.728","Table presents the comparative analysis of five machine learning models, namely Logistic Regression, Random Forest, Gradient Boosting, Naive Bayes, and K-Nearest Neighbor, along with different evaluation metrics. The evaluation metrics, Accuracy, F1-Score, Precision, Recall, ROC-AUC, and PR-AUC are used to measure each model's performance. The Random Forest model delivers the best results in all evaluation metrics, achieving an Accuracy of 0.843, an F1-Score of 0.848, the Precision of 0.861, Recall of 0.837, ROC-AUC of 0.891, and PR-AUC of 0.862. The Naive Bayes model exhibits the lowest performance among all the models with an Accuracy of 0.684, F1-Score of 0.689, Precision of 0.712, Recall of 0.674, ROC-AUC of 0.606, and PR-AUC of 0.596."
1954,"caption: Performance comparison of different models using multiple evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall,ROC-AUC, SVM,0.91,0.80,0.89,0.73,0.89, LR,0.85,0.63,0.88,0.48,0.80, KNN,0.78,0.55,0.70,0.47,0.72, RF,0.92,0.83,0.89,0.78,0.91, XGB,0.87,0.73,0.82,0.66,0.84","The table presents a comparison of different models on their performance judged by multiple evaluation metrics, including Accuracy, F1 Score, Precision, Recall, and ROC-AUC. The models being tested are SVM, LR, KNN, RF, and XGB. The results show that RF achieved the highest performance scores for all metrics, except for Recall, where SVM was better. SVM, on the other hand, achieved the highest Recall score compared to other models. Additionally, LR shows the lowest score for all metrics, while KNN comes second-lowest. XGB shows promising performance scores, while SVM, LR, and KNN perform the least."
1955,"caption: Comparison of model performances based on multiple evaluation metricstable: Model,Precision,Recall,F1-score,AUC, Logistic Regression,0.85,0.75,0.79,0.92, Decision Tree,0.80,0.70,0.74,0.86, Random Forest,0.90,0.85,0.87,0.95, SVM,0.89,0.88,0.89,0.94, Naive Bayes,0.75,0.80,0.77,0.82","Table X illustrates the comparison of different models' performances based on multiple evaluation metrics, including Precision, Recall, F1-Score, and AUC. The table consists of five common classification models, including Logistic Regression, Decision Tree, Random Forest, SVM, and Naive Bayes. The AUC score represents the model's ability to distinguish between the positive and negative classes, where Random Forest exhibited the highest AUC score of 0.95. Whereas, SVM and Logistic Regression performed similarly in terms of Precision. Additionally, with respect to Recall, SVM outperformed all other models, followed by Naive Bayes. The F1-score integrated both Precision and Recall, in which Random Forest performed the best. Overall, Random Forest showed the highest cumulative performance among all models based on all evaluation metrics."
1956,"caption: Table 4: Model performances based on different evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, Model-A,0.85,0.84,0.89,0.81, Model-B,0.81,0.81,0.83,0.80, Model-C,0.89,0.88,0.91,0.87, Model-D,0.92,0.92,0.94,0.90, Model-E,0.83,0.82,0.89,0.77","Table 4 presents the performances of different models based on different evaluation metrics, namely accuracy, F1-score, precision, and recall. The table includes Model-A, Model-B, Model-C, Model-D, and Model-E, each displaying their performance scores. Model-D shows the best performance in all metrics, with an accuracy of 0.92, F1-score of 0.92, precision of 0.94, and recall of 0.90, indicating that it outperformed the others. Notably, Model-C also exhibited notably good performance, with a relatively high accuracy of 0.89 and F1-score of 0.88. In contrast, Model-B touched the lowest performance with an accuracy of 0.81 and recall of 0.80."
1957,"caption: Performance of different models based on multiple evaluation metrics.table: Model,Accuracy,F1-score,Recall,Precision, Model 1,0.87,0.86,0.90,0.83, Model 2,0.73,0.65,0.78,0.56, Model 3,0.93,0.92,0.94,0.91, Model 4,0.85,0.82,0.87,0.77","The table compares the performance of four different models based on evaluation metrics, including Accuracy, F1-score, Recall, and Precision. Model 1 achieved the highest Accuracy of 0.87, while Model 3 had the highest F1-score of 0.92. Model 3 also had the highest Recall and Precision scores of 0.94 and 0.91, respectively. Model 2 had the lowest performance scores based on all evaluation metrics, while Model 4 had the lowest Recall and Precision scores of 0.87 and 0.77, respectively. Therefore, Model 3 appears to be the best-performing model based on the evaluated metrics."
1958,"caption: Table 4: Performance metrics for different modelstable: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.87,0.85,0.85,0.85, Naïve Bayes,0.92,0.92,0.89,0.91, Random Forest,0.95,0.94,0.95,0.95, Support Vector Machine,0.94,0.93,0.92,0.92","Table 4 provides a comparison of different models' performances using different metrics, including accuracy, precision, recall, and F1-score. The models presented in the table are Logistic Regression, Naïve Bayes, Random Forest, and Support Vector Machine (SVM). The table demonstrates that all models have high accuracy rates, with Random Forest exhibiting the best accuracy score of 0.95. Naïve Bayes had the highest precision score of 0.92, while Random Forest had the highest recall rate of 0.95. Furthermore, all models had high F1-scores, with Random Forest being the most balanced with an F1-score of 0.95. Overall, the table suggests that Random Forest is the best model based on its high accuracy and balanced F1-score."
1959,"caption: Comparison of Different Model Performances Based on Multiple Evaluation Metricstable: Model Name,Metric 1 Mean,Metric 1 Std. Dev.,Metric 2 Mean,Metric 2 Std. Dev.,Metric 3 Mean,Metric 3 Std. Dev., Model 1,0.70,0.05,0.65,0.03,0.80,0.02, Model 2,0.75,0.03,0.58,0.04,0.85,0.01, Model 3,0.62,0.02,0.75,0.06,0.90,0.01, Model 4,0.68,0.01,0.63,0.05,0.76,0.02, Model 5,0.79,0.06,0.50,0.04,0.92,0.01","The table presents a comparison of different models' performances based on multiple evaluation metrics. The table shows the mean and standard deviation (std. dev.) of three different performance metrics for each model. The models are labeled as Model 1, Model 2, Model 3, Model 4, and Model 5. The performance metrics are labeled as Metric 1, Metric 2, and Metric 3. Interestingly, Model 5 shows the highest mean scores in Metric 1 and Metric 3. However, Model 2 performs the best in Metric 2, even though Model 5 has the worst performance in Metric 2. Overall, Model 3 shows a more consistent performance across all three metrics with relatively low variations in std. dev."
1960,"caption: Performance evaluation of different models on the test dataset using various metrics.table: Model,Precision,Recall,F1-Score,Accuracy, Support Vector Machine,0.856,0.758,0.804,0.892, Logistic Regression,0.842,0.726,0.779,0.874, Decision Tree,0.792,0.678,0.725,0.821, Random Forest,0.914,0.832,0.871,0.928, Gradient Boosting,0.902,0.829,0.865,0.920","This table presents the performance evaluation of five different models using multiple evaluation metrics. The models included are Support Vector Machine, Logistic Regression, Decision Tree, Random Forest, and Gradient Boosting. The evaluation metrics used for measuring the model's performance are Precision, Recall, F1-Score, and Accuracy. The table reveals that the Random Forest model performed the best overall, with a precision of 0.914, recall of 0.832, F1-Score of 0.871, and Accuracy of 0.928. Interestingly, the Gradient Boosting model performed slightly better than the Random Forest model in terms of Precision and Accuracy, but it fell short in Recall and F1-Score. The Support Vector Machine model attained the highest precision score of 0.856, while the Decision Tree model had the lowest performance scores across all metrics."
1961,"caption: Performance comparison of different models based on multiple evaluation metrics.table: Model 1,Model 2,Model 3, Metric 1,0.85,0.90,0.92, Metric 2,0.73,0.75,0.82, Metric 3,0.88,0.89,0.91, Metric 4,0.91,0.93,0.95","The table represents the model's performance comparison based on four different evaluation metrics, namely Metric 1, Metric 2, Metric 3, and Metric 4. We compare three different models (Model 1, Model 2, and Model 3) in the table. Interestingly, Model 1 performs the worst in all four metrics compared to the other models. Model 2 and Model 3 have a considerable performance difference, with Model 3 achieving the highest value in all the metrics. Particularly, Model 3 achieves 0.95 in Metric 4, which is significantly higher than the other two models. Overall, the table shows Model 3 has better performance for all the evaluation metrics compared to the other models."
1962,"caption: Performance of machine learning models on the classification problem.table: Model,Accuracy,F1 score,Precision,Recall, Logistic Regression,0.89,0.92,0.87,0.9, K-Nearest Neighbors,0.85,0.89,0.84,0.86, Decision Tree,0.81,0.87,0.8,0.83, Gaussian Naive Bayes,0.87,0.91,0.84,0.88, Random Forest,0.91,0.94,0.91,0.93, Gradient Boosting,0.93,0.96,0.93,0.94","Table presents the evaluation results of six machine learning models on the classification problem. The models' performance was measured using Accuracy, F1 score, Precision, and Recall metrics. The Random Forest model achieved the highest Accuracy, F1 score, Precision, and Recall scores of 0.91, 0.94, 0.91, and 0.93, respectively. The Gradient Boosting model showed the second-best performance for all metrics except Precision. Interestingly, though other models' performance scores are lower, they still have acceptable performance scores for most metrics, and they might be suitable choices for other similar problems based on their particular requirement."
1963,"caption: Table 4: Model performances based on different evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.875,0.874,0.864,0.884, RF,0.885,0.878,0.883,0.874, k-NN,0.879,0.871,0.869,0.873, NB,0.809,0.788,0.828,0.751, DNN,0.880,0.881,0.876,0.888","Table 4 shows the comparison of model performances based on different evaluation metrics. The table summarizes SVM, RF, k-NN, NB, and DNN models' performances in terms of Accuracy, F1-Score, Precision, and Recall. The table contains interesting observations such as RF and DNN models' highest Accuracy of 0.885 and 0.880, respectively. In contrast, the NB model attained the lowest Accuracy of 0.809 while showing the highest Precision of 0.828. Interestingly, the k-NN model's Precision and Recall achieved identical scores of 0.869. Additionally, the DNN model showed the highest F1-Score and Recall performances of 0.881 and 0.888, respectively."
1964,"caption: Model performance comparison using multiple evaluation metrics.table: Model,Precision,Recall,F1 Score,AUC-PR,AUC-ROC, Model A,0.92,0.89,0.90,0.86,0.92, Model B,0.84,0.91,0.87,0.89,0.81, Model C,0.93,0.82,0.87,0.79,0.91, Model D,0.78,0.94,0.85,0.82,0.79","The table above compares the evaluation metrics of four different models- Model A, Model B, Model C, and Model D. The evaluation metrics include Precision, Recall, F1 Score, AUC-PR, and AUC-ROC. Model A performs well in terms of all five metrics, with particularly high scores for Precision (0.92), AUC-PR (0.86) and AUC-ROC (0.92). Model D shows a significantly high Recall score of 0.94 but has the lowest F1 Score and AUC-ROC among the models. Model C has a high Precision score of 0.93 but performs poorly in other metrics. Model B achieves a high Recall score of 0.91 but has the lowest AUC-ROC and Precision among the models."
1965,"caption: Table 1: Classification model's performance metrics.table: Model,Accuracy,F1-Score,Precision,Recall, CNN,0.904,0.901,0.910,0.896, LSTM,0.908,0.906,0.898,0.915, SVM,0.911,0.908,0.919,0.898, Naive Bayes,0.894,0.891,0.864,0.920","The table presents the classification models' performance metrics, including Accuracy, F1-Score, Precision, and Recall scores. The CNN, LSTM, and SVM models scored above 90% accuracy, while Naive Bayes scored slightly lower accuracy of 0.894. The SVM model achieved the highest F1-Score, Precision, and Recall scores of 0.908, 0.919, and 0.898, respectively. LSTM model closely followed with F1-Score and Recall scores of 0.906 and 0.915, respectively. On the other hand, CNN model scored better in terms of Precision, with a score of 0.910. Naive Bayes model had relatively lower accuracy and F1-scores compared to the other models."
1966,"caption: Performance comparison of different models using multiple evaluation metrics.table: Models,Accuracy,F1 Score,Precision,Recall, Model1,0.865,0.874,0.871,0.877, Model2,0.878,0.863,0.886,0.846, Model3,0.892,0.905,0.896,0.914, Model4,0.856,0.843,0.837,0.850, Model5,0.874,0.885,0.879,0.892","Table presents the performance comparison of five different models using four evaluation metrics: Accuracy, F1 score, Precision, and Recall. Accordingly, Model3 achieves the highest accuracy score of 0.892. On the other hand, Model2 shows the highest precision score of 0.886. Contrarily, Model4 shows the lowest performance in terms of precision and recall score. Interestingly, Model5 shows the highest F1 score with a close score of 0.885, while Model1 and Model3 also achieved a high F1 score of 0.874 and 0.905, respectively. Overall, results show that Model3 has a robust performance across all metrics, whereas Model4 has the lowest performance."
1967,"caption: Table 4: The performance evaluation of different models based on different evaluation metrics.table: Model Name,Accuracy,F1 Score,Precision,Recall, Model 1,0.84,0.81,0.9,0.74, Model 2,0.73,0.67,0.77,0.58, Model 3,0.89,0.87,0.86,0.89, Model 4,0.78,0.74,0.8,0.69, Model 5,0.93,0.91,0.92,0.90","Table 4 showcases a comparison of different models based on multiple evaluation metrics such as accuracy, F1 score, precision, and recall. Model 1 has the highest accuracy of 0.84, whereas Model 5 has the highest accuracy of 0.93, indicating that Model 5 performed better than the other models. Furthermore, in terms of F1 score, Model 5 achieved the highest score of 0.91, demonstrating that it outperformed the other models. Interestingly, Model 3 had a lower F1 score compared to Model 5, indicating that even though Model 3 had a high accuracy of 0.89, it did not perform well in terms of F1 score. Finally, across all models, precision and recall scores show slight variations, suggesting that all models have similar performance in terms of precision and recall."
1968,"caption: Table 4: Model Performance on Different Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.91,0.92,0.89,0.91, Logistic Regression,0.87,0.83,0.89,0.86, Random Forest,0.92,0.94,0.89,0.92, Naive Bayes,0.81,0.74,0.93,0.82","Table 4 presents the performance of different models based on multiple evaluation metrics. The table includes SVM, Logistic Regression, Random Forest, and Naive Bayes models' performance results on accuracy, precision, recall, and F1-Score metrics. The Random Forest model shows the highest accuracy of 0.92, outperforming SVM and Logistic Regression models, which achieved 0.91 and 0.87, respectively. Additionally, the Precision score was highest for the Random Forest model at 0.94, while Naive Bayes achieved the lowest precision score of 0.74. Naive Bayes model achieved the highest recall at 0.93, whereas the Logistic Regression model had the lowest recall score of 0.89. Finally, the F1-score was highest for Random Forest at 0.92, with Naive Bayes achieving the lowest F1-Score of 0.82."
1969,"caption: Evaluation Metrics of Different Modelstable: Model Name,Accuracy,F1-Score,Precision,Recall, Model A,0.85,0.85,0.87,0.83, Model B,0.89,0.89,0.90,0.88, Model C,0.91,0.91,0.92,0.90, Model D,0.90,0.89,0.91,0.88","Table above shows the evaluation metrics (Accuracy, F1-Score, Precision and Recall) of four different models. Model A, B, C, and D have accuracy of 0.85, 0.89, 0.91 and 0.90, respectively. Model C performs significantly better compared to other models, with the highest accuracy, F1-Score, precision and recall of 0.91, 0.91, 0.92 and 0.90, respectively. Although Model D performed slightly worse than Model B based on F1-Score, precisions and recalls, it still achieved a decent accuracy score of 0.90."
1970,"caption: Table 4: Model evaluation metrics on the test dataset.table: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.89,0.88,0.91,0.85, Decision Tree,0.81,0.79,0.83,0.76, Random Forest,0.93,0.92,0.95,0.90, Gradient Boosting,0.92,0.91,0.94,0.88, Support Vector Machine,0.88,0.87,0.90,0.84","Table 4 shows multiple evaluation metrics for various models on the test dataset. The models' performance shown are Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Support Vector Machine. The evaluation metrics include Accuracy, F1-score, Precision, and Recall. The Random Forest model had the best evaluation scores overall, with an accuracy score of 0.93, F1-score of 0.92, precision of 0.95, and recall of 0.90. However, the Gradient Boosting model also performed well, with high scores across all metrics, indicating strong predictive capability. Conversely, the Decision Tree model shows relatively lower scores across the evaluation metrics."
1971,"caption: Table 4: Comparison of various classifiers based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, Logistic regression,0.85,0.86,0.78,0.82, Random forest,0.88,0.87,0.84,0.85, Gradient Boosting,0.90,0.89,0.86,0.87, Support Vector Machines,0.87,0.89,0.79,0.83, Multi-layer Perceptron,0.89,0.85,0.88,0.86","The table 4 compares different classifiers based on various evaluation metrics, such as accuracy, precision, recall, and F1-score. The table includes Logistic Regression, Random Forest, Gradient Boosting, Support Vector Machine, and Multi-layer Perceptron. Results indicate that Gradient Boosting has the highest accuracy of 0.90. However, Multi-layer Perceptron has the highest recall of 0.88. On the other hand, Logistic Regression model exceeds others concerning precision, displaying the best value of 0.86, while the highest F1-score of 0.87 is achieved by Gradient Boosting. In summary, the Gradient Boosting model seems to provide the best overall performance according to different metrics."
1972,"caption: Model performance comparison of different machine learning algorithms for a supervised classification task.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.82,0.84,0.76,0.8, KNN,0.71,0.65,0.63,0.64, MLP,0.76,0.78,0.68,0.73, Random Forest,0.85,0.88,0.81,0.84, Decision Tree,0.78,0.77,0.73,0.75","The table presents a performance comparison of different machine learning algorithms' results for a supervised classification task, evaluated with accuracy, precision, recall, and F1-score metrics. Models, including SVM, KNN, MLP, Random Forest, and Decision Tree, were trained and tested using the same dataset. Notably, Random Forest achieved the highest accuracy of 0.85, whereas SVM had the highest precision with a score of 0.84. The highest recall score was obtained by Random Forest of 0.81, while SVM scored the highest F1-score of 0.8. Therefore, the performance of these models can be compared based on each metric's relative importance in the classification task."
1973,"caption: Model performances of different classification models based on evaluation metrics - Accuracy, F1 Score, Precision, and Recall.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.85,0.84,0.87,0.81, Logistic Regression,0.82,0.81,0.83,0.80, Decision Tree,0.78,0.77,0.74,0.82, Random Forest,0.87,0.86,0.90,0.83, XGBoost,0.90,0.89,0.92,0.87","The table presents the results of evaluating the performance of different classification models based on metrics such as Accuracy, F1 Score, Precision and Recall. The evaluation was done using the same dataset. From the table, it is evident that the XGBoost model achieved the highest accuracy of 0.90, followed closely by the Random Forest model, which attained a score of 0.87. The F1 Score and Precision results indicate that the models performed comparably but the XGBoost model still outranks the rest. Interestingly, the SVM model achieved the highest Precision score of 0.87 and the Decision Tree model achieved the highest Recall score of 0.82."
1974,"caption: Performance of different models on binary classification task using multiple evaluation metricstable: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.89,0.87,0.92,0.89, Decision Tree,0.92,0.94,0.89,0.91, Random Forest,0.94,0.95,0.92,0.94, KNN,0.85,0.84,0.85,0.84, SVM,0.93,0.93,0.93,0.93","The table displays the performance comparison of five different models, including Logistic Regression, Decision Tree, Random Forest, KNN, and SVM, on a binary classification task. The evaluation metrics include Accuracy, Precision, Recall, and F1-score. The Random Forest model shows better results across all evaluation metrics, with an Accuracy score of 0.94, Precision score of 0.95, Recall score of 0.92, and F1-score of 0.94. SVM model has the same Precision and Recall scores of 0.93, which are the highest in the table. Both Logistic Regression and Decision Tree models show good scores, albeit slightly lower scores compared to Random Forest and SVM. However, the KNN model shows relatively lower scores compared to other models in all evaluation metrics."
1975,"caption: Table 4: Performance evaluation of different Machine Learning Models based on Accuracy, F1-score, Precision, and Recall.table: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.82,0.83,0.84,0.82, Decision Tree,0.76,0.74,0.76,0.73, Random Forest,0.85,0.86,0.86,0.86, Support Vector,0.81,0.80,0.81,0.80, Multi-Layer,0.87,0.87,0.87,0.87","Table 4 showcases the performance of different machine learning models based on four metrics: Accuracy, F1-score, Precision, and Recall. The table exhibits Logistic Regression, Decision Tree, Random Forest, Support Vector, and Multi-Layer models. As seen, Multi-Layer perceptron achieved the highest performance score in all metrics with an accuracy score of 0.87, followed by Random Forest with 0.85 accuracy score. Although Decision Tree model performs well in F1-score, it has relatively lower scores in accuracy, precision, and recall. Finally, the Support Vector model demonstrates decent performance in all metrics with an accuracy score of 0.81."
1976,"caption: Comparison of Different Models based on Multiple Metricstable: Model,Accuracy,Precision,Recall,F1-Score, Model 1,0.76,0.77,0.74,0.72, Model 2,0.82,0.81,0.79,0.79, Model 3,0.79,0.83,0.72,0.75, Model 4,0.85,0.88,0.81,0.84, Model 5,0.87,0.79,0.94,0.86","Table presents a comparison of multiple models based on accuracy, precision, recall, and F1-score metrics. Model 1 has the lowest overall performance, achieving 0.76 accuracy, 0.77 precision, 0.74 recall, and 0.72 F1-score. In contrast, Model 5 outperforms the other models with 0.87 accuracy, 0.79 precision, 0.94 recall, and 0.86 F1-score. Model 4 also shows an excellent performance with 0.85 accuracy, 0.88 precision, 0.81 recall, and 0.84 F1-score. Notably, Model 3 has the highest precision score of 0.83 but lower recall and F1-Score scores of 0.72 and 0.75. On the other hand, Model 2 had consistently good scores across all the metrics, specifically an accuracy of 0.82, precision of 0.81, recall of 0.79, and F1-Score of 0.79. Overall, Model 5 is the best performing model, given its high recall and F1-score."
1977,"caption: Model performances based on different evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.892,0.833,0.872,0.796, Random forest,0.875,0.811,0.841,0.784, KNN,0.879,0.819,0.861,0.780, Decision tree,0.816,0.704,0.731,0.679, Multi-layer perceptron,0.891,0.831,0.853,0.812","Table depicts the accuracy, F1-score, precision, and recall metrics of five models, namely SVM, Random forest, KNN, Decision tree, and Multi-layer perceptron, trained and tested on the same dataset. Interestingly, SVM exhibits the highest accuracy score of 0.892, whereas the decision tree model performs the worst, with an accuracy score of only 0.816. F1-score shows a similar trend, and SVM acquires the highest score of 0.833, rendering it the best model based on F1-score. Furthermore, the Multi-layer perceptron performs well based on the precision and recall metrics compared to other models with scores of 0.853 and 0.812, respectively."
1978,"caption: Comparison of models' performance in terms of evaluation metrics.table: Model,F1-score,Accuracy,Precision,Recall, Model A,0.91,0.87,0.89,0.93, Model B,0.87,0.84,0.84,0.9, Model C,0.92,0.88,0.89,0.96, Model D,0.88,0.85,0.86,0.91, Model E,0.90,0.86,0.88,0.93","The table above presents the performance of five different models in terms of various evaluation metrics. F1-score, accuracy, precision, and recall are the performance evaluation metrics used in this table. Model C outperformed all other models with the highest F1-score of 0.92 and recall of 0.96. Model A and Model E had the second-highest F1-scores of 0.91 and 0.90, respectively. Model A showed the highest accuracy, precision, and recall amongst all models. Model B had the lowest performance with the lowest F1-score, precision, and recall. Overall, the table exhibits significant differences in model performance using multiple evaluation metrics."
1979,"caption: Model Performance Metricstable: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.78,0.73,0.80,0.68, LR,0.64,0.61,0.63,0.59, RF,0.87,0.85,0.92,0.79, KNN,0.65,0.62,0.71,0.56","The table presents the model evaluation metrics for different machine learning models such as Support Vector Machine (SVM), Logistic Regression (LR), Random Forest (RF), and K-Nearest Neighbor (KNN). The model performance is measured using evaluation metrics such as Accuracy, F1-Score, Precision, and Recall. The table shows that the Random Forest model performs the best with the highest Accuracy of 0.87, F1-Score of 0.85, Precision of 0.92, and Recall of 0.79. The Support Vector Machine model follows with an Accuracy of 0.78, F1-Score of 0.73, Precision of 0.80, and Recall of 0.68. The Logistic Regression and K-Nearest Neighbor models perform relatively poorer. Overall, the table emphasizes the Random Forest model as the best performing model."
1980,"caption: Table 4: Model performances based on multiple evaluation metrics.table: Model,Precision,Recall,F1-Score, Logistic Regression,0.87,0.92,0.89, Decision Tree,0.78,0.87,0.82, Random Forest,0.91,0.94,0.92, Naive Bayes,0.86,0.90,0.88, Support Vector Machine,0.84,0.92,0.88","Table 4 provides model performances based on several metrics for five different models. The models are Logistic Regression, Decision Tree, Random Forest, Naive Bayes, and Support Vector Machine. The table presents the Precision, Recall, and F1-Score performance results for these models. Notably, the Random Forest model achieved the highest Precision and Recall values of 0.91 and 0.94 respectively, which are the most important metrics in many classification problems. However, the Naive Bayes model performed well on all metrics with an F1-Score of 0.88. Meanwhile, the Decision Tree model shows the weakest performance among all models with the lowest F1-Score of 0.82."
1981,"caption: Performance Comparison of Different Modelstable: Model,Accuracy,F1-score,Precision,Recall, SVM,0.75,0.73,0.79,0.69, Random Forest,0.83,0.82,0.86,0.79, MLP,0.79,0.78,0.82,0.75, KNN,0.73,0.71,0.76,0.67","The table presents the performance comparison of four different models based on their evaluation metrics: Accuracy, F1-score, Precision, and Recall. The models evaluated include SVM, Random Forest, MLP, and KNN. The SVM model has the lowest accuracy of 0.75 but has the highest precision of 0.79. On the other hand, the Random Forest model has the highest accuracy of 0.83 and the highest precision of 0.86. Notably, the Random Forest model outperformed the other models in terms of F1-score and Recall, with values of 0.82 and 0.79, respectively. Overall, the Random Forest model is the best-performing model based on the evaluation metrics considered."
1982,"caption: Table 4: Model Performance on the test dataset using various evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score,AUC-ROC, Logistic Regression,0.85,0.86,0.80,0.83,0.91, Random Forest,0.89,0.90,0.86,0.88,0.93, Support Vector Machine,0.83,0.87,0.75,0.80,0.89, Neural Network,0.87,0.88,0.84,0.86,0.92",
1983,"caption: Model performance from different approaches based on different evaluation metrics.table: Model,Accuracy,F1-score,Recall,Specificity, SVM,0.87,0.87,0.91,0.83, KNN,0.82,0.78,0.75,0.85, RF,0.91,0.91,0.95,0.85, XGB,0.90,0.90,0.92,0.87","The table presents a comparison of the performance of four different models(SVM, KNN, RF, and XGB) with respect to different evaluation metrics, including Accuracy, F1-score, Recall and Specificity. The highest accuracy was reported by the Random Forest (RF) model with a score of 0.91. Moreover, both the RF and XGB models performed well in terms of the F1-score. Specifically, they both achieved a score of 0.91. In terms of Recall, the best performance was observed for the RF model (0.95), while in terms of Specificity, KNN performed better with a score of 0.85. Overall, the RF model seems to have shown better performance in most of the evaluation metrics among the models compared."
1984,"caption: Model performances based on various evaluation metrics.table: Model,Precision,Recall,F1-score,Accuracy, Logistic Regression,0.78,0.84,0.81,0.87, Decision Tree,0.82,0.79,0.80,0.85, Random Forest,0.88,0.87,0.87,0.91, SVM,0.91,0.93,0.92,0.93, XGBoost,0.89,0.90,0.89,0.91","The table showcases the performance of diverse models based on different evaluation metrics such as precision, recall, F1-score, and accuracy. The model's performance results suggest that SVM performed the best across all the metrics with an accuracy of 0.93 and F1-score of 0.92. Random forest also achieved a high accuracy of 0.91, precision of 0.88, recall of 0.87, and F1-score of 0.87. Logistic Regression and Decision Tree both indicate moderate performances compared to Random Forest and SVM. Interestingly, XGBoost shows a good balance of precision, recall, and F1-score but has slightly lower accuracy than Random Forest and SVM."
1985,"caption: Model performance metrics comparison of different classification modelstable: Model,Accuracy,Precision,Recall,F1, Random forest 1,0.9,0.89,0.92,0.905, Random forest 2,0.85,0.78,0.94,0.85, Logistic Regression,0.84,0.77,0.88,0.825, Naive Bayes,0.78,0.71,0.83,0.762","Table presents a comparison of commonly used classification models' performance metrics, including Accuracy, Precision, Recall, and F1 scores. The comparison table includes Random forest 1, Random forest 2, Logistic Regression, and Naive Bayes for the evaluation of different models. Random forest 1 exhibit the highest accuracy and recall of 0.9 and 0.92, respectively. On the other hand, Naive Bayes had a lower accuracy score of 0.78 but presented a precision score of 0.71. The table serves as a useful resource to determine the classification models that best fit a specific project's requirement."
1986,"caption: Comparison of different models' performance on the evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.847,0.854,0.802,0.827, Decision Tree,0.826,0.811,0.823,0.817, SVM,0.834,0.842,0.798,0.816, Random Forest,0.873,0.885,0.832,0.855, XGBoost,0.872,0.879,0.834,0.854","Table above reports the five models' accuracy, precision, recall, and F1-score. The models are Logistic Regression, Decision Tree, SVM, Random Forest, and XGBoost, and the evaluation metrics are calculated using the same dataset. The best-performing model for accuracy, precision, and F1-score is Random Forest with scores of 0.873, 0.885, and 0.855, respectively. XGBoost is the closest competitor and almost performed as well as the Random Forest. Interestingly, the Logistic Regression had the highest recall performance, obtaining a score of 0.802. Overall, the evaluation metrics showed a fair performance by all models."
1987,"caption: Comparison of Different Models on Different Evaluation Metricstable: Model,Accuracy (%),F1 Score,Precision,Recall, Support Vector Machine,80.3,0.752,0.794,0.722, Logistic Regression,78.4,0.727,0.780,0.679, Random Forest,83.1,0.798,0.818,0.780, Decision Tree,76.5,0.692,0.707,0.679, Multilayer Perceptron,79.8,0.746,0.789,0.710","The table above showcases the performance of five distinct models on different evaluation metrics, namely, accuracy, F1 score, precision, and recall. This table aims to compare which of these models gives the most desirable results dependent on the evaluation metric employed. Interestingly, Random Forest garnered the highest accuracy rate of 83.1%, while Logistic Regression garnered the lowest accuracy of 78.4%. However, in terms of F1-score, Random Forest was only second with 0.798, trailing behind SVM with 0.752. Similarly, SVM had the best precision score of 0.794, while Random forest had the highest recall of 0.780. Ultimately, the choice of model will depend on the evaluation metric that holds the most importance to the user."
1988,"caption: Comparison of different machine learning models based on evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.91,0.94,0.87,0.91, MLP,0.89,0.89,0.90,0.89, KNN,0.86,0.87,0.83,0.85, XGBoost,0.93,0.93,0.93,0.93","Table presents a comparison of four machine learning models based on different evaluation metrics: accuracy, precision, recall, and F1-score. The SVM model shows the highest accuracy of 0.91, while the XGBoost model outperformed the others in all evaluation metrics with an extraordinary score of 0.93. The MLP model achieved the highest precision and recall scores of 0.89 and 0.90, respectively. Furthermore, the SVM model displayed a relatively high precision score of 0.94. The KNN model, on the other hand, had the lowest performance in all evaluation metrics, except for accuracy, where it achieved a score of 0.86. Overall, the XGBoost model stands out as the best performing model in all evaluation metrics compared to the other models."
1989,"caption: Performance of Different Classification Models on the Test Datatable: Model,Accuracy,F1 Score,Recall,Precision,Specificity, Logistic Regression,0.91,0.9,0.87,0.93,0.93, Decision Tree,0.86,0.85,0.84,0.87,0.88, Random Forest,0.95,0.95,0.93,0.97,0.98, SVM,0.93,0.92,0.89,0.95,0.96, Naive Bayes,0.89,0.88,0.85,0.92,0.94","The table shows the performance of five different classification models, which are Logistic Regression, Decision Tree, Random Forest, SVM, and Naive Bayes. The models were evaluated on various metrics such as Accuracy, F1-Score, Recall, Precision, and Specificity. The results highlight that the Random Forest model achieved the best overall performance with an accuracy of 0.95 and F1-score of 0.95. Additionally, the SVM model showed the highest precision and specificity of 0.95 and 0.96, respectively. Despite their lower performance compared to the other models, Logistic Regression, Decision Tree, and Naive Bayes all achieved an accuracy of 0.89 or higher. Overall, the Random Forest model exhibits the best performance among all models."
1990,"caption: Table 4: Performance of various models based on different evaluation metrics on test datatable: Model,Precision,Recall,F1-Score,Accuracy, SVM (RBF),0.75,0.77,0.76,0.78, Logistic,0.71,0.81,0.76,0.77, Naive Bayes,0.66,0.90,0.76,0.72, Random Forest,0.82,0.69,0.74,0.76, AdaBoost,0.70,0.85,0.77,0.74","Table 4 shows the performance comparison of five different models (SVM, Logistic, Naive Bayes, Random Forest, and AdaBoost) under various evaluation metrics. The evaluation metrics used are precision, recall, F1-score, and accuracy. The best performance is observed in the Random Forest classifier in terms of precision (0.82) and the Naive Bayes classifier in term of recall (0.90). In terms of F1-score, the AdaBoost classifier showed the best performance of 0.77, while the Logistic classifier showed the best accuracy of 0.77. Overall, the Random Forest classifier had the highest average performance score of 0.7525."
1991,"caption: Table 4: Performance evaluation of different models using multiple metrics.table: Model,Accuracy,F1-score,Precision,Recall,MCC, A,0.845,0.832,0.857,0.808,0.696, B,0.832,0.826,0.844,0.809,0.678, C,0.825,0.827,0.833,0.822,0.663, D,0.813,0.809,0.821,0.797,0.642, E,0.794,0.78,0.798,0.762,0.609","Table 4 presents the results of different evaluation metrics for multiple models, including accuracy, F1-score, precision, recall, and MCC. Models A, B, C, D, and E were evaluated using the same test dataset, with Model A showing the highest accuracy of 0.845, while model E scored the lowest accuracy of 0.794. Interestingly, Model A performs the best in all evaluation metrics, except for F1-score, where Model B outperforms with a score of 0.826, while Model A scored 0.832. We observed that Models A, B, and C have similar levels of precision and recall, whereas Models D and E have the lowest precision and recall scores. In conclusion, Model A is the most performant model across all evaluation metrics in this comparison."
1992,"caption: Model performances based on accuracy, precision, recall, and F1 score.table: Model,Accuracy,Precision,Recall,F1 Score, Model A,0.85,0.87,0.82,0.84, Model B,0.88,0.89,0.88,0.88, Model C,0.80,0.83,0.75,0.79, Model D,0.82,0.80,0.89,0.84","The table presents the performance of four different models, namely Model A, Model B, Model C, and Model D. The models were evaluated using different metrics, including accuracy, precision, recall, and F1 score. Model B demonstrated the highest accuracy score of 0.88, while Model A exhibited the highest precision score of 0.87. Model D achieved the highest recall score of 0.89, and Model B displayed the highest F1 score of 0.88. Notably, Model C obtained the lowest performance in all the metrics reported in the table, with an accuracy of 0.80, precision of 0.83, recall of 0.75, and F1 score of 0.79."
1993,"caption: A comparison of different models based on multiple evaluation metrics.table: Model,F1 Score,Accuracy,Precision,Recall, Model A,0.81,0.85,0.90,0.76, Model B,0.87,0.82,0.78,0.98, Model C,0.79,0.87,0.92,0.70, Model D,0.93,0.91,0.86,1.00, Model E,0.85,0.80,0.75,0.98","The table above compares five different models based on their F1 score, accuracy, precision, and recall. Model D achieved the highest F1 score of 0.93, with a corresponding accuracy of 0.91, precision of 0.86, and recall of 1.00. Model B achieved the highest accuracy score of 0.82, with a corresponding F1 score of 0.87, precision of 0.78, and recall of 0.98. Notably, Model A and E scored highly on F1 score, precision, and recall, respectively, while Model C performed worse overall. This table shows the importance of evaluating models based on multiple metrics to obtain a comprehensive understanding of their performance."
1994,"caption: Table 4: Performance Results of Different Models on Binary Classification Tasktable: Model,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.78,0.75,0.74,0.76, Decision Tree,0.85,0.83,0.84,0.82, Random Forest,0.91,0.90,0.91,0.90, K-Nearest Neighbors,0.77,0.73,0.72,0.75, Support Vector Machine,0.88,0.86,0.87,0.85","Table 4 presents the results of different models' performances on a binary classification task assessed using various evaluation metrics, such as accuracy, F1-score, precision, and recall. The table shows that the Random Forest model achieved the highest accuracy (0.91) and F1-score (0.90), indicating good overall performance. Moreover, the Support Vector Machine model has also performed well, with a high accuracy score of 0.88. On the other hand, K-Nearest Neighbors underperformed, indicating the lowest values across the four metrics. The table suggests that the Random Forest and Support Vector Machine models can be viable choices for this binary classification task, providing practitioners with valuable insights when selecting an appropriate model."
1995,"caption: Table 4: Model performance comparison based on Accuracy, F1-score, Precision, and Recall.table: Model Name,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.85,0.84,0.86,0.83, SVM,0.87,0.86,0.88,0.83, Decision Tree,0.81,0.77,0.81,0.74, Random Forest,0.89,0.88,0.91,0.85, XGBoost,0.91,0.90,0.92,0.89","Table 4 compares different models' performances based on different evaluation metrics such as Accuracy, F1-score, Precision, and Recall. The table includes the Logistic Regression, SVM, Decision Tree, Random Forest, and XGBoost models. Notably, the Random Forest model achieved the highest Accuracy (0.89), F1-score (0.88), Precision (0.91), and Recall (0.85). The XGBoost model also achieved very high performance results as it achieved the highest Accuracy of 0.91 and F1-score of 0.90 among all models. The Logistic Regression and SVM models achieved good performance results with an accuracy of 0.85 and 0.87, respectively. However, the Decision Tree model was the worst performer in terms of all evaluation metrics, achieving an accuracy of 0.81 and an F1-score of only 0.77."
1996,"caption: Comparison of Different Models Based on Multiple Evaluation Metricstable: Model,Accuracy,F1-score,AUC, LR,0.89,0.89,0.93, RF,0.92,0.91,0.95, SVM,0.90,0.90,0.93, NB,0.85,0.86,0.89, KNN,0.84,0.84,0.83","Table 4 presents a comparison of the accuracy, F1-score, and AUC of different models. The table includes LR, RF, SVM, NB, and KNN models. All models were evaluated using the same dataset. We can observe that the RF model performs the best among all the models based on all three metrics, with the highest accuracy of 0.92, F1-score of 0.91, and AUC of 0.95. Conversely, the NB model has the worst performance with an accuracy of 0.85, F1-score of 0.86, and AUC of 0.89. In general, the RF model performs the best overall, outperforming all other models, while the NB model has the poorest performance."
1997,"caption: Table 4: Performance comparison of different models on the sample dataset using Accuracy, F1 Score, and Kappa metrics.table: Model,Accuracy,F1 Score,Kappa, SVM,0.845,0.828,0.689, Naive Bayes,0.776,0.741,0.551, Random Forest,0.894,0.890,0.781, XGBoost,0.921,0.915,0.844, Multi-layer Perceptron,0.913,0.908,0.831","Table 4 presents a comparison of multiple machine learning models' performances on a sample dataset using three evaluation metrics: Accuracy, F1 Score, and Kappa. The models used in the comparison are SVM, Naive Bayes, Random Forest, XGBoost, and Multi-layer Perceptron. The best performing model in terms of Accuracy, F1 Score, and Kappa is XGBoost with a score of 0.921, 0.915, and 0.844, respectively. Random Forest also performed well with an Accuracy of 0.894, F1 Score of 0.890, and Kappa of 0.781. SVM, Naive Bayes and Multi-layer Perceptron models showed performance scores in between XGBoost and Random Forest."
1998,"caption: Comparison of different machine learning models based on various evaluation metrics.table: Model,Precision,Recall,F1-Score,Accuracy, SVM,0.90,0.92,0.86,0.89, Logistic Regression,0.87,0.89,0.84,0.87, Random Forest,0.92,0.91,0.89,0.90, XGBoost,0.91,0.93,0.88,0.89","The table compares the performance of four machine learning models on the classification task using four evaluation metrics, namely precision, recall, F1-score, and accuracy. The SVM model achieved the highest precision with a score of 0.90 and the highest recall with the score of 0.92. On the other hand, random forest model achieved the highest F1-score with a score of 0.89 and accuracy score of 0.90. Notably, XGBoost model has shown promising results with high precision, recall, F1-score and accuracy, making it a competitive machine learning algorithm for this specific task."
1999,"caption: Table 4: Comparison of model performances based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1, SVM,0.85,0.8,0.9,0.827, Logistic Reg,0.83,0.82,0.77,0.787, Decision Tree,0.79,0.775,0.82,0.797","Table 4 presents a comparison of three different models using multiple evaluation metrics. The models' performance was measured by accuracy, precision, recall, and F1 score. SVM had the highest accuracy of 0.85, while Decision Tree had the lowest accuracy of 0.79. Logistic Regression had the highest precision of 0.82, while SVM had the highest recall of 0.9. Notably, SVM and Logistic Regression had similar values to recall and precision, respectively. The F1 score, which is a measure of model accuracy, was highest for SVM with 0.827 and lowest for Logistic Regression with 0.787. Overall, SVM had the best performance, followed by Logistic Regression and Decision Tree."
2000,"caption: Table 4: Model metrics performances using different evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.89,0.90,0.87,0.88, Decision Tree,0.85,0.84,0.86,0.85, Random Forest,0.93,0.95,0.90,0.92, Gradient Boosting,0.91,0.93,0.88,0.90, Naive Bayes,0.82,0.89,0.73,0.80","Table 4 presents the performance of five models based on four evaluation metrics--Accuracy, Precision, Recall, and F1-Score. The models considered for this study are Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Naive Bayes. Each model was trained and tested on the same dataset. Notably, the Random Forest model had the highest accuracy score of 0.93, while Logistic Regression had the highest precision and recall scores of 0.90 and 0.87, respectively. The Gradient Boosting model had the highest F1-Score score of 0.90, while the Naive Bayes model had the lowest performance metrics compared to the other models for all the evaluation metrics."
2001,"caption: Model performance metrics of various modelstable: Model,Accuracy,F1 Score,Recall,Precision, Logistic Regression,0.85,0.83,0.88,0.79, Decision Tree,0.81,0.76,0.83,0.70, Random Forest,0.87,0.85,0.88,0.82, XGBoost,0.88,0.86,0.90,0.81","The table above displays multiple models' performance results. The models included in the table are Logistic Regression, Decision Tree, Random Forest, and XGBoost. Evaluation metrics include Accuracy, F1 Score, Recall, and Precision. The Random Forest model achieved the highest accuracy of 0.87. The XGBoost model performed the best in F1 Score, with a score of 0.86. The highest recall was achieved by the Logistic Regression model, with a score of 0.88, while its precision score was the lowest among all models. The Decision Tree model had the lowest overall performance among the models, with an accuracy of 0.81, F1 Score of 0.76, Recall of 0.83, and Precision of 0.70."
2002,"caption: Model performance based on multiple evaluation metrics.table: Models,F1 Score,Precision,Recall,Accuracy, Model A,0.8,0.7,0.9,0.85, Model B,0.6,0.8,0.5,0.75, Model C,0.7,0.6,0.9,0.80, Model D,0.9,0.9,0.9,0.95, Model E,0.5,0.4,0.7,0.65","The table presents model performance based on multiple evaluation metrics that includes F1-Score, Precision, Recall, and Accuracy. Model A demonstrates the best F1-Score and Recall at 0.8 and 0.9, respectively, followed by Model D exhibiting the best Precision and Accuracy at 0.9 and 0.95, respectively. Model B has the lowest F1-Score and Recall of 0.6 and 0.5, respectively, while Model E has the lowest Precision and Accuracy of 0.4 and 0.65, respectively. The table shows different levels of model performance that can assist in choosing the appropriate model for specific tasks."
2003,"caption: Performance metrics of different machine learning models for classification task.table: Model Name,F1-Score,Accuracy,AUC (Area Under Curve),Precision,Recall,MCC (Matthews Correlation Coefficient), Logistic Regression,0.85,0.75,0.74,0.82,0.88,0.52, Random Forest,0.88,0.78,0.76,0.85,0.91,0.57, SVM,0.82,0.71,0.71,0.78,0.89,0.48, KNN,0.75,0.65,0.59,0.79,0.62,0.38","The table compares the performances of four different machine learning models on a classification task. The models are Logistic Regression, Random Forest, SVM, and KNN. The evaluation metrics used are F1-Score, Accuracy, AUC, Precision, Recall, and MCC. Interestingly, the Random Forest model performed with the highest scores among all models for all metrics except F1-Score, where the best performer was the Logistic Regression model. The SVM model's performance was relatively consistent regarding the chosen metrics, while the KNN model's performance was the weakest in comparison to all others."
2004,"caption: Table 4: Model Performance on Different Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.85 +/- 0.02,0.84,0.86,0.85, LR,0.75 +/- 0.03,0.73,0.76,0.75, KNN,0.80 +/- 0.01,0.81,0.79,0.79, RF,0.88 +/- 0.02,0.87,0.90,0.88, XGB,0.90 +/- 0.01,0.91,0.89,0.90","Table 4 illustrates a model comparison in terms of accuracy, precision, recall, and F1-score. SVM outperformed other models in terms of accuracy, with a score of 0.85+/-0.02. The RF and XGB models had the highest precision, both scoring 0.87 and 0.91, respectively, whereas LR had the lowest precision of 0.73. On the other hand, recall scores ranged from 0.76-0.90. The highest recall score was obtained by the RF model, with a score of 0.90, followed by XGB with a score of 0.89. Finally, the F1-scores showed that XGB outperformed other methods with a score of 0.90, while LR had the lowest score of 0.75. The table results show that the XGB model had the highest performance compared to the other models, while LR showed the weakest performance."
2005,"caption: Model performance measures for five different modelstable: Model Name,F1-Score (Class 0),F1-Score (Class 1),Precision,Recall,AUC-ROC,PR-AUC, Model A,0.84,0.67,0.91,0.54,0.89,0.66, Model B,0.91,0.55,0.77,0.87,0.76,0.53, Model C,0.87,0.81,0.74,0.94,0.89,0.65, Model D,0.92,0.66,0.89,0.50,0.91,0.76, Model E,0.85,0.70,0.93,0.50,0.84,0.61","The table above presents the results of the evaluation metrics of five different models' performance. These metrics include F1-score for class 0 and class 1, precision, recall, AUC-ROC, and PR-AUC. Among all the models, Model D achieved the highest F1-score for class 1 with a value of 0.66. Furthermore, Model B's AUC-ROC value was 0.76, which was the lowest among all the models. In comparison, Model A had the highest AUC-ROC value with a score of 0.89. Interestingly, Model C showed a balanced performance across all six metrics. Overall, Model D performed the best compared to other models, reflecting the importance of both precision and recall values in this classification problem."
2006,"caption: Model performances on different evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Model A,0.89,0.85,0.87,0.83, Model B,0.91,0.88,0.89,0.88, Model C,0.86,0.80,0.84,0.77, Model D,0.92,0.89,0.91,0.87, Model E,0.83,0.76,0.78,0.75",
2007,"caption: Table 4: Model Performances of Different Algorithmstable: Model,Accuracy,F1 score,Recall,Precision, Logistic Regression,0.75,0.74,0.70,0.79, Random Forest,0.85,0.84,0.86,0.83, Support Vector Machine,0.79,0.78,0.81,0.76, Decision Tree,0.81,0.79,0.82,0.77, AdaBoost,0.87,0.86,0.86,0.88","Table 4 shows the performances of different algorithms- Logistic Regression, Random Forest, Support Vector Machine (SVM), Decision Tree, and AdaBoost- through different evaluation metrics such as accuracy, F1 score, recall, and precision. It is notable that AdaBoost shows the best accuracy, F1 score, and precision. Random Forest performs well in accuracy, but SVM has the highest recall score. Overall, AdaBoost seems to be the best algorithm for the dataset, with an accuracy score of 87%."
2008,"caption: Table 4. Model performance from different algorithms based on multiple evaluation metrics.table: Model,Precision,Recall,F1-score,Accuracy, Decision Tree,0.65,0.70,0.67,0.72, Random Forest,0.78,0.82,0.80,0.83, Support Vector Machine,0.70,0.69,0.69,0.71, Logistic Regression,0.74,0.76,0.74,0.78, Multi-Layer Perceptron,0.73,0.77,0.74,0.77, Naive Bayes,0.59,0.55,0.53,0.57","In Table 4, we present the results of various machine learning algorithms applied to a dataset. The models' performance is evaluated based on multiple evaluation metrics, which include precision, recall, F1-score, and accuracy. The table shows the precision, recall, F1-score, and accuracy scores for each algorithm. Notably, the Random Forest algorithm performed the best in all four evaluation metrics, with precision of 0.78, recall of 0.82, F1-score of 0.80, and accuracy of 0.83. This suggests that Random Forest algorithm is a suitable model to predict the outcome of the dataset. However, all the models have significant score differences across the evaluation metrics, which indicates the need to select an appropriate algorithm based on the task at hand."
2009,"caption: Table 4: The performance results of different machine learning algorithms using multiple evaluation metrics.table: Model,Precision,Recall,F1-score,Accuracy, Logistic Regression,0.92,0.85,0.88,0.91, Decision Tree,0.81,0.76,0.78,0.80, K-Nearest Neighbors,0.87,0.84,0.85,0.88, Support Vector Machines,0.93,0.92,0.92,0.93, Random Forest,0.96,0.93,0.94,0.95, Gradient Boosting,0.94,0.91,0.92,0.93, Neural Network,0.90,0.87,0.88,0.89","The aim of Table 4 is to compare several machine learning algorithms' performance in terms of Precision, Recall, F1-score, and Accuracy evaluations. The models include Logistic Regression, Decision Tree, K-Nearest Neighbors, Support Vector Machines, Random Forest, Gradient Boosting, and Neural Network. The results indicate that the Random Forest model achieved the highest Precision and F1-score of 0.96 and 0.94, respectively. Additionally, the Support Vector Machines model produced the highest Recall and Accuracy scores of 0.92 and 0.93, respectively. Interestingly, Decision Tree performed the worst in all evaluation metrics, scoring below all other models."
2010,"caption: Comparing model performance based on different evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score,AUC, Model 1,0.82,0.78,0.88,0.82,0.908, Model 2,0.94,0.92,0.96,0.94,0.987, Model 3,0.76,0.81,0.68,0.74,0.827, Model 4,0.91,0.89,0.94,0.91,0.954, Model 5,0.88,0.85,0.90,0.87,0.912","Table presents a comparison of different models' performances based on various evaluation metrics, namely accuracy, precision, recall, F1-score, and AUC. Accuracy measures the proportion of correct predictions to total predictions made. Model 2 has the highest accuracy score of 0.94, while Model 3 has the lowest accuracy score of 0.76. Precision measures true positive predictions to all positively predicted samples. Model 4 has the highest precision score of 0.89, while Model 5 has the lowest precision score of 0.85. Recall measures true positive predictions to actual positive samples. Model 2 has the highest recall score of 0.96, while Model 3 has the lowest recall score of 0.68. F1-score is the harmonic mean of precision and recall measures. Model 2 has recorded the highest F1-score of 0.94, while Model 3 has the lowest F1-score of 0.74. AUC measures the area under the Receiver Operating Characteristic curve (ROC-AUC) that evaluates model performance at varying threshold values. Model 2 has the highest AUC score of 0.987, while Model 3 has the lowest AUC score of 0.827."
2011,"caption: Table 4: Model evaluation metricstable: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.78,0.79,0.72,0.76, Decision Tree,0.72,0.67,0.63,0.65, Random Forest,0.83,0.86,0.78,0.82, XGBoost,0.87,0.88,0.85,0.87, Support Vector,0.76,0.80,0.68,0.73","Table 4 compares five different models based on their evaluation metrics. The models include Logistic Regression, Decision Tree, Random Forest, XGBoost, and Support Vector. The table shows Accuracy, Precision, Recall, and F1 Score for each model. The best performing model is XGBoost, with the highest Accuracy of 0.87, Precision of 0.88, Recall of 0.85, and F1 Score of 0.87. Random Forest also exhibits an impressive performance with an Accuracy of 0.83 and the second-best Precision and F1 Score. Decision Tree shows the lowest performance with the lowest Accuracy, Precision, Recall, and F1 Score. Overall, the table provides a comprehensive comparison of model performance based on evaluation metrics."
2012,"caption: Comparison of model performance based on different evaluation metricstable: Model Name,Precision,Recall,F1-Score,AUC-ROC,AUC-PR, Logistic Regression,0.89,0.75,0.81,0.87,0.74, Support Vector Machine,0.91,0.76,0.83,0.89,0.75, Decision Tree Classifier,0.82,0.82,0.82,0.84,0.7, Random Forest Classifier,0.92,0.85,0.88,0.92,0.82, Gradient Boosting Classifier,0.93,0.86,0.89,0.93,0.84",
2013,"caption: Model performances of different machine learning algorithms.table: Model,Accuracy,F1-score,Recall,Precision, Random Forest,0.85,0.84,0.83,0.85, Logistic Regression,0.80,0.77,0.74,0.80, Gradient Boosting,0.87,0.87,0.86,0.87, Naive Bayes,0.77,0.76,0.80,0.73, Support Vector Machine,0.84,0.85,0.83,0.86","The table above presents the accuracy, F1-score, Recall, and Precision performances of five different machine learning algorithms: Random Forest, Logistic Regression, Gradient Boosting, Naive Bayes, and Support Vector Machine. The Random Forest and Gradient Boosting classifiers show the highest accuracy with 0.85 and 0.87, respectively. The Logistic Regression model, on the other hand, has the lowest accuracy of 0.80 and precision of 0.73. Notably, the Naive Bayes classifier exhibits the highest recall of 0.80. Thus, the Gradient Boosting model demonstrates the best overall performance with the highest accuracy of 0.87 and F1-score of 0.87."
2014,"caption: Comparison of different models' performances using various evaluation metrics.table: Model,Macro F1,Micro F1,Accuracy,AUC-ROC, Random Forest,0.859±0.011,0.908±0.007,0.910±0.007,0.956, Support Vector Machines,0.871±0.015,0.906±0.009,0.906±0.009,0.942, Multilayer Perceptron,0.847±0.019,0.896±0.010,0.897±0.010,0.932","Table presenting the performance of different classification models based on four evaluation metrics: Macro F1, Micro F1, Accuracy, and AUC-ROC. The table includes results from Random Forest, Support Vector Machines, and Multilayer Perceptron models. The Random Forest model had the highest AUC-ROC score of 0.956, while the Multilayer Perceptron achieved the lowest AUC-ROC score of 0.932. On the other hand, the Support Vector Machines surpassed the other models in terms of Macro F1 and Accuracy. It achieved 0.871+-0.015 and 0.906+-0.009, respectively."
2015,"caption: Comparison of different models based on evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Model 1,0.86,0.87,0.84,0.85, Model 2,0.90,0.92,0.88,0.90, Model 3,0.88,0.82,0.91,0.86, Model 4,0.85,0.89,0.81,0.85, Model 5,0.92,0.94,0.91,0.92","The table presents a comparison of five models based on multiple evaluation metrics, including accuracy, precision, recall, and F1-score. Model 5 shows the highest overall performance with the best accuracy of 0.92 and other notable scores such as precision of 0.94, recall of 0.91 and F1-Score of 0.92. Model 2 also performs well with an accuracy of 0.90 and high precision of 0.92. Interestingly, Model 3 has high recall of 0.91 but lower precision of 0.82, resulting in an overall F1-score of 0.86. Lastly, Model 4 had the lowest accuracy of 0.85 and F1-score of 0.85, but it performed relatively well in terms of precision with a score of 0.89."
2016,"caption: Model performance based on multiple evaluation metrics.table: Model,Precision,Recall,F1-Score,Accuracy, SVM,0.87,0.88,0.87,0.88, Random Forest,0.85,0.87,0.85,0.87, Gradient Boosting,0.88,0.89,0.87,0.89, Logistic Regression,0.84,0.86,0.84,0.86, Decision Tree,0.83,0.83,0.83,0.83, Neural Network,0.89,0.90,0.89,0.90","The table presents various models' performance based on multiple evaluation metrics, including Precision, Recall, F1-Score, and Accuracy. SVM shows the highest precision score of 0.87, while Neural Network achieved the highest precision score of 0.90. Similarly, Neural Network shows the highest recall score of 0.90, and Gradient Boosting shows the second-highest recall score of 0.89. As for F1-Score, Neural Network is the clear winner with a score of 0.89, while all other models' F1-Score ranges between 0.83 and 0.87. Finally, regarding accuracy, Neural Network achieves the highest accuracy score of 0.90, while Gradient Boosting, SVM, and Logistic Regression also show high accuracy with scores ranging from 0.88 to 0.89."
2017,"caption: Comparison of model performances based on different evaluation metrics.table: Model,Accuracy,F1 score,Precision score,Recall score, SVM,0.72,0.63,0.68,0.61, KNN,0.65,0.60,0.62,0.58, Random Forest,0.80,0.72,0.76,0.68, XGBoost,0.83,0.77,0.81,0.74, Logistic Regression,0.76,0.68,0.72,0.64","Table presents a comparison of accuracies, F1 scores, precision scores, and recall scores of different models - SVM, KNN, Random Forest, XGBoost, and Logistic Regression. The highest accuracy is achieved by the XGBoost model with the value of 0.83. Similarly, the Random Forest and Logistic Regression models are giving better accuracy results compared to SVM and KNN models. For F1 score, XGBoost is showing the best score of 0.77. The Random Forest model has the highest precision score (0.76), and the SVM model has the highest recall score (0.61). Overall, XGBoost is showing the best performance across all evaluation metrics."
2018,"caption: Evaluation metrics for six different models on a classification task.table: Model,Accuracy,Precision,Recall,F1 Score,AUC, Logistic Regression,0.82,0.83,0.78,0.80,0.85, K-Nearest Neighbors,0.78,0.79,0.73,0.75,0.82, Decision Tree,0.71,0.72,0.69,0.68,0.73, Random Forest,0.87,0.89,0.85,0.86,0.92, Gradient Boost,0.81,0.80,0.73,0.75,0.87, SVM,0.75,0.70,0.69,0.67,0.81","The table displays the classification performance of six distinct models, including Logistic Regression, K-Nearest Neighbors, Decision Tree, Random Forest, Gradient Boost, and SVM, evaluated based on five different metrics: Accuracy, Precision, Recall, F1 Score, and AUC. The table highlights that all models achieve a relatively high accuracy level, ranging from 0.71 to 0.87. Random Forest demonstrates superior results across all metrics, garnering the highest level of AUC with 0.92 and the highest F1 Score of 0.86. It is interesting to note that both Precision and Recall's results vary depending on the model used, indicating that the most suitable model will ultimately depend on the specific task requirements."
2019,"caption: Performance comparison of different Machine Learning modelstable: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.85,0.80,0.82,0.78, MLP,0.84,0.78,0.80,0.76, KNN,0.80,0.70,0.72,0.68, RF,0.88,0.82,0.84,0.80, NB,0.78,0.70,0.68,0.72","The table presents the accuracy, F1-score, precision, and recall performances of different Machine Learning models, including SVM, MLP, KNN, RF, and NB. It is evident that the Random Forest (RF) model yields the highest accuracy (0.88) and F1-score (0.82). Additionally, the RF model and SVM model perform the best in terms of precision and recall, respectively. Interestingly, the Naive Bayes (NB) model does not perform as well compared to other models, with the lowest accuracy, F1-score, and precision. Overall, the results indicate that the RF and SVM models could be considered suitable for classification tasks in similar datasets."
2020,"caption: Model performance comparison using various metrics.table: Model,F1-score,Precision,Recall,Accuracy,ROC-AUC, Logistic Reg.,58.4,61.3,56.0,66.7,0.719, Decision Tree,54.6,54.6,54.6,56.8,0.546, Random Forest,65.6,66.2,65.1,70.4,0.801, XGBoost,67.8,68.2,67.4,72.0,0.815, Bi-LSTM,68.9,67.6,70.4,72.6,0.822",
2021,"caption: Table 4: Model performance analysis based on multiple evaluation metricstable: Model,MAE,MSE,R2 Score, Linear Regression,4.92,38.24,0.58, Random Forest,3.70,24.36,0.76, Neural Network,7.35,76.44,-0.20, K-Nearest Neighbors,6.11,54.31,0.33",
2022,"caption: Table 4: Model Evaluation Metricstable: Model,Accuracy,F1 score,Precision,Recall, Model 1,0.82,0.74,0.69,0.81, Model 2,0.76,0.69,0.61,0.79, Model 3,0.81,0.73,0.67,0.80, Model 4,0.85,0.77,0.73,0.82, Model 5,0.89,0.80,0.76,0.85","Table 4 presents the evaluation metrics of multiple models. The table includes Accuracy, F1 score, Precision, and Recall. The models are numbered 1 through 5. Interestingly, model 5 had the highest score across all the evaluation metrics, achieving an Accuracy of 0.89, F1 score of 0.80, Precision of 0.76, and Recall of 0.85, indicating that it performs the best among the models. Conversely, Model 2 had the lowest scores for Accuracy, F1 score, and Precision, but still had a relatively high Recall score. Overall, this table provides a clear comparison of different models' evaluation metrics, enabling the reader to make an informed decision about which model best suits their specific needs."
2023,"caption: Model performance evaluation using different classifiers.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.85,0.88,0.83,0.85, RF,0.87,0.89,0.86,0.87, LR,0.84,0.87,0.84,0.84, MLP,0.88,0.90,0.87,0.88, K-NN,0.78,0.80,0.77,0.77","Table presents a comparison of the accuracy, precision, recall, and F1-score achieved by five different classification algorithms. The models included are Support Vector Machine (SVM), Random Forest (RF), Logistic Regression (LR), Multilayer Perceptron (MLP), and K-Nearest Neighbors (K-NN). The table shows that MLP has the highest accuracy with 0.88 and RF has the highest precision and recall scores of 0.89 and 0.86, respectively. Notably, the K-NN model has the lowest performance with scores of 0.78, 0.80, 0.77, and 0.77 for accuracy, precision, recall, and F1-score, respectively. Interestingly, the SVM model has the second-highest scores for all performance metrics."
2024,"caption: Comparison of classification model performance on a dataset of spam emails.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.84,0.77,0.87,0.71, KNN,0.79,0.69,0.77,0.63, Naive Bayes,0.72,0.62,0.79,0.52, Decision Trees,0.83,0.78,0.81,0.75, Random Forest,0.88,0.83,0.86,0.81","The table above demonstrates a comparison of classification models' performance on a dataset of spam emails using various evaluation metrics such as accuracy, F1 Score, precision, and recall. The models presented in the table are SVM, K-Nearest Neighbors (KNN), Naive Bayes, Decision Trees, and Random Forest. The Random Forest model demonstrated the best overall performance, achieving the highest accuracy score of 0.88 and F1 Score of 0.83, as well as a high precision score of 0.86 and recall score of 0.81. SVM also performed well, with an accuracy score of 0.84 and F1 Score of 0.77, while Naive Bayes had the lowest overall performance scores."
2025,"caption: Performance metrics of different Classification Modelstable: Model,Accuracy,F1-score,Precision,Recall, SVM,0.75,0.78,0.7,0.87, KNN,0.72,0.70,0.68,0.72, Random Forest,0.80,0.79,0.77,0.81, Decision Tree,0.74,0.71,0.69,0.75","The table compares the classification performance of different models based on various metrics. The models evaluated include SVM, KNN, Random Forest, and Decision Tree. The metrics used for evaluation are accuracy, F1-score, precision, and recall. The Random Forest model shows the best accuracy of 0.80 as well as the highest F1-score, precision, and recall. While SVM has the highest recall of 0.87, it had the lowest precision of 0.7 among other models. It is interesting to note that although KNN has the lowest accuracy score, it has a balanced F1-score, precision, and recall of 0.70, 0.68, and 0.72, respectively. Overall, the table provides insight into models' strengths and the trade-off between different performance metrics when evaluating classification models."
2026,"caption: Comparison of model performances using multiple metrics.table: Model,F1-Score,Precision,Recall,ROC-AUC, Logistic Regression,0.74,0.68,0.82,0.88, Random Forest,0.78,0.73,0.84,0.90, K-Nearest Neighbors,0.70,0.67,0.73,0.80, Support Vector Machines,0.77,0.72,0.84,0.89","Table presents a comparison of multiple models' performance scores using different metrics. The evaluation metrics compared are F1-Score, Precision, Recall, and ROC-AUC. Logistic Regression, Random Forest, K-Nearest Neighbors, and Support Vector Machines are the models considered in the table. The Random Forest model performed the best in F1-Score with a score of 0.78, while Support Vector Machines had the best Precision score of 0.72. Interestingly, Logistic Regression achieved the highest recall score at 0.82, displaying excellent grounding in a character classification task. The Random Forest model outperformed other models in the ROC-AUC with a score of 0.90. Thus, Random Forests can be considered the most suitable model for this task."
2027,"caption: Model performance based on classification metrics.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.89,0.88,0.92,0.84, Random Forest,0.86,0.85,0.88,0.83, Naive Bayes,0.73,0.69,0.78,0.62, Logistic Regression,0.91,0.90,0.93,0.87, Neural Network,0.87,0.86,0.87,0.85","Table above shows the comparison of five different models in terms of their classification metrics accuracy, F1-Score, precision, and recall. SVM, Random Forest, Naive Bayes, Logistic Regression, and Neural Network models were evaluated, and all were trained and tested on the same dataset. The Logistic Regression model exhibits the best accuracy score of 0.91, followed by the SVM model at 0.89. On the other hand, the Naive Bayes model demonstrated the lowest performance results compared to the other models with the lowest accuracy, F1-Score, precision, and recall scores of 0.73, 0.69, 0.78, and 0.62, respectively.  Notably, while all models show relatively close metric scores, the Logistic Regression model appears to be the best performing model in this comparison."
2028,"caption: Table 4: Model performances from different approaches based on different evaluation metrics.table: Model,Metric,Result, Random Forest,F1-Score,0.90, Random Forest,Precision,0.85, Random Forest,Recall,0.96, SVM,F1-Score,0.85, SVM,Precision,0.86, SVM,Recall,0.84, Naive Bayes,F1-Score,0.80, Naive Bayes,Precision,0.78, Naive Bayes,Recall,0.82, KNN,F1-Score,0.89, KNN,Precision,0.92, KNN,Recall,0.86","Table 4 shows the comparison of different models' performances based on different evaluation metrics. The table includes Random Forest, SVM, Naive Bayes, and KNN models, with their corresponding F1-Score, Precision, and Recall metrics. Notably, the Random Forest model obtained the highest F1-Score of 0.90, while the SVM model ranked second with an F1-Score of 0.85. In terms of Precision, the KNN model achieved the highest result of 0.92, while the Random Forest model ranked second with a Precision value of 0.85. Moreover, the Random Forest model obtained the highest Recall score of 0.96, while the Naive Bayes model obtained the lowest Recall score of 0.82."
2029,"caption: This table shows different model performances regarding accuracy, precision, recall, and F1-score. Each model's accuracy, precision, recall, and F1-score are reported, with logistic regression and random forest achieving the highest accuracy of 0.92 and 0.93, respectively.table: Model,Accuracy,Precision,Recall,F1, Logistic Reg,0.92,0.89,0.85,0.87, SVM,0.91,0.88,0.83,0.85, DecisionTree,0.80,0.72,0.68,0.67, Random Forest,0.93,0.91,0.89,0.90","The table highlights the classification models' performance based on the accuracy, precision, recall, and F1-score metrics. The logistic regression and random forest models are the best performing models with an accuracy of 0.92 and 0.93, respectively. The precision's scores are consistent across the models, with the highest precision score of 0.91 obtained by the random forest model. Notably, the decision tree model recorded the lowest accuracy, precision, recall, and F1-score. The table's data reveals that logistic regression and random forest models are the best options for high accuracy classification."
2030,"caption: Performance comparison of different models using different evaluation metrics.table: Model Name,Accuracy Score,F1 Score,Precision,Recall, Model A,0.85,0.81,0.89,0.75, Model B,0.90,0.86,0.92,0.81, Model C,0.87,0.83,0.91,0.76, Model D,0.91,0.88,0.94,0.82, Model E,0.89,0.84,0.91,0.78","Table 4 presents a comparison of various models' performances using different evaluation metrics. Specifically, the table exhibits the accuracy score, F1 score, precision, and recall for five models named Model A through Model E. Model D has the highest accuracy score of 0.91, F1 score of 0.88, precision of 0.94, and recall score of 0.82, highlighting the best overall performance. Meanwhile, Model B holds the second-highest performance for all metrics except recall score with top scores of 0.90 for accuracy, 0.86 for F1 score, and 0.92 for precision. Therefore, Model D would be the preferred choice based on the analysis, although Model B is also a potential contender."
2031,"caption: Table 4: Model evaluation with accuracy, F1 score, and AUC metrics.table: Model,Accuracy,F1 Score,AUC, Model A,0.85,0.87,0.92, Model B,0.82,0.85,0.90, Model C,0.87,0.87,0.92, Model D,0.79,0.80,0.85, Model E,0.77,0.81,0.82","Table 4 presents the evaluation results of five different models in terms of accuracy, F1 score, and AUC metrics. Model A shows the highest accuracy of 0.85, whereas Model C and Model B exhibit the highest AUC scores of 0.92 and 0.90, respectively. Interestingly, Model E has a high F1 score of 0.81 with a low accuracy of 0.77 and an AUC of 0.82. On the other hand, Model D outperforms Model E on accuracy and AUC metrics but has lower F1 score. Overall, the table shows varying model performances across different evaluation metrics, implying that no single model dominates across metrics."
2032,"caption: Table 4: Model performance based on various evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.89,0.87,0.92,0.84, Decision Tree,0.81,0.79,0.78,0.81, Random Forest,0.93,0.92,0.96,0.89, Support Vector Machine,0.88,0.87,0.90,0.84, Gradient Boosting,0.92,0.91,0.94,0.88","Table 4 displays the performance comparison of five different machine learning models based on various evaluation metrics such as accuracy, f1 score, precision, and recall. The models include Logistic Regression, Decision Tree, Random Forest, Support Vector Machine, and Gradient Boosting. The results illustrate that the Random Forest model achieved the highest accuracy of 0.93 and F1 score of 0.92. However, the best precision of 0.96 was obtained by the Random Forest model, while the best recall of 0.84 was attained by both Logistic Regression and Support Vector Machine models. The Gradient Boosting model produced the second-best result across all the metrics, except for precision, where it was outperformed by Logistic Regression model."
2033,"caption: Performance comparison of five different models evaluated by accuracy, F1-score, precision, and recall.table: Model,Accuracy,F1-Score,Precision,Recall, Model A,0.82,0.84,0.80,**0.90**, Model B,0.86,**0.89**,0.85,0.87, Model C,**0.88**,0.88,**0.87**,0.85, Model D,0.75,0.76,0.79,0.72, Model E,0.83,0.85,0.81,0.87","The table presents a performance comparison of five different models evaluated by accuracy, F1-score, precision, and recall. Model C achieved the highest accuracy with a score of **0.88**, while Model B had the highest F1-score of **0.89**. Interestingly, Model C also had the highest precision at **0.87**. On the other hand, Model A had the highest recall at **0.90**. It is also observed that Model D had the lowest accuracy, F1-score, and recall. Comparatively, Model E performed better than Model A in terms of accuracy, F1-score, and precision, but performed lower in recall. Overall, the results suggest that Model B and Model C were the best-performing models in terms of F1-score and accuracy respectively."
2034,"caption: Table 4: Evaluation metrics of different models using a binary classification task.table: Model,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.86,0.83,0.80,0.86, Decision Tree,0.81,0.79,0.75,0.83, Naive Bayes,0.92,0.90,0.88,0.92, Random Forest,0.94,0.93,0.92,0.94, XGBoost,0.95,0.94,0.93,0.95","Table 4 shows the evaluation metrics, including accuracy, F1-score, precision, and recall, of different models trained and tested on a binary classification task. The table presents the performance results of Logistic Regression, Decision Tree, Naive Bayes, Random Forest, and XGBoost models. Notably, the Random Forest and XGBoost models achieved the highest accuracy of 0.94 and 0.95, respectively, while the Logistic Regression model had the lowest accuracy of 0.86. Interestingly, the XGBoost model outperformed other models, achieving the best results in all evaluation metrics. On the other hand, the Decision Tree model had the lowest F1-score and precision. Overall, the table shows different models' variations in performance results when evaluated using various metrics in a binary classification task."
2035,"caption: Comparison of different classification models performancetable: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.80,0.77,0.74,0.80, Logistic Regression,0.84,0.81,0.85,0.79, Random Forest,0.86,0.82,0.87,0.78, KNN,0.77,0.70,0.75,0.66, Decision Tree,0.73,0.68,0.70,0.67","The table above presents a comparison of five different classification models' performances in terms of accuracy, F1 score, precision, and recall metrics. The models, SVM, Logistic Regression, Random Forest, KNN, and Decision Tree, were evaluated based on the same dataset. Interestingly, the Random Forest model achieved the best results for all metrics, with an accuracy score of 0.86, the highest F1 score of 0.82 and the highest precision score of 0.87. In contrast, the Decision Tree model had the lowest accuracy score of 0.73, while the SVM model achieved the highest recall score of 0.80. Overall, the Random Forest model is the most optimal model for the dataset as it has the best performance across all metrics."
2036,"caption: Performance Metrics of Different Modelstable: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.89,0.90,0.86,0.88, Naive Bayes,0.76,0.92,0.60,0.72, Decision Tree,0.81,0.72,0.81,0.76, Random Forest,0.89,0.85,0.92,0.88, Gradient Boost,0.91,0.92,0.86,0.89","The table above represents the performance metrics of different models used in a classification task. The evaluation metrics include Accuracy, Precision, Recall, and F1-Score. The models SVM, Random Forest, and Gradient Boost performed well resulting in accuracy scores greater than 0.89. The best performing model overall was the Gradient Boost model, producing the highest accuracy score of 0.91. Moreover, the Gradient Boost model performed the best in terms of Precision (0.92) and F1-Score (0.89), while the Naive Bayes model had the lowest Precision (0.92) and Recall (0.60) scores, indicating poor performance of the model."
2037,"caption: Table 4: Model evaluation metrics for different classifiers on the test dataset.table: Models,Accuracy (±std),Precision (±std),Recall (±std),F1-score (±std), Logistic Regression,0.89±0.02,0.85±0.02,0.92±0.01,0.88±0.02, Random Forest,0.92±0.01,0.88±0.01,0.94±0.01,0.91±0.01, KNN,0.83±0.03,0.75±0.04,0.89±0.03,0.81±0.04, SVM,0.88±0.02,0.84±0.03,0.91±0.01,0.87±0.02, Neural network,0.91±0.01,0.87±0.01,0.94±0.01,0.91±0.01","Table 4 illustrates the performance of various classifiers based on multiple evaluation metrics - Accuracy, Precision, Recall, and F1-score. The table displays the average and standard deviation values for all the metrics for each model. The Random Forest classifier performed the best among all the models, achieving high scores for Accuracy (0.92±0.01), Precision (0.88±0.01), Recall (0.94±0.01), and F1-score (0.91±0.01). Neural network is the second-best performer with an Accuracy of 0.91±0.01. KNN is the weakest performer with an Accuracy score of only 0.83±0.03. Additionally, all models performed better in Recall than Precision except for KNN, which had a higher Precision than Recall."
2038,"caption: Model performance on evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.85,0.83,0.88,0.79, Logistic Regression,0.75,0.74,0.77,0.72, Random Forest,0.87,0.85,0.89,0.82, Gradient Boosting,0.89,0.87,0.91,0.84, Neural Network,0.91,0.88,0.91,0.85","The table presents the performance evaluation metrics, such as Accuracy, F1-Score, Precision, and Recall of five different models (SVM, Logistic Regression, Random Forest, Gradient Boosting, and Neural Network). The model performances were evaluated using the same dataset. Interestingly, the Neural Network model had the highest accuracy of 0.91, followed by Gradient Boosting and Random Forest with the accuracies of 0.89 and 0.87, respectively. Furthermore, the Random Forest model has the highest F1-score, Precision, and Recall of 0.85, 0.89, and 0.82, respectively. SVM has the highest precision value of 0.88, and Neural Network achieved the highest Recall value of 0.85. Overall, the Neural Network and Gradient Boosting models demonstrate better performance on evaluation metrics compared to the other models in the table."
2039,"caption: Table 4: Model Performance on Different Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.85,0.86,0.84,0.85, Decision Tree,0.82,0.80,0.79,0.79, Random Forest,0.89,0.91,0.88,0.88, Support Vector Machine,0.87,0.88,0.87,0.87, Naive Bayes,0.74,0.60,0.89,0.66","Table 4 presents the performance of different models on various evaluation metrics. The table includes Logistic Regression, Decision Tree, Random Forest, Support Vector Machines, and Naive Bayes models. The evaluation metrics used to measure the models' performances include Accuracy, Precision, Recall, and F1-Score. Notably, the Random Forest model attained the highest Accuracy and Precision scores of 0.89 and 0.91, respectively. However, the Naive Bayes model had the highest Recall score of 0.89. Meanwhile, Decision Tree had the lowest F1-Score of 0.79 compared to other models. Overall, the Random Forest model appears to have the best overall performance."
2040,"caption: Comparison of model performance using different evaluation metricstable: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.89,0.85,0.88,0.82, RF,0.91,0.87,0.89,0.86, KNN,0.83,0.79,0.80,0.79, NN,0.92,0.88,0.91,0.85, DT,0.86,0.81,0.82,0.81","Table presents the comparison of five models based on evaluation metrics such as Accuracy, F1 score, Precision and Recall. The table displays the results of Support Vector Machine (SVM), Random Forest (RF), K-Nearest Neighbor (KNN), Neural Network (NN), and Decision Tree (DT) models. Notably, the model with the highest accuracy is NN with a score of 0.92 while the model with the lowest accuracy is KNN with a score of 0.83. Similarly, RF performed best on F1 score with a score of 0.87, and SVM performed best on precision with a score of 0.88 while DT performed best on recall with a score of 0.81. The table illustrates the need to consider different evaluation metrics while selecting a model."
2041,"caption: Performance of Different Modelstable: Model,F1-score,Accuracy,Precision,Recall,AUC-PR, Model 1,0.75,0.87,0.78,0.72,0.8, Model 2,0.77,0.84,0.8,0.75,0.79, Model 3,0.83,0.91,0.81,0.85,0.85, Model 4,0.81,0.88,0.79,0.83,0.84","The table above reports the performance evaluation of Model 1, Model 2, Model 3, and Model 4 in terms of F1-score, accuracy, precision, recall, and AUC-PR metrics. The F1-score of each model is one of the widely used metrics to evaluate the model on the balance of the precision and recall. It indicates the harmonic mean of both. The accuracy metric represents the number of records predicted correctly. Model 3 presents the best accuracy of 0.91. Precision indicates the percentage of values that are correctly predicted in the positive class, whereas recall is the percentage of actual positive cases predicted correctly. Model 3 also demonstrates the highest precision and recall values of 0.81 and 0.85, respectively. Finally, AUC-PR indicates the area under the precision-recall curve. Model 3 shows the highest AUC-PR score of 0.85."
2042,"caption: Evaluation results of four different modelstable: Model,Accuracy,Precision,Recall,F1-Score, Decision Tree,0.78,0.79,0.76,0.77, Logistic Regression,0.86,0.90,0.80,0.85, SVM,0.82,0.84,0.81,0.82, Random Forest,0.88,0.91,0.86,0.88","The table displays the evaluation results of four different models based on multiple metrics, including Accuracy, Precision, Recall, and F1-score. The models are Decision Tree, Logistic Regression, SVM, and Random Forest. As presented in the table, the Random Forest model showed the best overall performance, with an Accuracy score of 0.88, Precision score of 0.91, Recall score of 0.86, and F1-score of 0.88. The Logistic Regression model also performed well and had the highest Precision score of 0.90. Meanwhile, Decision Tree and SVM had lower scores in all evaluated metrics, with SVM showing the lowest Accuracy score of 0.82."
2043,"caption: Performance comparison of different models using precision, recall, and F1 Score.table: Model,Precision,Recall,F1 Score, SVM,0.75,0.74,0.73, KNN,0.68,0.67,0.68, Naive Bayes,0.69,0.71,0.69, Random Forest,0.84,0.82,0.82, XGBoost,0.82,0.81,0.81","Table above presents a comparison of precision, recall, and F1 Score for different models. SVM, KNN, Naive Bayes, Random Forest, and XGBoost models were evaluated using the same dataset. From the table, although Random Forest model performed best in terms of precision, recall and F1 score, XGBoost model is not that far behind either. Naive Bayes showed good recall score, but its precision score is low compared to other models. SVM has the highest precision score, but it has a slightly lower recall and F1 score. Overall, Random Forest and XGBoost appear to be the best models considering all the evaluation metrics."
2044,"caption: Table 1. Model performances based on multiple evaluation metricstable: Model,Accuracy,Precision,Recall,F1 Score,AUC, Logistic Regression,0.87,0.84,0.91,0.87,0.936, Random Forest,0.91,0.91,0.93,0.92,0.971, SVM,0.85,0.83,0.87,0.85,0.924, Naive Bayes,0.79,0.74,0.82,0.77,0.844, Deep Neural Network,0.93,0.93,0.94,0.93,0.976","Table 1 illustrates the performances of various models based on multiple evaluation metrics. The models include Logistic Regression, Random Forest, Support Vector Machines (SVM), Naive Bayes, and Deep Neural Network. The evaluation metrics included are Accuracy, Precision, Recall, F1 Score, and AUC. Random Forest showed the highest accuracy of 0.91, whereas Deep Neural Network showed the highest precision of 0.93. SVM had the highest recall score of 0.87, and F1 Score was the same for Random Forest and Deep Neural Network with a score of 0.92 and 0.93, respectively. Interestingly, Deep Neural Network produced the best overall performance with the highest Area Under the Curve (AUC) of 0.976."
2045,"caption: Comparison of Model Performance Results across Multiple Metricstable: Metric,Model 1,Model 2,Model 3,Model 4,Model 5, Accuracy,0.90,0.92,0.84,0.91,0.87, Precision,0.91,0.93,0.82,0.95,0.88, Recall,0.87,0.95,0.85,0.90,0.92, F1-Score,0.89,0.94,0.83,0.93,0.90, AUC,0.95,0.96,0.92,0.97,0.94","This table provides a comparison of different models' performance results across multiple evaluation metrics. The table includes five models, namely Model 1, Model 2, Model 3, Model 4, and Model 5, and evaluation metrics such as Accuracy, Precision, Recall, F1-Score, and AUC. Interestingly, Model 4 shows the best performance results across all evaluation metrics, where it has the highest accuracy (0.91), precision (0.95), recall (0.90), F1-Score (0.93), and AUC (0.97) scores. Model 2 also exhibits excellent performance results, with the highest precision (0.93) and AUC (0.96) scores. On the other hand, Model 3 has the lowest performance results across all evaluation metrics, where it has the lowest accuracy (0.84), precision (0.82), F1-Score (0.83), and AUC (0.92) scores."
2046,"caption: Performance of different machine learning models using various evaluation metricstable: Model,Accuracy,F1 Score,Recall,Precision, SVM,0.86,0.87,0.88,0.86, MLP,0.83,0.84,0.83,0.85, LR,0.87,0.88,0.86,0.87, DT,0.75,0.75,0.73,0.74, RF,0.89,0.90,0.91,0.89","The table above shows the performance of different machine learning models using various evaluation metrics – accuracy, F1 score, recall, and precision. The results show that the best performing model when it comes to accuracy, F1 score, and precision is the logistic regression model (LR). The decision tree (DT) model has the lowest scores for all evaluation metrics. While RF shows the highest performance when it comes to recall, SVM achieves the highest F1 score. These observations indicate that different evaluation metrics might lead to different model preferences, and thus, it might be important to choose the evaluation metric based on the problem at hand."
2047,"caption: Performance comparison of different models across multiple evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall,AUC, Logistic Regression,0.84,0.83,0.84,0.84,0.92, Random Forest,0.91,0.90,0.91,0.91,0.97, XGBoost,0.92,0.92,0.91,0.93,0.98, Naive Bayes,0.81,0.78,0.80,0.81,0.88, Support Vector Machine,0.87,0.86,0.87,0.87,0.94","The table exhibits the performance results of five different models across multiple evaluation metrics, including Accuracy, F1-Score, Precision, Recall, and AUC. The models are Logistic Regression, Random Forest, XGBoost, Naive Bayes, and Support Vector Machine (SVM), which were all trained and tested with the same dataset. The best overall performer across all evaluation metrics is XGBoost, achieving the highest accuracy of 0.92, F1-Score of 0.92, and AUC of 0.98. Random Forest also performs well, with accuracy, F1-Score, Precision, Recall, and AUC of 0.91, while Logistic Regression's AUC of 0.92 is second-best, but with slightly lower performance for other metrics compared to the Random Forest. Naive Bayes and SVM show respectable results, but with comparatively lower performance in all evaluation metrics."
2048,"caption: Model performance based on accuracy, F1-score, ROC-AUC and PR-AUCtable: Model,Accuracy,F1-Score,ROC-AUC,PR-AUC, Logistic,0.87,0.85,0.92,0.88, Decision Tree,0.82,0.80,0.80,0.77, Random Forest,0.92,0.90,0.94,0.94, SVM,0.89,0.87,0.91,0.88, Naive Bayes,0.78,0.76,0.82,0.80","Table X illustrates the evaluation results of five different models measured based on four metrics: Accuracy, F1-score, ROC-AUC, and PR-AUC. The models included in the table are Logistic Regression, Decision Tree, Random Forest, Support Vector Machine (SVM), and Naive Bayes. The Random Forest model demonstrates the best results in all the metrics with an accuracy of 0.92, F1-score of 0.90, ROC-AUC of 0.94, and PR-AUC of 0.94. In contrast, the Naive Bayes model reveals the poorest performance across all metrics with an accuracy of 0.78, F1-score of 0.76, ROC-AUC of 0.82, and PR-AUC of 0.80. SVM and Logistic regression lay between Random Forest and Decision Tree models in terms of performance."
2049,"caption: Model performance based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, Random Forest,0.783,0.802,0.756,0.777, Logistic Regression,0.765,0.756,0.800,0.777, Decision Tree,0.695,0.675,0.732,0.701, Support Vector Machine,0.787,0.787,0.778,0.782, Multi-Layer Perceptron,0.779,0.776,0.784,0.778","The table presents the model performance with respect to evaluation metrics, including Accuracy, Precision, Recall, and F1-score. Five different models, including Random Forest, Logistic Regression, Decision Tree, Support Vector Machine, and Multi-Layer Perceptron, are evaluated. According to the table, Random Forest provides the best overall evaluation results with the highest Accuracy of 0.783 and F1-score of 0.777. Support Vector Machine, on the other hand, demonstrates the highest precision with an equal score of 0.787, while Logistic Regression displays the highest recall with a score of 0.800."
2050,"caption: Performance comparison of different models based on accuracy, precision, recall, and F1 score.table: Model,Accuracy,Precision,Recall,F1 Score, Model A,0.89,0.92,0.87,0.89, Model B,0.91,0.91,0.92,0.92, Model C,0.85,0.79,0.88,0.83, Model D,0.87,0.86,0.89,0.87, Model E,0.93,0.94,0.92,0.93","Table presents the performance comparison of five different models based on four evaluation metrics: accuracy, precision, recall, and F1 score. Model B demonstrates the best accuracy score of 0.91 while Models A and E have a close accuracy score of 0.89 and 0.93, respectively. Model E provides the best precision score of 0.94, whereas Model C demonstrates the lowest precision score of 0.79. With respect to recall, Model B has the highest recall score of 0.92. F1 score, which is an average of precision and recall, is the highest for Model B and Model E with identical scores of 0.92 and 0.93, respectively. Overall, Model E performs relatively better as compared to others based on the provided evaluation metrics."
2051,"caption: Performance results of different machine learning models on the classification task.table: Model Name,Accuracy,F1-score,Precision,Recall,AUC, Logistic,0.89,0.81,0.90,0.94,0.85, SVM,0.87,0.82,0.84,0.88,0.82, Random Forest,0.93,0.90,0.92,0.89,0.91, XGBoost,0.94,0.92,0.94,0.95,0.93, Decision Tree,0.88,0.82,0.86,0.81,0.80","The table presents the results of five machine learning models for a classification task. The models are evaluated using different metrics such as Accuracy, F1-score, Precision, Recall, and AUC. The results exhibit that the XGBoost model demonstrates the best overall performance with the highest scores in Accuracy (0.94), F1-score (0.92), Precision (0.94), and Recall (0.95). The Random Forest model also performed very well, with a high accuracy of 0.93 and an impressive AUC score of 0.91. On the other hand, the Decision Tree model struggled to provide good results, showing the lowest performance scores in all the metrics."
2052,"caption: Performance comparison of five machine learning models on classification task.table: Model Name,F1-score,Recall,Precision,Accuracy, Support Vector Machine,0.86,0.89,0.83,0.91, Decision Tree,0.72,0.68,0.81,0.79, Random Forest,0.92,0.91,0.93,0.94, Gradient Boosting,0.88,0.86,0.90,0.90, Multilayer Perceptron,0.89,0.91,0.87,0.92","The table shows a comparison of five machine learning models, namely Support Vector Machine (SVM), Decision Tree (DT), Random Forest (RF), Gradient Boosting (GB), and Multilayer Perceptron (MLP), on a classification task. The metrics F1-score, Recall, Precision, and Accuracy were utilized to evaluate the models. Notably, the Random Forest model outperformed other models in all metrics except the F1-score, where MLP model achieved a slightly better result. SVM also shows a strong performance in all metrics. However, Decision Tree appears to perform poorly in comparison to other models, particularly in Recall and Accuracy scores. The results of this performance comparison can help decide the most suitable machine learning model for a classification task."
2053,"caption: Table 4. Model performance based on different evaluation metrics.table: Model,Metric,Score, RandomForestClassifier,Accuracy,0.92, KNeighborsClassifier,Accuracy,0.75, DecisionTreeClassifier,Accuracy,0.88, MLPClassifier,Accuracy,0.90, GaussianNB,Accuracy,0.74, SVC,Accuracy,0.91, RandomForestClassifier,F1 Score,0.92, KNeighborsClassifier,F1 Score,0.65, DecisionTreeClassifier,F1 Score,0.86, MLPClassifier,F1 Score,0.90, GaussianNB,F1 Score,0.29, SVC,F1 Score,0.89","Table 4 shows the performance of multiple models based on different evaluation metrics, including accuracy and F1-score. The table lists models such as RandomForestClassifier, KNeighborsClassifier, DecisionTreeClassifier, MLPClassifier, GaussianNB, and SVC, evaluated based on their accuracy and F1-score metrics. Notably, the RandomForestClassifier model had the highest accuracy score of 0.92, followed closely by the SVC model's score of 0.91. However, the model with the highest F1-score was RandomForestClassifier with the score of 0.92, while the GaussianNB model shows the lowest F1-score with the score of 0.29. The table provides an overview of various models and their performance metrics, aiding the selection of models based on the desired evaluation metric."
2054,"caption: Model evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.905,0.920,0.870,0.894, Decision Tree,0.847,0.820,0.850,0.824, Naive Bayes,0.872,0.885,0.853,0.866, MLP,0.934,0.925,0.949,0.937, Random Forest,0.935,0.923,0.960,0.941, KNN,0.804,0.783,0.830,0.800, Logistic Reg.,0.867,0.895,0.830,0.862, XGBoost,0.944,0.937,0.957,0.946, CatBoost,0.943,0.936,0.956,0.943","The table represents the evaluated performance of nine models on a similar dataset using various evaluation metrics such as accuracy, precision, recall, and F1-score. The MLP and Random Forest models showed the highest accuracy scores, with a value of 0.934 and 0.935, respectively. The Random Forest, XGBoost, and CatBoost models demonstrated the best precision, recall, F1-score combinations with scores of 0.923, 0.960, and 0.941, respectively. While the Random Forest, XGBoost, and CatBoost models performed similarly, the XGBoost model demonstrated the best performance with an accuracy score of 0.944 and higher precision, recall, and F1-scores. The KNN model achieved the weakest performance with an accuracy score of 0.804 and an F1-score of 0.800."
2055,"caption: Evaluation metrics of different models on a classification task.table: Model Name,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.87,0.86,0.91,0.83, Random Forest,0.90,0.89,0.92,0.87, Gradient Boosting,0.92,0.91,0.94,0.89, Support Vector Machine,0.85,0.84,0.88,0.80, Multi-layer Perceptron Network,0.91,0.90,0.93,0.87","The table presents the results of five different models on a classification task. Logistic Regression, Random Forest, Gradient Boosting, Support Vector Machine, and Multi-layer Perceptron Network's Accuracy, F1-Score, Precision, and Recall are evaluated and shown in the table. Gradient Boosting shows the highest Accuracy (0.92), F1-Score (0.91), and Precision (0.94) scores. On the other hand, Random Forest achieves relatively high scores for all metrics, with Accuracy of 0.90, F1-Score of 0.89, Precision of 0.92, and Recall of 0.87. Logistic Regression is also one of the top-performing models, with Accuracy of 0.87, F1-Score of 0.86, Precision of 0.91, and Recall of 0.83."
2056,"caption: Different models' performance on accuracy, F1-score (macro), and F1-score (micro) metrics.table: Model,Accuracy,F1-score (macro),F1-score (micro), SVM,0.87,0.81,0.87, k-NN,0.84,0.77,0.84, RF,0.90,0.85,0.90, NN,0.91,0.86,0.91, XGB,0.89,0.83,0.89","The table depicts a comparison among different models' performance on various evaluation metrics, namely Accuracy, F1-score (macro), and F1-score (micro). The models considered for comparison includes Support Vector Machine (SVM), k-Nearest Neighbors (k-NN), Random Forest (RF), Neural Network (NN), and eXtreme Gradient Boosting (XGB). Based on the performance results, the Neural Network (NN) stands out as the best model by achieving the highest accuracy with a score of 0.91 and F1-score (macro) and F1-score (micro) with scores of 0.86 and 0.91, respectively. However, the Random Forest (RF) performed remarkably well by achieving high scores as well and is worth further investigation."
2057,"caption: Table 4: A comparison of different models' performance based on multiple evaluation metrics.table: Model,Accuracy,F1-score,Recall,Precision, SVM,0.81,0.80,0.81,0.84, Logistic Regression,0.79,0.78,0.79,0.83, Random Forest,0.83,0.82,0.83,0.85, Gradient Boosting,0.85,0.84,0.85,0.88","Table 4 displays a comparison of four different models' performance. The models were evaluated based on four different evaluation metrics, including Accuracy, F1-score, Recall, and Precision. SVM, Logistic Regression, Random Forest, and Gradient Boosting models were trained and tested using the same dataset. The Random Forest model showed the highest Accuracy of 0.83, while the Gradient Boosting model achieved the highest F1-score, Recall, and Precision of 0.84, 0.85, and 0.88, respectively. Interestingly, the Gradient Boosting model had the best performance on all four evaluation metrics, even though the SVM and Logistic Regression models didn't perform poorly on the Accuracy measure."
2058,"caption: Table 4: Model Performance Evaluation using different metricstable: Model,Precision,Recall,F1-Score,AUC-ROC,AUC-PR, LogReg,0.85,0.83,0.82,0.92,0.83, SVM,0.76,0.79,0.75,0.87,0.73, Random Forest,0.86,0.84,0.85,0.95,0.86, MLP,0.85,0.87,0.85,0.91,0.88, Conv1D,0.81,0.83,0.82,0.90,0.81","Table 4 presents the performance evaluation of different models using standard classification evaluation metrics. The performance of the LogReg, SVM, Random Forest, MLP, and Conv1D models were evaluated using precision, recall, F1-score, AUC-ROC, and AUC-PR. The results show that the Random Forest model performed the best in terms of precision, recall, F1-score, AUC-ROC, and AUC-PR with values of 0.86, 0.84, 0.85, 0.95, and 0.86, respectively. However, the MLP model achieved the highest recall and AUC-PR scores of 0.87 and 0.88, respectively. Meanwhile, the SVM model attained the lowest precision, recall, F1-score, AUC-ROC, and AUC-PR with scores of 0.76, 0.79, 0.75, 0.87, and 0.73, respectively. The table provides a comprehensive overview of the models' performance on different metrics, which can aid researchers and practitioners in choosing the best model for their classification tasks."
2059,"caption: Model performances based on different evaluation metrics.table: Model,Precision,Recall,F1-Score,AUC-ROC,AUC-PR, Logistic Regression,0.85,0.92,0.88,0.9,0.83, Decision Tree,0.91,0.88,0.89,0.86,0.82, Random Forest,0.88,0.88,0.88,0.92,0.91, Gradient Boosting,0.87,0.91,0.89,0.93,0.91, Support Vector.,0.86,0.90,0.88,0.90,0.85","The table presents the comparison of multiple predictive models based on different evaluation metrics. The models include Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Support Vector. The presented evaluation metrics are precision, recall, F1-Score, AUC-ROC, and AUC-PR. All models were trained and tested on the same dataset using 10-fold cross-validation. The results demonstrate that the Gradient Boosting model performs the best with an AUC-ROC score of 0.93 and AUC-PR of 0.91. On the other hand, the Decision Tree model exhibits the highest precision score of 0.91, while the Logistic Regression model demonstrates the highest recall score of 0.92."
2060,"caption: Model performance results from different models based on evaluation metrics.table: Model,Precision,Recall,F1-Score,Accuracy, Model 1,0.85,0.82,0.83,0.89, Model 2,0.82,0.87,0.84,0.85, Model 3,0.76,0.81,0.78,0.83, Model 4,0.90,0.79,0.84,0.91, Model 5,0.87,0.89,0.88,0.88, Model 6,0.83,0.84,0.83,0.87","Table 4 showcases the performance results from six different models. The evaluation metrics used to measure the model performance include Precision, Recall, F1-Score, and Accuracy. Model 4 achieved the highest precision score of 0.90, while Model 5 attained the highest recall score of 0.89. Notably, both Model 1 and Model 5 have the same F1-Score score of 0.83. Additionally, Model 4 had the highest accuracy score of 0.91. Interestingly, the model with the lowest accuracy score (Model 3) also has the lowest F1-Score score. Overall, the table highlights the distinct and diverse performance results of the different models on different metrics."
2061,"caption: Table 4: Model Comparison with Different Performance Metricstable: Model,Precision,Recall,F1 Score,Accuracy, Model 1,0.75,0.83,0.77,0.80, Model 2,0.82,0.79,0.80,0.87, Model 3,0.88,0.72,0.79,0.91, Model 4,0.79,0.85,0.81,0.84, Model 5,0.91,0.65,0.73,0.93","In Table 4, we compare the performance of five different models using various evaluation metrics for a binary classification task. The evaluation metrics include precision, recall, F1 score, and accuracy. The highest precision score is achieved by Model 5 with a score of 0.91. Model 3 reaches the highest recall performance with a score of 0.72 while Model 1 shows the lowest recall score with 0.83. Model 2 performs all-rounded well and has the highest F1 score of 0.80. Finally, Model 5 achieves the highest accuracy with a score of 0.93, while Model 3 obtains the second-highest accuracy of 0.91. Overall, these results demonstrate a trade-off between the varying evaluation metrics used and provide insight into selecting the most appropriate model for the given classification task."
2062,"caption: Model performance based on different evaluation metrics.table: Model,Precision,Recall,F1,AUC, SVM,0.87,0.65,0.74,0.91, KNN,0.81,0.71,0.76,0.87, RF,0.89,0.79,0.84,0.93, Naive Bayes,0.78,0.59,0.67,0.84, Logistic Regression,0.86,0.74,0.80,0.89","The table exhibits the precision, recall, F1-score, and AUC performances of multiple classification models trained and tested on a labeled dataset. The SVM model shows the highest AUC score of 0.91, while the RF model had the highest F1-score with a value of 0.84. Moreover, the RF model also had the highest precision and recall with values of 0.89 and 0.79, respectively. The Logistic regression model achieved an F1-score of 0.80 along with a precision score of 0.86 and recall score of 0.74. The Naive Bayes model had the lowest performance scores, generating an F1-score of 0.67, precision score of 0.78, and recall score of 0.59. The table highlights the models' distinct performance in various evaluation metrics, enabling researchers to choose the appropriate model tailored to their preferences and needs."
2063,"caption: Model performance based on different evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall,AUC, LR,0.95,0.96,0.96,0.95,0.94, DT,0.91,0.91,0.93,0.90,0.85, KNN,0.89,0.88,0.91,0.87,0.83, SVM,0.93,0.93,0.94,0.92,0.90","Table presented above represents the performance of four different models: Logistic Regression (LR), Decision Tree (DT), K-Nearest Neighbor (KNN), and Support Vector Machine (SVM). These models have been evaluated based on five different evaluation metrics: Accuracy, F1-Score, Precision, Recall, and AUC. From the table, it is evident that all models performed relatively well on accuracy and F1-score. The SVM and LR models performed best in terms of AUC, where SVM outperformed all other models. On the other hand, the Precision metric was the highest for the LR model, followed by SVM and DT, with KNN being the lowest. DT and KNN models had the lowest Recall score compared to LR and SVM models. Overall, the SVM model seems to have performed the best based on the results."
2064,"caption: Evaluation metrics of the different modelstable: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.92,0.93,0.95,0.94, KNN,0.85,0.87,0.80,0.83, DT,0.80,0.78,0.85,0.81, LR,0.91,0.90,0.92,0.91, RF,0.94,0.93,0.96,0.95, NB,0.70,0.66,0.80,0.72","The table compares the evaluation metrics of different classification models, including SVM, KNN, DT, LR, RF, and NB. The evaluation metrics include Accuracy, Precision, Recall, and F1-Score. The RF model exhibited the highest accuracy of 0.94, whereas the NB model had the lowest accuracy of 0.70. The SVM model achieved the highest precision of 0.93, while LR had the highest recall and F1-score of 0.92 and 0.91, respectively. The KNN model had the lowest precision of 0.87 and recall of 0.80. Overall, the RF model appears to be the best performer across all evaluation metrics."
2065,"caption: Model Performance Comparison on Classification Tasktable: Model,Accuracy,Precision,Recall,F1-score, SVM,0.89,0.90,0.83,0.86, Logistic Regression,0.82,0.75,0.88,0.81, Random Forest,0.91,0.92,0.87,0.89, XGBoost,0.88,0.86,0.89,0.87","Table 4 presents the comparison of multiple different models' performances on a classification task. The table exhibits Accuracy, Precision, Recall, and F1-score results for SVM, Logistic Regression, Random Forest, and XGBoost models. Notably, the highest accuracy results are achieved by Random Forest with a score of 0.91, followed by SVM with a score of 0.89. On the other hand, Logistic Regression has the lowest accuracy score of 0.82. Interestingly, SVM model has the highest precision score of 0.90, while Random Forest has the highest recall and F1-score results of 0.87 and 0.89, respectively. Overall, Random Forest outperforms other models on all metrics, followed by SVM and XGBoost."
2066,"caption: Table 4: Model Evaluation Metrics of Various Modelstable: Model,Precision,Recall,F1 Score,Accuracy, Logistic Regression,0.752,0.821,0.785,0.86, Random Forest,0.811,0.787,0.787,0.85, Support Vector Machine,0.738,0.833,0.777,0.86, Naive Bayes,0.633,0.825,0.709,0.76","Table 4 presents the evaluation metrics of various models: Logistic Regression, Random Forest, Support Vector Machine, and Naive Bayes. The table illustrates four different evaluation metrics: Precision, Recall, F1 Score, and Accuracy. Interestingly, each model achieved different evaluation metrics results. The Support Vector Machine model achieved the highest Recall value of 0.833, while the Random Forest model had the highest Precision score of 0.811. The Logistic Regression model scored the highest accuracy of 0.86, while the Naive Bayes model had the lowest evaluation metrics results with the lowest Precision score of 0.633 and F1 score of 0.709."
2067,"caption: Performance evaluation of different models using precision, recall, and F1-score.table: Model,Precision-Positive,Precision-Negative,Recall-Positive,Recall-Negative,F1-Score, Model A,0.86,0.95,0.72,0.97,0.78, Model B,0.93,0.79,0.81,0.94,0.86, Model C,0.72,0.98,0.67,0.83,0.69, Model D,0.95,0.72,0.92,0.81,0.93, Model E,0.89,0.89,0.78,0.87,0.83","The above table shows the performance evaluation of five different models using precision, recall, and F1-score. Model A exhibits the highest Precision-Positive of 0.86, while Model D shows the highest Precision-Negative of 0.95. On the other hand, Model B achieved the highest Recall-Positive of 0.81, and Model A shows the highest Recall-Negative of 0.97. Comparing the F1-scores, Model D achieved the highest score of 0.93, while Model C shows the lowest score of 0.69, indicating overall poor performance."
2068,"caption: Comparison of different classification models based on various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.82,0.86,0.77,0.81, Decision Tree,0.75,0.68,0.72,0.70, Random Forest,0.85,0.88,0.82,0.85, Support Vector Machine,0.80,0.82,0.79,0.80, Multi-Layer Perceptron,0.87,0.84,0.89,0.87, Gradient Boosting,0.84,0.86,0.82,0.84","The table presents the comparison of six different classification models, namely Logistic Regression, Decision Tree, Random Forest, Support Vector Machine, Multi-Layer Perceptron, and Gradient Boosting. Each model's performance is evaluated using four different evaluation metrics, namely Accuracy, Precision, Recall, and F1-score. It is interesting to note that the Multi-Layer Perceptron model achieved the highest Recall score of 0.89, while the Logistic Regression model had the highest Precision score of 0.86. The table also shows that the Multi-Layer Perceptron model outperforms other models based on Accuracy and F1-score with a score of 0.87 and 0.87, respectively. In contrast, the Decision Tree model has the lowest performance among the considered models."
2069,"caption: Table 4: Model performance on the classification task using different models and evaluation metrics.table: Models,Accuracy,Recall,Precision,F1 Score, Logistic Regression,0.85,0.82,0.89,0.85, Random Forest,0.84,0.79,0.91,0.84, KNN,0.80,0.72,0.85,0.78, Neural Network,0.87,0.84,0.90,0.87, SVM,0.86,0.83,0.89,0.86","Table 4 displays the model performance results for different models and evaluation metrics used for a classification task. The table compares the accuracy, recall, precision, and F1 Score for Logistic Regression, Random Forest, KNN, Neural Network, and SVM models. The Neural Network achieved the highest accuracy with 0.87, while Logistic Regression, Random Forest, and SVM models recorded over 0.80 accuracy. All models had at least 0.72 recall and 0.85 precision. The F1 Score indicates that Neural Network and Logistic Regression models had the highest performance with a value of 0.87 and 0.85, respectively."
2070,"caption: Table 4: Model performances based on multiple evaluation metrics.table: Model,Precision,Recall,F1 Score,Accuracy, SVM,0.91,0.73,0.80,0.89, RF,0.84,0.65,0.73,0.81, MLP,0.82,0.57,0.66,0.77, KNN,0.75,0.48,0.59,0.72, NB,0.62,0.38,0.46,0.61","Table 4 presents the performance results of different machine learning models based on precision, recall, F1 score, and accuracy evaluation metrics. The table includes SVM, RF, MLP, KNN, and NB algorithms' performances. Notably, the SVM recorded the highest precision result of 0.91 and accuracy of 0.89. The RF and MLP models described second and third-best precision results and had comparable accuracy scores of 0.81 and 0.77, respectively. Interestingly, the SVM and RF models achieved their highest scores for recall and F1 scores. However, the KNN and NB models had the lowest performances for all metrics."
2071,"caption: Table 4: Model performance comparison based on Accuracy, F1-score, Precision, and Recall evaluation metricstable: Model,Accuracy,F1-score,Precision,Recall, Model1,0.88,0.85,0.81,0.89, Model2,0.86,0.83,0.79,0.87, Model3,0.89,0.86,0.83,0.89, Model4,0.85,0.82,0.78,0.86","Table 4 compares the performance of four different models in terms of accuracy, F1-score, precision, and recall evaluation metrics. The table shows that Model3 performed the best with the highest accuracy of 0.89 and F1-score of 0.86. On the other hand, Model4 had the lowest accuracy of 0.85 and F1-score of 0.82. Interestingly, Model1 had the highest precision of 0.81, while Model3 had the highest recall of 0.89. In conclusion, Model3 achieved the best overall performance in this comparison, while Model4 showed the lowest performance among all models."
2072,"caption: Table 4: Model Comparison Based on Different Evaluation Metricstable: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.837,0.831,0.845,0.818, kNN,0.809,0.798,0.814,0.782, RF,0.862,0.848,0.873,0.825, NB,0.694,0.657,0.795,0.559, DT,0.847,0.837,0.835,0.851","Table 4 provides a comparison of model performance based on different evaluation metrics, namely accuracy, F1-score, precision, and recall. The table includes five different models, SVM, kNN, RF, NB, and DT, and their corresponding performance results. Notably, the RF model has the highest accuracy rate of 0.862, followed by the SVM model with 0.837. The NB model achieved the lowest accuracy score of 0.694. In terms of F1-score, precision, and recall, the RF model outperformed other models. Conversely, the NB model had the lowest F1-score, precision, and recall, indicating its poor performance across all evaluation metrics compared to the other models."
2073,"caption: Comparison of model performances based on different evaluation metrics.table: Model Name,F1 Score,Accuracy Score,Precision Score,Recall Score, Model A,0.84,0.91,0.79,0.91, Model B,0.86,0.89,0.78,0.96, Model C,0.89,0.92,0.80,0.98, Model D,0.83,0.88,0.76,0.91, Model E,0.85,0.90,0.77,0.94","The table above compares the performances of five different models based on multiple evaluation metrics. The evaluation metrics include F1 Score, Accuracy Score, Precision Score, and Recall Score. Model C shows the best performance for all the evaluation metrics, with the highest F1 score of 0.89, accuracy score of 0.92, precision score of 0.80, and recall score of 0.98. However, Model B achieved the highest recall score of 0.96. Interestingly, the F1 score is not always the highest in the best performing model indicating that the importance of evaluating models on multiple metrics."
2074,"caption: Model Performance on Evaluation Metricstable: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.85,0.86,0.84,0.88, Naive Bayes,0.78,0.79,0.72,0.87, Random Forest,0.91,0.92,0.91,0.92, SVM,0.88,0.89,0.86,0.91, XGBoost,0.92,0.93,0.92,0.93","The table presents a comparison of the accuracy, F1-score, precision, and recall for different models. The models include Logistic Regression, Naive Bayes, Random Forest, SVM, and XGBoost, and all models were trained and evaluated on the same dataset. XGBoost achieved the highest accuracy of 0.92, closely followed by Random Forest, with a score of 0.91. XGBoost also achieved the highest F1-score, precision, and recall among all models, suggesting that it is the best-performing model on those metrics. However, SVM achieved the highest precision score of 0.86. Notably, the Naive Bayes model's performance is the weakest, with an accuracy of 0.78 and F1-score of 0.79."
2075,"caption: Table 4: Model performance evaluation based on different evaluation metrics.table: Model,Accuracy,F1-Score,AUC-ROC,Precision, Logistic regression,0.85,0.82,0.91,0.81, Support Vector Machine,0.83,0.78,0.87,0.80, Gradient Boosting,0.88,0.85,0.93,0.84, Random Forest,0.89,0.87,0.92,0.86, Neural Network,0.90,0.88,0.96,0.88","Table 4 presents the model performance evaluation results based on different evaluation metrics, including accuracy, F1-Score, AUC-ROC, and precision. It includes five models - Logistic regression, Support Vector Machine, Gradient Boosting, Random Forest, and Neural Network. The table shows that the Neural Network has the best performance regarding the evaluation metrics, with an accuracy of 0.90, F1-Score of 0.88, AUC-ROC of 0.96, and precision of 0.88. The Random Forest model also performs reasonably well, with an accuracy of 0.89, F1-Score of 0.87, AUC-ROC of 0.92, and precision of 0.86. The Logistic regression model shows the weakest performance, with an accuracy of 0.85, F1-Score of 0.82, AUC-ROC of 0.91, and precision of 0.81."
2076,"caption: Performance comparison of various models using multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score,AUC, Random Forest,0.85,0.86,0.85,0.84,0.91, Support Vector Machine,0.82,0.84,0.81,0.80,0.89, Logistic Regression,0.89,0.90,0.89,0.88,0.95, XGBoost,0.87,0.88,0.87,0.86,0.92",
2077,"caption: Comparison table of different classifiers' performances on the dataset.table: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.843,0.820,0.848,0.830, Decision Tree,0.864,0.842,0.863,0.851, Random Forest,0.902,0.892,0.906,0.898, Gradient Boosting,0.898,0.878,0.890,0.884, Support Vector Machine,0.855,0.850,0.844,0.845","The table above summarizes the performance of various classification models, including Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Support Vector Machine, based on Accuracy, Precision, Recall and F1-score metrics. The table presents the highest performing model based on accuracy was Random Forest, which achieved a score of 0.902. Random forest also achieved the highest Precision, Recall, and F1-score with 0.892, 0.906, and 0.898. Additionally, Decision Tree and Gradient Boosting obtained performance near to those of Random Forest, showing good capability to classify the dataset. However, SVM resulted in the lowest performance, achieving an accuracy of 0.855."
2078,"caption: Table 4: Model performance comparison using various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1, Logistic Regression,0.85,0.90,0.82,0.86, Random Forest,0.90,0.94,0.88,0.91, SVM with RBF Kernel,0.89,0.92,0.90,0.91, Naive Bayes,0.82,0.89,0.80,0.84, Decision Tree,0.83,0.86,0.79,0.82","Table 4 presents a comparison of multiple supervised learning models' performances using various evaluation metrics such as Accuracy, Precision, Recall, and F1. The table showcases Logistic Regression, Random Forest, SVM with RBF Kernel, Naive Bayes, and Decision Tree models' performances on the same dataset. Notably, the Random Forest model outperformed other models in accuracy and F1 score with 0.9 and 0.91, respectively. The Logistic Regression and SVM with RBF Kernel models performed almost similarly in all metrics. Additionally, Naive Bayes had the weakest accuracies compared to other models."
2079,"caption: Table 4: Model performance based on multiple evaluation metrics.table: Model,AUC,Log Loss,F1 Score, Logistic Regression,0.917,0.203,0.879, Random Forests,0.904,0.210,0.868, Gradient Boosting,0.920,0.196,0.883, Neural Network,0.902,0.205,0.864, Support Vector Machine,0.898,0.209,0.854","Table 4 presents a comparison of multiple models based on different evaluation metrics. The table reports the AUC score, Log loss, and F1 score for each model. The models include Logistic Regression, Random Forests, Gradient Boosting, Neural Network, and Support Vector Machine. Notably, many different evaluation metrics are employed to compare the performance of the models. The models' performances vary based on different metrics; for instance, Gradient Boosting has the highest AUC score with 0.92, while Logistic Regression achieved the best F1 score with 0.879. Overall, this table helps to decide the most suitable model for a particular evaluation metric."
2080,"caption: Model performances based on multiple metricstable: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.87,0.85,0.90,0.81, Random Forest,0.88,0.86,0.91,0.82, Support Vector Machine,0.86,0.83,0.89,0.79, Gradient Boosted Tree,0.89,0.87,0.90,0.84, Multi-layer perceptron,0.85,0.84,0.88,0.81","The table represents a comparison of different machine learning models based on multiple evaluation metrics, including accuracy, F1 Score, Precision, and Recall. The table shows that the Gradient Boosted Tree achieved the highest accuracy score of 0.89, while the Random Forest has the highest F1 score of 0.86. The highest precision score of 0.91 was attained by both Random Forest and Logistic Regression, and Gradient Boosted Tree attained the highest Recall score of 0.84. The Multi-layer perceptron model had the lowest performance scores for all the metrics compared to the other models in the table."
2081,"caption: Performance of Different Models Based on Evaluation Metricstable: Model,Accuracy,F1 score,Precision,Recall, Logistic Regression,0.85,0.82,0.86,0.79, Random Forest,0.90,0.88,0.91,0.86, KNN,0.78,0.76,0.80,0.72, SVM,0.87,0.84,0.89,0.79, Naive Bayes,0.81,0.79,0.83,0.75","Table shows a comparison of different models' performance based on multiple evaluation metrics. The models include Logistic Regression, Random Forest, KNN, SVM, and Naive Bayes. The evaluation metrics are Accuracy, F1 score, Precision, and Recall.  Random Forest model performed the best with an accuracy of 0.90 followed by Support Vector Machine (SVM)  with an accuracy of 0.87. Random Forest also had the highest F1-score and precision values. On the other hand, KNN had the lowest performance with an accuracy of 0.78 and lowest precision value. Overall, the table indicates that Random Forest and SVM could be good models for the given dataset, while KNN may require further improvement."
2082,"caption: Model performance based on multiple evaluation metrics.table: Model,F1 score,Precision,Recall,Accuracy, Logistic Regression,0.85,0.88,0.82,0.86, Decision Tree,0.80,0.82,0.78,0.82, SVM (linear),0.82,0.85,0.80,0.84, SVM (rbf),0.78,0.80,0.75,0.81, Random Forest,0.87,0.87,0.87,0.88","Table 4 presents the performance of five different models - Logistic Regression, Decision Tree, SVM (linear), SVM (rbf), Random Forest, based on four different evaluation metrics, namely F1 score, precision, recall, and accuracy. Among the models, the Random Forest model shows the highest F1 score of 0.87 and accuracy of 0.88, demonstrating a well-balanced model. Additionally, the Logistic Regression model achieved the best precision of 0.88, while the SVM (linear) model has the highest recall of 0.80. Although the Decision Tree model outperformed SVM (rbf) across all metrics, it still presented lower performance than other models in the table. Overall, the table indicates that the Random Forest and Logistic Regression models are the most promising classifiers among the selected ones."
2083,"caption: Comparison of different classification models using multiple evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.897,0.899,0.901,0.897, Decision Tree,0.876,0.875,0.881,0.876, Random Forest,0.912,0.911,0.914,0.912, XGBoost,0.916,0.915,0.917,0.916, LightGBM,0.905,0.904,0.908,0.905","The table above highlights the comparison of various classification models' performance based on different evaluation metrics. The five models tested, which are Logistic Regression, Decision Tree, Random Forest, XGBoost, and LightGBM, are evaluated based on Accuracy, F1 Score, Precision, and Recall metrics. It can be observed that the XGBoost model achieved the best performance across all evaluation metrics. The model had a high Accuracy value of 0.916 and F1 Score of 0.915. Similarly, the Random Forest model performed well with an Accuracy of 0.912, F1 Score of 0.911, Precision of 0.914, and Recall of 0.912. The Logistic Regression model demonstrated the least performance with an accuracy value of 0.897, while the Decision Tree and LightGBM had a moderate performance."
2084,"caption: Table 4: Model performance based on different evaluation metrics.table: Model,F1-Score,Precision,Recall, Model A,0.85,0.88,0.82, Model B,0.90,0.83,0.98, Model C,0.81,0.92,0.75, Model D,0.92,0.95,0.89, Model E,0.87,0.79,0.98, Model F,0.94,0.97,0.92","Table 4 exhibits the model performance based on F1-Score, Precision, and Recall. The table comprises six different models (Model A to Model F) with their respective scores based on the metrics. Notably, Model F achieved the best performance results across all evaluation metrics, with the F1-Score of 0.94, Precision of 0.97, and Recall of 0.92. Model D also performed well with an F1-Score of 0.92, Precision of 0.95, and Recall of 0.89. Models B and E had a strong performance metric in Recall and F1-Score, respectively. However, Model C had the lowest performance based on all metrics."
2085,"caption: Performance comparison of different models using various evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Model A,85.3%,0.83,0.79,0.87, Model B,87.1%,0.85,0.81,0.89, Model C,80.2%,0.78,0.76,0.82, Model D,88.5%,0.86,0.83,0.89, Model E,89.2%,0.87,0.85,0.89","The table presents a performance comparison of different models using multiple evaluation metrics, including accuracy, F1 Score, precision, and recall. Model B shows the highest accuracy of 87.1% and F1 Score of 0.85. Model E performs best in terms of precision with a score of 0.85 and also shows the highest recall of 0.89 in comparison to the other models. On the other hand, Model C performs worst, obtaining the lowest accuracy of 80.2% and F1 Score of 0.78. Overall, the table shows the diversity in performance results from each model, emphasizing the importance of evaluating models using multiple metrics to get a more comprehensive understanding of model performance."
2086,"caption: The performance comparison of different models on the classification task.table: Model,Accuracy,Precision,Recall,F1 Score, SVM,0.74,0.76,0.68,0.71, Random Forest,0.79,0.78,0.72,0.74, Gradient Boost,0.82,0.81,0.80,0.80, XGBoost,0.83,0.84,0.81,0.81, Neural Network,0.79,0.82,0.68,0.71","The table presents a comparison of five different models' performance on the classification task. Different evaluation metrics, including Accuracy, Precision, Recall, and F1 Score, are presented. The Gradient Boost and XGBoost models achieved the highest accuracy of 0.82 and 0.83, respectively, outperforming SVM(0.74), Random Forest (0.79), and Neural Network (0.79). Moreover, XGBoost achieves the best Precision (0.84), Recall (0.81), and F1 Score (0.81) among the compared models. On the other hand, the Neural Network has a higher Precision (0.82) and a lower Recall (0.68), indicating its potential in identifying True Positive samples but with a higher risk of False Negative error."
2087,"caption: Table 4: Model evaluation metrics for different modelstable: Model name,Accuracy,Precision,Recall,F1-Score, Model A,0.87,0.89,0.86,0.87, Model B,0.90,0.91,0.86,0.88, Model C,0.91,0.93,0.92,0.92, Model D,0.85,0.90,0.85,0.87","Table 4 compares the performances of different models based on four evaluation metrics: Accuracy, Precision, Recall, and F1-Score. The table demonstrates that Model C has the best performance across all evaluation metrics with an accuracy score of 0.91, precision of 0.93, recall of 0.92, and F1-score of 0.92. Model B has the second-highest overall performance, while Model D has the lowest performance score for all evaluation metrics. The table highlights the importance of considering multiple evaluation metrics to assess a model's performance."
2088,"caption: Model performance metrics on the classification task.table: Model Name,Accuracy (%),Precision (%),Recall (%),F1-Score (%), Logistic Regression,76.2,74.5,73.8,0.734, Decision Tree,75.8,71.8,71.3,0.712, Random Forest,77.7,75.5,75.7,0.755, K-Nearest Neighbors,74.1,70.2,71.6,0.708, Support Vector Machine,74.9,72.4,72.8,0.727, Naive Bayes,68.1,66.8,59.6,0.628","The table above presents a comparison of different machine learning models (Logistic Regression, Decision Tree, Random Forest, K-Nearest Neighbors, Support Vector Machine, Naive Bayes) evaluated on the basis of Accuracy (%), Precision (%), Recall (%), and F1-Score (%). Among all the models tested, Random Forest performed the best, achieving an accuracy of 77.7%, and an F1-Score of 0.755. Notably, Naive Bayes performed the worst, with an accuracy of 68.1% and an F1-Score of 0.628. Interestingly, Naive Bayes scored the highest Recall of 59.6% among all the models tested. In general, the Random Forest model is recommended for this classification task based on these evaluation metrics."
2089,"caption: Table 1: Comparison of model performance based on accuracy, F1-score, and AUC-ROC for different models.table: Model,Accuracy,F1-score,AUC-ROC, Logistic Regression,0.81,0.80,0.80, Decision Tree,0.73,0.70,0.67, Random Forest,0.87,0.86,0.85, Support Vector Machine,0.80,0.79,0.78, Gradient Boosting,0.88,0.87,0.86","The table above shows a comparison of various machine learning models, including Logistic Regression, Decision Tree, Random Forest, Support Vector Machine, and Gradient Boosting, based on different evaluation metrics. The models were evaluated using accuracy, F1-score, and AUC-ROC performance measures. The results indicate that the Gradient Boosting model outperformed all other models, achieving the highest accuracy, F1-score and AUC-ROC scores of 0.88, 0.87 and 0.86, respectively. The Random Forest model also exhibits good performance across all measures, achieving the second-highest scores. However, the Decision Tree model's performance fell short compared to the other models, especially in terms of AUC-ROC."
2090,"caption: Model performance comparison based on different metrics.table: Model,Accuracy,F1 Score,Precision,Recall,Cohen's Kappa, Logistic Regression,0.87,0.85,0.82,0.88,0.75, Random Forest,0.91,0.90,0.89,0.92,0.83, Naive Bayes,0.83,0.80,0.76,0.84,0.67, SVM,0.89,0.88,0.85,0.91,0.79, Gradient Boosting,0.90,0.89,0.87,0.91,0.81","Table presents a comparison of five different machine learning models' performances based on accuracy, F1 score, precision, recall, and Cohen's kappa. The models considered are Logistic Regression, Random Forest, Naive Bayes, SVM, and Gradient Boosting. Each model was trained and tested using the same dataset. The Random Forest model has the highest accuracy of 0.91, while Naive Bayes has the lowest accuracy of 0.83. Likewise, Random Forest outperforms all other models in terms of F1 score and Cohen's kappa, with scores of 0.90 and 0.83, respectively. However, Naive Bayes has the lowest F1 score and Cohen's kappa, primarily due to its lower precision score. Interestingly, SVM and Logistic Regression showed better performance for precision and recall scores. Gradient Boosting also exhibited excellent results, ranking the second-best model in all evaluation metrics."
2091,"caption: Comparison Table of Different Models Based on Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1 Score, Decision Tree,0.8352,0.840,0.905,0.8712, Logistic Regression,0.8791,0.896,0.933,0.9141, Naive Bayes,0.8193,0.811,0.952,0.8758, Support Vector Machine,0.8878,0.908,0.931,0.9193, Random Forest,0.9212,0.922,0.963,0.9429","The table displays the evaluation metrics of five different classification models, namely Decision Tree, Logistic Regression, Naive Bayes, Support Vector Machine, and Random Forest. The models were evaluated based on accuracy, precision, recall, and F1 score. The Random Forest model achieved the highest accuracy of 0.9212, with a precision of 0.922, which is the highest among all the models. The Naive Bayes model had the highest recall score of 0.952, while the Logistic Regression model had the highest F1 score of 0.9141. The table shows that all models performed well, with the Random Forest model topping the accuracy score."
2092,"caption: Performance comparison of different models using various metricstable: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.87,0.89,0.85,0.92, KNN,0.82,0.83,0.76,0.93, Naive Bayes,0.81,0.82,0.75,0.90, Decision Tree,0.94,0.94,0.94,0.94","Table above presents the performance comparison of different models using various evaluation metrics such as accuracy, F1 score, precision, and recall. The SVM model achieved the highest accuracy score of 0.87, where the decision tree has the highest F1 score, precision, and recall of 0.94. The KNN and Naive Bayes models had lower performance results with an accuracy score of 0.82 and 0.81, respectively. This table's findings show that the decision tree model achieved the most consistent performance across all metrics, while the SVM model achieved the highest accuracy score but was not the best in other metrics."
2093,"caption: Performance comparison of different models using multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Decision Tree,0.920,0.812,0.844,0.827, Random Forest,0.947,0.963,0.897,0.929, Support Vector Machine,0.921,0.873,0.899,0.886, Multi-Layer Perceptron,0.933,0.919,0.925,0.922","The above table demonstrates the performance comparison of different models based on various evaluation metrics, including accuracy, precision, recall, and F1 score. Decision Tree, Random Forest, Support Vector Machine, and Multi-Layer Perceptron models are presented in the table. The table highlights that the Random Forest model obtained the highest accuracy of 0.947 with a precision of 0.963 and recall of 0.897, producing an F1 score of 0.929, which is the second-best among all models. Although the decision tree model positioned in the last, it shows a close F1 score of 0.827. Ultimately, the table shows that the multiple evaluation metrics can provide comprehensive insights into the models' performances."
2094,"caption: Model performances based on various evaluation metrics using the same dataset.table: Model,Accuracy,Precision,Recall,F1-score, Random Forest,0.80,0.86,0.77,0.81, XGBoost,0.82,0.87,0.80,0.83, Decision Tree,0.70,0.72,0.65,0.68, Logistic Regression,0.75,0.77,0.72,0.73, Support Vector Machine,0.77,0.82,0.76,0.78","The table displays the performance of five models - Random Forest, XGBoost, Decision Tree, Logistic Regression, and Support Vector Machine - on a dataset using multiple evaluation metrics. The models' performances are evaluated based on Accuracy, Precision, Recall, and F1-score. Notably, XGBoost had the highest accuracy of 0.82, with a Precision of 0.87 and an F1-score of 0.83, while Decision Tree had the lowest Accuracy of 0.70, with a Precision of 0.72 and an F1-score of 0.68. Interestingly, the Random Forest had a high Precision of 0.86 and a Recall of 0.77, resulting in an F1-score of 0.81. Overall, the table highlights the varying performances of different models on the same dataset."
2095,"caption: Model comparison based on accuracy, F1-score, precision, and recall metrics.table: Model,Accuracy,F1-score,Precision,Recall, Model A,0.86,0.81,0.79,0.83, Model B,0.81,0.77,0.71,0.84, Model C,0.90,0.84,0.88,0.81, Model D,0.92,0.88,0.92,0.85, Model E,0.88,0.82,0.77,0.88","The table presents a comparison of five models based on the evaluation metrics accuracy, F1-score, precision, and recall. The models are labeled as Model A, Model B, Model C, Model D, and Model E. The results show that Model D has the highest accuracy score of 0.92 and F1-score of 0.88. Additionally, Model D has the highest precision score of 0.92, while Model C has the highest recall score of 0.81. Interestingly, Model E has the lowest accuracy score of 0.88 but it has the highest recall score of 0.88."
2096,"caption: Comparison of Model Performance on Different Metrics.table: Model,Accuracy,F1 Score,AUC Score, Logistic Regression,0.83,0.83,0.90, Random Forest,0.87,0.86,0.94, SVM,0.81,0.81,0.86, XGBoost,0.89,0.89,0.95","Table presents a comparison of model performances on three different metrics: Accuracy, F1 Score, and AUC Score. The Logistic Regression model achieved an accuracy score of 0.83, the F1 score of 0.83, and an AUC score of 0.90. The Random Forest model outperformed the Logistic Regression model with an accuracy score of 0.87, the F1 score of 0.86, and an AUC score of 0.94. The SVM model showed an accuracy score of 0.81, F1 score of 0.81, and AUC score of 0.86. Finally, the XGBoost model gives the best results with an accuracy score of 0.89, F1 score of 0.89, and an AUC score of 0.95. The XGBoost model exhibits superior performance compared to all the other models across all three metrics."
2097,"caption: Comparison of different classification models based on multiple evaluation metrics.table: Model,F1-Score,Precision,Recall,Accuracy, SVM,0.90,0.87,0.93,0.88, KNN,0.83,0.79,0.89,0.82, Naïve Bayes,0.78,0.83,0.74,0.79, Decision Tree,0.87,0.91,0.84,0.85, Random Forest,0.92,0.95,0.89,0.91","The table compares the performance of multiple classification models based on different evaluation metrics. The table includes SVM, KNN, Naïve Bayes, Decision Tree, and Random Forest models' F1-score, Precision, Recall, and Accuracy. Interestingly, the Random forest model shows the best performance in terms of all evaluation metrics. It obtained an F1-score of 0.92, Precision of 0.95, Recall of 0.89, and Accuracy of 0.91. The SVM model also achieved a good performance with an F1-score of 0.90 and a precision of 0.87. The table provides useful information on model selection, where the Random forest model is the best choice for classifying the given dataset based on the evaluated metrics."
2098,"caption: Performance metrics comparison among different models.table: Model,Accuracy,F1-Score,Precision,Recall, Model 1,0.82,0.76,0.81,0.75, Model 2,0.85,0.78,0.79,0.83, Model 3,0.89,0.84,0.85,0.83, Model 4,0.79,0.67,0.68,0.75, Model 5,0.91,0.87,0.88,0.90","The presented table compares multiple models' performances using accuracy, F1-Score, Precision, and Recall evaluation metrics. Model 1 achieved an accuracy score of 0.82 and an F1-Score of 0.76, whereas Model 2 demonstrates better performance in accuracy (0.85) and recall (0.83) scores. However, Model 3 is the best performing model with the highest accuracy score of 0.89, F1-Score of 0.84, and precision of 0.85. Remarkably, Model 5 demonstrated the best performance in accuracy (0.91) and F1-Score (0.87). Interestingly, Model 4 showed poor performance compared to other models, and the precision score of 0.68 was the lowest among all models, indicating that Model 4 has a high false-positive rate."
2099,"caption: Table 1: Comparison of different models based on multiple evaluation metrics.table: Model,F1-Score,Precision,Recall,Accuracy, SVM,0.93,0.92,0.94,0.91, Random Forest,0.91,0.95,0.89,0.93, XGBoost,0.94,0.91,0.98,0.92, Naive Bayes,0.86,0.80,0.94,0.87","Table 1 presents a comparison of multiple models based on F1-Score, Precision, Recall, and Accuracy evaluation metrics. The table includes SVM, Random Forest, XGBoost, and Naive Bayes models' performance results. Notably, the XGBoost model achieved the best F1-Score of 0.94, whereas SVM model achieved the best Precision of 0.92. Further, XGBoost had the highest Recall of 0.98, and the SVM model had the highest Accuracy of 0.91. Interestingly, the Naive Bayes model had the lowest F1-Score, Precision, and Accuracy, yet, it had the highest Recall score of 0.94. Overall, Table 1 provides a comprehensive comparison of different models based on multiple evaluation metrics."
2100,"caption: Performance comparison of different models on various evaluation metrics.table: Model,F1 Score,Precision,Recall,Specificity,AUC, Logistic Regression,0.75,0.66,0.87,0.44,0.66, Random Forest,0.76,0.68,0.87,0.47,0.68, XGBoost,0.78,0.72,0.85,0.54,0.68, Multilayer Perceptron,0.70,0.62,0.83,0.34,0.64, Decision Tree,0.68,0.63,0.74,0.54,0.64","Table above demonstrates the comparative results of different models on multiple evaluation metrics like F1 score, precision, recall, specificity, and AUC. The table includes Logistic Regression, Random Forest, XGBoost, Multilayer Perceptron, and Decision Tree. Interestingly, XGBoost had the highest F1 score of 0.78, while Random Forest had the highest precision with a rate of 0.68. Recall measure's highest score was achieved by Logistic Regression with 0.87. In contrast, specificity had the highest score by XGBoost, with 0.54. Finally, the area under the curve (AUC) measure showed Multilayer Perceptron reached the lowest score of 0.64, while Random Forest and XGBoost had the highest results with 0.68."
2101,"caption: Table 4: Comparison of different models based on precision, recall, and F1-score.table: Model,Precision,Recall,F1-Score, Decision Tree,0.86,0.91,0.88, K-Nearest Neighbors,0.91,0.81,0.86, Naive Bayes,0.78,0.92,0.84, Support Vector Machine,0.89,0.84,0.86","Table 4 provides a comparison of different models based on their precision, recall, and F1-score. The table includes the Decision Tree, K-Nearest Neighbors, Naive Bayes, and Support Vector Machine models. The table suggests that the K-Nearest Neighbors model achieved the best precision score of 0.91 and had a higher recall rate than Decision Tree, Naive Bayes, and Support Vector Machine. The Decision Tree model performed significantly better on recall at 0.91 and F1-score at 0.88 than the other models. The Support Vector Machine model also generated high precision at 0.89 while maintaining a reasonable recall rate. Overall, the results suggest that different models may perform better on different evaluation metrics, and the choice of models should depend on the specific needs of the research."
2102,"caption: Comparison of model performances based on multiple evaluation metrics.table: Model,Precision,Accuracy,F1 Score,ROC-AUC, Logistic Regression,0.86,0.83,0.89,0.78, Decision Tree,0.81,0.75,0.85,0.68, Random Forest,0.89,0.88,0.91,0.84, Support Vector Machine,0.84,0.82,0.86,0.80, Gradient Boosting,0.91,0.90,0.93,0.86","Table presents a comparison of multiple models using four different evaluation metrics, namely precision, accuracy, F1 score, and ROC-AUC. The table includes Logistic Regression, Decision Tree, Random Forest, Support Vector Machine, and Gradient Boosting models. All models were trained and tested on the same dataset. Interesting observations in the table include Gradient Boosting having the highest performance across all metrics, while Logistic Regression shows consistency in performance with no significant difference between precision, accuracy, and F1 Score. On the other hand, Random Forest performance is marginally better than that of Support Vector Machine, except in the case of F1 score."
2103,"caption: Table 4: Model performance on various evaluation metrics with different modelstable: Model,Accuracy,F1-score,AUC,Precision, SVM-RBF,0.93,0.92,0.89,0.99, Random Forest,0.91,0.9,0.86,0.97, XGBoost,0.89,0.88,0.84,0.95, Logistic Regression,0.87,0.86,0.82,0.93, Decision Tree,0.84,0.83,0.78,0.88","Table 4 includes a comparison of five different models' performances based on four evaluation metrics, i.e., accuracy, F1-score, AUC, and precision. SVM-RBF attained the highest accuracy of 0.93 and precision of 0.99. The Random Forest model achieved the second-highest results, with an accuracy of 0.91 and precision of 0.97. By contrast, the Decision Tree model achieved the lowest performance in all metrics. Interestingly, SVM-RBF, despite having the highest accuracy, performed poorly in AUC. Therefore, one should consider all evaluation metrics while selecting the best model for the required task."
2104,"caption: Table 4: Model Comparison Using Various Evaluation Metricstable: Model,Accuracy,F1-score,Precision,Recall, SVM,0.82,0.78,0.81,0.76, Random Forest,0.87,0.84,0.85,0.88, XGBoost,0.89,0.85,0.88,0.83, Neural Net,0.87,0.83,0.88,0.78","Table 4 shows a comparison of different models' performances using various evaluation metrics such as Accuracy, F1-score, Precision, and Recall. The table exhibits SVM, Random Forest, XGBoost, and Neural Net models' results. Notably, the Random forest model attained the highest accuracy score of 0.87, followed by XGBoost and Neural net with 0.89 and 0.87 respectively. The Random forest model also performed well in terms of F1-score and Precision, with F1-score of 0.84 and Precision of 0.85, while XGBoost had the best recall score of 0.83. The SVM model, on the other hand, had the lowest Recall score of 0.76 and the lowest F1-score of 0.78. Overall, the table provides a comprehensive comparison of the models' performances using various evaluation metrics."
2105,"caption: Table 4: Performance measures for various models.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.86,0.89,0.83,0.86, K-Nearest Neighbors,0.81,0.83,0.77,0.80, Decision Tree,0.78,0.79,0.76,0.77, Random Forest,0.89,0.90,0.88,0.89, Extreme Gradient Boosting,0.91,0.93,0.89,0.91","Table 4 displays the accuracy, precision, recall, and F1 scores of five different models. The models include Logistic Regression, K-Nearest Neighbors, Decision Tree, Random Forest, and Extreme Gradient Boosting (XGBoost). Notably, the XGBoost model achieved the highest accuracy of 0.91, followed by the Random Forest model, which attained a performance of 0.89. Also, the XGBoost model achieved the highest precision of 0.93, while the Logistic Regression model had the highest recall of 0.83. Finally, the XGBoost model achieved the highest F1 score of 0.91, followed closely by the Logistic Regression and Random Forest models."
2106,"caption: Table 4: Model Evaluation Metrics for different classifiers based on a binary classification problem.table: Model Name,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.81,0.78,0.85,0.81, Decision Tree,0.76,0.67,0.77,0.71, Random Forest,0.83,0.80,0.88,0.83, Support Vector Machine,0.80,0.82,0.73,0.76, Gradient Boosting,0.85,0.86,0.82,0.83","Table 4 shows the evaluation metrics for five different models for a binary classification problem. The models include Logistic Regression, Decision Tree, Random Forest, Support Vector Machine, and Gradient Boosting. The evaluation metrics presented in the table include Accuracy, Precision, Recall, and F1-Score. Interestingly, the models' accuracy ranges between 0.76 to 0.85, with Gradient Boosting achieving the highest accuracy of 0.85. The model that achieves the best precision is Gradient Boosting with 0.86, while the model that achieves the best recall is Random Forest with 0.88. In terms of F1-Score, Gradient Boosting achieved the highest score of 0.83. Overall, the results suggest that Gradient Boosting and Random Forest models outperform the others based on the evaluation metrics."
2107,"caption: Performance comparison of different models.table: Model,Accuracy,Recall,Precision,F1 Score, Logistic Reg,0.875,0.85,0.954,0.899, SVM,0.84,0.78,0.934,0.850, Naive Bayes,0.78,0.70,0.893,0.785, Decision Tree,0.77,0.68,0.827,0.741, Random Forest,0.89,0.84,0.948,0.892","Table above presents the performance of different models using various evaluation metrics such as Accuracy, Recall, Precision, and F1 Score. The models compared in the table are Logistic Regression, SVM, Naive Bayes, Decision Tree, and Random Forest. Interestingly, the Random Forest model shows the highest Accuracy and Precision, i.e., 0.89 and 0.948, respectively, whereas, Naive Bayes achieved the lowest result in both metrics. Similarly, Logistic Regression performed the best in terms of Recall, i.e., 0.85, while Decision Tree had the lowest F1 Score of 0.741. These results provide useful insights to the researchers who are working on creating robust models for their research domain."
2108,"caption: Comparison of different models performances based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Random Forest,0.89,0.90,0.87,0.88, Logistic Regression,0.86,0.86,0.87,0.86, Support Vector Machine,0.84,0.82,0.84,0.83, Multi-layer Perceptron,0.89,0.89,0.90,0.89, Naive Bayes,0.81,0.80,0.82,0.81","This table presents the performance evaluation of different models based on accuracy, precision, recall, and F1 score. The models include Random Forest, Logistic Regression, Support Vector Machine, Multi-layer Perceptron, and Naive Bayes. All models were tested on the same dataset, and the accuracy of all models is above 80%. The Random Forest model shows the highest accuracy of 0.89. The Multi-layer Perceptron model has the best precision, recall, and F1 scores of 0.89, 0.90, and 0.89, respectively. The Naive Bayes model shows the lowest performance in all metrics, which might suggest that the selected features are not linearly separable."
2109,"caption: Performance comparison of different models using various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, SVM,0.92,0.94,0.88,0.91, KNN,0.88,0.86,0.85,0.85, RF,0.94,0.95,0.92,0.94, MLP,0.91,0.93,0.85,0.89, NB,0.84,0.81,0.90,0.85","The table above provides a comparison of five different machine learning models' performance in a binary classification task. The models considered include SVM, KNN, RF, MLP, and NB. The evaluation metrics used to compare their performance are accuracy, precision, recall, and F1-score. It is clear that RF has the highest accuracy, with a score of 0.94, and also achieved the highest precision and F1-score among the models. However, SVM and MLP models are not far behind in terms of performance. Interestingly, NB model shows the highest recall score with a score of 0.90."
2110,"caption: Table 4: Performance Metrics of Different Modelstable: Model,Accuracy,Precision,Recall, SVM,0.95,0.96,0.92, kNN,0.91,0.92,0.84, RF,0.96,0.96,0.96, XGB,0.97,0.97,0.96","The table displays the performance metrics of multiple machine learning models, including SVM, kNN, RF (Random Forest), and XGB (XGBoost). The models' performance is evaluated based on three metrics: accuracy, precision, and recall. The RF and XGB models show the highest accuracy with 0.96 and 0.97, respectively. The SVM model exhibited the best precision performance with 0.96, while the recall was the highest in the RF model with 0.96. The performance metrics of the kNN model are slightly below the others, with accuracy, precision, and recall scores of 0.91, 0.92, and 0.84, respectively. Overall, the RF and XGB models perform well across all metrics, while the SVM model maintains high precision."
2111,"caption: Model performance comparison based on different evaluation metricstable: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.81,0.76,0.65,0.70, SVM,0.82,0.77,0.70,0.72, Random Forest,0.84,0.80,0.75,0.78, Decision Tree,0.75,0.68,0.72,0.65, KNN,0.80,0.74,0.68,0.70","The above table presents the model performance comparison of different classifiers, including Logistic Regression, SVM, Random Forest, Decision Tree, and KNN, on different evaluation metrics, i.e., Accuracy, Precision, Recall, and F1-score. From the table, it is observed that Random Forest outperforms all other models in all evaluation metrics with top ranks in Accuracy (0.84) and F1-score (0.78), while SVM has the highest Precision 0.77. On the other hand, the Decision Tree model performed the poorest among all models in terms of Accuracy, Precision, and F1-score, while having the highest Recall score (0.72) in the comparison."
2112,"caption: Performance evaluation of multiple models using various metrics.table: Models,F1,Accuracy,Precision,Recall, Model 1,0.75,0.80,0.80,0.76, Model 2,0.80,0.85,0.82,0.78, Model 3,0.82,0.87,0.85,0.79, Model 4,0.78,0.83,0.81,0.75, Model 5,0.81,0.86,0.83,0.80","Table above presents the performance evaluation of multiple models using different evaluation metrics. The models were evaluated based on F1 score, Accuracy, Precision, and Recall. Notably, Model 3 shows the best performance based on all metrics, achieving 0.82 F1 score, 0.87 accuracy, 0.85 precision, and 0.79 recall. Model 2 and Model 5 also show promising performance with decent F1 scores of 0.80 and 0.81, respectively. However, Model 5 achieved the highest accuracy score of 0.86. Model 4 exhibits the lowest performance based on all metrics among all the models."
2113,"caption: The model performance metrics for different machine learning algorithmstable: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.92,0.95,0.90,0.92, Naive Bayes,0.86,0.82,0.91,0.86, SVM,0.95,0.96,0.94,0.95, Decision Tree,0.89,0.87,0.93,0.90, Random Forest,0.94,0.93,0.96,0.94","Table 4 shows the comparison of different machine learning models based on their accuracy, precision, recall, and F1 score metrics. The models examined are Logistic Regression, Naive Bayes, SVM, Decision Tree, and Random Forest. The SVM model achieved the highest accuracy score of 0.95, while the Naive Bayes model had the lowest accuracy score of 0.86. Interestingly, the Naive Bayes model achieved the highest recall of 0.91, while the Random Forest model recorded the highest precision and F1 scores of 0.93 and 0.94, respectively. Overall, the Random Forest model gives the best performance across all the evaluation metrics."
2114,"caption: Table 4: Model performances for different evaluation metrics.table: Model,Accuracy,F1 Score,AUC Score, Model A,0.92,0.89,0.93, Model B,0.85,0.79,0.87, Model C,0.94,0.91,0.92, Model D,0.89,0.82,0.88","Table 4 shows the performance of four different models based on three evaluation metrics, namely accuracy, F1 score, and AUC score. The best performance in terms of accuracy is achieved by Model C with a score of 0.94. For F1 score, Model A performed the best, yielding a score of 0.89. Interestingly, Model C had the lowest F1 score despite having the highest accuracy score. For AUC score, Model A and Model D showed similar performances with scores of 0.93 and 0.88, respectively. Overall, Model C appeared to perform the best, achieving the highest accuracy and second-highest AUC score."
2115,"caption: Table 1 - Model Performance Comparison using Multiple Evaluation Metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.72,0.73,0.69,0.71, Decision Tree,0.65,0.62,0.68,0.64, Random Forest,0.82,0.84,0.81,0.81, Support Vector Machine,0.75,0.80,0.71,0.75, Gradient Boosting,0.80,0.82,0.78,0.79","Table 1 is a comparison of models' performances using multiple evaluation metrics, including accuracy, precision, recall, and F1 score. The table shows the performance of five different models, including Logistic Regression, Decision Tree, Random Forest, Support Vector Machine, and Gradient Boosting. Notably, the Random Forest model has the highest accuracy and precision of 0.82 and 0.84, respectively. The Gradient Boosting model has the highest recall and F1 score with 0.78 and 0.79, respectively. The Decision Tree has the lowest accuracy with 0.65, while it has the highest recall of 0.68. The table's results suggest that the Random Forest model outperforms the other models in terms of accuracy and precision, while the Gradient Boosting model performs the best in terms of recall and F1 score."
2116,"caption: Table 4: Performance comparison of different models based on accuracy, precision, recall, and F1 score.table: Model,Accuracy,Precision,Recall,F1 Score, LR,0.73,0.73,0.78,0.75, SVM,0.69,0.70,0.66,0.67, RF,0.83,0.85,0.81,0.82, XGB,0.80,0.80,0.83,0.81, MLP,0.84,0.86,0.82,0.83","Table 4 presents the performance comparison of five different models based on four various evaluation metrics, namely accuracy, precision, recall, and F1 score. The table exhibits LR, SVM, RF, XGB, and MLP models' performance results. Notably, the MLP model has the highest accuracy, precision, and F1 score with scores of 0.84, 0.86, and 0.83, respectively. Conversely, the SVM model has the lowest accuracy and F1 score with scores of 0.69 and 0.67, respectively. Interestingly, the RF model outperforms the other models with the highest recall of 0.81."
2117,"caption: Model performances on classification task based on accuracy, precision, recall, and F1-score.table: Model,Accuracy,Precision,Recall,F1-Score, SVM with RBF Kernel,0.923,0.918,0.897,0.907, Logistic Regression,0.888,0.904,0.858,0.875, Neural Network,0.927,0.923,0.904,0.911, XGBoost,0.924,0.920,0.900,0.910, Random Forest,0.922,0.921,0.891,0.907","The table presents the evaluation of various models based on their accuracy, precision, recall, and F1-score in classification tasks. SVM with RBF Kernel stood out with an accuracy score of 0.923 while the Neural Network had the highest accuracy score of 0.927. On the other hand, Logistic Regression yielded the highest precision and recall rates with scores of 0.904 and 0.858, respectively. The Random Forest model yielded the highest F1-score of 0.907. Notably, all models displayed competitive performances across the different metrics indicating their overall strengths in the classification task."
2118,"caption: A comparison of different models' evaluation metrics.table: Model,Accuracy,Precison,Recall,F1-score, SVM,0.94,0.92,0.96,0.94, KNN,0.89,0.83,0.94,0.88, Decision trees,0.83,0.82,0.81,0.81, Random Forest,0.94,0.93,0.94,0.93, XGBoost,0.95,0.94,0.95,0.94, AdaBoost,0.93,0.92,0.93,0.92, DNN,0.96,0.96,0.96,0.96","Table presents a comparison of different machine learning models in terms of accuracy, precision, recall, and F1-score. The table compares the performance of SVM, KNN, Decision Trees, Random Forest, XGBoost, AdaBoost, and DNN models. Notably, the highest-performing model was the DNN model with the highest accuracy, precision, recall, and F1-score of 0.96. Random Forest and XGBoost models also showed strong performance with high precision, recall, and F1-score of 0.93 and 0.94, respectively. Furthermore, KNN and Decision Trees models have the lowest performance measures, with an F1-score of 0.88 and 0.81, respectively. Ultimately, the table presents a comprehensive comparison of different machine learning models with varying performance results across multiple evaluation metrics."
2119,"caption: Performance results of various models using different evaluation metrics.table: Model,Precision,Recall,F1-score,AUC, Model 1,0.85,0.93,0.89,0.78, Model 2,0.72,0.81,0.76,0.61, Model 3,0.89,0.91,0.90,0.81, Model 4,0.78,0.85,0.81,0.65, Model 5,0.91,0.92,0.91,0.84","The table presents the performance results of five different models using four different evaluation metrics. The evaluation metrics included are Precision, Recall, F1-score, and AUC. Model 1 achieved the highest Precision of 0.85, while Model 5 had the highest Recall score of 0.92. Model 5 also has the highest F1-score of 0.91, followed closely by Model 3 with an F1-score of 0.90. Model 5 also achieved the highest AUC score of 0.84, while Model 2 had the lowest performance across all metrics. Overall, the table indicates that Model 5 appears to be the best-performing model across all evaluation metrics, while Model 2 had the worst performance."
2120,"caption: Comparison of different models’ performances based on multiple evaluation metrics.table: Model,F1 Score,Accuracy,Precision,Recall, A,0.67,0.79,0.64,0.70, B,0.72,0.81,0.68,0.77, C,0.75,0.83,0.72,0.78, D,0.68,0.80,0.63,0.74, E,0.69,0.79,0.65,0.73","Table shows the performance comparison of five different models based on four evaluation metrics - F1 Score, Accuracy, Precision, and Recall. The highest F1 score is obtained by Model C with a score of 0.75, while Model B achieved the highest accuracy score with 0.81. Model C also displayed the highest precision (0.72), and Model B exhibited the highest recall (0.77). Overall, Model C appears to be the most performant with the highest F-1 score, precision, and recall. However, it has slightly lower accuracy than Model B, which reveals its tendency to predict some negative outcomes as positive."
2121,"caption: Comparison of different models in terms of accuracy, F1-score, and AUC.table: Model,Accuracy,F1-score,AUC, Model 1,0.87,0.88,0.91, Model 2,0.82,0.75,0.84, Model 3,0.89,0.89,0.92, Model 4,0.91,0.89,0.9, Model 5,0.85,0.81,0.88","The table above presents a comparison of five separate models' performance metrics. The models evaluated in the table vary in their accuracy, F1-score, and AUC. The results show that Model 4 performed the best in terms of accuracy and AUC, reaching 0.91 and 0.9, respectively. Conversely, Model 2 yielded the lowest accuracy of 0.82 and F1-score of 0.75. Notably, differences in model performance can be attributed to various factors such as model architecture, training data, and evaluation criteria. Overall, the table provides a snapshot of each model's performance, demonstrating the need for careful consideration in model selection for specific tasks."
2122,"caption: Table 4: Performance metrics of various classification modelstable: Model,F1-Score,Precision,Recall,Accuracy, Logistic Regression,0.81,0.86,0.79,0.85, Random Forest,0.83,0.87,0.81,0.86, CatBoost,0.86,0.88,0.85,0.87, Gradient Boosting,0.87,0.89,0.87,0.88, Support Vector Machine,0.82,0.88,0.80,0.84",
2123,"caption: A comparison of the Accuracy, F1-Score, Precision and Recall of different models.table: Model,Accuracy,F1-Score,Precision,Recall, LR,0.856,0.857,0.876,0.848, SVM,0.846,0.846,0.837,0.856, RF,0.872,0.874,0.870,0.878, MLP,0.880,0.882,0.879,0.884, KNN,0.819,0.819,0.808,0.832","Table above compares the performances of five different models using several evaluation metrics. The models are Logistic Regression (LR), Support Vector Machines (SVM), Random Forest (RF), Multilayer Perceptron (MLP) and K-Nearest Neighbors (KNN), respectively. The Accuracy, F1-Score, Precision and Recall of each model is presented in the corresponding columns. The MLP model is observed to outperform other models with the highest Accuracy of 0.880 and F1-Score of 0.882 while, the RF model achieved the highest Precision of 0.870 and Recall of 0.878 among the models. The KNN model lags behind with the least performance among the models across all metrics."
2124,"caption: Comparison of model performances based on different evaluation metricstable: Models,Accuracy,F1 Score,Precision,Recall, Model A,0.89,0.87,0.90,0.84, Model B,0.91,0.90,0.87,0.93, Model C,0.88,0.86,0.91,0.82, Model D,0.92,0.91,0.89,0.94","Table comparing four different models' performances based on four different evaluation metrics, namely accuracy, F1 score, precision, and recall. The table shows that Model D has the highest accuracy and F1 score metrics with 0.92 and 0.91, respectively. The highest precision metric is obtained by Model B with a score of 0.87, while Model C has the lowest precision score. Meanwhile, Model D shows the highest recall score of 0.94. Overall, Model D performs better than other models in most evaluation metrics, while Model A and Model C show similar accuracy, F1 score, and precision scores."
2125,"caption: Table 4: Model performance comparison using different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score,ROC-AUC, Logistic Regression,0.97,0.96,0.98,0.97,0.99, Random Forest,0.98,0.99,0.95,0.97,0.98, Support Vector Machine,0.96,0.96,0.93,0.94,0.97, XGBoost,0.99,0.98,0.99,0.99,0.99, Decision Tree,0.95,0.94,0.95,0.94,0.95","Table 4 presents the performance results of five different models, Logistic Regression, Random Forest, Support Vector Machine, XGBoost, and Decision Tree model, based on various evaluation metrics. The evaluation metrics considered are accuracy, precision, recall, F1 score, and ROC-AUC. The Random Forest model displayed the highest accuracy score of 0.98, while the XGBoost model recorded the best precision score of 0.98 and highest recall score of 0.99, resulting in the best F1 score of 0.99. Moreover, the Logistic Regression and XGBoost models demonstrated the best and the same ROC-AUC score of 0.99, respectively."
2126,"caption: Model performance for different classifiers based on evaluation metricstable: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.85,0.82,0.88,0.77, KNN,0.78,0.72,0.8,0.66, RF,0.91,0.9,0.92,0.88, XGB,0.89,0.87,0.91,0.83","The table presents a comparison of different classifiers using Accuracy, F1-Score, Precision, and Recall evaluation metrics. The table includes Support Vector Machine (SVM), K-Nearest Neighbor (KNN), Random Forest (RF), and XGBoost (XGB) models' performance scores. The Random Forest model achieved the highest accuracy score of 0.91, followed by XGBoost with 0.89. Similarly, Random Forest and SVM models achieved the highest F1-Score with a close score of 0.9 and 0.82, respectively. The highest Precision was observed in Random Forest with a score of 0.92. Interestingly, SVM's recall score was the highest with 0.77 while the Random Forest and XGBoost models showed a similar recall score of 0.88 and 0.83, respectively."
2127,"caption: Model Performance on Binary Classification Tasktable: Model,Accuracy,F1-Score,Precision, Logistic Regression,0.82,0.74,0.76, Decision Tree,0.80,0.68,0.73, Random Forest,0.87,0.82,0.83, Gradient Boosting,0.88,0.84,0.85, Support Vector Machine,0.89,0.86,0.87","The table presents a comparison between five different machine learning models on a binary classification task, with their respective accuracy, F1-score and precision. The evaluation metrics reflect how well the models perform in terms of correctly identifying positive instances and avoiding false positives. The Random Forest and Gradient Boosting models display the best accuracy scores of 0.87 and 0.88, respectively, while the Support Vector Machine model shows the highest performance in terms of precision with a score of 0.87. Further, the Gradient Boosting and SVM models show the highest F1-scores with values ranging from 0.84 to 0.86, which indicates that these models have a good balance between precision and recall."
2128,"caption: Model performance comparison based on different evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.85,0.82,0.85,0.81, Naive Bayes,0.79,0.76,0.70,0.83, Decision Tree,0.75,0.70,0.72,0.68, Random Forest,0.88,0.87,0.90,0.84, Gradient Boosting,0.91,0.90,0.94,0.87","This table presents a comparison of five models based on different evaluation metrics. The models include SVM, Naive Bayes, Decision Tree, Random Forest, and Gradient Boosting. The metrics used to evaluate each model are Accuracy, F1 Score, Precision, and Recall. Interestingly, the Gradient Boosting model achieved the best overall performance and highest accuracy score of 0.91. The Random Forest model also displayed good performance with an accuracy score of 0.88 and an F1 score of 0.87. However, the Naive Bayes model had the lowest performance and scores, across all the evaluation metrics."
2129,"caption: Table 4: Performance comparison of different models using various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.73,0.70,0.77,0.73, Naive Bayes,0.68,0.61,0.87,0.71, Decision Tree,0.76,0.75,0.76,0.75, Random Forest,0.83,0.81,0.85,0.83, Support Vector Machine,0.78,0.76,0.79,0.77",
2130,"caption: Comparison of model performances based on different evaluation metricstable: Model,F1 Score (class 1),F1 Score (class 2),F1 Score (average),AUC Score, Model A,0.86,0.67,0.77,0.89, Model B,0.78,0.73,0.72,0.87, Model C,0.63,0.85,0.67,0.74, Model D,0.88,0.58,0.75,0.93, Model E,0.75,0.77,0.76,0.81","The table presents a comparison of the F1 score for class 1, F1 score for class 2, average F1 score, and AUC score of different models. The models are denoted by Model A, Model B, Model C, Model D, and Model E. The table highlights the F1 score for each class and the average F1 score for all models. Notably, Model D has the highest F1 score for class 1 of 0.88 and the highest AUC score of 0.93, while Model C performed the best in the F1 score for class 2 with a score of 0.85. In terms of the average F1 score, Model A has the highest score of 0.77. Overall, the table shows variations in models' performances based on different evaluation metrics."
2131,"caption: Model performance on different evaluation metricstable: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.82 ± 0.03,0.82 ± 0.04,0.83 ± 0.05,0.82 ± 0.03, SVM,0.85 ± 0.02,0.85 ± 0.03,0.86 ± 0.03,0.85 ± 0.02, Random Forest,0.88 ± 0.01,0.88 ± 0.02,0.88 ± 0.03,0.88 ± 0.02, Neural Network,0.90 ± 0.01,0.90 ± 0.02,0.91 ± 0.03,0.90 ± 0.01","Table 4 compares model performances based on different evaluation metrics. The table includes Logistic Regression, SVM, Random Forest, and Neural Network models and their accuracy, F1-score, precision, and recall scores. All models were trained and tested using the same dataset. The table shows that the Neural Network model had the best performance across all evaluation metrics with 0.90 ± 0.01 accuracy, 0.90 ± 0.02 F1-score, 0.91 ± 0.03 precision, and 0.90 ± 0.01 recall. Moreover, Random Forest and SVM models performed similarly, while Logistic Regression had lower performances across all evaluation metrics. The outcome shows that the Neural Network model could be recommended for potential applications in this field."
2132,"caption: Comparison of Different Machine Learning Models across Multiple Evaluation Metric.table: Model,Accuracy,F1-score,Precision,Recall, Random Forest,0.84,0.82,0.81,0.84, Logistic Regression,0.80,0.78,0.77,0.80, Gradient Boosting,0.85,0.84,0.82,0.85, Support Vector Machines,0.82,0.80,0.79,0.82","The table illustrates the performance of different machine learning models based on four evaluation metrics—accuracy, F1-score, precision, and recall. The Random Forest model has high accuracy (0.84), F1-score (0.82), precision (0.81), and recall (0.84) scores. The Gradient Boosting model had good overall performance on all the evaluation metrics, with accuracy (0.85), F1-score (0.84), precision (0.82) and recall (0.85). The Logistic Regression model had the lowest score among all the models in terms of accuracy, F1-score, precision, and recall. The Support Vector Machines model performed reasonably well overall. Overall, the table showcases that the Random Forest and Gradient Boosting models produce better results than the Support Vector Machines and Logistic Regression models."
2133,"caption: Model performances based on different evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.86,0.87,0.89,0.86, Decision Tree,0.76,0.77,0.76,0.78, Random Forest,0.89,0.90,0.92,0.89, Support Vector Mach.,0.85,0.88,0.90,0.85, Gradient Boosting,0.87,0.89,0.91,0.87","Table 4 displays the model performances based on different evaluation metrics, namely Accuracy, F1-Score, Precision, and Recall. The table consists of five models, namely Logistic Regression, Decision Tree, Random Forest, Support Vector Machine, and Gradient Boosting. Interestingly, Random Forest performed the best among all models, achieving high accuracy, F1-Score, Precision, and Recall with scores of 0.89, 0.90, 0.92, and 0.89, respectively. However, Gradient Boosting also showed notable performance, achieving high scores in all evaluation metrics with an accuracy score of 0.87, F1-Score of 0.89, Precision of 0.91, and Recall of 0.87. Overall, the results in Table 4 highlight the importance of selecting the appropriate evaluation metrics when comparing model performances."
2134,"caption: Table 4: Model performance comparison based on different evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.82,0.76,0.84,0.70, KNN,0.79,0.71,0.81,0.64, Naive Bayes,0.72,0.66,0.69,0.63, Decision Tree,0.76,0.69,0.71,0.68","Table 4 shows a comparison of model performance based on different evaluation metrics - Accuracy, F1-Score, Precision, and Recall. The table exhibits four different models - SVM, KNN, Naive Bayes, and Decision Tree. The accuracy metric shows the percentage of correct predictions the model makes, where the SVM model achieved an accuracy of 0.82, the highest among the evaluated models. The F1-Score considers both precision and recall, where the SVM model shows the highest score of 0.76. The precision metric measures the percentage of true positives among all positive predictions, where the KNN model shows the highest score of 0.81. The recall metric measures the percentage of true positives correctly identified by the model, where the SVM model achieved the highest recall score of 0.70."
2135,"caption: Comparison of different models' performance based on various evaluation metrics.table: Model,F1-score,Accuracy,Precision,Recall, Model A,0.84,0.85,0.81,0.87, Model B,0.81,0.83,0.74,0.89, Model C,0.87,0.86,0.89,0.85, Model D,0.79,0.81,0.72,0.87, Model E,0.85,0.84,0.78,0.93","Table 4 presents a comparison of different models' performances based on four evaluation metrics: F1-score, accuracy, precision, and recall. Model A achieved the highest F1-score of 0.84, while Model C performed the best with respect to accuracy with a score of 0.86. Model C also had the highest precision score of 0.89, whereas Model E achieved the highest recall of 0.93. Interestingly, the highest performing models based on individual metrics varied across different evaluation metrics, indicating the importance of examining multiple metrics while evaluating model performance."
2136,"caption: Table 4. Model Performances Based on Multiple Evaluation Metrics.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.86,0.88,0.82,0.85, KNN,0.72,0.76,0.69,0.72, Random Forest,0.91,0.93,0.90,0.91, Naive Bayes,0.64,0.61,0.63,0.61","Table 4 presents various models' performance based on multiple evaluation metrics, such as accuracy, precision, recall, and F1-score. SVM exhibits high precision, accuracy, and F1-score of 0.88, 0.86, and 0.85, respectively. On the other hand, Random forest shows the highest values of accuracy, precision, and recall of 0.91, 0.93, and 0.90, respectively. Interestingly, Naive Bayes' model has the lowest performance with the accuracy, precision, recall, and F1-score of 0.64, 0.61, 0.63, and 0.61, respectively. The study compared these models on the same dataset to ensure a fair evaluation."
2137,"caption: Model Performance Comparison using Multiple Metricstable: Model,Accuracy,F1-score,Precision,Recall, SVM,0.85,0.85,0.86,0.83, Random Forest,0.87,0.88,0.84,0.92, K-Nearest Neighbors,0.78,0.76,0.74,0.78, Naive Bayes,0.82,0.81,0.85,0.78, Neural Network,0.89,0.90,0.89,0.91","The table presents a comparison of several models based on different metrics. The evaluated models are SVM, Random Forest, K-Nearest Neighbors, Naive Bayes, and Neural Network. Accuracy, F1-score, Precision, and Recall are chosen as evaluation metrics to compare the performance of these models. The Random Forest and Neural Network models perform well with high accuracy, F1-score, Precision, and Recall. The Random Forest model achieves the highest accuracy (0.87), F1-score (0.88), and Recall (0.92). However, the Neural Network model showed the highest precision (0.89). The K-Nearest Neighbors model shows the lowest performance in all the metrics compared to other models."
2138,"caption: Table 4: Model performance based on multiple evaluation metricstable: Model,F1 Score,Precision,Recall,Accuracy, Model A,0.845,0.812,0.881,0.871, Model B,0.872,0.839,0.908,0.891, Model C,0.832,0.865,0.802,0.879, Model D,0.895,0.919,0.872,0.899","Table 4 presents the performances of different models based on multiple evaluation metrics, including F1 score, precision, recall, and accuracy. The models evaluated in this table are model A, model B, model C, and model D. Model D exhibits the best overall performance among the models, with the highest F1 score of 0.895, precision of 0.919, and recall of 0.872, resulting in an accuracy score of 0.899. Model B achieved the second-best performance with an F1 score of 0.872, precision of 0.839, and recall of 0.908, resulting in an accuracy score of 0.891. Meanwhile, model A and model C had lower overall performance, with model C having the lowest F1 score of 0.832."
2139,"caption: Comparison of different models' accuracy, F1 score, precision, and recall.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic,0.93,0.92,0.92,0.92, SVM,0.94,0.94,0.94,0.94, Random Forest,0.95,0.95,0.95,0.95, XGBoost,0.96,0.96,0.96,0.96, LightGBM,0.95,0.95,0.96,0.94","The presented table provides a comparison of five different models' accuracy, F1 score, precision and recall metrics. Logistic regression and SVM models show relatively high accuracy scores of 0.93 and 0.94, respectively. The Random Forest, XGBoost, and LightGBM models show higher accuracy results ranging from 0.95 to 0.96. These three models show impressive precision, recall, and F1 scores that all range from 0.94 to 0.96. Notably, the LightGBM model has the highest precision score of 0.96, while the other models showed the same score. Additionally, the SVM model has the highest F1-score, which is 0.94. Finally, the XGBoost and Random Forest models have the highest recall of 0.96."
2140,"caption: Comparison of different classification models based on various evaluation metrics.table: Model,Accuracy Score,F1-Score,Precision,Recall, Random Forest,0.91,0.89,0.92,0.88, Logistic Regression,0.87,0.88,0.85,0.91, XGBoost,0.88,0.90,0.87,0.93, Decision Tree,0.83,0.80,0.81,0.82, Multi-layer Perceptron,0.85,0.83,0.86,0.81","Table presents the performance comparison of different models based on various evaluation metrics. The accuracy score, F1-score, precision, and recall of the models are tabulated. The Random Forest model leads the classification task with an accuracy score of 0.91, followed by the XGBoost model with 0.88 accuracy score. Interestingly, the logistic regression model scored the highest F1-score of 0.88 and recall of 0.91. Meanwhile, the Multi-layer Perceptron model attained the best precision score of 0.86 among the various models. Nevertheless, the decision tree model displays the weakest performance among the models, with an accuracy score of 0.83, an F1-score of 0.80, precision of 0.81, and recall of 0.82."
2141,"caption: Performance metrics for various models trained on the given dataset.table: Model,Accuracy,F1 Score,AUC,Precision,Recall, XGB,0.86,0.77,0.94,0.82,0.74, RF,0.89,0.83,0.94,0.91,0.77, SVM,0.78,0.63,0.83,0.79,0.56, LR,0.77,0.61,0.79,0.81,0.48, KNN,0.72,0.55,0.77,0.69,0.46",
2142,"caption: Performance comparison of different models on the given dataset using various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.76,0.78,0.68,0.72, Naive Bayes,0.67,0.62,0.80,0.70, Decision Tree,0.70,0.75,0.60,0.67, Random Forest,0.82,0.83,0.72,0.77","The table presents the performance of four different models, namely SVM, Naive Bayes, Decision Tree, and Random Forest, on the given dataset based on multiple evaluation metrics, which are Accuracy, Precision, Recall, and F1-Score. Notably, the Random Forest model exhibits the highest accuracy of 0.82 and Precision of 0.83. Meanwhile, The SVM model has the highest Recall score of 0.68. On the contrary, the Naive Bayes model shows the highest Precision score of 0.80, but the lowest accuracy of 0.67. In terms of F1-Score, the Random Forest model outperforms the others, with a score of 0.77, while the Decision Tree model demonstrates the lowest score of 0.67."
2143,"caption: Model Performance Metrics for Classification Tasks.table: Model,Accuracy,Precision,Recall,F1 Score,AUC Score, Logistic Regression,0.85,0.88,0.79,0.83,0.91, Random Forest,0.91,0.92,0.87,0.89,0.94, Support Vector Machine,0.83,0.86,0.74,0.80,0.89, K-Nearest Neighbor,0.80,0.82,0.73,0.76,0.86, Multi-Layer Perceptron,0.89,0.91,0.82,0.85,0.93","The table presents various classification models' performance evaluated on different evaluation metrics such as Accuracy, Precision, Recall, F1 Score, and AUC Score. It is observed that the Random Forest model performs the best with the highest Accuracy of 0.91, Precision of 0.92, Recall of 0.87, F1 Score of 0.89, and AUC Score of 0.94. The Multi-Layer Perceptron model is the second best with an Accuracy of 0.89, F1 Score of 0.85, and AUC Score of 0.93. The K-Nearest Neighbor model has the lowest performance result among the presented models with an Accuracy of 0.80, F1 Score of 0.76, and AUC Score of 0.86."
2144,"caption: Comparison of different models' performances by multiple evaluation metrics.table: Models,F1-Score,Accuracy,Precision,Recall,AUC, Model 1,0.76,0.82,0.70,0.83,0.92, Model 2,0.78,0.81,0.72,0.85,0.90, Model 3,0.80,0.84,0.75,0.86,0.91, Model 4,0.82,0.85,0.78,0.87,0.92, Model 5,0.84,0.86,0.80,0.88,0.93","Table presents a comparison of different models' performance measured by multiple metrics, including F1-Score, Accuracy, Precision, Recall, and AUC. Five different models' performances are compared. Interestingly, Model 5 is the best performing model across all the evaluation metrics with the highest F1-Score of 0.84, Accuracy of 0.86, Precision of 0.80, Recall of 0.88, and AUC of 0.93. Model 1 had the lowest performance, even though its AUC score was higher than some of the other models. This table implies that some models might achieve high AUC scores, but that does not necessarily mean they perform well across all the evaluation metrics."
2145,"caption: A comparison of different machine learning models' performances using multiple evaluation metricstable: Model Name,F1 Score,Accuracy,Recall,Precision, Logistic Regression,0.83,0.82,0.85,0.87, Decision Tree,0.72,0.68,0.75,0.68, Random Forest,0.87,0.85,0.90,0.88, Support Vector Machine,0.78,0.73,0.76,0.81, Gradient Boosting,0.90,0.88,0.91,0.93, Multi-Layer Perceptron,0.84,0.81,0.80,0.87, K-Nearest Neighbors,0.61,0.55,0.49,0.68","Table X presents a comparison of different machine learning models' performances using multiple evaluation metrics. The models' performances are evaluated using F1 Score, Accuracy, Recall, and Precision. The models used in this evaluation are Logistic Regression, Decision Tree, Random Forest, Support Vector Machine, Gradient Boosting, Multi-Layer Perceptron, and K-Nearest Neighbors. From the table, it is evident that Gradient Boosting has the highest F1 Score of 0.90, and Logistic Regression has the highest accuracy of 0.82. On the other hand, K-Nearest Neighbors has the lowest F1 Score and Accuracy of 0.61 and 0.55, respectively, indicating poor performance. Additionally, Gradient Boosting achieved the highest Recall and Precision of 0.91 and 0.93, respectively. In contrast, Decision Tree had the lowest Recall and Precision values of 0.75 and 0.68, respectively. Overall, the table provides valuable insights into different models' performance using multiple evaluation metrics, which is useful in selecting the most appropriate model for a specific task."
2146,"caption: Table 4: Performance comparison of different models based on multiple evaluation metricstable: Model,Loss,Accuracy,F1-score,PR-AUC,MSE, Model A,0.11,0.89,0.86,0.81,0.10, Model B,0.05,0.92,0.88,0.77,0.12, Model C,0.12,0.87,0.85,0.78,0.14, Model D,0.06,0.91,0.89,0.82,0.11, Model E,0.09,0.90,0.87,0.80,0.13","Table 4 provides a performance comparison of different models based on multiple evaluation metrics. The metrics used in this table include Loss, Accuracy, F1-score, PR-AUC, and MSE. The table compares the performance of Model A, Model B, Model C, Model D and Model E based on these evaluation metrics. The results demonstrate that Model B had the highest Accuracy of 0.92 and F1-score of 0.88, while Model D had the best PR-AUC of 0.82. However, Model B had the highest loss of 0.05 while Model C had the highest MSE of 0.14. These results indicate that different models perform differently based on various evaluation metrics and choosing an appropriate evaluation metric is important based on the specific problem in question."
2147,"caption: Table 4: Model performance comparison based on multiple evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, Logistic regression,0.85,0.83,0.87,0.82, Random Forest,0.88,0.85,0.89,0.82, SVM,0.86,0.84,0.88,0.78, XGBoost,0.92,0.91,0.93,0.90, Multilayer Perceptron,0.80,0.76,0.80,0.77","Table 4 presents the model performance comparison based on multiple evaluation metrics, namely Accuracy, F1-score, Precision, and Recall. The table includes five different models, including Logistic Regression, Random Forest, SVM, XGBoost, and Multilayer Perceptron. Notably, all models were trained and tested using the same dataset. The XGBoost model displayed the best performance among all models, obtaining the highest Accuracy of 0.92, F1-Score of 0.91, Precision of 0.93, and Recall of 0.90. On the other hand, the Multilayer Perceptron model exhibited the lowest performance with Accuracy of 0.80, F1-Score of 0.76, Precision of 0.80, and Recall of 0.77. The table's results suggest that the XGBoost model might be the most suitable model for the given problem."
2148,"caption: Performance of different models on evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.87,0.85,0.88,0.86, Decision Tree,0.80,0.73,0.82,0.77, SVM (linear),0.91,0.88,0.92,0.89, Random Forest,0.92,0.90,0.92,0.91, XGBoost,0.93,0.91,0.93,0.92","The table above displays the comparison of different models based on various evaluation metrics, including Accuracy, Precision, Recall, and F1 Score. The models include Logistic Regression, Decision Tree, SVM (linear), Random Forest, and XGBoost. Among these models, XGBoost demonstrates the best performance with the highest values in all the metrics, i.e., Accuracy of 0.93, Precision of 0.91, Recall of 0.93, and F1 Score of 0.92. Compared to XGBoost, Random Forest model shows the second-best performance while the Decision Tree model demonstrates the worst performance among all the models."
2149,"caption: Table 4: Model performance comparison based on different evaluation metricstable: Model,Accuracy,Precision,F1 Score,Average Precision,Recall, Logistic Regression,0.712,0.720,0.695,0.764,0.742, Decision Tree Classifier,0.861,0.885,0.861,0.825,0.851, Random Forest Classifier,0.895,0.877,0.891,0.902,0.908, Support Vector Machines,0.671,0.684,0.585,0.691,0.438, Neural Network,0.840,0.848,0.838,0.865,0.835","Table 4 presents a comparison of model performance based on various evaluation metrics. The table includes five different models, including Logistic Regression, Decision Tree Classifier, Random Forest Classifier, Support Vector Machines, and Neural Network. The evaluation metrics presented in the table include Accuracy, Precision, F1 Score, Average Precision, and Recall. Interestingly, while Random Forest Classifier achieved the highest scores on Average Precision and Recall (0.902 and 0.908, respectively), Decision Tree Classifier obtained the highest Accuracy (0.861). Meanwhile, the Neural Network achieved the highest scores on Precision and F1 Score, with scores of 0.848 and 0.838, respectively."
2150,"caption: Evaluation results of different classification models.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.86,0.89,0.84,0.86, KNN,0.78,0.85,0.73,0.78, NB,0.62,0.73,0.60,0.65, RF,0.92,0.93,0.91,0.92, XGB,0.90,0.91,0.89,0.90","The table above shows the performance of Support Vector Machine (SVM), K-Nearest Neighbor (KNN), Naive Bayes (NB), Random Forest (RF), and XGBoost (XGB) models, measured by their accuracy, precision, recall, and F1-score. It is evident that the RF model performed the best with the highest accuracy (0.92), precision (0.93), recall (0.91), and F1-score (0.92). The SVM also achieved remarkable results, with an accuracy of 0.86 and a precision score of 0.89. However, the NB model demonstrated a weaker result in terms of accuracy (0.62), precision (0.73), recall (0.60), and F1-score (0.65). Overall, the RF and XGB models' performances were significantly better than those of the SVM, KNN, and NB models in this study."
2151,"caption: Model performance evaluation using different metric approachestable: Model,F1-score,Precision,Recall,Accuracy, Model 1,0.80,0.75,0.85,0.90, Model 2,0.85,0.80,0.90,0.88, Model 3,0.82,0.73,0.93,0.85, Model 4,0.87,0.89,0.86,0.91","The table above shows the performance of multiple models based on different evaluation metrics, namely F1 score, precision, recall, and accuracy. The four models were evaluated using the same dataset, and their performance metrics are shown in the respective columns. Notably, Model 4 achieved the highest F1-score of 0.87, which indicates its balanced precision and recall measure. However, Model 2 had the highest precision and recall scores of 0.80 and 0.90, respectively, while Model 1 had the highest accuracy score of 0.90. This demonstrates the need to consider multiple performance evaluation metrics when selecting the best model for a specific task."
2152,"caption: Model Performances Based on Different Evaluation Metricstable: Model,Accuracy,F1 Score,Precision,Recall, Model 1,0.85,0.80,0.75,0.86, Model 2,0.88,0.87,0.82,0.92, Model 3,0.75,0.67,0.65,0.70, Model 4,0.91,0.91,0.89,0.93, Model 5,0.73,0.66,0.59,0.76","Table displays multiple models' performance using different evaluation metrics, including Accuracy, F1 Score, Precision, and Recall. Model 4 shows the best performance across all evaluation metrics, with an accuracy of 0.91, F1 Score of 0.91, Precision of 0.89, and Recall of 0.93. Model 2 has the second-best performance with high values across all evaluation metrics. In contrast, Model 5 has the lowest performance across all the evaluation metrics, indicating that it is the weakest model. The table showcases that evaluating different metrics is important to accurately measure models' performances."
2153,"caption: Table 4: Performance of different models using multiple evaluation metrics.table: Model,Accuracy,Sensitivity,Specificity,F1 Score, SVM,0.85,0.78,0.92,0.82, KNN,0.74,0.85,0.64,0.74, Naive Bayes,0.62,0.41,0.85,0.52, Random Forest,0.89,0.86,0.91,0.87, Logistic Regression,0.80,0.69,0.87,0.74","Table 4 presents the performance of different models, including SVM, KNN, Naive Bayes, Random Forest, and Logistic Regression, using four different evaluation metrics: Accuracy, Sensitivity, Specificity, and F1 Score. Interestingly, Random Forest obtained the highest accuracy with a score of 0.89 and had the second-highest scores in Sensitivity, Specificity, and F1 Score among all the models. SVM had the highest Specificity score of 0.92 and the second-highest F1 Score, whereas KNN had the highest Sensitivity score of 0.85 but the lowest score in the other three evaluation metrics. Naive Bayes had the lowest scores for all the evaluation metrics, with an accuracy of 0.62, sensitivity of 0.41, specificity of 0.85, and F1 Score of 0.52. Logistic Regression had moderate performance in all the evaluated metrics, obtaining an accuracy of 0.80, a sensitivity of 0.69, a specificity of 0.87, and an F1 Score of 0.74."
2154,"caption: Model comparison based on different evaluation metrics.table: Model,F1-Score,Precision,Recall,Accuracy, SVM,0.75,0.78,0.72,0.81, Random Forest,0.77,0.76,0.80,0.82, K-Nearest Neighbors,0.66,0.59,0.81,0.70, Neural Network,0.73,0.71,0.76,0.76","The table shows a comparison of four different models based on four different evaluation metrics: F1-Score, Precision, Recall, and Accuracy. SVM model achieved the highest precision score of 0.78, while the Random Forest model scores better in both the F1-score (0.77) and Recall (0.80). K-Nearest Neighbors model seems to perform the worst with the lowest scores in F1-Score (0.66) and Precision (0.59). However, K-Nearest Neighbors shows the highest Recall score of 0.81. Finally, the Neural Network model achieved a moderate performance with an F1-Score of 0.73, precision of 0.71, Recall of 0.76, and Accuracy of 0.76."
2155,"caption: Performance comparison of different models using various evaluation metrics.table: Models,F1-score,Accuracy,Precision,Recall, Model 1,0.75,0.80,0.70,0.81, Model 2,0.80,0.82,0.86,0.75, Model 3,0.68,0.75,0.71,0.65, Model 4,0.82,0.83,0.78,0.87, Model 5,0.76,0.79,0.82,0.71","Table presents the performance results of five models based on multiple evaluation metrics, including F1-score, Accuracy, Precision, and Recall. The table demonstrates that Model 4 shows the highest F1-score of 0.82. However, Model 2 has the highest accuracy of 0.82. Similarly, Model 2 demonstrates the highest Precision of 0.86, while Model 4 shows the highest Recall of 0.87. It is noteworthy that Model 5 exhibits a balanced tradeoff in all the evaluation metrics, making it a good choice for an equally optimized model when multiple metrics are considered."
2156,"caption: Table 4. Model Evaluation Metrics.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.85,0.85,0.86,0.85, Naive Bayes,0.81,0.79,0.83,0.81, Logistic Regression,0.87,0.86,0.87,0.87, Random Forest,0.90,0.90,0.91,0.90, Gradient Boosting,0.89,0.88,0.89,0.89","The table illustrates model evaluation metrics, comparing the accuracy, F1-score, precision, and recall for five models, SVM, Naive Bayes, Logistic Regression, Random Forest, and Gradient Boosting. The Random Forest model achieved the highest accuracy score of 0.90, followed closely by Gradient Boosting with an accuracy of 0.89. Similarly, these two models also achieved similar F1-scores, precision, and recall scores. Surprisingly, Logistic regression and SVM models achieved the same precision and recall scores despite having different accuracy and F1-score results. The Naive Bayes model reported the lowest accuracy and F1-score, but it still achieved a decent precision and recall score."
2157,"caption: The table displays a comparison of different models' performances based on various evaluation metrics. The models include SVM, Decision Tree, Random Forest, Naive Bayes, and Neural Network. The metrics include F1-score, Accuracy, Precision, and Recall.table: Model,F1-score,Accuracy,Precision,Recall, SVM,0.85,0.83,0.89,0.81, Decision Tree,0.74,0.75,0.73,0.82, Random Forest,0.92,0.91,0.95,0.89, Naive Bayes,0.65,0.70,0.57,0.77, Neural Network,0.89,0.88,0.91,0.87","The table summarizes the performance of five models trained and tested using a similar dataset and evaluation metrics. The Random Forest model demonstrated the highest F1-score, Accuracy, and Precision scores of 0.92, 0.91, and 0.95, respectively. The Neural network model, on the other hand, achieved the highest recall score of 0.87. Although the SVM model achieved the second-best F1-score, Accuracy, and Precision scores, it had the lowest Recall score, implying low sensitivity. The Naive Bayes model performed poorly across all evaluation metrics. Overall, the table demonstrates that the Random Forest and Neural Network models outperformed the other models, especially in F1-score and Accuracy."
2158,"caption: Comparison of model performance based on different evaluation metrics.table: Model,MAE,MSE,RMSE,R-squared, Linear Regression,5.25,40.25,6.34,0.72, Decision Tree,4.15,25.58,5.05,0.81, Random Forest,3.75,20.68,4.54,0.86, XGBoost,3.92,24.55,4.96,0.83, Support Vector Reg.,6.45,56.20,7.50,0.60","The table provides a comprehensive comparison of different models, including Linear Regression, Decision Tree, Random Forest, XGBoost, and Support Vector Regression, based on various evaluation metrics such as MAE, MSE, RMSE, and R-squared. The Random Forest model performed best across all evaluation metrics and achieved the lowest MAE, MSE, and RMSE, indicating higher precision in predicting outcomes. Additionally, the R-squared value shows that the model explains 86% of the variance in the data. Comparatively, the Support Vector Regression model had the highest MAE and RMSE, indicating lower prediction accuracy."
2159,"caption: Performance comparison of different classification models based on multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.78,0.75,0.82,0.78, Decision Tree,0.73,0.67,0.75,0.70, Random Forest,0.80,0.74,0.87,0.78, XGBoost,0.83,0.78,0.88,0.82, Multi-layer Perceptron,0.76,0.70,0.82,0.75","The table compares the performance of five different classification models - Logistic Regression, Decision Tree, Random Forest, XGBoost, and Multi-layer Perceptron - based on four different evaluation metrics - Accuracy, Precision, Recall, and F1-Score. The results show that XGBoost achieved the best overall performance, with the highest Accuracy (0.83), Precision (0.78), Recall (0.88), and F1-Score (0.82). Random Forest also performed well, achieving an Accuracy of 0.80 and the highest Recall score of 0.87. Logistic Regression and Multi-layer Perceptron achieved the lowest and mid-range performance, respectively. The results suggest that XGBoost and Random Forest should be considered for further evaluation and deployment in practical applications."
2160,"caption: Performance of different models on the classification tasktable: Model,Accuracy,F1_score,Precision,Recall, Logistic Regression,0.867,0.835,0.864,0.811, Decision Tree,0.843,0.807,0.825,0.791, Random Forest,0.895,0.876,0.893,0.859, Gradient Boosting,0.881,0.860,0.883,0.838","The table portrays the evaluation results of four classification models: Logistic Regression, Decision Tree, Random Forest, and Gradient Boosting. Each model's accuracy, F1_score, precision, and recall measures are shown in the table. Interestingly, the Random Forest model shows the best performance results in terms of all performance metrics with 0.895 accuracy, 0.876 F1_score, 0.893 precision, and 0.859 recall score. The Logistic Regression model has the second-best performance with an accuracy of 0.867, while the Decision Tree model has the lowest accuracy of 0.843. The Gradient Boosting model achieved an accuracy of 0.881, which is significantly better than the Decision Tree model but slightly lower than the Logistic Regression model."
2161,"caption: Comparison of different models' performances using multiple evaluation metrics.table: Model,Accuracy,Recall,Precision,F1-score, SVM,0.80,0.83,0.79,0.81, KNN,0.77,0.79,0.74,0.75, MLP,0.86,0.89,0.85,0.87, XGBoost,0.88,0.90,0.87,0.88","Table showing the comparison of different models' performances using multiple evaluation metrics such as accuracy, recall, precision, and F1-score. The table contains four models, namely SVM, KNN, MLP, and XGBoost. XGBoost achieved the highest performance in all the metrics with an accuracy of 0.88, recall of 0.90, precision of 0.87, and an F1-score of 0.88, while MLP achieved the second-best performance with an accuracy of 0.86 and an F1-score of 0.87. SVM and KNN had the lowest accuracy values of 0.80 and 0.77, respectively. The table indicates that both accuracy and F1-score were highest for XGBoost, which demonstrates its superior overall performance compared to the other models."
2162,"caption: Model performance evaluation using multiple metricstable: Model,Accuracy,Sensitivity,Specificity,Precision, SVM,0.78,0.67,0.81,0.63, XGBoost,0.85,0.72,0.88,0.80, Random Forest,0.82,0.70,0.84,0.75, Decision Tree,0.77,0.65,0.81,0.63","The table presents four different models evaluated using multiple metrics, including accuracy, sensitivity, specificity, and precision. The models are SVM, XGBoost, Random Forest, and Decision Tree. Overall, XGBoost showed the best result in terms of accuracy, achieving 0.85. It also performed better in the other metrics, attaining 0.72, 0.88, and 0.8, in sensitivity, specificity, and precision, correspondingly. Random Forest had the highest sensitivity of 0.70. The SVM model had the lowest precision and achieved the worst performance overall."
2163,"caption: Performances of various machine learning algorithms using Accuracy, F1-Score, Precision, Recall, and AUC evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall,AUC, Random Forest,0.89,0.87,0.91,0.84,0.93, Gradient Boosting,0.85,0.82,0.84,0.8,0.88, Support Vector Machine,0.83,0.80,0.85,0.74,0.89, K-Nearest Neighbors,0.78,0.77,0.79,0.75,0.85, Decision Tree,0.73,0.72,0.75,0.69,0.78","Table presents performances of five different machine learning algorithms on the given dataset. All the models were compared using multiple evaluation metrics, including Accuracy, F1-Score, Precision, Recall, and AUC. The Random Forest model shows the highest accuracy score of 0.89 and the highest AUC of 0.93. Meanwhile, the Decision Tree model has the lowest accuracy of 0.73 and lowest AUC of 0.78. The Precision performance of the Random Forest and Support Vector Machine algorithms is the best with a score of 0.91 and 0.85, respectively. However, the Recall performance of the Support Vector Machine algorithm is the worst among all models with a score of 0.74."
2164,"caption: Table 4. Evaluation metrics for different modelstable: Model,F1-score,Accuracy,Precision,Recall, Model A,0.86,0.91,0.85,0.87, Model B,0.81,0.90,0.83,0.79, Model C,0.88,0.92,0.89,0.87, Model D,0.83,0.88,0.81,0.87, Model E,0.89,0.93,0.90,0.88","Table 4 presents evaluations of different models using multiple evaluation metrics. The table shows five models, Model A to E, with their corresponding F1-scores, accuracies, precision, recall scores. Interestingly, Model C had the highest F1-score, accuracy, precision, and recall scores of 0.88, 0.92, 0.89, and 0.87, respectively. Model E also had impressive scores with an F1-score of 0.89, accuracy of 0.93, precision of 0.9, and recall of 0.88. Model D showed the lowest F1-score of 0.83, while Model B had the lowest accuracy of 0.90. Overall, the table provides an in-depth comparison of each model's performance using different evaluation measures."
2165,"caption: Performance of different models based on multiple evaluation metrics.table: Model,Accuracy,F1 Score,ROC AUC,Precision,Recall, Model 1,85.6%,0.854,0.917,0.892,0.821, Model 2,87.2%,0.875,0.905,0.897,0.854, Model 3,86.8%,0.868,0.894,0.889,0.846, Model 4,88.1%,0.881,0.912,0.908,0.854, Model 5,86.4%,0.862,0.899,0.881,0.843","The table highlights the performance analysis of different models based on various evaluation metrics. These models were trained and evaluated using the same dataset. The models' performance is evaluated using different metrics, including accuracy, F1 Score, ROC AUC, precision, and recall. Model 4 obtained the highest accuracy of 88.1% with F1 Score, precision, and recall of 0.881, 0.908, and 0.854, respectively. However, Model 1 scored the highest ROC AUC of 0.917. Overall, it is clear that Model 4 outperformed the other models in most of the evaluation metrics."
2166,"caption: Comparison of Accuracy, F1-score, Precision, and Recall of Different Classification Modelstable: Model,Accuracy,F1-score,Precision,Recall, SVM,0.92,0.92,0.88,0.95, KNN,0.88,0.87,0.83,0.91, Naive Bayes,0.81,0.74,0.90,0.63, Decision Tree,0.89,0.88,0.85,0.92, Random Forest,0.94,0.93,0.94,0.93, Gradient Boosting,0.92,0.91,0.89,0.93","The table compares six different classification models' performances based on multiple evaluation metrics: Accuracy, F1-score, Precision, and Recall. The highest accuracy score is obtained by the Random Forest model, which achieves a score of 0.94. The Random Forest model also has a high F1-score of 0.93 and both precision and recall scores of 0.94 and 0.93, respectively. The SVM model, on the other hand, has the highest precision score of 0.88, while the Naive Bayes model has the lowest precision score of 0.90 but the highest recall score of 0.63. Among the models evaluated, the Random Forest model emerges as the best-performing model based on the different evaluation metrics."
2167,"caption: Table 4. Model performance comparison.table: Model 1,Model 2,Model 3,Model 4, Metric 1,0.80,0.82,0.90,0.95, Metric 2,0.85,0.88,0.92,0.93, Metric 3,0.70,0.75,0.80,0.85, Metric 4,0.60,0.65,0.78,0.82","Table 4 presents a comparison of four different models based on multiple evaluation metrics: Metric 1, Metric 2, Metric 3, and Metric 4. The table demonstrates that Model 4 outperforms all other models. Model 4 had the highest score in Metric 1 (0.95), and it also had the second-highest score in Metric 2 and Metric 3 (0.93 and 0.85, respectively). Model 1 had the lowest score in all metrics. Interestingly Model 3, while having the highest score in Metric 3 (0.80), had lower scores in other metrics compared to Model 4. Overall, Model 4 shows the best performance in the evaluation metrics considered in this study."
2168,"caption: Performance comparison of multiple machine learning models using accuracy, precision, recall, and F1-Score metrics.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.85,0.80,0.90,0.85, KNN,0.78,0.72,0.80,0.76, Naive Bayes,0.62,0.58,0.65,0.61, Decision Tree,0.82,0.75,0.88,0.81, Random Forest,0.89,0.84,0.93,0.88","The above table presents a comparison of five machine learning models' performances using four different performance metrics: Accuracy, Precision, Recall, and F1-Score. The models include Support Vector Machine (SVM), K-Nearest Neighbor (KNN), Naive Bayes, Decision Tree, and Random Forest. Notably, the Random Forest model has the highest accuracy (0.89) and F1-Score (0.88), while the Naive Bayes model has the lowest results for all metrics. Interestingly, the SVM model has the highest precision score of 0.80, while the Random Forest model has the highest recall score of 0.93. Overall, the Random Forest model appears to have the best performance across all metrics represented in the table."
2169,"caption: Comparison of different classifiers based on various evaluation metrics.table: Model Name,Accuracy (%),F1-Score(%),Precision (%),Recall (%), Random Forest,85.2,83.6,82.3,85.0, Decision Trees,77.9,74.5,75.2,74.4, Support Vector,89.4,87.6,86.3,89.0, Gradient Boost,86.1,84.4,82.1,86.8, ANN,90.0,88.5,88.9,88.4","Table presents the performance of different classifiers using multiple evaluation metrics such as Accuracy, F1-score, Precision, and Recall. The table displays Random Forest, Decision Trees, Support Vector, Gradient Boost, and Artificial Neural Network (ANN) models with their respective performance results. Notably, ANN obtained the highest accuracy of 90.0%, followed by SVM with 89.4%. Decision Trees showed the lowest performance among all models, achieving an accuracy of only 77.9%. Support Vector outperformed other models based on F1-score, Precision, and Recall, while ANN showed the highest F1-score, Precision, and Recall."
2170,"caption: Performance metrics of different models on a classification task.table: Model,Precision,Recall,F1-score, Logistic Regression,0.83 (+-0.01),0.74 (+-0.008),0.77 (+-0.009), Decision Tree,0.72 (+-0.02),0.63 (+-0.007),0.66 (+-0.015), Random Forest,0.91 (+-0.01),0.67 (+-0.003),0.76 (+-0.004), KNN,0.69 (+-0.02),0.56 (+-0.03),0.60 (+-0.04), SVM,0.81 (+-0.03),0.52 (+-0.02),0.63 (+-0.01), Naive Bayes,0.62 (+-0.03),0.84 (+-0.04),0.69 (+-0.02)","Table above illustrates the performances of different machine learning models for a single classification task. The models' evaluation was based on precision, recall, and the F1-score metrics. SVM model attained a precision of 0.81 (+-0.03), though its recall was only 0.52 (+-0.02) and F1-score was 0.63 (+-0.01). The random forest model had the best F1-score of 0.76 (+-0.004). However, the Naive Bayes model had the highest recall of 0.84 (+-0.04) but with a poor precision of 0.62 (+-0.03). Thus, depending on the metric of interest, different models can be suitable for different scenarios."
2171,"caption: Performance of different models using multiple performance metricstable: Model,Accuracy (%),F1 (%),MCC (%),AUC-ROC (%), SVM,76.43,75.15,52.32,85.19, KNN,61.87,60.08,23.87,67.93, RF,88.67,88.74,76.72,93.55, XGB,87.12,86.45,72.75,92.40, MLP,86.84,85.67,71.18,93.20","The table above shows the performance of different models using multiple evaluation metrics like Accuracy, F1 score, Matthews Correlation Coefficient (MCC), and Area Under the Curve of the Receiver Operating Characteristic Curve (AUC-ROC). The models presented in the table are SVM, KNN, RF, XGB, and MLP. The RF model displayed the best accuracy, F1 score, and MCC percentages, scoring 88.67%, 88.74%, and 76.72%, respectively. SVM recorded the highest AUC-ROC of 85.19%. Also, the MLP model obtained the highest accuracy and the second-highest AUC-ROC percentage. Comparatively, despite the lackluster performance of KNN, all models performed above the 60% accuracy threshold, but their performances varied with different performance metrics."
2172,"caption: Table 4: Model performances based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 score, Logistic Regression,0.85,0.86,0.80,0.83, SVM,0.81,0.82,0.77,0.77, K-Nearest Neighbor,0.78,0.76,0.72,0.73, Random Forest,0.89,0.91,0.88,0.89","Table 4 presents the performance of four different classification models based on various evaluation metrics. The models' performances are measured using Accuracy, Precision, Recall, and F1 score. Logistic Regression produced the highest Accuracy of 0.85, while Random Forest gave the best result on each evaluation metric. It achieved an Accuracy of 0.89, Precision of 0.91, Recall of 0.88, and F1 score of 0.89. On the other hand, K-Nearest Neighbor produced the lowest result on all metrics. The results show that Random Forest is the most effective model for this classification task, as it produced better performance on all the metrics compared to the other models."
2173,"caption: Table 4: Model Performance Evaluation Metricstable: Model,Precision,Recall,F1-Score,Accuracy, Model A,0.78,0.81,0.79,0.89, Model B,0.82,0.75,0.78,0.91, Model C,0.86,0.88,0.87,0.93, Model D,0.79,0.90,0.84,0.87","Table 4 reports the performance evaluation metrics of models A, B, C, and D. The table exhibits four evaluation metrics, namely precision, recall, F1-score, and accuracy. It can be observed that Model C has the overall best performance with the highest precision score of 0.86, recall score of 0.88, and F1-score of 0.87. Additionally, Model C achieved the highest accuracy of 0.93. However, Model B achieved the best precision score of 0.82 among all models, while Model D achieved the best recall score of 0.90. Overall, researchers can use these evaluation metrics to select the most suitable model for their research based on the desired metric."
2174,"caption: Table 4: Model performance using different evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.92,0.92,0.94,0.90, Logistic Regression,0.85,0.85,0.91,0.79, Random Forest,0.89,0.89,0.91,0.87, Gradient Boosting,0.90,0.90,0.92,0.88, Neural Network,0.87,0.87,0.89,0.85","Table 4 summarizes the evaluation results of five different models using different evaluation metrics. The models include SVM, Logistic Regression, Random Forest, Gradient Boosting, and Neural Network. The evaluation metrics are Accuracy, F1 Score, Precision, and Recall. Among the models, SVM demonstrates the best Accuracy and Recall scores of 0.92 and 0.90, respectively. On the other hand, Logistic Regression presents the lowest Accuracy score of 0.85, while Neural Network has the lowest Precision and Recall scores of 0.89 and 0.85, respectively. Overall, the table shows a comparative view of different models concerning various evaluation metrics."
2175,"caption: Table 4: Performance Metrics of Different Modelstable: Model,Precision,Recall,F1-Score,Accuracy, Logistic Regression,0.85,0.87,0.84,0.88, Decision Tree,0.78,0.75,0.76,0.80, Random Forest,0.89,0.90,0.89,0.91, Support Vector Machine,0.87,0.91,0.88,0.89","Table 4 reports the evaluation metrics - Precision, Recall, F1-Score, and Accuracy - of various machine learning models, including Logistic Regression, Decision Tree, Random Forest, and Support Vector Machine. The table shows that the Random Forest model outperformed all other models, achieving the highest precision of 0.89, recall of 0.90, F1-Score of 0.89, and accuracy of 0.91. The Logistic Regression and Support Vector Machine models also achieved high performance results, with accuracy scores of 0.88 and 0.89, respectively. In contrast, the Decision Tree model reported the lowest performance scores of all models, with precision, recall, F1-Score, and accuracy scores of 0.78, 0.75, 0.76, and 0.80, respectively."
2176,"caption: Table 4 - Evaluation metrics of different modelstable: Model,Accuracy,F1-Score,AUC, Model A,0.80,0.75,0.85, Model B,0.82,0.77,0.82, Model C,0.78,0.72,0.88, Model D,0.85,0.80,0.80, Model E,0.79,0.74,0.84","Table 4 presents a comparison of the performance evaluation metrics of five different models - Model A, Model B, Model C, Model D, and Model E. The evaluation metrics include Accuracy, F1-Score, and AUC, which were computed and reported for each model. Notably, Model D showed the best performance in terms of Accuracy, having the highest score of 0.85. However, Model C performed the best regarding F1-Score, which had the highest score of 0.88. Furthermore, Model A and Model E had comparable performance for all three metrics. These results highlight the importance of carefully selecting evaluation metrics to understand the performance of various models in the given task."
2177,"caption: Model performance results on a binary classification datasettable: Model,Accuracy,F1-score,Sensitivity,Specificity, SVM,0.95,0.93,0.94,0.96, Random forest,0.93,0.90,0.89,0.97, Adaboost,0.91,0.87,0.86,0.94, Decision tree,0.88,0.82,0.82,0.91, MLP,0.92,0.89,0.89,0.95","The table presents the performances of different models on a binary classification dataset, measured by accuracy, F1-score, sensitivity, and specificity. The SVM model shows the highest accuracy and specificity scores with 0.95 and 0.96 respectively. The Random forest model achieves the highest F1-score and sensitivity of 0.90 and 0.89 respectively. Interestingly, the MLP model's sensitivity and specificity scores are almost close to those of the SVM model, indicating comparable performance. The Decision tree model performance lagged behind other models in all metrics except specificity."
2178,"caption: Comparison of different models' performance using various evaluation metrics based on the dataset.table: Model,F1-score,Precision,Recall,AUC, Logistic Regression,0.775,0.811,0.743,0.871, Decision Tree,0.789,0.792,0.787,0.842, Random Forest,0.823,0.816,0.830,0.886, XGBoost,0.831,0.847,0.815,0.894","Table presents a comparison of different models' performance using various evaluation metrics based on the dataset. Four models were evaluated, namely Logistic Regression, Decision Tree, Random Forest, and XGBoost. Evaluation metrics included F1-score, precision, recall, and AUC. The Random Forest model demonstrated higher performance in F1-score, precision, and recall, with a score of 0.823, 0.816, and 0.83, respectively. The XGBoost model achieved the best AUC of 0.894. Interestingly, Logistic Regression achieved the best precision score with a value of 0.811, while Decision Tree gave the best recall score with a value of 0.787. Overall, the results show that Random Forest and XGBoost models outperformed others for this dataset."
2179,"caption: Table 4: Model performances across multiple metricstable: Model,Accuracy,F1 Score,Precision,Recall, Model 1,0.85,0.80,0.85,0.79, Model 2,0.80,0.75,0.74,0.80, Model 3,0.89,0.86,0.89,0.82, Model 4,0.75,0.70,0.73,0.64","Table 4 exhibits a comparison of different models' performances across multiple evaluation metrics, including accuracy, F1 score, precision, and recall. The table displays four models and their corresponding evaluation metrics. Interestingly, Model 3 scored the highest accuracy, F1 score, and precision, all equal to 0.89. However, Model 1 recorded the highest recall score of 0.79. Model 4's performance across all metrics was the lowest, with accuracy of 0.75, F1 score of 0.70, precision of 0.73, and recall of 0.64."
2180,"caption: Comparison of different classifiers based on evaluation metricstable: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.89,0.91,0.85,0.88, Decision Tree,0.82,0.79,0.84,0.81, Random Forest,0.91,0.93,0.89,0.91, KNN,0.78,0.82,0.75,0.78, SVM,0.88,0.90,0.85,0.87","The table above compares the performance of five different classification models that have been trained and tested using the same dataset. The evaluation metrics used in the table are accuracy, precision, recall, and F1-score. The Random Forest model showed the best overall performance with an accuracy of 0.91, precision of 0.93, recall of 0.89, and F1-score of 0.91. The Logistic Regression model also performed well, achieving an accuracy of 0.89 and precision of 0.91. Interestingly the KNN model outperformed the Decision tree and SVM models, but struggled to achieve a respectable accuracy, coming in last in that regard."
2181,"caption: Table 4: Model Performance Comparison on Evaluation Metricstable: Model,Accuracy,F1 Score,Precision,Recall, LogReg,0.82,0.81,0.81,0.82, SVM,0.78,0.80,0.82,0.78, Naive Bayes,0.70,0.72,0.73,0.70, Random Forest,0.85,0.86,0.87,0.85, XGBoost,0.87,0.88,0.89,0.87","The table presents a performance comparison of different models, including Logistic Regression (LogReg), Support Vector Machine (SVM), Naive Bayes, Random Forest, and XGBoost based on evaluation metrics such as accuracy, F1 score, precision, and recall. The Random Forest model shows the best accuracy score of 0.85, while the XGBoost model exhibits the highest accuracy score of 0.87. The XGBoost model also shows the highest F1 score, precision, and recall with respective scores of 0.88, 0.89, 0.87, respectively. While Logistic Regression outputs the second-best performance for all the metrics, Naive Bayes shows the lowest performance among all."
2182,"caption: Comparison of Different Models using Multiple Evaluation Metrics.table: Model,Precision,Recall,F1-Score,ROC-AUC,PR-AUC, Model 1,0.89,0.87,0.88,0.91,0.87, Model 2,0.92,0.85,0.88,0.92,0.89, Model 3,0.93,0.84,0.88,0.90,0.85, Model 4,0.85,0.91,0.88,0.92,0.87, Model 5,0.90,0.87,0.88,0.89,0.86","The table compares the performance of different models using multiple evaluation metrics, namely Precision, Recall, F1-Score, ROC-AUC, and PR-AUC. Model 2 had the highest precision score of 0.92, while Model 4 had the highest recall of 0.91. Interestingly, Models 1, 2, and 4 had an identical F1-Score of 0.88. In terms of ROC-AUC, Model 4 had the highest score of 0.92, while Model 1 had the highest PR-AUC of 0.87. Overall, the comparison highlights variations in model performance for different evaluation metrics, indicating the importance of considering multiple metrics in model selection."
2183,"caption: Table 4: Model evaluation metrics for different modelstable: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.85,0.84,0.87,0.82, Random Forest,0.82,0.80,0.85,0.75, Naïve Bayes,0.78,0.75,0.81,0.71, Decision Tree,0.81,0.81,0.84,0.79","Table 4 presents the performance evaluation of four models, SVM, Random Forest, Naïve Bayes, and Decision Tree, in terms of accuracy, F1 Score, precision, and recall. The table shows how these models performed based on the evaluation metrics. The SVM model achieved the highest accuracy of 85%. However, the Random Forest model exhibited the highest F1 score of 0.8, with SVM and Decision Tree tied for second place. In addition, the Decision Tree model exhibited the highest precision score of 0.84, followed closely by SVM. Naïve Bayes ranked last in all evaluation metrics except recall, achieving 0.71. Overall, the table provides valuable insights into the model with the best performance based on the evaluation metric used for comparison."
2184,"caption: Model Performance Comparisontable: Model,Accuracy,Precision,Recall,F1 Score, SVM,0.964,0.965,0.961,0.963, Random Forest,0.958,0.961,0.953,0.957, XGBoost,0.967,0.968,0.964,0.966, MultinomialNB,0.940,0.932,0.938,0.935","The table presents a comparison of different models' performance based on multiple evaluation metrics, including Accuracy, Precision, Recall and F1 Score. The models evaluated are SVM, Random Forest, XGBoost and MultinomialNB. The highest values of Accuracy are observed in XGBoost at 0.967, followed by SVM at 0.964, and finally Random Forest at 0.958. The highest Precision is observed in XGBoost at 0.968, followed by SVM at 0.965, and Random Forest at 0.961. Random Forest has the highest Recall score of 0.953, while XGBoost and SVM follow closely at 0.964 and 0.961, respectively. Finally, the highest F1 Score is observed in XGBoost at 0.966, followed by SVM at 0.963, and Random Forest at 0.957. MultinomialNB performs the worst among all models, having the lowest performance scores for all metrics."
2185,"caption: Table 4: Performance of different classifiers using multiple evaluation metricstable: Model name,Accuracy,F1-Score,Log Loss, Logistic regression,0.85,0.83,0.32, SVM,0.88,0.85,0.28, Naïve Bayes,0.82,0.80,0.38, Decision Tree,0.78,0.75,0.42, Random Forest,0.89,0.87,0.27","Table 4 presents a comparison of different classifiers based on multiple evaluation metrics. The table shows the accuracy, F1-Score, and Log Loss of Logistic Regression, SVM, Naïve Bayes, Decision Tree, and Random Forest models. The table shows that the Random Forest model achieved the highest accuracy and F1-Score of 0.89 and 0.87, respectively, compared to other models. The decision tree model performs worst with the lowest accuracy and F1-Score of 0.78 and 0.75, respectively. The SVM model outperforms other models regarding Log Loss with the lowest Log Loss of 0.28."
2186,"caption: Model performances using different algorithms based on evaluating metrics such as accuracy, precision, recall, F1-score and AUC.table: Model,Accuracy,Precision,Recall,F1-score,AUC, Logistic Regression,0.83,0.82,0.96,0.88,0.90, Support Vector Machine,0.72,0.67,0.75,0.71,0.78, Random Forest,0.87,0.84,0.93,0.88,0.94, Gradient Boosting,0.88,0.86,0.94,0.90,0.93, Multilayer Perceptron,0.84,0.81,0.95,0.88,0.91, K-Nearest Neighbors,0.67,0.61,0.79,0.68,0.71","Table presents the comparison of multiple models' performance utilizing various evaluation metrics such as accuracy, precision, recall, F1-score, and AUC. Logistic Regression, Random Forest, Multilayer Perceptron, Gradient Boosting, Support Vector Machine, and K-Nearest Neighbors models' evaluation metrics are demonstrated. Interestingly, Random Forest had the highest accuracy, precision, AUC, and F1-score values, excluding recall. The Gradient Boosting model achieved the highest recall score, whereas the Support Vector Machine got the highest AUC. K-Nearest Neighbors model achieved the lowest score in all evaluation metrics tested here."
2187,"caption: Table 4: Model performance evaluation using accuracy, PR-AUC, and F1-score.table: Model,Accuracy,PR-AUC,F1-Score, Random Forest,0.94,0.92,0.93, XGBoost,0.93,0.91,0.92, SVM,0.85,0.84,0.82, Multi-Layer Perceptron,0.91,0.87,0.90, Logistic Regression,0.89,0.82,0.87","Table 4 displays the model performance evaluation results obtained from different evaluation metrics, namely Accuracy, PR-AUC, and F1-score. The table presents the results of five models: Random Forest, XGBoost, SVM, Multi-Layer Perceptron (MLP), and Logistic Regression. Notably, Random Forest achieved the highest accuracy and PR-AUC scores with 0.94 and 0.92, respectively. XGBoost and MLP models achieved reasonably close performance scores across the evaluation metrics. However, the SVM model scored the lowest among all models."
2188,"caption: Table 4: Comparison of Different Machine Learning Models' Performances Using Various Evaluation Metricstable: Model,Precision,Recall,F1 Score,ROC-AUC, Logistic Regression,0.93,0.76,0.83,0.85, Decision Tree,0.82,0.78,0.80,0.71, Random Forest,0.92,0.86,0.89,0.86, KNN,0.72,0.69,0.71,0.59, SVM,0.90,0.91,0.90,0.84","Table 4 displays the performances of five different machine learning algorithms, namely Logistic Regression, Decision Tree, Random Forest, KNN, and SVM, using four evaluation metrics, namely Precision, Recall, F1 score, and ROC-AUC. The table indicates Random Forest as the best model based on precision, with a score of 0.92. On the other hand, SVM has the highest recall of 0.91. When considering F1 score, Random Forest again achieved the highest score of 0.89, followed by Logistic Regression and Decision Tree. However, when considering ROC-AUC, Logistic Regression outperformed the rest with a score of 0.85. KNN performed the poorest in all regards. Overall, the table demonstrates the different strengths and weaknesses of each model across multiple evaluation metrics."
2189,"caption: Performance comparison of different models on regression tasks.table: Model Name,Mean Absolute Error (MAE),Root Mean Squared Error (RMSE),R-Squared (R2), Model A,2.42,3.61,0.79, Model B,2.29,3.81,0.76, Model C,2.71,3.93,0.75, Model D,3.14,4.11,0.72, Model E,3.17,4.09,0.73, Model F,2.78,3.65,0.78","The table provides a comparison of the performance of six different models on regression tasks based on multiple evaluation metrics. The evaluation metrics considered in this study are Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and R-Squared (R2). Model B shows the best MAE score of 2.29, while Model F has the best RMSE score of 3.65. On the other hand, Model A has the best R2 score of 0.79. It is interesting to note that no single model outperforms others in all evaluation metrics. Therefore, the choice of model would depend on the specific needs and priorities of the user."
2190,"caption: Table 4: Performance comparison of different models based on different metricstable: Model,Accuracy,F1-Score,Precision,Recall,AUROC, Model A,0.85,0.83,0.87,0.81,0.92, Model B,0.82,0.81,0.77,0.86,0.89, Model C,0.87,0.86,0.90,0.82,0.94, Model D,0.84,0.82,0.85,0.80,0.91","Table 4 provides a comparison of multiple machine learning models based on various evaluation metrics. Models A, B, C, and D were evaluated based on accuracy, F1-score, precision, recall, and area under the ROC curve (AUROC). Overall, model C performed the best, achieving the highest accuracy (0.87) and F1-score (0.86) among all models. Additionally, model C had the highest AUROC (0.94). Interestingly, models A and D had similar performance, with model A having slightly better scores for precision and recall, while model D achieved marginally better results in accuracy and F1-score. Model B had the lowest performance results across all metrics."
2191,"caption: Table 4: Model performance based on different evaluation metrics.table: Model,F1-score,Accuracy,Precision,Recall,AUC-PR,AUC-ROC, Logistic Regression,0.82,0.79,0.84,0.80,0.67,0.84, Decision Tree,0.78,0.75,0.75,0.82,0.57,0.74, Random Forest,0.87,0.85,0.88,0.86,0.80,0.87, Support Vector Machine,0.84,0.81,0.85,0.83,0.70,0.83, XGBoost,0.89,0.87,0.88,0.91,0.82,0.89","Table 4 shows the performance of different models based on various evaluation metrics. The table includes Logistic Regression, Decision Tree, Random Forest, Support Vector Machine, and XGBoost models' F1-score, accuracy, precision, recall, AUC-PR, and AUC-ROC. Interestingly, XGBoost has the best F1-score, precision, and AUC-PR scores, while the Random Forest model has the best accuracy, recall, and AUC-ROC scores. Notably, the Decision Tree model shows the lowest F1-score, AUC-PR, and AUC-ROC scores. Overall, the table highlights the different models' strengths and weaknesses based on different evaluation metrics, which is crucial in selecting the best model for a specific task."
2192,"caption: Performance comparison of different classification models using various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1, SVM,0.83,0.84,0.80,0.82, Decision tree,0.78,0.76,0.83,0.79, Random Forest,0.89,0.86,0.95,0.90, Naive Bayes,0.80,0.83,0.72,0.77, Neural Network,0.94,0.94,0.92,0.93","The presented table compares the performance of different machine learning classification models using various evaluation metrics. The table lists accuracy, precision, recall, and F1 score for SVM, Decision Tree, Random Forest, Naive Bayes, and Neural Network. Results indicate that the Neural Network model has the highest accuracy of 0.94, followed by Random forest with 0.89, and Naive Bayes with 0.80. Precision rates show that Neural Network and SVM have the highest scores of 0.94 and 0.84, respectively. Random Forest model indicates the highest recall score of 0.95, whereas Decision Tree has the highest F1 score of 0.79."
2193,"caption: Table 4: Performance evaluation results of different models based on multiple evaluation metricstable: Model,PR-AUC,ROC-AUC,F1-Score,Accuracy, Logistic Regression,0.88,0.72,0.74,0.76, Decision Tree,0.84,0.68,0.68,0.72, Random Forest,0.93,0.79,0.83,0.85, XGBoost,0.91,0.75,0.79,0.81","Table 4 presents the performance evaluation results of different models based on multiple evaluation metrics, including PR-AUC, ROC-AUC, F1-score, and accuracy. The table includes Logistic Regression, Decision Tree, Random Forest, and XGBoost models. Notably, Random Forest achieved the highest scores in all evaluation metrics, with PR-AUC of 0.93, ROC-AUC of 0.79, F1-score of 0.83, and accuracy of 0.85. Interestingly, XGBoost had the second-best scores in all evaluation metrics and outperformed Logistic Regression and Decision Tree."
2194,"caption: A comparison of classification models based on multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.87,0.85,0.87,0.85, KNN,0.80,0.76,0.81,0.77, Decision tree,0.82,0.79,0.84,0.81, Random forest,0.93,0.92,0.94,0.93, Multi-layer perceptron,0.89,0.88,0.90,0.89","The table presents a comparison of different classification models based on multiple evaluation metrics, including accuracy, precision, recall, and F1-score. Five models, namely SVM, KNN, Decision Tree, Random Forest, and Multi-layer Perceptron are compared using the same dataset. Random forest achieved the highest accuracy, precision, recall, and F1-score with values of 0.93, 0.92, 0.94, and 0.93, respectively. The second-best performer is SVM with an accuracy of 0.87 and precision, recall, F1-score of 0.85. Interestingly, KNN has a recall score higher than precision, while Multi-layer perceptron shows an almost equal score for the same. Decision tree performs the worst compared to other models in terms of accuracy, precision, recall, and F1-score. Overall, the table presents an insightful comparison of different classification models based on multiple evaluation metrics."
2195,"caption: Performance comparison of different models using multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1, Logistic Regression,0.84,0.82,0.76,0.79, Random Forest,0.88,0.89,0.79,0.84, K-Nearest Neighbor,0.8,0.77,0.67,0.71, Support Vector Machine,0.86,0.85,0.81,0.83, Gradient Boosting,0.9,0.9,0.83,0.85","The table above shows the performance comparison of different classification models using four evaluation metrics, accuracy, precision, recall, and F1-score. The models assessed were Logistic Regression, Random Forest, K-Nearest Neighbor, Support Vector Machine, and Gradient Boosting. It's interesting to note that the Gradient Boosting model shows the highest accuracy of 0.9, while the Random Forest model achieves the highest precision with a score of 0.89. Out of all the models tested, Random Forest has the highest F1 score of 0.84, and the Support Vector Machine has the highest recall score of 0.81."
2196,"caption: Table 4: Performance comparison of models based on different evaluation metrics.table: Model,Accuracy Score,F1 Score,Precision Score,Recall Score, Model1,0.89,0.87,0.91,0.85, Model2,0.91,0.89,0.92,0.87, Model3,0.92,0.91,0.93,0.89, Model4,0.88,0.86,0.90,0.84, Model5,0.90,0.89,0.91,0.88","Table 4 compares model performances using various evaluation metrics. The evaluation metrics considered in the table are Accuracy Score, F1 Score, Precision Score, and Recall Score. The table includes information about the scores achieved by Model1, Model2, Model3, Model4, and Model5. The accuracy range of the models varies from 0.88 to 0.92, with Model3 having the highest accuracy score of 0.92. Model3 also ranks first on F1 Score, Precision Score, and Recall Score with 0.91, 0.93, and 0.89, respectively. Model5 secured the second-highest scores on all metrics, barring Recall Score."
2197,"caption: Performance Metrics for Different Modelstable: Model,Accuracy,F1 Score,Precision,Recall, Model A,0.85,0.83,0.87,0.82, Model B,0.82,0.81,0.84,0.78, Model C,0.79,0.77,0.79,0.74, Model D,0.86,0.84,0.88,0.84, Model E,0.83,0.81,0.85,0.79","The table presents the evaluation results of five different models, namely Model A, Model B, Model C, Model D, and Model E, using four different evaluation metrics, namely Accuracy, F1 Score, Precision, and Recall. The table exhibits a mixed distribution of performances across models and metrics. Model A showed the highest accuracy of 0.85 and precision of 0.87. Model D showcased the highest precision of 0.88 and recall of 0.84. On the other hand, Model C performed the least on all evaluation metrics. The table showcases the necessity of using multiple metrics to evaluate model performance and selecting the best performing model based on the specific evaluation task's requirements."
2198,"caption: Comparison of different models based on various metrics.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.75,0.60,0.55,0.70, KNN,0.80,0.65,0.60,0.75, RF,0.85,0.75,0.70,0.80, ANN,0.80,0.68,0.65,0.71, NB,0.70,0.55,0.50,0.60","Table above provides a comparison of multiple machine learning models based on different evaluation metrics. The models include Support Vector Machine (SVM), K-Nearest Neighbors (KNN), Random Forest (RF), Artificial Neural Network (ANN), and Naive Bayes (NB). All models were evaluated and tested using the same dataset, resulting in accuracy, F1-score, precision, and recall scores. Results show that RF model achieved the highest scores across different metrics with an accuracy of 0.85, F1-score of 0.75, precision of 0.70, and recall of 0.80. However, the KNN model is not far off with 0.80 accuracy and 0.75 F1-score. Additionally, the SVM model achieved the best recall score of 0.70, while NB had the lowest performance result across all metrics."
2199,"caption: Model performances of different classifiers based on evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score,AUC, Logistic Regression,0.85,0.86,0.76,0.81,0.92, Decision Tree,0.82,0.80,0.74,0.77,0.77, Random Forest,0.88,0.89,0.80,0.84,0.93, K-Nearest Neighbor (KNN),0.81,0.82,0.72,0.76,0.80, Support Vector Machine (SVM),0.84,0.85,0.75,0.79,0.89","The table presents the performance results of five different classifiers, i.e., Logistic Regression, Decision Tree, Random Forest, K-Nearest Neighbor (KNN), and Support Vector Machine (SVM) on the given dataset. The models are evaluated based on multiple evaluation metrics, including Accuracy, Precision, Recall, F1-score, and AUC. Interestingly, Random Forest achieved the best performance on all evaluation metrics except Precision. While Decision Tree has the lowest Accuracy, it has a high AUC score indicating good model performance for classification. The results suggest that Random Forest and SVM are the two best models for this classification task based on overall performance."
2200,"caption: Comparison of different models based on F1-Score, G-Mean, and Accuracy evaluation metrics.table: Model,F1-Score,G-Mean,Accuracy, Logistic Regression,0.89,0.92,0.91, Random Forest,0.91,0.93,0.92, Support Vector Machine,0.86,0.90,0.90, Decision Tree,0.83,0.85,0.87, XGBoost Classifier,0.93,0.94,0.94","Table 4 presents a comparison of multiple classification models based on F1-Score, G-Mean, and Accuracy metrics. The table comprises of five different machine learning models such as Logistic Regression, Random Forest, Support Vector Machine, Decision Tree, and XGBoost Classifier. The evaluation metrics for each model are presented in rows, including F1-Score, G-Mean, and Accuracy. The highest performance scores were achieved by XGBoost Classifier model across all the metrics with F1-Score of 0.93, G-Mean of 0.94, and Accuracy of 0.94. Random Forest and Logistic Regression models also show promising results with similar scores in all the metrics. The Decision Tree model reflects relatively lower accuracy and F1-Score than the rest of the models. Additionally, the Support Vector Machine model exhibits the lowest scores across all the metrics."
2201,"caption: Table 4: Model performances based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,ROC-AUC,F1-score, Decision Tree,0.72,0.57,0.63,0.69,0.6, SVM,0.80,0.70,0.75,0.79,0.71, KNN,0.77,0.62,0.61,0.76,0.62, Random Forest,0.87,0.83,0.81,0.87,0.82, XGBoost,0.89,0.86,0.85,0.92,0.85","Table 4 exhibits the performances of multiple models based on different evaluation metrics such as Accuracy, Precision, Recall, ROC-AUC, and F1-score. The table shows Decision tree, SVM, KNN, Random forest, and XGBoost models with their respective performance measures. The highest accuracy measure is obtained by XGBoost at 0.89, with the Random Forest model following closely with 0.87. The XGBoost model also shows high precision, recall, and F1-score. Similarly, the Random Forest model shows the highest precision and recall scores of 0.83 and 0.81, respectively. XGBoost exhibits the best ROC-AUC score of 0.92, followed by random forest with 0.87."
2202,"caption: Comparison of different classification models on accuracy, F1-score, precision, and recall.table: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.92,0.89,0.91,0.87, Decision Tree,0.88,0.84,0.85,0.83, Support Vector Machines,0.94,0.91,0.93,0.89, Random Forest,0.96,0.95,0.95,0.94, Gradient Boosting Classifier,0.95,0.94,0.94,0.94","The table provides a comparison of different models' performance based on evaluation metrics, including accuracy, F1-score, precision, and recall. Five models, including Logistic Regression, Decision Tree, Support Vector Machines, Random Forest, and Gradient Boosting Classifier, were evaluated. The Random Forest model shows the highest accuracy with a score of 0.96, while the Logistic Regression model has the second-highest accuracy score of 0.92. Interestingly, the Gradient Boosting Classifier shows the highest F1-score and precision of 0.94. Nevertheless, the Support Vector Machines model achieved the highest recall of 0.89, while the Random Forest model had the best precision of 0.95. Overall, the results provide insight into the different models' strengths in classification tasks."
2203,"caption: Model performance assessment using different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 score, Logistic Regression,0.84,0.78,0.83,0.80, K-Nearest Neighbor,0.72,0.68,0.69,0.67, Decision Tree,0.79,0.78,0.72,0.75, Random Forest,0.86,0.82,0.85,0.82, Support Vector Machine,0.77,0.75,0.66,0.70, Multilayer Perceptron,0.83,0.82,0.79,0.80","Table 4 displays the accuracy, precision, recall, and F1 score of six different models. The models assessed are Logistic Regression, K-Nearest Neighbor, Decision Tree, Random Forest, Support Vector Machine, and Multilayer Perceptron. The evaluation metrics employ widely in binary classification tasks, and the models are trained and tested on the same dataset. The Random Forest model appears to perform best across all evaluation metrics, with an accuracy of 0.86, precision of 0.82, recall of 0.85, and an F1 score of 0.82. Logistic Regression also shows promising performance with high precision and recall scores. On the other hand, K-Nearest Neighbor and SVM models exhibit inferior results in all evaluation metrics when compared to the rest of the models.presenting observations and highlighting the best model's performance."
2204,"caption: Evaluation metrics of different machine learning models.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.86,0.88,0.82,0.85, KNN,0.72,0.69,0.76,0.72, RF,0.91,0.92,0.90,0.91, MLP,0.89,0.90,0.87,0.89, GB,0.87,0.82,0.95,0.88, DT,0.78,0.76,0.82,0.77","The table presents the evaluation metrics of different machine learning models, including SVM, KNN, RF, MLP, GB, and DT. The measures include Accuracy, Precision, Recall, and F1-score. The RF model performed best in terms of all the metrics, whereas KNN model performed worst in terms of accuracy and F1-score. The MLP model and GB model showed high precision and recall, respectively, although the RF model scored the highest in both. Notably, the DT model had a low accuracy score of 0.78. The table shows that different models are suitable for different tasks, and one should choose the right model based on the evaluation metrics and project requirements."
2205,"caption: Table 4. Evaluation metrics of different machine learning models.table: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.76,0.69,0.78,0.73, Decision Tree,0.82,0.79,0.77,0.78, Random Forest,0.85,0.83,0.80,0.81, Support Vector Machine,0.79,0.74,0.82,0.78","Table 4 summarizes the evaluation metric results of four different machine learning models, including Logistic Regression, Decision Tree, Random Forest, and Support Vector Machine. The table displays the accuracy, precision, recall, and F1-score for each model. The Random Forest model shows the highest accuracy of 0.85, followed by Decision Tree with an accuracy of 0.82. The Random Forest model also performs well on precision, recall, and F1-score with values of 0.83, 0.80, and 0.81, respectively. Meanwhile, the Decision Tree model has the highest precision score of 0.79, while the Support Vector Model ranks the highest on recall with a score of 0.82."
2206,"caption: The performance of different models using various evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.87,0.86,0.89,0.83, kNN,0.81,0.80,0.84,0.76, MLP,0.93,0.92,0.94,0.90, DT,0.75,0.74,0.76,0.73, RF,0.91,0.90,0.92,0.88","The table compares the performance of five distinct models, namely, SVM, kNN, MLP, DT, and RF based on multiple evaluation metrics such as Accuracy, F1-score, Precision, and Recall. The best performer* of each metric is colored in bold. The MLP model shows the most exceptional performance for each metric, achieving the highest score for Accuracy (0.93), F1-score (0.92), Precision (0.94), and Recall (0.90). The RF model achieved a commendable Accuracy score of 0.91, indicating a reliable model for classification tasks. The DT model, on the other hand, presents the lowest score for all metrics, suggesting that it is not suitable for this classification task."
2207,"caption: Table 4: Model performances based on precision, recall, F1-score, accuracy, and AUC.table: Model Name,Precision,Recall,F1-score,Accuracy,AUC, Model 1,0.84,0.85,0.84,0.85,0.85, Model 2,0.87,0.84,0.85,0.86,0.87, Model 3,0.82,0.81,0.81,0.81,0.81, Model 4,0.85,0.76,0.79,0.83,0.80, Model 5,0.88,0.85,0.85,0.86,0.86, Model 6,0.71,0.95,0.80,0.81,0.83","Table 4 presents a comparison of six models in terms of precision, recall, F1-score, accuracy, and AUC. Model 2 exhibits the best performance in the majority of evaluation metrics, outperforming the other models in precision, accuracy, and AUC with scores of 0.87, 0.86, and 0.87, respectively. On the other hand, Model 6 performed excellently in recall, scoring 0.95, while Model 3 had the lowest performance across the board with precision, recall, and F1-score scores of 0.82, 0.81, and 0.81, respectively. These results demonstrate that evaluating multiple metrics is essential to get a complete picture of model performance."
2208,"caption: Table 4: Comparison of model performance based on multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.8765,0.879,0.863,0.871, Random Forest,0.9123,0.919,0.900,0.908, XGBoost,0.8998,0.903,0.890,0.896, SVM,0.8756,0.885,0.861,0.873","Table 4 presents a comparison of different models based on multiple evaluation metrics. The four models, Logistic Regression, Random Forest, XGBoost, and SVM, are evaluated based on their accuracy, precision, recall, and F1-Score. The Random Forest model has the highest accuracy, precision, recall, and F1-Score, achieving 0.9123, 0.919, 0.900, and 0.908, respectively. The XGBoost and Logistic Regression models perform similarly across the evaluation metrics, except for precision, where XGBoost outperforms Logistic Regression. SVM performs decently but falls behind the other models' performance in terms of accuracy, precision, and F1-Score."
2209,"caption: Comparison of different models using different evaluation metrics.table: Model,Accuracy,F1-Score,AUC,Precision,Recall, SVM,0.72,0.65,0.78,0.68,0.63, MLP,0.82,0.76,0.87,0.79,0.74, KNN,0.66,0.60,0.73,0.63,0.58, RF,0.87,0.84,0.89,0.82,0.88, DT,0.75,0.69,0.79,0.72,0.67",
2210,"caption: Performance comparison of different classification models based on accuracy, F1-score, precision, and recall.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.98,0.97,0.96,0.98, KNN,0.95,0.92,0.87,0.98, Random Forest,0.99,0.98,0.97,0.99, MLP,0.96,0.94,0.91,0.98","The table above shows the performance comparison of four classification models based on multiple evaluation metrics- accuracy, F1-score, precision, and recall. The SVM model exhibits the highest accuracy score of 0.98, while the Random Forest model achieves the highest F1-score, precision, and recall scores of 0.98, 0.97, and 0.99, respectively. Interestingly, the KNN model shows the lowest performance with an accuracy score of 0.95, F1-score of 0.92, precision of 0.87, and recall of 0.98. These scores indicate that the Random Forest model has the best overall performance among all the models, while the SVM model has the best accuracy."
2211,"caption: Table 4. Model performances based on various evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, Logistic Reg.,0.85,0.84,0.81,0.88, SVM,0.86,0.85,0.85,0.85, Random Forest,0.87,0.87,0.87,0.88, XGBoost,0.88,0.88,0.89,0.87, Multi-Layer Per.,0.84,0.83,0.82,0.84","Table 4 displays the performance of five different models based on various evaluation metrics such as accuracy, F1-score, precision, and recall. The models are Logistic Regression, SVM, Random Forest, XGBoost, and Multi-layer perceptron. The Random Forest model has the highest accuracy by obtaining a score of 0.87, while XGBoost has the highest F1-score with a score of 0.88. XGBoost also shows the highest precision score of 0.89, and Logistic Regression has the highest recall score with a value of 0.88. Based on the table, it can be observed that all models exhibit a high-performance level in overall, with a close range in the achieved results."
2212,"caption: Model performance summary of different classification models.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.89,0.88,0.87,0.87, Decision Tree,0.81,0.72,0.77,0.72, Random Forest,0.92,0.91,0.92,0.91, SVM,0.88,0.83,0.85,0.84","The table above highlights the performance of various classification models based on accuracy, precision, recall, and F1-Score. The models evaluated in this study include Logistic Regression, Decision Tree, Random Forest, and SVM. According to the results, Random Forest achieved the highest accuracy, precision, recall, and F1-Score with values of 0.92, 0.91, 0.92, and 0.91, respectively. The Logistic Regression model also performed well with an accuracy of 0.89 and a precision, recall, and F1-Score of 0.88, 0.87, and 0.87, respectively. The Decision Tree model had the lowest performance on all evaluation metrics. Overall, the Random Forest model appears to be the best model based on these results."
2213,"caption: Table 4: Model performance evaluation measures.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.89,0.90,0.85,0.87, Naive Bayes,0.80,0.81,0.75,0.76, K-Nearest Neighbors,0.84,0.85,0.79,0.80, Decision Tree,0.90,0.91,0.88,0.89, Random Forest,0.94,0.95,0.92,0.93, Gradient Boosting,0.95,0.96,0.94,0.95","Table 4 displays the evaluation measures of six classification models, including Logistic Regression, Naive Bayes, K-Nearest Neighbors, Decision Tree, Random Forest, and Gradient Boosting. The evaluation metrics present in the table are Accuracy, Precision, Recall, and F1-Score. Interestingly, the Gradient Boosting model demonstrates the best overall performance for all of the evaluation metrics, achieving the highest accuracy of 0.95 and the highest F1-Score of 0.95, whereas the Random Forest model demonstrates the second-best performance across all the evaluation metrics. Conversely, the Naive Bayes model performs the worst among the other models with an accuracy of 0.80 and an F1-score of 0.76."
2214,"caption: Performance comparison of four different models on six evaluation metricstable: Model,Accuracy,F1-score,Precision,Recall,AUC-ROC,AUC-PR, Model A,0.85,0.87,0.84,0.9,0.78,0.81, Model B,0.82,0.84,0.77,0.93,0.85,0.78, Model C,0.88,0.9,0.91,0.89,0.92,0.89, Model D,0.78,0.81,0.8,0.82,0.74,0.72","The presented table shows the accuracy, F1-score, precision, recall, AUC-ROC, and AUC-PR of four distinct models. Each model's performance was evaluated on the same dataset using different evaluation metrics. Model C had the highest accuracy (0.88), F1-score (0.90), precision (0.91), and AUC-PR (0.89) scores among the four models, whereas Model D had the lowest scores on all of these metrics. Interestingly, Model B's recall score was the highest among all the models (0.93), whereas Model A had the lowest recall score (0.9). Finally, Model C had the highest AUC-ROC of 0.92. Overall, the table indicates crucial differences in model performances under six different metrics, thereby providing useful insights for selecting the appropriate model for specific applications."
2215,"caption: Table 4: Model Performance using different evaluation metrics.table: Model,Accuracy (mean ± SD),F1-score (mean ± SD),AUC (mean ± SD), SVM,0.86 ± 0.04,0.834 ± 0.05,0.93 ± 0.03, Logistic Reg,0.89 ± 0.03,0.864 ± 0.04,0.94 ± 0.01, Random Forest,0.91 ± 0.02,0.896 ± 0.02,0.96 ± 0.01, XGBoost,0.91 ± 0.02,0.899 ± 0.03,0.96 ± 0.02, MLP,0.92 ± 0.02,0.905 ± 0.02,0.97 ± 0.01","Table 4 compares the performance metrics of five models in the classification task. The models include: SVM, Logistic Regression, Random Forest, XGBoost, and MLP. The table displays the mean score and standard deviation for accuracy, F1-score, and AUC. Interestingly, MLP achieves the highest accuracy (0.92±0.02) and F1-score (0.905±0.02) among all models, while Random Forest and XGBoost have the highest AUC (0.96±0.01 and 0.96±0.02, respectively). These results suggest that MLP outperforms the other models in this particular classification task."
2216,"caption: Table 4: Model Performance Comparison for Different Models and Evaluation Metrics.table: Model,Accuracy,Precision,Recall,F1, Logistic Regression,0.85,0.86,0.87,0.85, Decision Tree,0.80,0.76,0.82,0.78, Random Forest,0.86,0.88,0.87,0.87, XGBoost,0.88,0.89,0.91,0.89, SVM,0.81,0.85,0.79,0.82","Table 4 presents a performance comparison of different models, including Logistic Regression, Decision Tree, Random Forest, XGBoost, and SVM based on various evaluation metrics, including Accuracy, Precision, Recall, and F1-score. The models were trained and tested on the same dataset. The XGBoost model provides the highest accuracy score of 0.88 among all the models. However, the SVM model has the highest precision score of 0.85, while the XGBoost has the highest recall score of 0.91. The F1-score was highest for the Random Forest model, with a score of 0.87. Overall, it can be concluded that the XGBoost and Random Forest models perform well across different metrics, while the SVM model performs best in precision."
2217,"caption: Table 4: Model performance on evaluation metrics using the test set.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.88,0.84,0.85,0.82, Naive Bayes,0.82,0.78,0.8,0.76, Random Forest,0.94,0.91,0.94,0.89, XGBoost,0.92,0.90,0.91,0.89","Table 4 shows the comparison results of the SVM, Naive Bayes, Random Forest, and XGBoost models using the test set. Each model's performance was measured by multiple evaluation metrics such as accuracy, F1-score, precision, and recall. The Random Forest model achieved the highest accuracy (0.94) with an F1-score of 0.91, which outperformed the SVM, Naive Bayes, and XGBoost models. The Naive Bayes model had the lowest performance among all models, including the lowest accuracy of 0.82, followed by XGBoost. Despite having lower accuracy scores, SVM and Naive Bayes obtained better precision scores 0.85 and 0.8, respectively, than the other two models."
2218,"caption: Comparison of Different Models' Performance based on Multiple Evaluation Metrics.table: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.84,0.86,0.73,0.79, Random Forest,0.92,0.94,0.85,0.89, Naive Bayes,0.77,0.62,0.91,0.74, Support Vector Machine,0.88,0.90,0.82,0.85, Gradient Boosting,0.91,0.93,0.86,0.89","The table provides a comparison of different machine learning models' performances based on multiple evaluation metrics. We can observe that the random forest and gradient boosting classifiers had higher accuracy, precision, recall and F1-score compared to other models such as logistic regression, naive bayes and support vector machine classifier. The random forest model had the highest accuracy of 0.92 with precision of 0.94 and recall of 0.85. On the other hand, naive bayes had the highest recall of 0.91. The logistic regression achieved the lowest recall score with 0.73. Overall, the table reveals that the random forest classifier outperforms all other models across different metrics."
2219,"caption: Evaluation Metrics for Classification Modelstable: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.83,0.84,0.81,0.82, Decision Tree,0.75,0.68,0.78,0.72, Random Forest,0.89,0.88,0.90,0.88, Support Vector Machine,0.82,0.79,0.85,0.82","The table above presents the evaluation metrics of different classification models such as Logistic Regression, Decision Tree, Random Forest, and Support Vector Machine. The table evaluates each model's accuracy, precision, recall, and F1-score. The Random Forest algorithm presents the best overall performance with 89% accuracy, a precision score of 0.88, recall of 0.90, and an F1-score of 0.88. This model also performed better in terms of accuracy and recall than Logistic Regression and Support Vector Machine. However, Decision Tree, while having the lowest overall score, had the highest precision value of 0.68, indicating that it had fewer false positives than other models."
2220,"caption: Table 4: Model performances in accuracy, recall, precision, and F1-score.table: Model,Accuracy,Recall,Precision,F1-Score, Model A,0.780,0.650,0.785,0.712, Model B,0.812,0.740,0.811,0.774, Model C,0.705,0.556,0.665,0.602, Model D,0.802,0.780,0.804,0.792, Model E,0.825,0.720,0.840,0.776","Table 4 presents the comparison of multiple machine learning models, considering various evaluation metrics. The models are compared based on their accuracy, recall, precision, and F1-score values. Model B performed the best in all metrics, achieving an accuracy of 0.812, recall of 0.740, precision of 0.811, and F1-score of 0.774. Model E also had a high accuracy and precision (0.825 and 0.840), but its recall and F1-score were relatively lower (0.720 and 0.776). Model D had the highest recall (0.780), and its precision and F1-score were also high at 0.804 and 0.792, respectively. Model A performed well in accuracy (0.780) and precision (0.785), while Model C had a relatively lower performance in all metrics compared to other models."
2221,"caption: Model performance comparison of different classifiers based on various evaluation metrics.table: Model,Accuracy,F1-Score,Sensitivity,Specificity, SVM,0.76,0.71,0.82,0.68, Naive Bayes,0.82,0.80,0.75,0.88, Logistic Regression,0.84,0.82,0.89,0.79, Random Forest,0.91,0.90,0.93,0.89","This table presents the model performance comparison of different classifiers based on various evaluation metrics. The table includes SVM, Naive Bayes, Logistic Regression, and Random Forest models' accuracy, F1-Score, sensitivity, and specificity. It is evident from the table that the Random Forest model achieved the best overall performance with the highest accuracy of 0.91, F1-Score of 0.90, and sensitivity of 0.93. While the Naive Bayes model achieved the second-highest overall performance with the accuracy of 0.82, F1-score of 0.80, and very high specificity of 0.88. The SVM model has the lowest performance compared to the other classifiers. The Logistic Regression model performed better than the SVM with the accuracy of 0.84, F1-score of 0.82, sensitivity of 0.89 but slightly lower specificity of 0.79."
2222,"caption: Table 4: Model performances based on accuracy, F1-score, and AUCtable: Model,Accuracy,F1-Score,AUC, Logistic Regression,0.83,0.84,0.90, Decision Tree,0.78,0.79,0.82, Random Forest,0.85,0.85,0.91, Gradient Boosting,0.86,0.87,0.92, Support Vector Machines,0.81,0.83,0.88","Table 4 presents a comparison of different models' performance based on different evaluation metrics such as accuracy, F1-Score, and AUC. The table includes Logistic regression, Decision tree, Random forest, Gradient boosting, and Support vector machines' model performances. Notably, the Random Forest models show the best AUC of 0.91 and an accuracy and F1-score of 0.85. Gradient boosting also demonstrated competitive results, with an AUC of 0.92 and accuracy and F1-score of 0.86 and 0.87 correspondingly. The Decision Tree model demonstrated an overall lowest result for all metrics."
2223,"caption: Comparison of model performance based on different evaluation metricstable: Model,F1-score,Accuracy,Precision,Recall, Random Forest,0.89,0.91,0.87,0.91, K-NN,0.78,0.81,0.80,0.76, Logistic Regression,0.92,0.92,0.88,0.98, Decision Tree,0.83,0.86,0.82,0.85, SVM,0.87,0.89,0.91,0.85","Table shows the comparison of five different models' performances based on multiple evaluation metrics. The metrics used for evaluation are F1-score, accuracy, precision, and recall. The table indicates that the logistic regression achieved the highest F1-score (0.92), which is higher compared to other models. The Random Forest model comes second with an F1-score of 0.89. Similarly, Logistic Regression shows the highest accuracy and recall values of 0.92 and 0.98, respectively. SVM has the highest precision value of 0.91. Notably, K-NN has the lowest performance score in all four evaluation metrics."
2224,"caption: Comparison of different models' classification performance on the test dataset.table: Model,Accuracy,F1-score,Precision,Recall, Model A,0.90,0.92,0.91,0.91, Model B,0.92,0.93,0.95,0.91, Model C,0.91,0.94,0.92,0.96, Model D,0.89,0.91,0.90,0.93, Model E,0.93,0.94,0.94,0.94","Table above entails the comparison of different models' performances on a classification task using different evaluation metrics. Each model's accuracy, F1-score, precision, and recall are measured and presented in the table. Here, Model E achieved the highest accuracy of 0.93. Model C has the highest F1-score and recall of 0.94 and 0.96, respectively, while Model B has the highest precision of 0.95. Moreover, all the models exhibit a significant performance, considering that their accuracy scores range between 0.89-0.93."
2225,"caption: Comparison of model performance for a binary classification problem using different evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.789,0.731,0.758,0.735, Decision Tree,0.802,0.772,0.695,0.730, Random Forest,0.837,0.803,0.808,0.804, Gradient Boosting,0.846,0.801,0.860,0.828, Support Vector Machine,0.780,0.748,0.615,0.675","The table compares the performance of different models using various evaluation metrics, namely accuracy, precision, recall, and F1-score. The models used for comparison include Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Support Vector Machine. The Random Forest model shows the highest accuracy score of 0.837, while the Gradient Boosting model presents the best precision and recall scores of 0.801 and 0.860, respectively. Interestingly, the Decision Tree model has a high precision score of 0.772 with a moderate recall score of 0.695, whereas the Logistic Regression model resulted in a high recall score of 0.758 with a moderate precision score of 0.731. Finally, the SVM model shows the lowest overall performance compared to the other models."
2226,"caption: Performance metrics of different classification modelstable: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.85,0.847,0.854,0.843, Logistic Regression,0.83,0.826,0.834,0.819, Naïve Bayes,0.75,0.745,0.74,0.75, K-Nearest Neighbors,0.81,0.811,0.815,0.807, Random Forest,0.89,0.885,0.891,0.878, Neural Network,0.90,0.897,0.901,0.891","The table presents the performance metrics of six different classification models, including SVM, Logistic Regression, Naïve Bayes, K-Nearest Neighbors, Random Forest, and Neural Network. The models were evaluated on four different performance metrics, namely accuracy, F1-score, precision, and recall. The Random Forest and Neural Network models showed the best performance across all four metrics. Remarkably, the Neural Network outperformed all other models in accuracy, F1-score, and precision, with an accuracy score of 0.90, F1-score of 0.897, and precision of 0.901. However, the Random Forest model had the highest recall of 0.878. The Naïve Bayes model showed the lowest performance scores across all four metrics."
2227,"caption: Model performance comparison for different classifiers using accuracy, F1-score, precision, and recall metricstable: Model Name,Accuracy (%),F1-score,Precision,Recall, SVM,87.42,0.873,0.881,0.865, Random Forest,86.14,0.855,0.865,0.846, KNN,83.27,0.826,0.835,0.817, Naive Bayes,80.63,0.797,0.803,0.791","The table displays the comparison of four different classifiers' performances, namely SVM, Random Forest, KNN, and Naive Bayes. The table exhibits the evaluation metrics including Accuracy (%), F1-score, Precision, and Recall. Notably, SVM performed the best with an accuracy of 87.42%, an F1-score of 0.873, precision of 0.881, and recall of 0.865, while the Random Forest model exhibited an accuracy of 86.14%, an F1-score of 0.855, precision of 0.865, and recall of 0.846. Interestingly, the Naive Bayes model exhibited precision and recall scores of 0.803 and 0.791, respectively, which is better than KNN. However, KNN showed the lowest performance scores with an accuracy rate of 83.27%, F1-score of 0.826, precision of 0.835, and recall of 0.817."
2228,"caption: Table 4: Model performances based on different evaluation metricstable: Model Name,F1-Score,Precision,Recall,Accuracy, Model 1,0.85,0.86,0.84,0.91, Model 2,0.78,0.81,0.75,0.88, Model 3,0.92,0.88,0.96,0.94, Model 4,0.80,0.79,0.81,0.87, Model 5,0.95,0.94,0.97,0.96",
2229,"caption: Table 4: Performance of different models based on multiple evaluation metrics.table: Model,Precision,Recall,F1-Score,Accuracy, SVM,0.89,0.76,0.82,0.87, Logistic Regression,0.90,0.81,0.83,0.88, Random Forest,0.93,0.84,0.88,0.90","Table 4 presents the performance of three different models based on multiple evaluation metrics. The table compares SVM, Logistic Regression, and Random Forest models regarding Precision, Recall, F1-Score, and Accuracy. The table shows that the Random Forest model outperforms the other models on all evaluation metrics. The model obtained a Precision score of 0.93, Recall of 0.84, F1-Score of 0.88, and Accuracy of 0.90. The SVM and Logistic Regression models' performances are relatively similar but relatively inferior to the Random Forest model, with both models obtaining Precision scores slightly lower than 0.90 and F1-Scores slightly below 0.85."
2230,"caption: Performance of different classification models on the test dataset in terms of precision, recall, F1-Score, and accuracy.table: Model,Precision,Recall,F1-Score,Accuracy, SVM,0.89,0.85,0.87,0.82, Gradient Boosting,0.92,0.87,0.89,0.86, Decision Tree,0.76,0.78,0.77,0.73, k-nearest neighbor,0.84,0.83,0.83,0.81, Random Forest,0.93,0.94,0.93,0.91","The table compares the performance of SVM, Gradient Boosting, Decision Tree, k-nearest neighbor, and Random Forest classification models on the test dataset regarding precision, recall, F1-Score, and accuracy. The Random Forest model shows the best performance in all metrics, having the highest precision, recall, F1-Score, and accuracy scores of 0.93, 0.94, 0.93, and 0.91, respectively. Notably, the Gradient Boosting model has the second-best performance in all metrics, except precision, where it was surpassed by the Random Forest. The Decision Tree model has the lowest F1-Score and accuracy, while the SVM and k-nearest neighbor models are in between the rest of the models in terms of their performance."
2231,"caption: Comparison of different machine learning models based on their performance with five different evaluation metrics.table: Model Name,Loss,F1 Score,Precision,Recall,AUC Score, Logistic Regression,0.250,0.93,0.91,0.94,0.83, XGBoost,0.132,0.96,0.96,0.96,0.89, Random Forest,0.095,0.97,0.97,0.97,0.94, CNN,0.075,0.96,0.95,0.98,0.91, RNN,0.067,0.95,0.94,0.96,0.89","This table presents a comparison of different machine learning models based on their performance with respect to five different evaluation metrics. The models included in this comparison are Logistic Regression, XGBoost, Random Forest, CNN, and RNN. The table shows the loss, F1 score, Precision, Recall, and AUC score for each model. Notably, the Random Forest model achieved the highest F1 score, Precision, Recall, and AUC score with the scores of 0.97, 0.97, 0.97, and 0.94, respectively. The CNN model had the lowest AUC score of 0.91, while the XGBoost had the highest AUC score of 0.89. Overall, the table provides a clear overview of different machine learning models' performances and enables better comparison among the models based on multiple evaluation metrics."
2232,"caption: Results from the classification models on the test dataset.table: Model,Accuracy,Precision,Recall,F1-Score, LR,0.87,0.88,0.85,0.86, SVM,0.85,0.85,0.84,0.84, KNN,0.82,0.81,0.83,0.82, RF,0.91,0.90,0.92,0.91","The presented table compares the accuracy, precision, recall, and F1-Score of different classification models on the test dataset. The table reveals that the Random Forest (RF) model has obtained the highest accuracy of 0.91 and F1-Score of 0.91. However, the Logistic Regression (LR) model has achieved the highest precision of 0.88, while the K-Nearest Neighbor (KNN) model has obtained the highest recall of 0.83. Another interesting observation is that the SVM model has obtained comparable performance results with the RF model despite having a lower accuracy score of 0.85. These observations could provide insight into which model to use for a particular task based on multiple evaluation metrics."
2233,"caption: Performance comparison of different models based on various evaluation metrics.table: Model,F1,Precision,Recall,Accuracy,ROC-AUC, Model A,0.87,0.89,0.85,0.84,0.91, Model B,0.82,0.78,0.87,0.82,0.88, Model C,0.77,0.83,0.72,0.76,0.84, Model D,0.91,0.92,0.90,0.89,0.93, Model E,0.94,0.91,0.97,0.93,0.92","The table compares the performance of five different models, namely Model A to Model E, based on five evaluation metrics, namely F1, Precision, Recall, Accuracy, and ROC-AUC. Notably, all the models deliver impressive overall performance with F1 scores ranging from 0.77 to 0.94. Model E scores the highest F1 with a performance score of 0.94. Model D achieves the highest precision (0.92) and recall (0.90) and the second-highest F1 score  of 0.91. The highest accuracy obtained was 0.93 by Model E, while Model A had the highest ROC-AUC score of 0.91. Overall, the table presents a comprehensive analysis of the different models' performance, showcasing their strengths and weaknesses in terms of multiple metrics."
2234,"caption: Performance results of different models on the classification task.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.92,0.93,0.94,0.92, KNN,0.87,0.88,0.90,0.87, Naive Bayes,0.81,0.82,0.91,0.75, Decision Tree,0.89,0.88,0.87,0.90, Random Forest,0.95,0.95,0.96,0.95, XGBoost,0.93,0.94,0.94,0.94","Table above presents the accuracy, F1-score, precision, and recall results of SVM, KNN, Naive Bayes, Decision Tree, Random Forest, and XGBoost models on the classification task. The Random Forest model scored the highest accuracy of 0.95 and F1-score of 0.95 amongst all the models, positioning as the best performer. The Naive Bayes model had the lowest accuracy and F1-score of 0.81 and 0.82, respectively. Precision and recall scores of the Random Forest and XGBoost models performed well and achieved above-average scores across all the models."
2235,"caption: Comparative performance of various models based on different metricstable: Model,F1-Score,Precision,Recall,Accuracy, Logistic Regression,0.891,0.886,0.897,0.901, Naive Bayes,0.862,0.837,0.891,0.879, Random Forest,0.935,0.931,0.940,0.944, XGBoost,0.943,0.938,0.949,0.952, SVM,0.930,0.925,0.936,0.941","The table compares the performance of different models based on various evaluation metrics: F1-Score, precision, recall, and accuracy. The models include Logistic Regression, Naive Bayes, Random Forest, XGBoost, and SVM. The table shows that the XGBoost model achieves the highest F1-Score of 0.943, while the Random Forest model achieves the highest precision, recall, and accuracy of 0.931, 0.940, and 0.944, respectively. Interestingly, the SVM model also demonstrates relatively good performance with an F1-Score of 0.930, precision of 0.925, recall of 0.936, and accuracy of 0.941. Overall, the table elucidates the superiority of ensemble-based models (Random Forest and XGBoost) over other traditional models."
2236,"caption: Performance comparison of different models based on different evaluation metrics.table: Model,F1 Score,Accuracy,Precision,Recall, Model A,0.84,0.88,0.81,0.88, Model B,0.79,0.91,0.91,0.68, Model C,0.81,0.89,0.73,0.97, Model D,0.75,0.92,0.86,0.67, Model E,0.82,0.90,0.79,0.87","The table presents the comparison of different models' performance based on four evaluation metrics, namely F1 score, accuracy, precision, and recall. Models A, B, C, D, and E were tested on the same dataset, and their performances were evaluated. Interestingly, Model A achieved the highest F1 score of 0.84, and Model B had the highest accuracy of 0.91. Furthermore, Model C achieved the highest precision of 0.73, whereas Model D obtained the highest recall value of 0.67. Overall, the table presents an insightful comparison of the models' performances based on multiple evaluation metrics."
2237,"caption: A comparison of different machine learning models based on evaluation metrics.table: Models,Accuracy,F1-score,Precision,Recall, SVM,0.786,0.569,0.488,0.744, Logistic Regression,0.794,0.612,0.512,0.758, NN (2 layers),0.802,0.653,0.531,0.834, NN (3 layers),0.806,0.663,0.543,0.832, Decision Tree,0.759,0.582,0.458,0.811, Random Forest,0.807,0.665,0.549,0.845, Gradient Boosting Tree,0.815,0.683,0.565,0.839","The above table compares different machine learning models' performances on various evaluation metrics like Accuracy, F1-score, Precision and Recall. The table presents results based on SVM, Logistic Regression, NN with two layers, NN with three layers, Decision Tree, Random Forest, and Gradient Boosting Tree. Among these models, the Gradient Boosting Tree shows the best accuracy score of 0.815 and F1-score of 0.683. The Random Forest and NN with three layers achieve the next highest accuracy of 0.807 and 0.806, respectively. SVM shows the lowest F1-score of all the models, while the Random Forest model exhibits the highest precision score of 0.549. All in all, the Gradient Boosting Tree model outperforms the others on most evaluation metrics."
2238,"caption: Table 4: Model Performance Comparison with Multiple Different Evaluation Metricstable: Model,F1 Score,Precision,Recall,Accuracy, Logistic Regression,0.89,0.94,0.85,0.92, Decision Tree,0.78,0.83,0.74,0.81, Random Forest,0.92,0.91,0.93,0.95, Gradient Boosting,0.94,0.92,0.96,0.96, Support Vector,0.88,0.89,0.88,0.91","Table 4 compares the performance of different models using various evaluation metrics, including F1 Score, Precision, Recall, and Accuracy. The table shows the scores of Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Support Vector models. Notably, the Random Forest and Gradient Boosting models outperformed other models with high F1 scores of 0.92 and 0.94, respectively. The Random Forest model achieved the highest recall score of 0.93, while the Gradient Boosting model had the highest precision score of 0.92. Additionally, the Gradient Boosting model achieved the highest accuracy score of 0.96, indicating its ability to accurately predict the outcomes."
2239,"caption: Comparison of different regression models' performance using different evaluation metrics on a dataset of house prices.table: Model,MSE,RMSE,MAE,R²,Explained variance score, Linear Regression,14.055,3.750,2.757,0.905,0.905, Ridge Regression,14.076,3.753,2.768,0.905,0.905, Lasso Regression,14.053,3.750,2.757,0.905,0.905, ElasticNet Regression,14.051,3.749,2.755,0.905,0.905, Random Forest,10.620,3.259,1.912,0.940,0.940, Gradient Boosting,14.129,3.761,2.775,0.903,0.903, KNN Regression,25.650,5.065,3.521,0.777,0.777, Decision Tree,14.501,3.805,2.797,0.899,0.899","Table presents the results of various regression models' performance evaluation metrics on a dataset of house prices. Multiple regression models using different techniques such as Linear Regression, Ridge Regression, Lasso Regression, and ElasticNet Regression, Random Forest, Gradient Boosting, KNN Regression, and Decision Tree were utilized to predict the house price. The performance of the models was evaluated by estimating different metrics such as Mean Squared Error (MSE), Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), R², and Explained Variance Score. The results indicate that the Random Forest model outperforms other models with the lowest MSE of 10.620, lowest RMSE of 3.259 and MAE of 1.912. Random Forest also achieved the best R² score of 0.940, and explained variance score of 0.940."
2240,"caption: Comparison of results of different models based on different evaluation metricstable: Model Name,Accuracy,F1 Score,Precision,Recall, Model A,0.87,0.89,0.92,0.88, Model B,0.85,0.87,0.90,0.85, Model C,0.80,0.83,0.89,0.79, Model D,0.88,0.91,0.91,0.92","The table compares the effectiveness of different classification models using performance metrics such as accuracy, F1 score, precision, and recall. Model A reports the highest accuracy of 0.87 and the highest precision result of 0.92, while Model D outperforms all other models in all performance metrics except precision with an F1 score of 0.91, accuracy of 0.88, and recall of 0.92. Contrarily, the Model C shows comparatively lower metrics with an accuracy of 0.80, F1 score of 0.83, precision of 0.89, and recall of 0.79. Overall, the table provides valuable insights for model selection based on desired metrics for classification problems."
2241,"caption: Performance metrics of different modelstable: Model,Accuracy,Precision,Recall,F1-Score,ROC-AUC, Model 1,0.85,0.82,0.86,0.84,0.92, Model 2,0.78,0.75,0.80,0.77,0.83, Model 3,0.92,0.89,0.94,0.91,0.96, Model 4,0.80,0.74,0.82,0.77,0.84, Model 5,0.88,0.86,0.87,0.87,0.92","The table presents the performance metrics of 5 different models. The evaluation metrics include accuracy, precision, recall, F1-score, and ROC-AUC. Model 3 achieved the highest scores in all metrics, with the highest accuracy of 0.92 and ROC-AUC of 0.96. Model 1 achieved the second-best scores, with accuracy of 0.85, precision of 0.82, recall of 0.86, F1-score of 0.84, and ROC-AUC of 0.92. Model 5 achieved the third-best scores with accuracy of 0.88 and ROC-AUC of 0.92. However, Model 2 and Model 4 performed significantly less favorably than the other models, with accuracy scores of 0.78 and 0.80, respectively."
2242,"caption: Performance comparison of different models based on accuracy, precision, recall, and F1-score.table: Model,Accuracy,Precision,Recall,F1-Score, Model A,0.89,0.92,0.85,0.88, Model B,0.92,0.89,0.93,0.91, Model C,0.83,0.73,0.91,0.81, Model D,0.88,0.83,0.92,0.87, Model E,0.94,0.94,0.93,0.94","The above table compares different models' performance metrics, including accuracy, precision, recall, and F1-score. We can observe that Model E has the best overall performance in all categories, achieving a high accuracy of 0.94, a high precision of 0.94, a high recall of 0.93, and an F1-score of 0.94. Meanwhile, Model C has the lowest accuracy, achieving only 0.83. On the other hand, Model B has the highest recall score of 0.93. Overall, it is crucial to evaluate model performance based on different metrics to identify model strengths and weaknesses accurately."
2243,"caption: Comparison of different supervised learning models based on Precision, Recall, F1 score, and Accuracy.table: Model,Precision,Recall,F1 Score,Accuracy, SVM,0.82,0.79,0.81,0.85, KNN,0.78,0.84,0.81,0.83, Naive Bayes,0.73,0.80,0.76,0.81, Decision Tree,0.80,0.78,0.79,0.82, Random Forest,0.86,0.89,0.87,0.88, XGBoost,0.90,0.91,0.90,0.92","The table presents the performance metrics of various supervised learning models. The models' performances are evaluated based on multiple metrics, including Precision, Recall, F1 score, and Accuracy. The models compared in the table include SVM, KNN, Naive Bayes, Decision Tree, Random Forest, and XGBoost. Random Forest performs best in terms of Precision (0.86), Recall (0.89) and F1 score (0.87). However, XGBoost outperforms all the other models in terms of Accuracy, achieving a score of 0.92. KNN has balanced results as it has the second best Recall and F1 score, while SVM and Decision Tree show similar overall performances. Naive Bayes shows the worst performance among the models."
2244,"caption: Table 4: Model Performance Metrics for Classification Task on Breast Cancer Datasettable: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.75,0.68,0.82,0.74, RF,0.80,0.75,0.89,0.81, LR,0.73,0.67,0.84,0.74, DT,0.62,0.56,0.77,0.64",
2245,"caption: Table 4: Model Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1 Score, Random Forest,0.85,0.87,0.78,0.82, Logistic Regression,0.80,0.82,0.78,0.80, Support Vector Machine,0.82,0.84,0.77,0.80, k-Nearest Neighbors,0.73,0.70,0.67,0.68, Decision Tree,0.72,0.60,0.64,0.62","Table 4 shows a comparison of different models based on multiple evaluation metrics, including Accuracy, Precision, Recall, and F1 Score. The models evaluated in the table are Random Forest, Logistic Regression, Support Vector Machine, k-Nearest Neighbors, and Decision Tree. The Random Forest model secured the highest accuracy score of 0.85, while the Logistic Regression and Support Vector Machine models achieved 0.82 and 0.80, respectively. The Precision score of 0.87 of the Random Forest model is the highest among all models, while the Decision Tree model had the lowest Precision score of 0.60. Though the Decision Tree model had the lowest scores in Precision and Recall, it achieved the highest Recall score of 0.64 among all models. Overall, Random Forest has the highest F1 Score of 0.82, while the Decision Tree had the lowest score of 0.62."
2246,"caption: Comparison of different classification modelstable: Model,F1-Score (micro),F1-Score (macro),Precision,Recall, LogReg,0.83,0.79,0.80,0.78, SVM,0.84,0.77,0.81,0.74, kNN,0.80,0.72,0.73,0.71, Naive Bayes,0.75,0.67,0.70,0.66, Decision Tree,0.75,0.69,0.72,0.69","The table shows the performance of five different classification models regarding F1-score, precision, and recall measures using the micro and macro averaging methods. The models include logistic regression(LogReg), support vector machine(SVM), k-nearest neighbors(kNN), Naive Bayes, and decision tree. The SVM model showed the highest F1-score for both micro and macro averaging, with scores of 0.84 and 0.77, respectively. However, the LogReg model exhibited the highest precision, at 0.80, and recall, at 0.78, measures. Additionally, kNN and Naive Bayes methods presented lower F1-scores and precision/recall measures compared to the other models. The results demonstrate that the performance of the classification models may vary according to the measure employed."
2247,"caption: Model performances of different Machine Learning algorithms.table: Model,F1-score,Precision,Recall,Accuracy, SVM,0.876,0.919,0.838,0.875, MLP,0.852,0.875,0.831,0.843, KNN,0.816,0.807,0.825,0.812, RF,0.904,0.901,0.907,0.904, LR,0.842,0.872,0.815,0.838","The table presents the performances of different Machine Learning algorithms based on multiple evaluation metrics. The F1-score, Precision, Recall, and Accuracy measures were reported for SVM, MLP, KNN, RF, and LR models. The table shows that the Random Forest model achieved the highest F1-score, Precision, Recall, and Accuracy score of 0.904, 0.901, 0.907, and 0.904, respectively. Meanwhile, the KNN model had the lowest F1-score and Accuracy score, but SVM had the lowest Precision and Recall score. Overall, the table provides insights into the strengths and weaknesses of different Machine Learning models' performances based on various metrics."
2248,"caption: Model evaluation metrics with different classifierstable: Model,F1-score,Precision,Recall,Accuracy, SVM,0.90,0.89,0.91,0.89, KNN,0.85,0.83,0.87,0.84, MLP,0.92,0.91,0.93,0.91, RF,0.94,0.93,0.95,0.92, XGB,0.93,0.92,0.94,0.92","Table above shows the performance of five different algorithms, SVM, KNN, MLP, RF, and XGB, evaluated on F1-score, Precision, Recall, and Accuracy metrics. The best performing algorithm in terms of F1-score, RF, achieved a score of 0.94, followed by MLP and XGB at 0.92 and 0.93, respectively. Unlike the F1-score, MLP achieved the highest precision and recall scores of 0.91 and 0.93, respectively. It is also interesting to see that RF has the highest accuracy of 0.92 despite its relatively low performance in terms of precision and recall. Overall, the table provides valuable insights into the classification algorithms' performances across different metrics."
2249,"caption: Model performances based on multiple evaluation metricstable: Model,F1 Score,Accuracy,Precision,Recall, Logistic Regression,0.876,0.847,0.852,0.901, Random Forest,0.901,0.874,0.886,0.917, Decision Tree,0.824,0.795,0.828,0.830, K-Nearest Neighbor (KNN),0.853,0.796,0.886,0.823, Naive Bayes,0.795,0.718,0.697,0.912","The table presents a comparison of different machine learning algorithms' performance based on F1 score, accuracy, precision, and recall. The models compared are Logistic Regression, Random Forest, Decision Tree, K-Nearest Neighbor (KNN), and Naive Bayes. Random Forest outperformed the other models in all metrics, with the highest F1 score of 0.901, accuracy of 0.874, precision of 0.886, and recall of 0.917. Logistic Regression and K-Nearest Neighbor (KNN) models were also highly accurate with F1 scores of 0.876 and 0.853, respectively. Naive Bayes model's precision and recall scores were high at 0.697 and 0.912, respectively, but had the lowest F1 score of 0.795. Moreover, the Decision Tree model performed comparatively poorly in all metrics, except precision, where it scored 0.828."
2250,"caption: Table 1: Performance comparison of different models using various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, SVM,0.85,0.87,0.84,0.85, RF,0.82,0.80,0.83,0.81, KNN,0.79,0.77,0.74,0.75, Naive Bayes,0.75,0.72,0.76,0.74, MLP,0.87,0.89,0.86,0.87, CNN,0.82,0.83,0.81,0.82","Table 1 exhibits a comparison of multiple machine learning models' performance based on various evaluation metrics. The models' accuracy, precision, recall, and F1-Score were evaluated and are presented in the table. The models considered are SVM, RF, KNN, Naive Bayes, MLP, and CNN. Notably, MLP shows the highest accuracy, precision, recall, and F1-Score with 0.87, 0.89, 0.86 and 0.87, respectively. SVM, on the other hand, exhibits the highest precision of 0.87, whereas Naive Bayes shows the least performance result across all metrics. Overall, MLP seems to be the best-performing model in this comparison."
2251,"caption: Table 4: Evaluation results for different classification models.table: Model,Accuracy,Precision,Recall,F1 score, Logistic Regression,0.85,0.87,0.84,0.85, K-Nearest Neighbors,0.82,0.83,0.80,0.81, Support Vector Machine,0.81,0.82,0.78,0.80, Random Forest,0.89,0.91,0.88,0.89, XGBoost,0.91,0.93,0.90,0.91","Table 4 displays the performance evaluation of five different classification models, namely Logistic Regression, K-Nearest Neighbors (KNN), Support Vector Machine (SVM), Random Forest, and XGBoost. The evaluation metrics comprise Accuracy, Precision, Recall, and F1 score. The Random Forest model achieved the highest accuracy of 0.89, and XGBoost showed the best accuracy score among all models with a value of 0.91. The XGBoost model shows the highest Precision and F1 score of 0.93 and 0.91, respectively, which are the best performance results in the table. Conversely, KNN gave the weakest outcomes among all models."
2252,"caption: Table 1: Model performance comparison based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score,AUC-ROC, Model 1,0.80,0.77,0.73,0.75,0.83, Model 2,0.82,0.74,0.82,0.77,0.85, Model 3,0.85,0.80,0.81,0.80,0.88, Model 4,0.78,0.72,0.69,0.70,0.81, Model 5,0.88,0.85,0.88,0.86,0.92","Table 1 presents a comparison of five different models based on different evaluation metrics, including accuracy, precision, recall, F1-score, and AUC-ROC. The models' performances were evaluated and tested using a similar dataset. Model 5 shows superior performance in all evaluation metrics with an accuracy of 0.88, precision of 0.85, recall of 0.88, F1-score of 0.86, and AUC-ROC of 0.92. Model 3 also shows promising results with the second-highest performance in all evaluation metrics. Conversely, Model 4 demonstrates the lowest performance in all evaluation metrics. The table provides essential information for researchers and practitioners to select the most appropriate model for their classification task based on their required evaluation metrics."
2253,"caption: Model performance comparison using different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score,AUC, Model 1,0.92,0.87,0.82,0.84,0.95, Model 2,0.91,0.92,0.81,0.83,0.89, Model 3,0.89,0.83,0.86,0.85,0.93, Model 4,0.93,0.89,0.89,0.90,0.92, Model 5,0.94,0.91,0.90,0.91,0.94","Table 1 presents a comparison of the five models' performances based on five evaluation metrics, including Accuracy, Precision, Recall, F1-score, and AUC. Each model was trained and tested using the same dataset. Interestingly, Model 5 achieved the highest scores in all metrics, with an accuracy score of 0.94, precision score of 0.91, recall score of 0.90, F1-score of 0.91, and an AUC of 0.94. Results reveal that Model 5 outperformed the other models in all metrics. Model 1 and Model 4 achieved high scores as well. However, Model 2 and Model 3 scored lower than the other models in the majority of the metrics."
2254,"caption: Performance metrics of four different models on a classification task.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.92,0.87,0.94,0.90, Random Forest,0.89,0.82,0.90,0.85, Logistic Regression,0.91,0.86,0.92,0.89, KNN,0.87,0.80,0.86,0.83","The table above compares the performance results of four different models on a classification task, using accuracy, precision, recall, and F1-score metrics. The SVM model had the highest accuracy of 0.92, while the KNN model had the lowest accuracy of 0.87. The Random Forest model had a precision score of 0.82, which is the lowest among all models. In contrast, the SVM model had the highest precision score of 0.87. The Recall metric results show that SVM had the highest recall score of 0.94, while KNN had the lowest recall score of 0.86. Finally, the F1-score metric shows that the SVM model outperformed all other models with a score of 0.90, while the Random Forest model had the lowest F1-score of 0.85."
2255,"caption: Results of model performances evaluated using different metrics.table: Model,Accuracy,F1 Score,AUC-ROC,Precision,Recall, Logistic Regression,0.85,0.88,0.74,0.92,0.85, Random Forest,0.79,0.82,0.68,0.80,0.87, Support Vector Machines,0.88,0.89,0.75,0.94,0.83, K-Nearest Neighbors,0.81,0.85,0.69,0.83,0.89, Naive Bayes,0.76,0.81,0.64,0.78,0.87","The table summarizes the performances of multiple machine learning models by evaluating different metrics. The evaluation metrics used are Accuracy, F1 Score, AUC-ROC, Precision, and Recall. The models included in the table are Logistic Regression, Random Forest, Support Vector Machines, K-Nearest Neighbours, and Naive Bayes. Interestingly, Support Vector Machines achieved the highest accuracy with a score of 0.88, while Logistic Regression had the highest precision with a score of 0.92. On the other hand, the K-Nearest Neighbors model had the highest recall rate of 0.89. These results imply potential insights for the model selection to be used in subsequent data science tasks."
2256,"caption: Comparison of different models' performance using various metrics.table: Model,Precision,Recall,F1 score,Accuracy,ROC-AUC,PR-AUC, SVM,0.81,0.72,0.76,0.74,0.79,0.68, Naive Bayes,0.62,0.84,0.71,0.64,0.68,0.47, Random Forest,0.83,0.84,0.84,0.83,0.86,0.76, Gradient Boosting,0.86,0.82,0.84,0.85,0.89,0.78, Neural Network,0.78,0.76,0.77,0.77,0.84,0.72, Logistic Regression,0.72,0.68,0.7,0.67,0.74,0.62","Table represents a comparison of six different machine learning models for a classification task. The evaluation metrics include Precision, Recall, F1 score, Accuracy, ROC-AUC, and PR-AUC. The Random Forest model had the highest F1 score, Precision, Recall, and Accuracy. The Gradient Boosting model demonstrated the best ROC-AUC and PR-AUC. Interestingly, the Neural Network model had the best ROC-AUC after the Gradient Boosting model. The Naive Bayes model performed worst in all evaluation metrics except Recall. The Logistic Regression model showed similar performance to the Naive Bayes model. Overall, the Random Forest and Gradient Boosting models achieved the best performance, depending on the chosen evaluation metric."
2257,"caption: Table 4: Model performances evaluated by different metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.85,0.87,0.85,0.86, Random Forest,0.81,0.83,0.82,0.82, Naive Bayes,0.76,0.80,0.75,0.77, Support Vector Machine,0.82,0.81,0.89,0.85, Neural Network,0.88,0.89,0.92,0.90","Table 4 presents model performances of five different models that were evaluated using multiple metrics: Accuracy, Precision, Recall, and F1-Score. The table shows that the Neural Network model outperformed the other models in all metrics, achieving the highest accuracy of 0.88, highest precision of 0.89, highest recall of 0.92, and highest F1-Score of 0.90. The best performing non-neural network model is Logistic Regression, achieving the accuracy score of 0.85, the precision score of 0.87, recall score of 0.85, and F1-Score of 0.86. Interestingly, the Naive Bayes model achieved a precision score of 0.80, which is higher than other models, suggesting a lower false-positive rate."
2258,"caption: Performance of different models using various evaluation metrics.table: Model,Metric,Score, SVM,Accuracy,0.75, Recall,0.70, Precision,0.80, Decision Tree 1,Accuracy,0.70, Recall,0.65, Precision,0.75, Decision Tree 2,Accuracy,0.65, Recall,0.75, Precision,0.65, KNN,Accuracy,0.80, Recall,0.75, Precision,0.85","The table presents various models' performance using different evaluation metrics such as accuracy, recall, and precision. The models in the table are SVM, Decision Tree 1, Decision Tree 2, and KNN. SVM achieved the highest accuracy of 0.75, while KNN had the highest precision of 0.85 and recall of 0.75. Apart from KNN, Decision Tree 1 and 2 performed similarly, achieving scores of 0.70 and 0.65 in accuracy, 0.65 and 0.75 in recall, and 0.75 and 0.65 in precision, respectively. Notably, the models' performances vary significantly depending on the evaluation metric used."
2259,"caption: Model comparison based on different evaluation metrics.table: Models,Accuracy,F1 Score,Precision,Recall,AUC, Model 1,0.86,0.86,0.91,0.83,0.91, Model 2,0.84,0.84,0.90,0.80,0.88, Model 3,0.87,0.87,0.89,0.86,0.90, Model 4,0.82,0.81,0.87,0.75,0.87, Model 5,0.89,0.89,0.92,0.86,0.93","The above table compares five different models' performances based on five evaluation metrics, namely accuracy, F1 score, precision, recall, and AUC. The models are labeled as Model 1 to Model 5. The models' performance is determined based on a common dataset, and all models are evaluated using the same evaluation metrics. Interestingly, Model 5 shows the best performance with the highest values for all evaluation metrics, while Model 4 demonstrates the lowest performance. Specifically, Model 5 exhibits an accuracy of 0.89, F1 score 0.89, precision 0.92, recall 0.86, and AUC 0.93. Furthermore, Model 3 also shows a remarkable performance with an accuracy of 0.87 and AUC of 0.90. Overall, the table helps to compare and identify the best-performing models based on specific evaluation metrics."
2260,"caption: Performance comparison of different models based on evaluation metrics for binary classification problem.table: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.85,0.85,0.87,0.83, Decision Tree,0.77,0.77,0.84,0.72, K-Nearest Neighbor,0.80,0.80,0.85,0.76, Random Forest,0.87,0.87,0.89,0.86, Support Vector Machine,0.82,0.82,0.87,0.78","Table presents the performance of different models based on five evaluation metrics, including accuracy, F1-score, precision, and recall. The models evaluated include Logistic Regression, Decision Tree, K-Nearest Neighbor, Random Forest, and Support Vector Machines based on binary classification. The results show that Random Forest has the highest accuracy, F1-score, precision, and recall values with 0.87, 0.87, 0.89, and 0.86, respectively. Meanwhile, the Decision Tree model achieves the lowest performance within this group. However, all tested models seem to perform reasonably well, with an accuracy of 0.77 and higher."
2261,"caption: Model performance based on different evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.79,0.72,0.83,0.64, Naive Bayes,0.76,0.70,0.77,0.64, Decision Tree,0.73,0.65,0.69,0.62, Random Forest,0.81,0.74,0.81,0.70, XGBoost,0.83,0.78,0.84,0.76","Table 4 shows the model performance of Logistic Regression, Naive Bayes, Decision Tree, Random Forest, and XGBoost based on different evaluation metrics, including Accuracy, F1-Score, Precision, and Recall. The highest performing model is XGBoost, with the best accuracy of 0.83 and an F1-Score of 0.78. Logistic Regression and Naive Bayes models have comparable performances, with Precision scores of 0.83 and 0.77, respectively. The Decision Tree model has the lowest accuracy of 0.73. Interestingly, the Random Forest model has a high accuracy of 0.81 but a lower F1-Score of 0.74 compared to XGBoost's higher F1-Score of 0.78. Overall, the XGBoost model performs the best among the models in this evaluation."
2262,"caption: Table 4: Model performances based on different evaluation metrics.table: Model,Precision,Recall,F1-Score, SVM,0.76,0.81,0.78, KNN,0.69,0.66,0.68, RF,0.85,0.84,0.84, DT,0.72,0.74,0.73, LR,0.82,0.80,0.81","Table 4 presents the performance comparison of SVM, KNN, RF, DT, and LR models based on precision, recall, and F1-score evaluation metric. The results are computed based on the same dataset. The RF model achieved the highest precision and recall score with 0.85 and 0.84, respectively. LR model gained the highest F1-score of 0.81 that shows a balance between precision and recall scores. The SVM and LR models also performed well with scores of 0.76 and 0.82 for precision, 0.81 and 0.80 for recall, and 0.78 and 0.81 for F1-score, respectively. Meanwhile, KNN and DT models achieved lower scores in comparison."
2263,"caption: Comparison of classification models' performance based on multiple evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.85,0.87,0.91,0.83, Logistic Reg.,0.79,0.80,0.83,0.77, Naive Bayes,0.62,0.62,0.70,0.55, Random Forest,0.91,0.92,0.93,0.90, BERT,0.93,0.94,0.95,0.93",
2264,"caption: Model performances in both accuracy and four evaluation metrics from distinct machine learning models.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.89,0.91,0.83,0.99, k-NN,0.84,0.85,0.77,0.94, MLP,0.91,0.93,0.88,0.98, LR,0.83,0.80,0.70,0.90, DT,0.77,0.77,0.80,0.74","The table presents a comparison of five machine learning models' performance based on multiple evaluation metrics - accuracy, F1-score, precision and recall. SVM had the highest accuracy score of 0.89, distinguishing it from other models. MLP achieved the highest F1-score of 0.93 and precision of 0.88. However, both the SVM and MLP models had relatively optimal recall scores of 0.99 and 0.98, respectively. The k-NN model had the lowest accuracy of 0.84 and the lowest scores in F1-score, precision, and recall compared to other models. The LR model's performance results were in the middle, with a recall score of 0.90 and precision of 0.70. The DT model had a relatively low accuracy score of 0.77 and the lowest precision score compared to other models."
2265,"caption: Model Performance Metricstable: Model Name,Accuracy,F1-Score,Precision,Recall, Model 1,85.2%,0.839,0.821,0.858, Model 2,79.4%,0.734,0.689,0.784, Model 3,89.1%,0.879,0.896,0.863, Model 4,76.5%,0.682,0.694,0.670, Model 5,91.8%,0.901,0.915,0.888","The table above displays the performance comparison of five different models based on Accuracy, F1-Score, Precision, and Recall metrics. Model 5 outperforms all the other models with the highest accuracy score of 91.8%, the highest F1-Score of 0.901, highest Precision of 0.915, and highest Recall score of 0.888. Interestingly, Model 3 achieved the second-best performance for all the metrics, which shows promising results. It is important to note that Model 2 had the lowest overall performance for all the metrics compared to the other models."
2266,"caption: Table 4: Model performance comparisons based on different evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall,AUC, SVM,0.92,0.89,0.85,0.93,0.95, KNN,0.88,0.82,0.75,0.9,0.89, Naive Bayes,0.83,0.75,0.78,0.72,0.87, Random Forest,0.97,0.96,0.96,0.96,0.98, XGBoost,0.94,0.92,0.91,0.92,0.96","Table 4 presents a comparison of different models' performances based on various evaluation metrics. The models' evaluation metrics include Accuracy, F1 Score, Precision, Recall, and AUC. SVM, Random Forest, and XGBoost exhibit an Accuracy greater than 0.9. Additionally, all models have an AUC above 0.87. The highest AUC score was achieved by Random Forest with 0.98, followed by XGBoost with 0.96 scores. Further, Random Forest and XGBoost models show the best F1 Score and Precision results, with F1 Scores of 0.96 and 0.92, respectively, and Precision scores of 0.96 and 0.91, respectively. SVM achieved the highest Recall score of 0.93, while Naive Bayes obtained the lowest AUC score of 0.87."
2267,"caption: Table 4: Model performance comparison for different evaluation metrics.table: Model,Precision,Recall,F1 Score,ROC-AUC,PR-AUC, Logistic Regression,0.91,0.72,0.80,0.87,0.66, Random Forest,0.94,0.78,0.85,0.90,0.78, Gradient Boosting,0.89,0.83,0.86,0.92,0.82, MLP,0.92,0.76,0.83,0.88,0.72",
2268,"caption: Table 4: Performance of different machine learning models using multiple evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Naive Bayes,0.87,0.88,0.91,0.86, Decision Tree,0.82,0.82,0.85,0.81, Random Forest,0.89,0.90,0.92,0.89, Support Vector Machine,0.88,0.89,0.90,0.88","Table 4 presents the performances of four different machine learning models concerning accuracy, F1 score, precision, and recall metrics. The evaluation was carried out using a common dataset and under the same experimental settings. The table shows that among the models, Random Forest achieved the highest accuracy of 0.89 and F1 score of 0.90, followed by Support Vector Machine, Naive Bayes, and Decision Tree. In terms of Precision and Recall, all the models have done an excellent job. That being said, Naive Bayes has the highest precision of 0.91, while Random Forest has the highest recall of 0.89."
2269,"caption: Table 4: Model performance based on different evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.82,0.76,0.88,0.82, Decision Tree,0.78,0.68,0.77,0.71, Random Forest,0.84,0.80,0.90,0.84, Gradient Boosting,0.85,0.81,0.91,0.85","Table 4 presents the performance of four different models, namely, Logistic Regression, Decision Tree, Random Forest, and Gradient Boosting, based on multiple evaluation metrics, including Accuracy, Precision, Recall, and F1-Score. The Logistic Regression model has an Accuracy of 0.82, Precision of 0.76, Recall of 0.88, and F1-Score of 0.82. On the other hand, the Decision Tree model scored lower on all the evaluation metrics with Accuracy of 0.78, Precision of 0.68, Recall of 0.77, and F1-Score of 0.71. The Random Forest model performed relatively better with Accuracy of 0.84, Precision of 0.80, Recall of 0.90, and F1-Score of 0.84. The Gradient Boosting model exhibits the best performance among all models with Accuracy of 0.85, Precision of 0.81, Recall of 0.91, and F1-Score of 0.85."
2270,"caption: Table 4: Comparison of different models' performance on various evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.86,0.88,0.90,0.86, RF,0.82,0.85,0.88,0.82, MLP,0.88,0.90,0.92,0.88, NB,0.78,0.82,0.84,0.78, LR,0.84,0.86,0.87,0.84","Table 4 presents a comparison of different models' performance based on various evaluation metrics. The table displays five models: Support Vector Machine (SVM), Random Forest (RF), Multi-layer perceptron(MLP), Naive Bayes (NB), and Logistic Regression (LR). Each model's performance is evaluated based on four metrics: accuracy, F1-score, precision, and recall. Interestingly, the MLP model achieved the highest performance in all metrics, with 0.88 accuracy, 0.90 F1-score, 0.92 precision, and 0.88 recall. The SVM model performed second best with an accuracy of 0.86 and an F1-score of 0.88. In contrast, the NB model had the lowest performance in all metrics."
2271,"caption: Models performance based on different evaluation metrics.table: Model,Accuracy,F1 Score,Sensitivity,Specificity, Model 1,0.84 ±0.01,0.85 ±0.01,0.87 ±0.02,0.81 ±0.03, Model 2,0.82 ±0.02,0.84 ±0.03,0.89 ±0.02,0.75 ±0.04, Model 3,0.80 ±0.03,0.83 ±0.04,0.85 ±0.02,0.76 ±0.03, Model 4,0.88 ±0.01,0.89 ±0.01,0.89 ±0.01,0.88 ±0.02, Model 5,0.86 ±0.02,0.88 ±0.02,0.87 ±0.02,0.85 ±0.03","Table format above exhibits multiple performance metrics (Accuracy, F1 Score, Sensitivity, and Specificity) for five different models' performances. Comparing the models' accuracy, Model 4 achieved the highest accuracy score of 0.88 ± 0.01, followed by Model 5 with a score of 0.86 ± 0.02. Model 1 and Model 2 demonstrated the highest F1 scores of 0.85±0.01 and 0.84±0.03, respectively. Model 2 has the highest Sensitivity score of 0.89±0.02, while Model 1 has the highest specificity of 0.81±0.03. It should be noted that each model's performance has different metrics that reflect its capabilities and limitations."
2272,"caption: Table 4: Model performance using different evaluation metrics.table: Model,Accuracy,F1 Score,AUC-ROC, Logistic Regression,0.83,0.84,0.88, Naive Bayes,0.79,0.75,0.83, K-Nearest Neighbor,0.76,0.73,0.80, Decision Tree,0.88,0.85,0.89, Random Forest,0.91,0.90,0.93","Table 4 compares the performances of different models based on their accuracy, F1 score, and AUC-ROC. The table exhibits five different models: Logistic Regression, Naive Bayes, K-Nearest Neighbor, Decision Tree, and Random Forest. The Random Forest model shows high performance in all three evaluation metrics, obtaining an accuracy value of 0.91, F1 score of 0.90, and AUC-ROC of 0.93. Moreover, the Decision Tree model also showed high performance with an accuracy of 0.88 and AUC-ROC of 0.89. Interestingly, the Logistic Regression model performed reasonably well in all three metrics by obtaining an accuracy of 0.83, an F1 score of 0.84, and an AUC-ROC of 0.88."
2273,"caption: Table 4. Model Performance on Evaluation Metrics.table: Model,AUC,Precison,Recall, Logistic Regression,0.86,0.64,0.72, Decision tree,0.72,0.57,0.56, Random Forest,0.92,0.75,0.89, AdaBoost,0.82,0.62,0.75","The presented table shows the performance of different models on multiple evaluation metrics including AUC, precision, and recall. The models' performance is evaluated using standard datasets and trained using appropriate data preprocessing and feature engineering methods. The table shows that the Random Forest model outperforms all other models with the highest AUC of 0.92, precision of 0.75, and recall of 0.89. Interestingly, the logistic regression model achieved the highest precision score of 0.64, while the Random Forest model achieved the highest recall with a score of 0.89. The Decision tree and AdaBoost models exhibited weaker performance with lower AUC, precision, and recall scores."
2274,"caption: Table 4: Model comparison based on different evaluation metricstable: Model,F1-Score,Accuracy,Recall,Precision, SVM,0.88,0.86,0.90,0.87, Random Forest,0.86,0.85,0.89,0.83, MLP,0.82,0.80,0.83,0.81, Naive Bayes,0.75,0.78,0.73,0.78, KNN,0.68,0.70,0.65,0.70",
2275,"caption: Model performances based on Accuracy, F1 score, Precision, and Recall.table: Model,Accuracy,F1 score,Precision,Recall, Random Forest,0.892+-0.007,0.902+-0.006,0.914+-0.009,0.893+-0.010, SVM,0.818+-0.002,0.820+-0.001,0.810+-0.003,0.815+-0.001, Logistic Regression,0.862+-0.003,0.870+-0.002,0.880+-0.002,0.862+-0.004, Naive Bayes,0.760+-0.004,0.762+-0.005,0.768+-0.008,0.749+-0.009","The table presents the results of evaluating multiple models using different evaluation metrics. The models include Random Forest, SVM, Logistic Regression, and Naive Bayes, with performances compared in terms of Accuracy, F1 score, Precision, and Recall. Random forest shows the best overall performance with the highest scores in accuracy (0.892+-0.007), F1 score (0.902+-0.006), Precision (0.914+-0.009), and Recall (0.893+-0.010) among all models. SVM model had the lowest score in Accuracy (0.818+-0.002), whereas Naive Bayes shows the lowest score in F1 Score (0.762+-0.005), Precision (0.768+-0.008), and Recall (0.749+-0.009)."
2276,"caption: Performance results for multiple classification models based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score,AUC, Model 1,0.89,0.82,0.91,0.86,0.92, Model 2,0.91,0.78,0.95,0.86,0.91, Model 3,0.84,0.86,0.77,0.81,0.88","The table presents the performance results of three different classification models that were evaluated based on five different metrics - accuracy, precision, recall, F1-score, and AUC. Model 2 has the highest accuracy score of 0.91, while Model 1 and Model 3 got accuracy scores of 0.89 and 0.84, respectively. However, Model 3 has the highest precision score of 0.86, while Model 1 has the highest recall score of 0.91. Interestingly, the F1-scores of all models have a close range of 0.81-0.86, which indicates that their precision and recall scores are relatively balanced. Lastly, AUC scores of all models suggest that they are good predictors, with Model 1 having the highest AUC score of 0.92."
2277,"caption: Comparison table of different classification models based on accuracy, precision, recall, and F1-score.table: Model,Accuracy,Precision,Recall,F1-Score, Model 1,0.88,0.91,0.89,0.90, Model 2,0.84,0.87,0.91,0.88, Model 3,0.91,0.89,0.85,0.87, Model 4,0.83,0.88,0.87,0.87, Model 5,0.92,0.93,0.95,0.94","The table compares the performance of five different classification models based on several evaluation metrics, including accuracy, precision, recall, and F1-score. Model 1 achieved the highest accuracy score of 0.88, while Model 5 achieved the highest precision, recall, and F1-score of 0.93, 0.95, and 0.94, respectively. Interestingly, Model 2 gained the lowest accuracy score of 0.84 but achieved the highest recall score of 0.91. Overall, the table demonstrates that different models might show varying degrees of performance in different evaluation metrics, highlighting the need to evaluate models from multiple angles before selecting the appropriate one for a particular task."
2278,"caption: Model comparison based on multiple evaluation metricstable: Model,Accuracy,F1 Score,Recall,Precision, Logistic Regression,0.92,0.89,0.85,0.94, Decision Tree,0.87,0.84,0.75,0.95, Random Forest,0.95,0.93,0.91,0.94, Naive Bayes,0.89,0.88,0.80,0.98, Support Vector Machine,0.93,0.91,0.87,0.95","The table compares the accuracy, F1 score, recall, and precision metrics for five different models, including Logistic Regression, Decision Tree, Random Forest, Naive Bayes, and Support Vector Machine. All models were evaluated using the same dataset. The highest accuracy score of 0.95 was achieved by the Random Forest model, which also had a high F1 score of 0.93. However, the Logistic Regression model performed reasonably well, and it achieved a high precision score of 0.94. The Support Vector Machine model had the highest precision score of 0.95, but it was outperformed by the Random Forest model in terms of accuracy and F1 score. The Decision Tree and Naive Bayes models had the lowest accuracy scores, although the Naive Bayes model demonstrated high precision."
2279,"caption: Evaluation of Different Models using Multiple Metricstable: Model Name,Accuracy,Precision,Recall,F1-Score, SVM,0.89,0.87,0.92,0.89, Decision tree,0.82,0.83,0.81,0.80, Random forest,0.93,0.94,0.91,0.92, Naive Bayes,0.75,0.68,0.84,0.72, K-Nearest Neighbors,0.87,0.85,0.89,0.86","The table presents the performance of five different machine learning models on a given dataset evaluated using four different metrics- accuracy, precision, recall, and F1-Score. The SVM model achieved the highest accuracy of 0.89, while the Random forest model achieved the highest precision of 0.94. On the other hand, the Naive Bayes model had the lowest accuracy, while its recall was much higher than the decision tree model. Interestingly, the Random forest model scored the highest on both precision and recall, indicating it is a good model for precision-driven problems. Overall, the table shows that the Random forest model has the best performance among all the models evaluated."
2280,"caption: Performance of Five Different Models Based on Various Evaluation Metrics.table: Model,Accuracy,F1 score,Precision,Recall, Model 1,0.92,0.88,0.85,0.91, Model 2,0.91,0.89,0.87,0.92, Model 3,0.89,0.87,0.82,0.93, Model 4,0.90,0.88,0.87,0.89, Model 5,0.85,0.81,0.76,0.89",
2281,"caption: Performance of different models based on various evaluation metricstable: Model,Accuracy,F1 score,Precision,Recall, Logistic Regression,0.82,0.75,0.68,0.84, Random Forest,0.86,0.80,0.73,0.88, SVM,0.80,0.73,0.65,0.83, MLP,0.88,0.82,0.75,0.89, CNN,0.90,0.85,0.81,0.89",
2282,"caption: Table 4: Model performance on classification task using different evaluation metrics.table: Model,F1 Score,Accuracy,AUC, Logistic Regression,0.89,0.92,0.715, Random Forest,0.92,0.95,0.825, Decision Tree,0.86,0.90,0.765, Gradient Boosting,0.93,0.96,0.835, Support Vector Machines,0.88,0.91,0.725, K-Nearest Neighbors (KNN),0.83,0.87,0.660","Table 4 compares various models' performance on a classification task using different evaluation metrics, including F1 Score, Accuracy, and AUC. Logistic Regression achieved the highest F1 Score of 0.89, followed closely by Support Vector Machines with F1 Score of 0.88. However, Gradient Boosting yielded the highest accuracy and AUC with a score of 0.96 and 0.835, respectively. Interestingly, the Random forest model outperformed other models in all evaluation metrics except the F1 Score, where it scored 0.92. The K-Nearest Neighbors (KNN) model yielded the lowest performance score in all evaluation metrics compared to other models."
2283,"caption: A comparison of different classification models based on their accuracy, precision, recall, and F1-score.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.89,0.92,0.87,0.89, Decision tree,0.82,0.84,0.81,0.83, Logistic reg.,0.86,0.88,0.85,0.86, Random forest,0.92,0.94,0.91,0.92, XGBoost,0.94,0.96,0.94,0.94","Table 4 displays a comparison of five classification models, namely SVM, Decision tree, Logistic regression, Random forest, and XGBoost, based on their accuracy, precision, recall, and F1-score. The models were trained and validated on the same dataset. The Random forest model obtained the highest accuracy of 0.92, with corresponding precision, recall, and F1-score of 0.94, 0.91, and 0.92. The XGBoost model, on the other hand, obtained the highest precision, recall, and F1-score with values of 0.96, 0.94, and 0.94, respectively. The SVM model had the lowest F1-score of 0.89. Overall, the table highlights the importance of considering multiple evaluation metrics when comparing classification models."
2284,"caption: Comparison of different ML models in terms of Accuracy, Precision, Recall, F1-score, and AUC.table: Model,Accuracy,Precision,Recall,F1-score,AUC, SVM,0.76,0.8,0.6,0.67,0.75, k-NN with k=3,0.72,0.64,0.72,0.68,0.71, Decision Tree,0.70,0.68,0.67,0.67,0.70, Random Forest,0.82,0.81,0.78,0.79,0.83","The table above compares the performances of four different machine learning models: SVM, k-NN with k=3, Decision Tree, and Random Forest. The models were evaluated on their Accuracy, Precision, Recall, F1-score, and AUC scores. The Random Forest model achieved the best overall performance with an Accuracy of 0.82. Additionally, it had the highest Precision score of 0.81 and a slightly higher recall of 0.78 concerning the SVM, whose Precision score was 0.8 and recall was 0.6. The k-nearest neighbour with k=3 has a slightly lower score concerning the other models except the Decision Tree model with the lowest performance along with all the evaluation metrics."
2285,"caption: Performance table comparing multiple different models based on different evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, LSTM,0.95,0.93,0.94,0.92, CNN,0.92,0.89,0.91,0.87, SVM,0.96,0.94,0.95,0.93, Naive Bayes,0.85,0.82,0.89,0.74, Random Forest,0.98,0.96,0.96,0.96, BERT-large,0.99,0.99,0.99,0.99","The table above shows the performance of multiple models in terms of accuracy, precision, recall, and F1-score. The models included in the table are LSTM, CNN, SVM, Naive Bayes, Random Forest, and BERT-large. Interestingly, the BERT-large model achieves 0.99 in all performance metrics, indicating a high-precision level of the model. Moreover, Random Forest has the best accuracy score of 0.98, closely followed by the BERT-large model with a score of 0.99. However, Naive Bayes has a lower performance score, which highlights the importance of choosing the right model for a specific task."
2286,"caption: Table 4: Evaluation metrics for different models.table: Model,F1-Score,Precision,Recall,Accuracy, Logistic Regression,0.87,0.76,0.98,0.82, SVM,0.90,0.78,1.00,0.85, K-NN,0.79,0.75,0.84,0.76, Decision Tree,0.84,0.75,0.95,0.81, Random Forest,0.93,0.87,0.99,0.91","Table 4 compares the F1-Score, Precision, Recall, and Accuracy metrics of different models. The table includes the Logistic Regression, SVM, K-NN, Decision Tree, and Random Forest models. Among the models, the Random Forest model performed the best, achieving the highest F1-score of 0.93, with high precision and recall of 0.87 and 0.99, respectively, and accuracy of 0.91. The SVM model produced the highest recall score of 1.00, indicating that it had the ability to accurately identify the positive cases, while the K-NN model showed the lowest F1-score of 0.79."
2287,"caption: Table 4: Model evaluation metrics depicting the accuracy, precision, recall, and F1-score for different models.table: Model,Accuracy,Precision,Recall,F1-Score, Model 1,0.89,0.88,0.92,0.90, Model 2,0.90,0.83,0.95,0.89, Model 3,0.88,0.85,0.90,0.87, Model 4,0.91,0.89,0.92,0.90","Table 4 provides a comparison of different models based on their evaluation metrics of accuracy, precision, recall, and F1-score. The table shows four different models (Model 1, Model 2, Model 3, and Model 4) with varying degrees of success. Model 4 performed the best with an accuracy of 0.91, precision of 0.89, recall of 0.92, and F1-Score of 0.90. Interestingly, Model 2 had the highest recall of 0.95 and the second-best F1-score of 0.89, while Model 1 had the highest precision score of 0.88. Overall, the table indicates that different models excel in different evaluation metrics, and it's crucial to consider them all before selecting the best performing model."
2288,"caption: Performance comparison of different classification models using various evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.89,0.90,0.91,0.89, Decision Tree,0.84,0.83,0.88,0.79, Random Forest,0.91,0.91,0.95,0.87, Gradient Boosting,0.88,0.88,0.91,0.85, Support Vector Machine,0.90,0.90,0.92,0.88","The above table provides a comparison of different classification models based on five evaluation metrics, namely accuracy, F1 score, precision, recall, and specificity. The models' performances are measured on a common test dataset. Based on the table, we notice that the Random Forest classification model achieves the highest accuracy (0.91) and F1 score (0.91), while Logistic Regression has the highest precision (0.91) and Decision Tree has the highest recall (0.79). The Gradient Boosting model's performance is slightly lower than other models concerning all the metrics, which is indicated by its lower performance scores. Overall, the table shows the performance variations of different models in different evaluation metrics, giving us an insight into each model's relative strengths and weaknesses."
2289,"caption: Performance of Different Models on Evaluation Metricstable: ```, Model Name,Metric Name,Score, Logistic Regression,Accuracy,0.88, Precision,0.86, Recall,0.87, F1 Score,0.86, ROC-AUC,0.92, K-Nearest Neighbors,Accuracy,0.83, Precision,0.82, Recall,0.84, F1 Score,0.82, ROC-AUC,0.87, Decision Tree,Accuracy,0.74, Precision,0.73, Recall,0.74, F1 Score,0.73, ROC-AUC,0.80","The table presents the performance of three different models, Logistic Regression, K-Nearest Neighbors, and Decision Tree, based on multiple evaluation metrics: Accuracy, Precision, Recall, F1 Score, and ROC-AUC. The best-performing model based on these evaluation metrics is Logistic Regression, with the highest scores in Accuracy (0.88), Precision (0.86), Recall (0.87), F1 Score (0.86), and ROC-AUC (0.92). Although K-Nearest Neighbors had a lower overall performance rate, it still performed relatively well with Accuracy (0.83), Precision (0.82), Recall (0.84), F1 Score (0.82), and ROC-AUC (0.87). In contrast, the Decision Tree model performed the poorest among the three models, with the lowest scores in all evaluation metrics."
2290,"caption: Comparison of Model Performance on Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.92,0.91,0.93,0.92, Decision Tree,0.87,0.84,0.89,0.85, Naive Bayes,0.84,0.78,0.90,0.82, Random Forest,0.93,0.92,0.93,0.92, KNN,0.89,0.86,0.89,0.87","The table compares the performance of SVM, Decision Tree, Naive Bayes, Random Forest, and KNN models based on different evaluation metrics - Accuracy, Precision, Recall, and F1-Score. The Random Forest model performs the best with the highest accuracy, precision, and F1-Score of 0.93, 0.92, and 0.92, respectively. The SVM model also performed well with an accuracy of 0.92 and balanced precision and recall values of 0.91 and 0.93, respectively. On the other hand, the Naive Bayes model shows the lowest accuracy of 0.84, and the Decision Tree model has the lowest F1-Score of 0.85. Overall, the Random Forest model appears to be the best-performing model, making it a good choice for the task at hand."
2291,"caption: Comparison of model performance for different metrics.table: Model,F1-score,Balanced accuracy,Matthews correlation coefficient, A,0.85,0.76,0.71, B,0.78,0.81,0.64, C,0.89,0.83,0.76, D,0.76,0.79,0.60","The table summarizes the F1-score, balanced accuracy, and Matthews correlation coefficient (MCC) of four different models, A, B, C, and D. Model C has the highest F1-score (0.89), while model B has the highest balanced accuracy score (0.81). The MCC score, which accounts for all four cells of the confusion matrix, is highest for model C with a score of 0.76. In contrast, model D has the lowest performance across all three metrics, with an F1-score of 0.76, balanced accuracy of 0.79, and an MCC of 0.60."
2292,"caption: Model performance based on different evaluation metricstable: Model,Accuracy,F1-score,Precision,Recall, Model A,0.80,0.70,0.75,0.65, Model B,0.75,0.68,0.72,0.65, Model C,0.84,0.73,0.78,0.68, Model D,0.83,0.75,0.81,0.70, Model E,0.79,0.71,0.76,0.66","Table 1 presents the performance results of five different models evaluated using accuracy, F1-score, precision, and recall metrics. Model C demonstrated the highest accuracy score of 0.84, while Model D illustrated the highest F1-score of 0.75. Interestingly, Model A attained the highest precision with a score of 0.75, and Model E achieved the highest recall with a score of 0.66. These results suggest that each model has specific strengths in its performance evaluation, and the choice of evaluation metric should be based on the specific application and goals of the research."
2293,"caption: Table 4: Evaluation metrics of different models.table: Model Name,Accuracy,Precision,Recall,F1-Score, Model 1,0.87,0.89,0.86,0.875, Model 2,0.92,0.94,0.89,0.916, Model 3,0.85,0.88,0.80,0.837, Model 4,0.91,0.90,0.93,0.918","Table 4 shows the evaluation metrics of four different models. The evaluation metrics include accuracy, precision, recall, and F1-score. Model 2 has the highest overall performance in the evaluation metrics, with an accuracy of 0.92, precision of 0.94, recall of 0.89, and F1-score of 0.916. On the other hand, Model 3 has the lowest overall performance with an accuracy of 0.85, precision of 0.88, recall of 0.80, and F1-score of 0.837. Interestingly, Model 4 has a high precision of 0.90 and a high recall of 0.93, but only a slightly lower F1-score than Model 2 at 0.918."
2294,"caption: Performance comparison of different models based on accuracy, F1 score, and area under curve (AUC).table: Model,Accuracy,F1 Score,Area Under Curve (AUC), Random Forest,0.95,0.94,0.92, Logistic Regression,0.89,0.87,0.86, Support Vector Machines,0.91,0.90,0.88, Neural Network,0.93,0.92,0.91, Naive Bayes,0.84,0.80,0.82","The table presents a performance comparison of five different models based on three metrics: Accuracy, F1 score, and AUC. Random Forest achieved the highest accuracy of 0.95, followed by Neural network with 0.93 accuracy score. However, Naive Bayes scored the least with only 0.84 accuracy score. Regarding F1 score, all models had good scores with Random Forest leading with a score of 0.94 followed closely by the Neural network and Support Vector Machines, scoring 0.92 and 0.90, respectively. Concerning AUC, Random Forest also outperformed others with 0.92 scores. Logistic regression scored the least with 0.86 AUC while the remaining models had AUC scores of 0.88 and 0.91."
2295,"caption: Table 4: Performance comparison of different models for the classification problem using multiple metrics.table: Model,Accuracy,F1_score,Precision,Recall, SVM,0.861,0.901,0.928,0.876, Logistic Regression,0.844,0.897,0.912,0.882, KNN,0.825,0.874,0.905,0.846, Naive Bayes,0.806,0.862,0.897,0.829, Decision Tree,0.765,0.823,0.846,0.802",
2296,"caption: Model performance comparison using different evaluation metricstable: Model,F1 Score,Precision,Recall,Accuracy, Logistic Regression,0.74,0.75,0.73,0.77, Random Forest,0.83,0.85,0.81,0.84, SVM,0.65,0.57,0.78,0.69, Decision Tree,0.75,0.76,0.73,0.74","The table presents a comparison of four different models' performance using different evaluation metrics in binary classification. The models included in the table are Logistic Regression, Random Forest, SVM and Decision Tree. The evaluation metrics used are F1 Score, Precision, Recall and Accuracy. The Random Forest model outperformed the other models in all evaluation metrics with an F1 score, Precision, Recall, and Accuracy of 0.83, 0.85, 0.81, and 0.84, respectively. The SVM model had the lowest performance with an F1 score of 0.65 and Precision of 0.57, while the Decision tree had the lowest Recall of 0.73. Overall, the table provides a quick comparison of multiple models and metrics in a tabular form to help identify the best performing model for a specific evaluation metric."
2297,"caption: Table 4: Performance metrics for different modelstable: Model name,Accuracy,Precision,Recall,F1-score, Model A,0.890,0.825,0.780,0.801, Model B,0.892,0.815,0.792,0.803, Model C,0.887,0.832,0.767,0.795, Model D,0.879,0.812,0.753,0.780, Model E,0.895,0.846,0.799,0.820","Table 4 provides a comparison of the performance of different models based on various evaluation metrics. The models include Model A, Model B, Model C, Model D, and Model E. The evaluation metrics for these models include Accuracy, Precision, Recall, and F1-score. These models were evaluated using the same dataset. Interestingly, Model E exhibits the best performance across all evaluation metrics with an Accuracy of 0.895, Precision of 0.846, Recall of 0.799, and F1-score of 0.820. However, Model C performs slightly better in terms of Precision, while Model B demonstrates better Recall performance."
2298,"caption: Model Performance Comparison for Binary Classification Problem.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.82,0.81,0.81,0.80, Decision Tree,0.73,0.71,0.70,0.62, Random Forest,0.89,0.86,0.87,0.86, Neural Network,0.91,0.89,0.88,0.88","The table represents a model performance comparison for a binary classification problem using four different models, namely Logistic Regression, Decision Tree, Random Forest, and Neural Network. The table displays four evaluation metrics such as Accuracy, Precision, Recall, and F1 Score for each model. Random Forest and Neural Network models performed better than Logistic Regression and Decision Tree models for all evaluation metrics. The Neural Network achieved the highest accuracy score of 0.91, whereas, the Random Forest model achieved the highest precision, recall, and F1 Score scores of 0.86, 0.87, and 0.86, respectively. Overall, the results suggest that the Neural Network and Random Forest models could be appropriate for the given binary classification problem."
2299,"caption: Classification performance of four different models on a binary classification task.table: Model,Precision,Recall,F1-score,Accuracy, SVM,0.83,0.71,0.76,0.74, LR,0.75,0.82,0.78,0.72, MLP,0.69,0.73,0.71,0.68, Random Forest,0.79,0.76,0.77,0.75","The table presents the performance comparison of four different models for a binary classification task using multiple evaluation metrics. The models include SVM, LR, MLP, and Random Forest. The evaluation metrics utilized in the analysis were precision, recall, F1-score, and accuracy. The Random Forest model outperformed other models regarding precision and F1-score, obtaining 0.79 and 0.77, respectively. Meanwhile, the SVM model achieved the highest recall, with a score of 0.71, and its F1-score was 0.76. The LR model achieved the highest accuracy with a score of 0.72. The MLP model achieved the lowest precision, recall, F1-score, and accuracy with scores of 0.69, 0.73, 0.71, and 0.68, respectively. Overall, the Random Forest model had the highest precision and F1-score, while the LR model achieved the highest accuracy."
2300,"caption: Table 4: Evaluation metrics of five machine learning modelstable: Model,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.87,0.86,0.88,0.85, Decision Tree,0.82,0.80,0.81,0.79, Random Forest,0.92,0.91,0.93,0.89, Gradient Boosting,0.89,0.88,0.88,0.89, Support Vector Machine,0.88,0.87,0.89,0.85","Table 4 displays the evaluation metrics of five machine learning models: Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Support Vector Machine. The table exhibits the accuracy, F1-score, precision, and recall results of each model. Interestingly, the Random Forest model showed the best results in all four metrics with an accuracy of 0.92, F1-score of 0.91, precision of 0.93, and recall of 0.89. On the other hand, Decision Tree model achieved the lowest accuracy of 0.82 and the lowest F1-score of 0.80. The highest precision score was obtained by Random Forest, while the highest recall score was obtained by Gradient Boosting. Overall, the results suggest that Random Forest is the best-performing model in terms of accuracy, F1-score, precision, and recall."
2301,"caption: Table 4: Evaluation metrics of different models on the test set.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.87,0.90,0.86,0.88, LR,0.85,0.89,0.82,0.85, RF,0.91,0.92,0.90,0.91, MLP,0.89,0.91,0.87,0.89, KNN,0.83,0.85,0.82,0.83","Table 4 displays the evaluation metrics of different machine learning models on the test set, where SVM, LR, RF, MLP, and KNN models were used to classify instances. The metrics used to evaluate the models were Accuracy, Precision, Recall, and F1-score. Among the models, RF achieved the best Accuracy score of 0.91 followed closely by MLP with an accuracy score of 0.89. RF also achieved the highest precision score of 0.92 and highest recall of 0.90. The results suggest that RF is the best performing model among all the models for this classification task, while KNN is the worst-performing based on all evaluation metrics."
2302,"caption: Model evaluation metrics for five different models.table: Model Name,Precision,Recall,F1-Score,Accuracy, Model A,0.85,0.92,0.88,0.91, Model B,0.79,0.84,0.81,0.85, Model C,0.91,0.95,0.93,0.94, Model D,0.76,0.91,0.82,0.89, Model E,0.87,0.83,0.85,0.84","The table presents evaluation metrics for five different models. The metrics in the table include precision, recall, F1-score, and accuracy. Model C performed the best overall with a precision score of 0.91, recall of 0.95, F1-score of 0.93, and accuracy of 0.94. Model A and Model E achieved the highest precision score of 0.85 and 0.87, respectively. On the other hand, Model D indicated the highest recall score of 0.91. Notably, Model B obtained the lowest evaluation scores across all metrics, except for accuracy where it scored 0.85."
2303,"caption: Table 4: Model performance for binary classification using various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, LR (C=1),0.89,0.75,0.85,0.79, SVM (rbf),0.91,0.81,0.87,0.83, Random Forest,0.92,0.82,0.89,0.85, XGBoost,0.93,0.89,0.87,0.88","Table 4 presents the model performance for binary classification using evaluation metrics such as accuracy, precision, recall, and F1-score. The table shows four models, logistiс regression (LR), support vector machine (SVM), Random Forest, and XGBoost. The best performance is shown by XGBoost with an accuracy of 0.93 and a Precision of 0.89. SVM performed better than LR, but Random Forest showed a better performance in Precision, Recall, and F1-score than both SVM and LR. Overall, XGBoost showcased the best performance compared to the other models in all evaluation metrics except for precision that was slightly better by Random Forest."
2304,"caption: Table 4: Comparison of model performance based on multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.856,0.849,0.871,0.860, Support Vector Machine,0.892,0.894,0.890,0.889, K-Nearest Neighbors,0.801,0.795,0.810,0.800, Decision Tree,0.810,0.845,0.780,0.798, Random Forest,0.912,0.915,0.910,0.911","Table 4 presents the comparison of five different machine learning models' performances based on multiple evaluation metrics, namely accuracy, precision, recall and F1-Score. The models considered are Logistic Regression, Support Vector Machine, K-Nearest Neighbors, Decision Tree, and Random Forest. The table demonstrates that Random Forest has the highest accuracy metric with a score of 0.912, while Support Vector Machine has the highest precision, recall, and F1-score with 0.894, 0.890, and 0.889 scores, respectively. Interestingly, Logistic Regression and Decision Tree models show moderate performances, while K-Nearest Neighbors show the worst performance among the models."
2305,"caption: Comparison of different models based on different evaluation metrics.table: Model,Accuracy,F1-score,AUC-ROC,Precision,Recall, Logistic Regression,0.85,0.87,0.90,0.83,0.92, Decision tree,0.76,0.75,0.77,0.78,0.72, Random Forest,0.90,0.91,0.92,0.89,0.93, Support Vector Machine,0.82,0.84,0.88,0.80,0.88, Artificial Neural Network,0.89,0.89,0.91,0.88,0.90","Table presents a comparison of different machine learning classifiers based on their performance on various evaluation metrics such as Accuracy, F1-Score, AUC-ROC, Precision, and Recall. The models assessed are Logistic Regression, Decision tree, Random Forest, Support Vector Machine, and Artificial Neural Network. The highest performing model on all evaluation metrics was Random Forest, with the accuracy of 0.90, F1-Score of 0.91, AUC-ROC of 0.92, Precision of 0.89 and Recall of 0.93. The lowest performing model on all evaluation metrics was Decision Tree with an average accuracy of 0.76, F1-Score of 0.75, AUC-ROC of 0.77, Precision of 0.78, and Recall of 0.72."
2306,"caption: Model performance based on multiple evaluation metricstable: Model,F1-score,Precision,Recall,Accuracy, SVM,0.82,0.87,0.79,84%, Logistic Regression,0.76,0.82,0.72,78%, Neural Network,0.81,0.85,0.78,82%, Random Forest,0.85,0.88,0.83,86%, Decision Tree,0.74,0.79,0.71,76%","The table compares five different models' performance on a particular task based on various evaluation metrics. The models using in the comparison are SVM, Logistic Regression, Neural Network, Random Forest, and Decision Tree. Each model's performance is assessed based on F1-score, Precision, Recall, and Accuracy. The Random Forest model shows the highest F1-score and Precision of 0.85 and 0.88, respectively, and a recall of 0.83. SVM and Neural Network models exhibit the highest accuracy with 84% and 82%, respectively. The Decision Tree model has the lowest performance results compared to other models. Overall, the table highlights each model's strengths and weaknesses and provides useful insights for choosing the best model for a specific task."
2307,"caption: Table 4: Model performances based on accuracy, F1-score, Recall, and Precision.table: Model,Accuracy,F1-Score,Recall,Precision, SVM,0.75,0.69,0.68,0.70, Naive Bayes,0.69,0.63,0.71,0.56, Decision Tree,0.80,0.74,0.72,0.77, Random Forest,0.86,0.82,0.82,0.83, XGBoost,0.88,0.85,0.84,0.86","Table 4 summarizes the model performance based on four different evaluation metrics: Accuracy, F1-Score, Recall, and Precision. The table includes five models: SVM, Naive Bayes, Decision Tree, Random Forest, and XGBoost. It is observed that the Random Forest and XGBoost models show higher accuracy, F1-Score, recall, and precision scores in comparison to the other models. Specifically, the XGBoost model performs the best in all four metrics. The Naive Bayes model performs the worst in this comparison. Overall, the table indicates that the Random Forest and XGBoost models are the most effective in terms of model evaluation metrics in this context."
2308,"caption: Table 4: Performance Evaluation of Different Models using Various Metricstable: Models,Accuracy,Precision,Recall,F1-score, Model1,0.88,0.85,0.89,0.87, Model2,0.92,0.89,0.93,0.91, Model3,0.76,0.82,0.69,0.75, Model4,0.85,0.78,0.89,0.83, Model5,0.95,0.94,0.96,0.95","Table 4 presents the performance evaluation of five different models using four different evaluation metrics. The evaluation metrics include accuracy, precision, recall, and F1-score. The table highlights that Model5 has achieved highest accuracy, precision, recall, and F1-score of 0.95, 0.94, 0.96, and 0.95, respectively, indicating its superior performance compared to other models. Interestingly, Model2 has achieved the second-best performance, followed by Model1, Model4, and Model3. This table's results show that Model5 and Model2 are the top-performing models based on the evaluation metrics used in this study."
2309,"caption: Evaluation metrics of different modelstable: Model,Accuracy,Precision,Recall,F1-score, Model A,0.85,0.63,0.78,0.70, Model B,0.90,0.72,0.85,0.78, Model C,0.79,0.56,0.68,0.61, Model D,0.92,0.78,0.88,0.82, Model E,0.86,0.65,0.80,0.72","The table above compares the performance of five different models based on four evaluation metrics: Accuracy, Precision, Recall, and F1-score. Each model was trained and tested on the same dataset. Model D achieved the highest accuracy score of 0.92, followed by Model B with 0.90. Model D also performed the best in terms of Precision with 0.78, while Model E had the highest Recall value of 0.80. Interestingly, Model B and Model D have shown very similar results in terms of evaluation metrics. Model C had the lowest F1-score with 0.61, while Model D had the highest F1-score with 0.82. Overall, Model D seems to have the best performance across the different evaluation metrics in this comparison among the five models."
2310,"caption: Model performance using multiple evaluation metrics.table: Models,Accuracy,Precision,Recall,F1-Score, Model A,0.95,0.96,0.92,0.94, Model B,0.89,0.93,0.86,0.89, Model C,0.92,0.87,0.94,0.90, Model D,0.88,0.90,0.85,0.87, Model E,0.93,0.92,0.95,0.93","The table displays the performance measures of five different models, as evaluated by their accuracy, precision, recall, and F1-score metrics. Model A achieves the highest accuracy of 0.95, with corresponding precision, recall, and F1-score of 0.96, 0.92, and 0.94, respectively. Model E demonstrates the best recall of 0.95, while Model B produces the highest precision of 0.93. Interestingly, Model C generates the highest F1-score of 0.9, with a moderately high recall of 0.94 and precision of 0.87. Among all models, Model D performs the worst with the lowest accuracy, precision, recall, and F1-score values indicating poor performance."
2311,"caption: Table 4: Evaluation metrics of different models.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.893,0.892,0.891,0.890, Naive Bayes,0.872,0.876,0.874,0.870, Decision Tree,0.823,0.824,0.826,0.820, Random Forest,0.925,0.926,0.927,0.924, Gradient Boosting,0.934,0.936,0.937,0.934","Table 4 presents the evaluation metrics, including accuracy, precision, recall, and F1-score, of different classification models, namely Logistic Regression, Naive Bayes, Decision Tree, Random Forest, and Gradient Boosting. The table indicates that Gradient Boosting achieved the highest accuracy score of 0.934, followed by Random Forest with 0.925. Moreover, all models demonstrated similar precision, recall and F1-scores, except Decision Tree with slightly lower scores compared to other classifiers. Interestingly, Naive Bayes achieved the second-highest precision, recall, and F1-scores despite having a lower accuracy score than other classifiers in the table. Overall, the table highlights the importance of considering multiple evaluation metrics while comparing different classification models."
2312,"caption: Performance metrics comparison of multiple classification models.table: Model,Precision,Recall,F1-score,Accuracy, SVM_1,0.82,0.76,0.77,0.83, SVM_2,0.80,0.77,0.76,0.83, RF_1,0.85,0.85,0.83,0.87, RF_2,0.87,0.83,0.85,0.88, LSTM,0.89,0.85,0.87,0.90","The table compares the performance metrics of multiple classification models, including SVM_1, SVM_2, RF_1, RF_2, and LSTM. The evaluation metrics are precision, recall, F1-score, and accuracy. Both the SVM and RF models show good precision scores, with RF_2 being the best with 0.87. SVM models have a relatively high recall, while RF_1 and RF_2 outperform other models in recall. The LSTM model has the highest precision and F1-score, making it the best performer overall. However, the RF_2 model has the highest accuracy score of 0.88, indicating that it has the lowest misclassification rate."
2313,"caption: Table 4: Evaluation of Different Models on the Classification Tasktable: Model,Accuracy,Precision,Recall,F1-Score,AUC, SVM,0.91,0.93,0.89,0.91,0.96, KNN,0.87,0.85,0.88,0.86,0.92, Decision tree,0.92,0.94,0.91,0.92,0.95, Random forest,0.94,0.95,0.93,0.94,0.97","The evaluation of different models on the classification task is presented in Table 4. The table shows multiple different models, including SVM, KNN, Decision tree, and Random forest. Various evaluation metrics are used to assess the performance of these models, including Accuracy, Precision, Recall, F1-score, and AUC. The Random forest model performs the best in all evaluation metrics, achieving the highest accuracy of 0.94, the highest AUC of 0.97, the highest precision of 0.95, the highest recall of 0.93, and the highest F1-score of 0.94. SVM reports the second-best performance, while KNN performs the worst among all the models."
2314,"caption: Performance comparison of multiple classification models on a given dataset using precision, recall, F1-score, and support metrics.table: Model,Precision,Recall,F1-Score,Support, Logistic regression (LR),0.82,0.83,0.82,991, Decision tree (DT),0.78,0.76,0.77,991, Random forest (RF),0.84,0.88,0.86,991, Gradient boosting (GB),0.86,0.85,0.85,991, Support vector machines (SVM),0.80,0.79,0.79,991, Naive Bayes (NB),0.73,0.70,0.71,991","Table X showcases the performance comparison of six models: Logistic regression (LR), Decision tree (DT), Random forest (RF), Gradient boosting (GB), Support vector machines (SVM), and Naive Bayes (NB). The table presents four different evaluation metrics such as precision, recall, F1-Score, and support. The models were evaluated using a given dataset. RF achieved the highest F1-Score of 0.86, supported by a precision score of 0.84 and a recall score of 0.88, indicating better performance. GB has shown promising results too, having the highest precision score of 0.86 among other models. The NB model obtained the lowest F1-Score of 0.71, with the precision and recall scores of 0.73 and 0.70, respectively."
2315,"caption: Comparison of Models based on Performance Metricstable: Model,Precision,Recall,F1-score,AUC, SVM,0.82,0.75,0.78,0.89, KNN,0.80,0.76,0.78,0.84, LR,0.85,0.80,0.81,0.88, RF,0.87,0.82,0.83,0.92, XGB,0.86,0.83,0.84,0.91",
2316,"caption: Table 4: Model Performance on Multiple Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1 Score, SVM,0.90,0.89,0.91,0.90, Logistic Regression,0.88,0.84,0.91,0.87, Random Forest,0.91,0.92,0.90,0.91, XGBoost,0.93,0.94,0.92,0.93, Ensemble,0.95,0.96,0.95,0.95","Table 4 presents model performance on multiple evaluation metrics, including Accuracy, Precision, Recall, and F1-score. The models evaluated are SVM, Logistic Regression, Random Forest, XGBoost, and an ensemble model that averages the five models' outputs. The best-performing models in terms of each evaluation metric are the ensemble model, with an Accuracy of 0.95, Precision of 0.96, Recall of 0.95, and F1-Score of 0.95. XGBoost also performs well, with an Accuracy of 0.93, Precision of 0.94, Recall of 0.92, and F1-Score of 0.93. Notably, Random Forest has the highest Accuracy of 0.91, while SVM has the highest Recall of 0.91. Overall, the ensemble model shows the best performance across all evaluation metrics."
2317,"caption: Performance comparison of multiple different modelstable: Model,Accuracy,AUC,Precision,Recall, Model A,0.87,0.91,0.92,0.85, Model B,0.81,0.88,0.84,0.83, Model C,0.92,0.93,0.93,0.91, Model D,0.79,0.85,0.78,0.89","The table presents the performance comparison of four different machine learning models in terms of accuracy, AUC, precision, and recall. Model A shows the highest accuracy and AUC of 0.87 and 0.91, respectively. It also presents the highest precision with a value of 0.92 and a recall of 0.85. Model C also shows an impressive performance with an accuracy of 0.92 and an AUC of 0.93, along with the highest precision and recall values. Model B features an accuracy of 0.81, which is the lowest among the presented models. However, it has a relatively high AUC of 0.88. Model D shows the worst performance with an accuracy of 0.79 and an AUC of 0.85. However, it has a higher recall value than Model A, making it a better choice for certain applications."
2318,"caption: Table showing the performance of three different models using various evaluation metrics: Accuracy, F1 score, Precision, and Recall.table: Model,Accuracy,F1 Score,Precision,Recall, A,0.85,0.86,0.87,0.85, B,0.81,0.82,0.83,0.81, C,0.87,0.87,0.86,0.89","The table shows the performance of three different models, A, B, and C, evaluated using various metrics, including Accuracy, F1 score, Precision, and Recall. Model A achieved the highest accuracy and F1 score with values of 0.85 and 0.86, respectively, while model C achieved the highest precision and recall with values of 0.86 and 0.89, respectively. Model B showed the lowest performance across all evaluation metrics. The results from this table could help to choose the optimal model based on the required performance metric."
2319,"caption: Table 4: Evaluation metrics (Accuracy, Precision, Recall, F1) for different models.table: Model,Accuracy,Precision,Recall,F1, Logistic Regression,0.87,0.85,0.68,0.75, Random Forest,0.92,0.92,0.84,0.87, Decision Tree,0.85,0.82,0.79,0.80, Support Vector Machine,0.89,0.87,0.75,0.80, Neural Network,0.91,0.90,0.88,0.89","Table 4 presents the evaluation metrics of Accuracy, Precision, Recall, and F1 for different models. The models included in the table are Logistic Regression, Random Forest, Decision Tree, Support Vector Machine, and Neural Network. From the table, the Random Forest algorithm exhibits the highest Accuracy score of 0.92, while Logistic Regression shows the lowest Accuracy score of 0.87. The Neural Network model shows the highest Precision, Recall, and F1 scores of 0.90, 0.88, and 0.89, respectively. Overall, the table demonstrates a comparative analysis of model performances based on different evaluation metrics."
2320,"caption: Comparison of different models based on multiple evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, Model 1,0.87,0.85,0.84,0.863, Model 2,0.9,0.86,0.85,0.859, Model 3,0.92,0.88,0.89,0.875, Model 4,0.85,0.84,0.86,0.837, Model 5,0.89,0.87,0.88,0.867","Table 1 shows a comparison of five different models based on multiple evaluation metrics, including accuracy, F1-score, precision, and recall. Model 3 performs the best with the highest accuracy of 0.92, F1 score of 0.88, and recall of 0.875. On the other hand, Model 4 has the lowest accuracy of 0.85, F1-score of 0.84, and recall of 0.837. Notably, Model 4 has the highest precision score of 0.86. Model 2 performs well overall with the second-highest accuracy, F1-score, and precision. However, Model 5 beats Model 2 in terms of recall. Therefore, based on these metrics, Model 3 is the best performing model, whereas Model 4 is best at precision."
2321,"caption: Model performance for various evaluation metrics.table: Models,Accuracy,F1 Score,Precision,Recall, SVM,0.85,0.84,0.87,0.83, Naive Bayes,0.87,0.86,0.84,0.89, Decision Tree,0.79,0.76,0.81,0.72, Random Forest,0.92,0.91,0.93,0.90, XGBoost,0.90,0.89,0.91,0.87","The table displays the performance results of SVM, Naive Bayes, Decision Tree, Random Forest, and XGBoost models based on multiple evaluation metrics. The models' accuracy, F1 score, precision, and recall are shown in the table. Random Forest shows the highest accuracy of 0.92. In contrast, Naive Bayes achieves the highest F1 score and recall of 0.86 and 0.89, respectively. Notably, Random Forest and XGBoost models' precision scores are 0.93 and 0.91, respectively, outperforming other models, indicating that the models are reliable for classification tasks that require high-precision scores. Overall, the table provides a comprehensive comparison of different models' performance in terms of multiple evaluation metrics."
2322,"caption: Comparison of different machine learning classifiers' performance on the test set.table: Model,F1-score,Precision,Recall,Accuracy, Decision Tree,0.85,0.83,0.87,0.84, Random Forest,0.88,0.86,0.91,0.87, k-Nearest Neighbors,0.80,0.77,0.84,0.79, Support Vector Machine,0.90,0.87,0.93,0.89, Logistic Regression,0.87,0.85,0.90,0.86",
2323,"caption: Model evaluation metrics for different machine learning classifierstable: Model,Accuracy,Precision,Recall,F1-Score, Naive Bayes,0.87,0.93,0.82,0.87, Decision Tree,0.90,0.92,0.89,0.90, Random Forest,0.93,0.95,0.92,0.93, Support Vector Machine,0.92,0.93,0.91,0.92, Logistic Regression,0.91,0.94,0.90,0.91","Table presents the performance of different machine learning models on evaluation metrics that include Accuracy, Precision, Recall, and F1-Score. Naive Bayes achieved an accuracy of 0.87 with Precision, Recall, and F1-Score scores of 0.93, 0.82, and 0.87, respectively. Meanwhile, Decision Tree performed marginally better with an accuracy of 0.90 and Precision, Recall, and F1-Score scores of 0.92, 0.89, and 0.90. Random Forest, Support Vector Machine, and Logistic Regression obtained the highest accuracy of 0.93, 0.92, and 0.91, respectively. The Precision, Recall, and F1-Score scores for Random Forest, Support Vector Machine, and Logistic Regression were 0.95, 0.92, and 0.93; 0.93, 0.91, and 0.94; and 0.92, 0.90, and 0.91, respectively."
2324,"caption: Table 4: Performance evaluation of different models using multiple metrics.table: Models,Precision,Recall,F1,AUPRC,AUC, Model 1,0.78,0.81,0.79,0.75,0.82, Model 2,0.86,0.75,0.80,0.77,0.81, Model 3,0.80,0.89,0.84,0.80,0.79, Model 4,0.91,0.81,0.86,0.81,0.87, Model 5,0.87,0.90,0.88,0.85,0.88","Table 4 shows the performance evaluation of five different models using multiple evaluation metrics. The table exhibits precision, recall, F1, AUPRC, and AUC scores for each model. Notably, Model 4 obtained the highest precision score of 0.91, while Model 5 had the highest recall score of 0.90. The highest F1 score of 0.88 was obtained by Model 5, while the highest AUPRC score of 0.85 was obtained by Model 5 as well. Furthermore, Model 1 and Model 2 obtained the highest and lowest AUC scores of 0.82 and 0.81, respectively. The table indicates that Model 5 could be considered the best performer based on its overall highest scores in different metrics."
2325,"caption: Performance Comparison of Different Machine Learning Modelstable: Model,Precision,Recall,F1-score,AUC, SVM,0.85,0.89,0.87,0.94, Decision Tree,0.75,0.77,0.72,0.82, Random Forest,0.91,0.89,0.90,0.96, Logistic Regression,0.88,0.82,0.85,0.92, Gradient Boosting,0.87,0.93,0.90,0.94","The table shows the performance comparison of multiple machine learning models based on different metrics, including precision, recall, F1-score, and AUC. SVM, Decision Tree, Random Forest, Logistic Regression, and Gradient Boosting machine learning models were evaluated using the same dataset. Random Forest model produced the highest precision score of 0.91. Gradient Boosting produced the highest recall score of 0.93. Although Random Forest and Gradient Boosting performed well in terms of precision and recall scores, respectively, Logistic Regression yielded the highest F1-score of 0.85. In terms of AUC score, Random Forest had the highest performance with a score of 0.96. These findings indicate that different machine learning models may excel in different evaluation metrics and performance measures, and the choice of the model would depend upon the problem at hand."
2326,"caption: Model performance based on different evaluation metrics.table: Metric,Model 1,Model 2,Model 3,Model 4, F1-score,0.88,0.92,0.86,0.91, Precision,0.90,0.94,0.85,0.89, Recall,0.89,0.90,0.87,0.95, Accuracy,0.89,0.93,0.90,0.93","The table presents a comparison of four models based on different evaluation metrics, including F1-score, precision, recall, and accuracy. The models are assigned Model 1 to Model 4. It can be observed from the table that Model 2 displays the best performance concerning all four metrics. Indeed, Model 2 scored the highest in F1, precision, and accuracy with 0.92, 0.94, and 0.93 respectively, outshining the other models. However, it is noticeable that Model 4 achieved the highest in recall with a score of 0.95.Despite Model 3 being the lowest in the performance metric with a score of 0.85 in precision, it scored a competitive recall of 0.87."
2327,"caption: Model evaluation metrics for different modelstable: Model,F1-score,Precision,Recall,Accuracy, SVM,0.83,0.89,0.78,0.76, MLP,0.85,0.92,0.80,0.78, KNN,0.81,0.84,0.79,0.73, RF,0.87,0.92,0.83,0.81, LR,0.82,0.88,0.78,0.75","Table presents various models' performances with evaluation metrics of F1-score, Precision, Recall, and Accuracy. The models compared were SVM, MLP, KNN, RF, and LR, and all models were applied to the same dataset. The results show that RF model outperformed other models with the highest F1-score of 0.87, Precision of 0.92, Recall of 0.83, and Accuracy score of 0.81. MLP model achieved the second-highest score with F1-score of 0.85, Precision of 0.92, Recall of 0.80, and Accuracy score of 0.78. SVM model achieved the highest precision score of 0.89, while KNN model shows the lowest performance among all models with the lowest F1-score of 0.81 and accuracy score of 0.73."
2328,"caption: Comparison of different machine learning models based on evaluation metric scores.table: Model,F1-score,Precision,Recall,Accuracy, Logistic Regression,0.54,0.65,0.47,0.68, Support Vector Machine,0.68,0.73,0.64,0.75, Random Forest,0.78,0.82,0.74,0.80, XGBoost,0.81,0.84,0.78,0.84, Multi-Layer Perceptron,0.67,0.72,0.62,0.76","Table presents the performance evaluation of various machine learning models based on four metrics, namely F1-score, precision, recall, and accuracy. The models tested include Logistic Regression, Support Vector Machine, Random Forest, XGBoost, and Multi-Layer Perceptron. Of the models presented, XGBoost performed the best with an F1-score of 0.81, precision of 0.84, recall of 0.78, and accuracy of 0.84. The Random Forest model performed the next best, achieving an F1-score of 0.78, precision of 0.82, recall of 0.74, and accuracy of 0.80. Logistic Regression model achieved the lowest overall scores."
2329,"caption: Model Performance Comparison based on Multiple Evaluation Metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.86,0.84,0.88,0.82, Random Forest,0.89,0.88,0.90,0.87, Support Vector Machine,0.84,0.82,0.86,0.80, Naive Bayes,0.81,0.78,0.82,0.74",
2330,"caption: Performance metrics for four different models.table: Model,Acc,F1-score,Precision,Recall, Model A,0.92,0.80,0.84,0.77, Model B,0.88,0.78,0.72,0.85, Model C,0.93,0.85,0.87,0.82, Model D,0.86,0.75,0.69,0.82","The table above presents the test results of different models, including Model A, Model B, Model C, and Model D in four different evaluation metrics, including Accuracy, F1-score, Precision, and Recall. The best performance across the models varies according to the evaluation metric. Model C has the highest Accuracy score of 0.93, while Model B had the lowest with a score of 0.88. In terms of F1-score, Model C showed the highest performance with a score of 0.85, whereas Model D had the lowest performance with a score of 0.75. Interestingly, Model A had the highest Precision of 0.84, but the lowest Recall of 0.77. Overall, the table provides an overview of the four different models' overall performance concerning multiple evaluation metrics."
2331,"caption: Table 4. Model performance using different evaluation metricstable: Model,Precision,Recall,F1-score,Accuracy, logistic regression,0.89,0.78,0.81,0.89, Random Forest,0.94,0.95,0.94,0.94, SVM,0.84,0.86,0.84,0.84, Naive Bayes,0.81,0.90,0.83,0.81, KNN,0.76,0.76,0.75,0.75","Table 4 presents the results obtained from different Machine Learning models, which were evaluated using multiple metrics such as Precision, Recall, F1-score, and Accuracy. The table compares how the models perform based on the different metrics. According to the results, the Random Forest model performed the best with the highest precision, recall, F1-score, and accuracy scores of 0.94, 0.95, 0.94, and 0.94, respectively. Naive Bayes also shows a decent performance with a precision score of 0.81 and an F1-score of 0.83. However, KNN demonstrates the lowest performance in all the metrics, showing that it is not the best model for this task."
2332,"caption: Table 4: Model Performance metrics comparison.table: Model Name,Accuracy (%),F1-Score (%),Recall (%),Precision (%), Logistic Regression,89.5,87.2,88.4,86.1, Random Forest,91.8,88.3,89.2,89.5, XGBoost,93.2,90.5,91.2,90.8, Multilayer Perceptron,87.6,85.1,86.4,84.2, AdaBoost,90.1,87.7,88.9,86.6","Table 4 presents a comparison of model performances for various machine learning models. The table shows the model names, along with their performance metrics' (Accuracy, F1-Score, Recall, and Precision) evaluation scores. The models presented in the table are Logistic Regression, Random Forest, XGBoost, Multilayer Perceptron, and AdaBoost. The Random Forest model appears to perform the best with the highest Accuracy (91.8%), F1-Score (88.3%), and Precision (89.5%) scores. However, XGBoost performed the best in terms of Recall (91.2%) and had the highest accuracy (93.2%)."
2333,"caption: Performance comparison of different classification models based on various evaluation metrics.table: Model,F1 Score,Accuracy,Precision,Recall,ROC-AUC,PR-AUC, Logistic Regression,0.84,0.83,0.86,0.82,0.91,0.79, Random Forest,0.89,0.88,0.89,0.90,0.93,0.85, XGBoost,0.91,0.90,0.92,0.90,0.94,0.88, Support Vector Machine,0.82,0.81,0.84,0.81,0.90,0.75","Table 1 presents a performance comparison of different classification models based on various evaluation metrics. The models evaluated include Logistic Regression, Random Forest, XGBoost, and Support Vector Machine (SVM). Evaluation metrics include F1 Score, Accuracy, Precision, Recall, ROC-AUC, and PR-AUC. The results indicate that the XGBoost model performs the best with the highest F1 Score of 0.91, followed closely by the Random Forest model with an F1 Score of 0.89. Additionally, the XGBoost model achieves the highest ROC-AUC and PR-AUC scores of 0.94 and 0.88, respectively. The Logistic Regression model performs relatively well, but the SVM model has the lowest performance results for all evaluation metrics."
2334,"caption: Model Performance Comparison based on Different Evaluation Metricstable: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.95,0.93,0.92,0.94, Random Forest,0.93,0.91,0.89,0.93, Logistic Regression,0.92,0.90,0.87,0.91, K-Nearest Neighbors,0.90,0.86,0.85,0.90, Decision Tree,0.85,0.81,0.78,0.84, Naïve Bayes,0.80,0.76,0.73,0.80","Table presents the performance comparison of six different models based on multiple evaluation metrics for a specific dataset. The evaluation metrics included in the table are accuracy, F1 score, precision, and recall. The models evaluated were SVM, Random Forest, Logistic Regression, K-Nearest Neighbors, Decision Tree, and Naïve Bayes. Notably, the SVM model performed the best overall with an accuracy of 0.95, F1 score of 0.93, precision of 0.92, and recall of 0.94. However, the Naïve Bayes model showed the lowest performance results with an accuracy of 0.80, F1 score of 0.76, precision of 0.73, and recall of 0.80. The results suggest that SVM and Random Forest are the best models for this particular dataset, considering their overall performance."
2335,"caption: Performance comparison of different models based on various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Model 1,0.853,0.852,0.842,0.846, Model 2,0.857,0.860,0.840,0.849, Model 3,0.865,0.870,0.855,0.862, Model 4,0.862,0.859,0.875,0.867, Model 5,0.870,0.878,0.862,0.870","The table compares the performance of five different models based on four evaluation metrics, namely Accuracy, Precision, Recall, and F1-Score. The Model 5 has achieved the highest performance with an accuracy score of 0.870 and F1-Score of 0.870, which is the same. The precision score of Model 5 and Model 3 is the highest with 0.878 and 0.870, while Model 4 has the highest recall score of 0.875. Model 1 holds the lowest performance with an accuracy score of 0.853 and an F1-Score of 0.846. The table shows that different models perform differently on different evaluation metrics."
2336,"caption: Model performances summary using multiple evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall,AUC, SVM,0.92,0.90,0.93,0.88,0.95, Random Forest,0.91,0.89,0.92,0.87,0.94, Logistic Regression,0.88,0.85,0.88,0.83,0.91, MLP Classifier,0.89,0.86,0.89,0.83,0.92","This table presents the performance of four different models, namely SVM, Random Forest, Logistic Regression, and MLP Classifier, according to five evaluation metrics, accuracy, F1-score, precision, recall, and AUC. The highest accuracy score is observed in SVM with a value of 0.92, followed closely by Random Forest with an accuracy of 0.91. On the other hand, Logistic Regression achieved the lowest accuracy score of 0.88. The Random Forest model received the highest F1-score and AUC, with values of 0.89 and 0.94, respectively. SVM achieved the highest precision score of 0.93, and MLP Classifier achieved the lowest recall of 0.83. Therefore, depending on the evaluation metric of interest, one model may be preferred over others."
2337,"caption: Model performance comparison based on different evaluation metrics using four different models.table: Model 1,Model 2,Model 3,Model 4, Metric 1,0.82,0.75,0.89,0.93, Metric 2,0.92,0.83,0.81,0.75, Metric 3,0.77,0.85,0.91,0.79, Metric 4,0.92,0.93,0.95,0.91, Metric 5,0.68,0.74,0.80,0.87","The table presents the performance comparison of four different models based on five different evaluation metrics. The models' names are not provided, categorized as Model 1, Model 2, Model 3, and Model 4. The five evaluation metrics are listed horizontally, including Metric 1, Metric 2, Metric 3, Metric 4, and Metric 5. Each cell in the table shows the performance results of the corresponding model and metric. Interestingly, the best-performing model varies depending on the evaluation metric. For example, Model 4 seems to be the best-performing model for Metric 1, 4, and 5, while Model 3 has the highest score for Metric 3. Overall, the table provides a clear comparison of performance results among multiple models and evaluation metrics."
2338,"caption: Comparison of different models' performances based on several evaluation metrics.table: Model,F1 Score (Class 0),F1 Score (Class 1),Precision (Class 0),Precision (Class 1),Recall (Class 0),Recall (Class 1),Accuracy,AUC, Model A,0.72,0.85,0.63,0.90,0.84,0.80,0.81,0.88, Model B,0.79,0.84,0.77,0.87,0.85,0.81,0.83,0.87, Model C,0.81,0.83,0.79,0.85,0.84,0.81,0.83,0.85, Model D,0.77,0.88,0.73,0.91,0.83,0.85,0.81,0.89, Model E,0.83,0.80,0.88,0.72,0.79,0.86,0.79,0.82","The table compares the performances of five different models based on various evaluation metrics. The models are compared based on F1 Score, Precision, Recall, Accuracy, and AUC for two classes (Class 0 and Class 1). Model E displayed the highest F1 Score for class 0 with 0.83 and Model D displays the highest F1 Score for class 1 with 0.88. Interestingly, Model C shows the highest AUC with a score of 0.85, while Model A achieved the lowest AUC score of 0.88. This table can be helpful for selecting the best approach as it compares model performance on various evaluation metrics."
2339,"caption: Table 4: Performance comparison of different classification models on the test data.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.83,0.8,0.85,0.75, KNN,0.75,0.65,0.72,0.60, Decision Tree,0.81,0.77,0.79,0.75, Random Forest,0.89,0.86,0.91,0.81, XGBoost,0.92,0.90,0.93,0.88","Table 4 presents a performance comparison of SVM, KNN, Decision Tree, Random Forest, and XGBoost models on the test dataset using multiple evaluation metrics. The evaluation metrics include accuracy, F1-score, precision, and recall. The best performance model is the XGBoost model, which shows the highest accuracy of 0.92 and F1-score of 0.90. The Random Forest model also exhibits excellent performance with an accuracy of 0.89 and F1-score of 0.86. The SVM model has the best precision score of 0.85. Interestingly, the KNN model achieved the lowest performance with an accuracy of 0.75 and F1-score of 0.65."
2340,"caption: Model Evaluation Metricstable: Model,Accuracy,F1 Score,AUC, Logistic Regression,85.6 %,0.85,0.729, Random Forest,92.3 %,0.91,0.893, K-Nearest Neighbors,83.2 %,0.82,0.670, Gradient Boosting,93.5 %,0.94,0.912, Support Vector Machine,84.6 %,0.84,0.711","The table above shows the evaluation results of five models in terms of Accuracy, F1 Score, and AUC. These models include Logistic Regression, Random Forest, K-Nearest Neighbors, Gradient Boosting, and Support Vector Machine. Random Forest achieved the highest accuracy of 92.3% indicating its ability to classify correctly most of the observations in the dataset. Also, the Gradient Boosting model achieved the highest F1 score of 0.94, indicating its ability to maintain a balance between precision and recall. On the other hand, the AUC metric provides a measure of how well the model can classify between the positive and negative classes. Gradient Boosting and Random Forest models outperformed the other models with AUC values of 0.912 and 0.893, respectively."
2341,"caption: Table 4: Model Performance using different evaluation metricstable: Model,Accuracy,Precision,Recall,ROC-AUC, LR,0.842,0.873,0.809,0.913, SVM,0.827,0.878,0.765,0.899, RF,0.855,0.899,0.817,0.922, GB,0.860,0.890,0.832,0.919, NN,0.855,0.886,0.824,0.917","Table 4 demonstrates the performance of five different models evaluated by four different evaluation metrics. The models are Logistic Regression (LR), Support Vector Machine (SVM), Random Forest (RF), Gradient Boosting (GB), and Neural Network (NN). The table reports accuracy, precision, recall, and ROC-AUC for each model. Among the models, the Random Forest shows the best overall performance with the highest accuracy, precision, and recall of 0.855, 0.899, and 0.817, respectively. However, the Logistic Regression model indicates the best ROC-AUC score of 0.913 among evaluated models."
2342,"caption: Model performances for Random Forest, SVM, and XGBoost on dataset X.table: Model,Accuracy,Precision,Recall,F1 Score,AUC ROC, Random Forest,0.89,0.91,0.87,0.89,0.94, Support Vector Machine,0.86,0.84,0.90,0.87,0.92, XGBoost,0.90,0.92,0.88,0.90,0.95","The table presents an evaluation of three different models on dataset X. The models are Random Forest, Support Vector Machine (SVM), and XGBoost. Five evaluation metrics include accuracy, precision, recall, F1 score, and area under the ROC curve (AUC ROC). Overall, the XGBoost model achieved the highest accuracy, precision, F1 score, and AUC ROC with scores of 0.90, 0.92, 0.90, and 0.95, respectively, showing its superior performance over the other models. The Random Forest model had the lowest AUC ROC at 0.94, while the SVM model had the lowest accuracy and F1 Score at 0.86 and 0.87, respectively. Such results could help researchers choose the best model for the data."
2343,"caption: Evaluation metrics of different classification models.table: Model,Accuracy,F1-Score,AUC_ROC,AUC_PR, SVM,0.83,0.85,0.77,0.79, MLP,0.84,0.86,0.81,0.80, KNN,0.78,0.80,0.74,0.70, RF,0.88,0.89,0.87,0.85, XGB,0.90,0.91,0.88,0.86","The presented table provides multiple classification models' evaluation metrics, including SVM, MLP, KNN, RF, and XGB. The evaluation metrics include Accuracy, F1-Score, AUC_ROC, and AUC_PR. The highest accuracy score was achieved by the XGB model, with a score of 0.90, followed by the RF model with 0.88 accuracy. Additionally, the XGB model achieved the best results in F1-Score and AUC_PR among all models with 0.91 and 0.86 scores, respectively. However, the RF model produced the highest AUC_ROC values of 0.87. This table provides valuable insights into each model's classification performance metrics, indicating that different models can significantly impact a classification task's results."
2344,"caption: Model performances using different evaluation metrics based on the dataset.table: Model,Acc,F1,AUC,PR-AUC, Decision tree,0.75,0.71,0.78,0.62, Random forest,0.81,0.76,0.83,0.72, XGBoost,0.82,0.78,0.85,0.75, Logistic regression,0.79,0.74,0.80,0.67","The table compares the performance of four models based on multiple evaluation metrics, including accuracy (Acc), F1-score (F1), area under the receiver operating characteristic curve (AUC), and area under the precision-recall curve (PR-AUC). The models compared in the table are Decision tree, Random forest, XGBoost, and Logistic regression. From the table, the XGBoost model shows the best performances in all of the evaluation metrics. It obtained the highest accuracy of 0.82, F1-score of 0.78, AUC of 0.85 and PR-AUC of 0.75. In contrast, Decision tree achieved the worst performance in all of the evaluation metrics among the models."
2345,"caption: Table 4: Model Performance from Different Approaches Based on Multiple Evaluation Metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.73,0.72,0.77,0.74, Naïve Bayes,0.67,0.54,0.62,0.58, Random Forest,0.77,0.77,0.81,0.79, XGBoost,0.80,0.80,0.84,0.82","Table 4 displays the performance of multiple models evaluated using multiple metrics. The table shows that XGBoost has the highest Accuracy (0.80) and F1-Score (0.82) among all models, followed closely by Random Forest with an Accuracy of 0.77 and an F1-score of 0.79. Naive Bayes appears to have the lowest Accuracy (0.67) and F1-Score (0.58) among the models. Notably, all models have reasonably high Precision and Recall scores, with XGBoost having the highest Precision and Recall scores, indicating its overall better performance."
2346,"caption: Table 4: Performance results of different classification models based on multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, LogisticRegression,0.91,0.91,0.91,0.91, DecisionTree,0.76,0.76,0.76,0.76, K-Nearest Neighbor,0.86,0.85,0.86,0.85, SVM,0.88,0.87,0.88,0.87","Table 4 provides a comparison of the performance of four different classification models represented by their accuracy, precision, recall, and F1-score. These models are Logistic Regression, Decision Tree, K-Nearest Neighbors, and Support Vector Machine (SVM). The table highlights that Logistic Regression has the best accuracy of 0.91, with a corresponding precision, recall, and F1-score of 0.91. The Decision Tree model has the lowest accuracy of 0.76, with the corresponding evaluation metrics for precision, recall, and F1-score of 0.76. Finally, SVM shows relatively good performance, with 0.88 accuracy and 0.87 precision, recall, and F1-score."
2347,"caption: Model performance evaluation on classification of Heart diseasetable: Model,Accuracy,Precision,Recall,F1-score,Support, Random Forest,0.943,0.931,0.937,0.934,520, Decision Tree,0.927,0.952,0.874,0.902,520, SVM,0.938,0.918,0.936,0.925,520, K-NN,0.834,0.820,0.823,0.815,520","The table shows the model performance of Random Forest, Decision Tree, SVM, and K-NN algorithms using various evaluation metrics on the classification of Heart disease. The evaluation metrics include Accuracy, Precision, Recall, F1-score, and support. The Random Forest algorithm obtained the highest accuracy score of 0.943, while the Decision Tree algorithm achieved the highest Precision score of 0.952. Additionally, the SVM algorithm achieved the highest Recall score of 0.936, while the F1-score of all algorithms ranges between 0.925 and 0.934. Notably, all models have the same support of 520. This table shows that different models can perform well on different evaluation metrics, and selecting the appropriate model depends on the evaluation metric required."
2348,"caption: Performance comparison of different models based on accuracy, F1 score, precision, and recall.table: Models,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.87,0.90,0.92,0.88, Random Forest,0.91,0.94,0.94,0.94, Naive Bayes,0.85,0.87,0.90,0.85, Support Vector Machine,0.89,0.91,0.94,0.88, Multi-Layer Perceptron,0.93,0.95,0.95,0.95","Table shows the comparison of various models based on evaluation metrics such as accuracy, F1 score, precision, and recall. The models are Logistic Regression, Random Forest, Naive Bayes, Support Vector Machine, and Multi-Layer Perceptron. The results show that the Multi-Layer Perceptron achieved the highest accuracy (0.93) and F1 score (0.95). Random Forest achieved the highest precision (0.94), while Logistic Regression and Support Vector Machine tied for the highest recall of 0.88. Interestingly, Naive Bayes achieved the lowest accuracy of 0.85. These findings suggest that Multi-Layer Perceptron and Random Forest may be the most suitable models for this dataset based on the evaluation metrics."
2349,"caption: Comparison of model performances using different classification evaluation metrics.table: Model,Accuracy,Recall,F1 score,Precision,AUC, SVM,0.82,0.64,0.67,0.81,0.81, Decision Tree,0.70,0.50,0.53,0.61,0.62, Random Forest,0.85,0.68,0.71,0.84,0.87, Logistic Regression,0.81,0.62,0.64,0.79,0.79, XGBoost,0.88,0.76,0.79,0.84,0.91, LightGBM,0.86,0.72,0.73,0.85,0.89",
2350,"caption: Comparison of different models on evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Decision Tree,0.81,0.79,0.83,0.76, Logistic Regression,0.85,0.84,0.86,0.82, Support Vector Machines (SVM),0.86,0.85,0.87,0.83, Random Forest,0.89,0.88,0.90,0.86, Gradient Boosting,0.91,0.89,0.92,0.87","Table lists the evaluation metrics of five models: Decision Tree, Logistic Regression, Support Vector Machines (SVM), Random Forest, and Gradient Boosting. The models participate in a classification task, and the evaluation metrics are Accuracy, F1 Score, Precision, and Recall. Interestingly, the Gradient Boosting model outperformed the other models, achieving the highest accuracy of 0.91, F1 score, Precision, and Recall values of 0.89, 0.92, and 0.87, respectively. On the other hand, the Decision Tree model scored the lowest values in all evaluation metrics. Overall, the table highlights the strengths and weaknesses of the models and helps in selecting the best model for the classification task based on the evaluation metric requirements."
2351,"caption: Performance of different models on evaluation metrics.table: Model Name,Accuracy,Precision,Recall,F1-Score, Random Forest,0.90,0.91,0.90,0.90, Logistic Regression,0.88,0.87,0.88,0.87, Neural Network,0.91,0.92,0.91,0.91, Support Vector Machine,0.89,0.90,0.89,0.89","The table displays the performance of four different models concerning evaluation metrics, including Accuracy, Precision, Recall, and F1-Score. The Random Forest achieved the highest Accuracy score of 0.90, followed by the Neural Network with a score of 0.91. Additionally, the Neural Network showed the highest scores in all other metrics with Precision of 0.92, Recall of 0.91, and F1-Score of 0.91. On the other hand, the Logistic Regression model showed the lowest score in all evaluation metrics, except for Precision, which was higher than the Support Vector Machine's Precision."
2352,"caption: The performance of different models using multiple evaluation metricstable: Model,Accuracy,F1-score,Precision,Recall,PR-AUC,ROC-AUC, Random Forest,0.89,0.85,0.92,0.80,0.80,0.89, Naïve Bayes,0.77,0.67,0.59,0.79,0.53,0.74, K-NN,0.82,0.79,0.84,0.74,0.69,0.81, SVM,0.79,0.77,0.84,0.71,0.72,0.80, Decision Tree,0.86,0.83,0.81,0.86,0.90,0.84","The table presents the performances of five models, including Random Forest, Naïve Bayes, K-NN, SVM, and Decision Tree, using multiple evaluation metrics. The evaluation metrics include Accuracy, F1-score, Precision, Recall, PR-AUC, and ROC-AUC. Notably, all models were trained and tested using the same dataset. The Decision Tree model showed the best PR-AUC with a score of 0.90, and the Random Forest model recorded the best ROC-AUC with a score of 0.89. Interestingly, the Random Forest model also showed the highest accuracy of 0.89, while the Naïve Bayes model had the lowest performance across all metrics. Overall, the Decision Tree model can be concluded as the best performing model when considering all the evaluation metrics."
2353,"caption: Model performance comparison from different algorithms based on multiple evaluation metricstable: Model,Accuracy,Recall,F1-Score,AUC, SVM,0.87,0.82,0.84,0.91, Random Forest,0.92,0.88,0.89,0.93, Multilayer Perceptron,0.84,0.82,0.83,0.88, Logistic Regression,0.81,0.79,0.80,0.87, Naive Bayes,0.72,0.65,0.68,0.76",
2354,"caption: Comparison of classification models based on accuracy, precision, recall, and F1-score.table: Model,Accuracy,Precision,Recall,F1-Score, Random Forest,0.907,0.874,0.825,0.849, Logistic Regression,0.904,0.857,0.839,0.848, Decision Tree,0.855,0.828,0.741,0.781, Support Vector Machines,0.901,0.826,0.801,0.813, K-Nearest Neighbors,0.877,0.845,0.705,0.759","The table compares five different classification models based on their accuracy, precision, recall, and F1-score performances. The models include Random Forest, Logistic Regression, Decision Tree, Support Vector Machines, and K-Nearest Neighbors. The results show that the Random Forest model performs the best in terms of accuracy with a score of 0.907. The Logistic Regression model shows the highest precision score of 0.857 and the best recall score of 0.839. K-Nearest Neighbors, on the other hand, shows the lowest recall score of 0.705. Finally, the F1-score indicates that the Random Forest performs the best overall with a score of 0.849. Overall, the results suggest that the Random Forest and Logistic Regression models have better performance compared to the other models in the table."
2355,"caption: Performance of different models in classification task based on various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.86,0.88,0.82,0.85, RF,0.89,0.90,0.85,0.87, MLP,0.92,0.93,0.90,0.91, Logreg,0.87,0.87,0.83,0.85","The table above depicts the performance of different models in a classification task based on four different evaluation metrics, namely Accuracy, Precision, Recall, and F1-score. The table consists of four models, SVM, RF, MLP, and Logreg, where each model's performance is measured based on the evaluation metrics. According to the results, MLP outperforms all other models in every evaluation metric, achieving the highest Accuracy score of 0.92, the highest precision score of 0.93, the highest recall score of 0.90, and the highest F1-score 0.91. RF comes in second place in terms of overall performance. The SVM and Logreg models also performed well, but not as good as MLP and RF."
2356,"caption: Performance of different models based on evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Model 1,0.90,0.91,0.88,0.89, Model 2,0.87,0.92,0.83,0.87, Model 3,0.88,0.89,0.91,0.88, Model 4,0.82,0.83,0.81,0.82, Model 5,0.89,0.88,0.87,0.89","The performance of different models was evaluated based on multiple evaluation metrics, namely Accuracy, Precision, Recall, and F1-Score. The table depicts that Model 1 and Model 5 achieved the highest and the closest accuracy, respectively, with scores of 0.90 and 0.89. Similarly, Model 2 revealed the highest Precision score of 0.92, while Model 4 had the lowest Precision score of 0.83. In contrast, Model 3 had the highest Recall score of 0.91, while Model 4 had the lowest Recall score of 0.81. Moreover, Model 1 and Model 5 obtain the highest F1-score, while Model 4 had the lowest F1-Score."
2357,"caption: Table 4: Model performances on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, Model A,0.75,0.80,0.65,0.72, Model B,0.82,0.78,0.90,0.83, Model C,0.68,0.72,0.55,0.62, Model D,0.88,0.85,0.92,0.88, Model E,0.78,0.80,0.70,0.75","Table 4 presents a comparison of different models based on various evaluation metrics. The metrics include Accuracy, Precision, Recall, and F1-score. All five models (Model A to E) were trained and tested using the same dataset. Model D achieved the highest accuracy of 0.88. Model B achieved the highest precision of 0.78 and recall of 0.9. Meanwhile, Model D achieved the highest F1-score of 0.88. Interestingly, Model A and Model E exhibit very similar performance results across all evaluation metrics."
2358,"caption: Model performance comparison based on multiple evaluation metricstable: Model,Accuracy,F1-Score,AUC-ROC, Random Forest (RF),0.85,0.84,0.92, Gradient Boost (GB),0.83,0.80,0.91, K-Nearest Neighbor (KNN),0.73,0.66,0.83, Naive Bayes (NB),0.68,0.62,0.76, Decision Tree (DT),0.72,0.68,0.78","Table 1 summarizes the model performance comparison for five different models based on three commonly used evaluation metrics, including accuracy, F1-score, and AUC-ROC. The Random Forest (RF) and Gradient Boost (GB) models outperform the other models in terms of accuracy, F1-score, and AUC-ROC. Conversely, the K-Nearest Neighbor (KNN) and Naive Bayes (NB) models show relatively lower performance for all three evaluation metrics. Overall, the Random Forest model shows the best performance among all five models, with an accuracy of 0.85, an F1-score of 0.84, and an AUC-ROC of 0.92."
2359,"caption: Table 4: Model performance based on five different evaluation metrics.table: Model,Accuracy,F1 score,Precision,Recall, CART,0.7921,0.7831,0.7771,0.8312, Random Forest,0.8887,0.8857,0.8855,0.8844, SVM,0.8776,0.8731,0.8701,0.8776, AdaBoost,0.8545,0.8479,0.8479,0.8539, Gradient Boosting,0.8814,0.8791,0.8762,0.8800, Neural Net,0.8908,0.8888,0.8846,0.8942","Table 4 compares various machine learning models' performances based on five different evaluation metrics, namely accuracy, F1 score, precision, recall, and area under the receiver operating characteristic curve (AUC-ROC) on a given dataset. The table shows the evaluated metrics' scores for six models, namely CART, Random forest, SVM, AdaBoost, Gradient Boosting, and Neural Net. Based on the scores presented in the table, it is clear that the Neural Net model has the highest scores in all the evaluation metrics. The Random Forest model also shows strong performance in all evaluation metrics, closely followed by the Gradient Boosting model. Overall, the Neural Network model achieved the best performance among all models, making it a suitable candidate for predictive analytics tasks."
2360,"caption: Table 4: Evaluation metrics of five different models based on accuracy, F1 score, and AUC-ROC score.table: Model Name,Accuracy,F1 Score,AUC-ROC Score, Model 1,0.80,0.76,0.82, Model 2,0.78,0.73,0.79, Model 3,0.82,0.79,0.81, Model 4,0.85,0.82,0.87, Model 5,0.83,0.81,0.85","Table 4 shows the evaluation metrics of five different models based on accuracy, F1 score, and AUC-ROC score. The table reveals Model 4 acquires the highest accuracy of 0.85. Model 4 also has the highest F1 score of 0.82, implying a better balance between precision and recall. Furthermore, it is observed that Model 4 has the highest AUC-ROC score of 0.87, indicating a better model's strength to differentiate between positive and negative samples. Consequently, Model 4 outperforms all the other models based on all the evaluation metrics presented in the table."
2361,"caption: A comparison of multiple models based on various evaluation metrics.table: Model 1,Model 2,Model 3,Model 4,Model 5, Metric 1,0.83,0.88,0.92,0.75,0.82, Metric 2,0.68,0.72,0.91,0.60,0.64, Metric 3,0.71,0.55,0.81,0.62,0.74, Metric 4,0.77,0.84,0.94,0.78,0.80, Metric 5,0.90,0.82,0.77,0.75,0.89","The table above presents a comparison of Model 1, Model 2, Model 3, Model 4, and Model 5 based on five different evaluation metrics. These metrics encompass different aspects of model performance and evaluate their efficacy in different ways. Notably, Model 3 was observed to perform particularly well across all metrics. It shows the highest Metric 2 score of 0.91, highest Metric 4 score of 0.94, as well as a notably high Metric 1 score of 0.92. However, Metric 5 shows that Model 1 and Model 5 perform better but does not mean that Model 3 is not worth considering as it still performed comparably well. Therefore, the table showcases the importance of considering multiple evaluation metrics when comparing the performance of different models."
2362,"caption: Table 4: Model performance on the evaluation metrics of Accuracy, Precision, Recall, and F1-Score.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.78,0.80,0.68,0.74, Random Forest,0.83,0.83,0.78,0.80, Decision Tree,0.72,0.69,0.71,0.70, Support Vector Machine,0.79,0.81,0.73,0.76, XGBoost,0.84,0.81,0.81,0.81","The presented table shows the performance of five different models on the evaluation metrics of Accuracy, Precision, Recall, and F1-Score. The models compared are Logistic Regression, Random Forest, Decision Tree, Support Vector Machine, and XGBoost. Observe that Random Forest and XGBoost performed relatively well, with an accuracy of 0.83 and 0.84, respectively compared to Decision Tree's accuracy of only 0.72. In terms of Precision, XGBoost and Logistic Regression models achieved the highest score of 0.81, followed by Random Forest's score of 0.83. The Recall metric analyses the correctly identified positive cases from actual positive cases, and XGBoost obtained the highest Recall score of 0.81. Similarly, the F1-score metric of XGBoost outperforms the other models with the highest score of 0.81."
2363,"caption: Model performance on different evaluation metricstable: Model,Accuracy,F1-Score,Precision,Recall, Model 1,0.75,0.71,0.68,0.75, Model 2,0.83,0.81,0.78,0.84, Model 3,0.77,0.75,0.76,0.77, Model 4,0.89,0.88,0.87,0.89, Model 5,0.81,0.79,0.74,0.85","Table 2 presents the performance of five different models based on multiple evaluation metrics, including Accuracy, F1-Score, Precision, and Recall. The table shows that Model 4 performed the best among all models, with the highest score in all evaluation metrics, including Accuracy, F1-Score, Precision, and Recall. Model 4 outperformed the other models by a considerable margin, with an Accuracy score of 0.89, F1-Score of 0.88, Precision of 0.87, and Recall of 0.89. Model 2 achieved the second-best performance, with a score of 0.83 in Accuracy, 0.81 in F1-Score, 0.78 in Precision, and 0.84 in Recall. Model 1, Model 3, and Model 5 have the lowest accuracy, F1-score, precision, and Recall scores, respectively."
2364,"caption: Model Performance Comparison using Various Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1-score,ROC-AUC, Logistic Regression,0.85,0.88,0.82,0.84,0.91, Random Forest,0.86,0.91,0.83,0.85,0.95, Support Vector Machines,0.81,0.81,0.81,0.79,0.88, Neural Network,0.89,0.92,0.87,0.89,0.95","The table above illustrates the performance comparison of four different models, namely, Logistic Regression, Random Forest, Support Vector Machines, and Neural Networks. The models' evaluation is done using multiple metrics, including Accuracy, Precision, Recall, F1-score, and ROC-AUC. The Random Forest model shows the best performance in most evaluation metrics, with an Accuracy score of 0.86, the highest Precision of 0.91 and the highest F1-score of 0.85. In terms of ROC-AUC, the Neural Network model outperforms the others, exhibiting a score of 0.95. Despite Logistic Regression achieving the lowest Precision, it provides good performance in other evaluation metrics, including an Accuracy score of 0.85 and a high ROC-AUC score of 0.91."
2365,"caption: Performance Comparison of Machine Learning Modelstable: Model,Accuracy (±std dev),Precision (±std dev),Recall (±std dev), SVM,0.853±0.002,0.796±0.008,0.684±0.011, Decision tree,0.789±0.003,0.654±0.008,0.663±0.011, Random forest,0.912±0.002,0.834±0.007,0.832±0.009, KNN,0.827±0.002,0.724±0.007,0.721±0.012, Naïve Bayes,0.784±0.003,0.607±0.010,0.646±0.011","The table compares the performance of five different machine learning models on the given dataset in terms of Accuracy, Precision, and Recall, along with their standard deviation. The models include SVM, Decision Tree, Random Forest, KNN, and Naïve Bayes. The Random Forest model outperformed all other models with the highest accuracy score of 0.912±0.002 and precision and recall scores of 0.834±0.007 and 0.832±0.009, respectively. Interestingly, SVM showed the second-best performance with an accuracy score of 0.853±0.002 and precision and recall scores of 0.796±0.008 and 0.684±0.011, respectively. In contrast, Naïve Bayes exhibited the lowest accuracy score of 0.784±0.003 and precision and recall scores of 0.607±0.010 and 0.646±0.011, respectively."
2366,"caption: Performance comparison of different classification algorithms.table: Model,Accuracy,Precision,Recall,F1-Score,ROC-AUC, SVM,0.84,0.88,0.81,0.84,0.80, KNN,0.79,0.85,0.67,0.75,0.73, NB,0.82,0.92,0.70,0.79,0.82, RF,0.87,0.91,0.81,0.85,0.87, MLP,0.88,0.90,0.83,0.86,0.89","The table highlights the evaluation metrics of five different classification algorithms, including SVM, KNN, NB, RF, and MLP. The models' accuracy, precision, recall, F1-score, and ROC-AUC were computed using the same dataset. RF model exhibits the highest accuracy of 0.87 followed by MLP with 0.88. The lowest accuracy is found in KNN model at 0.79. In terms of precision, MLP has the highest score at 0.9 while SVM performs the best on recall metric with the score of 0.81. F1-Score metric is also showing that MLP has the highest score, while the ROC-AUC result indicating that RF has the highest score of 0.87."
2367,"caption: A comparison of models' performance with multiple evaluation metricstable: Model,Precision,Recall,F1-score,Accuracy, Logistic Regression,0.85,0.80,0.82,0.89, Random Forest,0.86,0.83,0.83,0.88, K-NN,0.81,0.79,0.79,0.86, SVM,0.84,0.81,0.82,0.89, MLP,0.87,0.86,0.86,0.90",
2368,"caption: Model performance metrics of different models.table: Model,Accuracy,F1 Score,Recall,Precision, LR,0.918,0.919,0.920,0.918, SVM,0.921,0.919,0.917,0.924, RF,0.916,0.916,0.914,0.918, GB,0.922,0.921,0.919,0.922, NN,0.918,0.919,0.914,0.925","Table presents model performances of different machine learning algorithms, including Logistic Regression (LR), Support Vector Machines (SVM), Random Forests (RF), Gradient Boosting (GB), and Neural Network (NN). Evaluation metrics such as Accuracy, F1 Score, Recall, and Precision for the models are presented. The Gradient Boosting model exhibits the highest Accuracy and F1 Score of 0.922 and 0.921, respectively. The SVM model has the best recall rate (0.917), while the Neural Network model has the highest precision score of 0.925. It is important to consider multiple model performances and evaluation metrics while selecting a model for any machine learning task."
2369,"caption: Table 4: Evaluation Metrics of Different Modelstable: Model,Accuracy,Precision,Recall,F1-Score, Random Forest,0.92,0.91,0.89,0.90, Support Vector,0.93,0.91,0.90,0.91, Gradient Boosting,0.89,0.87,0.86,0.86, Naive Bayes,0.83,0.82,0.81,0.80, Decision Tree,0.81,0.83,0.79,0.81","Table 4 presents the evaluation metrics of five different models used for classification tasks. The table shows Accuracy, Precision, Recall, and F1-Score for each of the models: Random Forest, Support Vector, Gradient Boosting, Naive Bayes, and Decision Tree. Based on the results, the Support Vector model achieved the highest accuracy of 0.93, which is followed by Random Forest with an accuracy of 0.92. However, the Random Forest model performed the best with a Precision score of 0.91, and a Recall score of 0.89, which makes it a well-rounded model based on all the evaluation metrics. The Naive Bayes and Decision Tree models showed relatively lower accuracy scores, but Decision Tree had the highest Precision score of 0.83."
2370,"caption: Table 4. Model Performance Comparison of Different Evaluation Metrics.table: Model,F1-score,Precision,Recall, SVM,0.82,0.85,0.79, Naive Bayes,0.70,0.67,0.73, Decision Tree,0.76,0.72,0.80, Random Forest,0.86,0.88,0.84, XGBoost,0.88,0.88,0.88","Table 4 presents the F1-score, Precision, and Recall of five different models: SVM, Naive Bayes, Decision Tree, Random Forest, and XGBoost, on a classification task. The models' performances were evaluated based on three metrics, and the results were reported in the table. Interestingly, the Random Forest and XGBoost models show the best performances with an F1-score of 0.86 and 0.88, respectively. They also exhibit high precision and recall scores of around 0.88. SVM and Decision Tree show moderate performance with an F1-score of 0.82 and 0.76, respectively. Naive Bayes show the lowest performance with an F1-score of 0.70. Overall, the comparison of different models based on multiple metrics provides essential insights into the algorithms' strengths and weaknesses."
2371,"caption: Comparison of different machine learning models using multiple evaluation metricstable: Model,Metric,Result, Logistic Reg.,Accuracy,0.91, Precision,0.87, Recall,0.81, F1 Score,0.84, Random Forest,Accuracy,0.93, Precision,0.90, Recall,0.86, F1 Score,0.88, SVM,Accuracy,0.90, Precision,0.84, Recall,0.80, F1 Score,0.82, XGBoost,Accuracy,0.95, Precision,0.93, Recall,0.90, F1 Score,0.91","Table presents the comparison of several machine learning models using various evaluation metrics such as Accuracy, Precision, Recall and F1 Score. The models are Logistic Regression, Random Forest, SVM, and XGBoost. The table highlights the differences in performance among the models. The best performing model based on these evaluation metrics is XGBoost, which achieved an accuracy of 0.95, and a high precision of 0.93, demonstrating the model's ability to make fewer false positive predictions. In contrast, Logistic regression had the lowest accuracy score among all models with 0.91 but had the highest recall of 0.81."
2372,"caption: Model performance comparison based on accuracy, F1 score, precision, and recall.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.80,0.78,0.79,0.81, Decision Tree,0.75,0.70,0.68,0.75, Random Forest,0.87,0.85,0.83,0.88, XGBoost,0.88,0.86,0.87,0.85, KNN,0.72,0.68,0.71,0.69","Table 4 exhibits a comparison of model performance based on four different evaluation metrics, namely Accuracy, F1 Score, Precision, and Recall. The table presents the results of SVM, Decision Tree, Random Forest, XGBoost, and KNN models' performance. Notably, all models were trained and tested using the same dataset. The highest Accuracy was achieved by XGBoost with a score of 0.88, followed by Random Forest with 0.87. The same trend was observed for F1 Score, where XGBoost and Random Forest outperformed the other three models. Interestingly, KNN had the worst performance compared to the other models, being outperformed in all evaluation metrics."
2373,"caption: Comparison of Machine Learning Models based on Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1-Score,AUC, SVM,0.87,0.89,0.81,0.85,0.92, Random Forest,0.84,0.90,0.76,0.81,0.89, Logistic Regression,0.80,0.86,0.75,0.80,0.88, XGBoost,0.88,0.90,0.85,0.87,0.93, ANN,0.82,0.84,0.82,0.83,0.90","The table above presents a comparison of five Machine Learning models' (SVM, Random Forest, Logistic Regression, XGBoost, and ANN) performance based on evaluation metrics such as Accuracy, Precision, Recall, F1-Score, and AUC. The highest Accuracy score of 0.88 was achieved by the XGBoost model, while SVM and Random Forest models had the highest Precision score of 0.90. Interestingly, the SVM model had the highest Recall score of 0.81, while XGBoost had the highest F1-Score of 0.87. Moreover, XGBoost model performed best with highest AUC score of 0.93 among all models."
2374,"caption: Table 4: Model evaluation results using different metricstable: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.82,0.84,0.78,0.81, Decision Tree,0.81,0.82,0.77,0.79, Random Forest,0.87,0.88,0.85,0.87, Support Vector Machine,0.79,0.80,0.76,0.78","Table 4 depicts the evaluation results of four different models using multiple metrics. The models include Logistic Regression, Decision Tree, Random Forest, and Support Vector Machine. The metrics used are Accuracy, Precision, Recall, and F1 Score. Interestingly, the Random Forest model shows the highest accuracy and F1 Score with scores of 0.87 and 0.87, respectively. On the other hand, the Logistic Regression model shows the highest precision and recall with scores of 0.84 and 0.78, respectively. The Support Vector Machine model turned out to have the lowest accuracy, precision, recall, and F1 Score."
2375,"caption: Table 4: Model performances based on different evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.84,0.86,0.81,0.83, Random Forest,0.91,0.92,0.89,0.90, SVM,0.82,0.84,0.80,0.82, KNN,0.79,0.77,0.81,0.79","Table 4 presents the evaluation metrics for four different models: Logistic Regression, Random Forest, SVM, and KNN. The table reports the accuracy, precision, recall, and F1-score. The Random Forest model achieved the best performance across all four metrics: accuracy (0.91), precision (0.92), recall (0.89), and F1-score (0.90). The Logistic Regression model performed the second-best, with an accuracy of 0.84 and precision, recall, and F1-score all around 0.83. The SVM model had the lowest accuracy of 0.82 but still achieved precision, recall, and F1-score above 0.80. The KNN model had the lowest performance with an accuracy of 0.79 and precision, recall, and F1-score around 0.79."
2376,"caption: Performance metrics of different models.table: Model,Accuracy,Recall,Precision,F1-Score, Model A,0.86,0.83,0.78,0.80, Model B,0.92,0.94,0.87,0.91, Model C,0.77,0.69,0.82,0.71, Model D,0.89,0.91,0.85,0.88, Model E,0.94,0.95,0.92,0.94","The table summarizes the performance evaluation of multiple models using different evaluation metrics. The evaluation metrics include accuracy, recall, precision, and F1-score. The table presents the performance results of Model A, Model B, Model C, Model D, and Model E. Interestingly, Model E shows the highest performance results across all evaluation metrics with an accuracy score of 0.94, recall of 0.95, precision of 0.92, and F1-score of 0.94. On the other hand, Model C had the lowest performance results. This table's findings suggest Model E as the best model for performing the task evaluated with the metrics considered."
2377,"caption: Comparison of model performance on evaluation metricstable: Model,F1-score,Precision,Recall,Accuracy, Model A,0.890,0.900,0.880,0.922, Model B,0.879,0.880,0.878,0.919, Model C,0.900,0.895,0.905,0.926, Model D,0.875,0.870,0.878,0.917","The table presents the performance evaluation of four different models, Model A, B, C, and D on multiple evaluation metrics- F1-score, Precision, Recall, and Accuracy. Model C achieved the highest F1-score of 0.900, attesting to its ability to balance precision and recall, while Model D had the lowest F1-score of 0.875. However, Model A recorded the highest Precision of 0.900, indicating its ability to make fewer false positives, and Model C recorded the highest Recall of 0.905, indicating its ability to detect more positive instances. Finally, Model C also achieved the highest accuracy score of 0.926, indicating its overall goodness of classification performance."
2378,"caption: Model performance table for different classification algorithmstable: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.874,0.862,0.850,0.855, KNN,0.909,0.898,0.892,0.893, Naive Bayes,0.688,0.727,0.651,0.624, Random Forest,0.948,0.945,0.942,0.942","The table summarizes the performance of four different classification algorithms, namely SVM, KNN, Naive Bayes, and Random Forest. The evaluation metrics include Accuracy, Precision, Recall, and F1-Score. The Random Forest model outperforms all the other models, achieving the highest accuracy of 0.948. The KNN model achieved the highest scores in Precision, Recall, and F1-Score with scores of 0.898, 0.892, and 0.893, respectively. Naive Bayes, on the other hand, has the lowest accuracy of 0.688. This table provides insight into the classification algorithms' ability to classify the data accurately, enabling an informed decision on which algorithm to use."
2379,"caption: Table 4: Model performance measured by different metricstable: Model,Precision,Recall,F1-Score,Accuracy, Support-Vector Machine,0.82,0.8,0.81,0.853, Random Forest Classifier,0.88,0.89,0.88,0.901, Naive Bayes Classifier,0.79,0.6,0.68,0.812","Table 4 shows the performance of different models using different evaluation metrics. The table compares the Precision, Recall, F1-Score, and Accuracy of models, including Support-Vector Machine, Random Forest Classifier, and Naive Bayes Classifier. The Random Forest Classifier obtained the best Precision, Recall, F1-Score, and Accuracy with 0.88, 0.89, 0.88, and 0.901, respectively. The Support-Vector Machine came second with the second-best Precision and Recall of 0.82 and 0.8, respectively. The Naive Bayes Classifier exhibited the lowest values of Precision, Recall, and F1-Score."
2380,"caption: Summary of the performance of five different Machine Learning models on a binary classification task.table: Model name,Accuracy,F1-score,PR-AUC,ROC-AUC, Model 1,0.76,0.73,0.83,0.87, Model 2,0.84,0.82,0.88,0.91, Model 3,0.68,0.65,0.75,0.82, Model 4,0.89,0.88,0.91,0.94, Model 5,0.82,0.80,0.87,0.90","The table provides a summary of the performance of five different Machine Learning models on a binary classification task, in terms of accuracy, F1-score, PR-AUC, and ROC-AUC. Model 4 has the highest scores across all evaluation metrics, with Accuracy of 0.89, F1-score of 0.88, PR-AUC of 0.91, and ROC-AUC of 0.94. Model 1 has the lowest scores in all evaluation metrics except for PR-AUC, where it has a score of 0.83, which is higher than Model 5. Model 5 also has a good performance, similar to Model 2, with an Accuracy of 0.82, F1-score of 0.80, PR-AUC of 0.87, and ROC-AUC of 0.90. Overall, Model 4 is the best performing model, followed by Model 2 and Model 5."
2381,"caption: Comparison of Different Models' Performance using Multiple Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1-Score, Model 1,0.89,0.94,0.87,0.90, Model 2,0.91,0.92,0.90,0.91, Model 3,0.88,0.87,0.89,0.88, Model 4,0.90,0.91,0.88,0.89, Model 5,0.93,0.95,0.92,0.93","Table presents the performance of five different models based on accuracy, precision, recall, and F1-score. Model 2 shows the best accuracy score of 0.91, while Model 5 illustrates the highest precision score of 0.95, and Model 4 displays the best recall score of 0.88. Interestingly, Model 1 achieved the highest F1-score of 0.90. The results indicate that each model performed differently based on the evaluation metric used. Therefore, it is crucial to select the most appropriate evaluation metric that aligns with the research goals."
2382,"caption: Table 4: Classification models' performances based on accuracy, F1-score, precision, and recall metricstable: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.904,0.898,0.893,0.903, Naive Bayes,0.827,0.762,0.784,0.741, Random Forest,0.951,0.947,0.940,0.955, XGBoost,0.956,0.951,0.946,0.957, Support Vector Machine,0.899,0.893,0.889,0.896","Table 4 showcases the performances of different classification models using several evaluation metrics: accuracy, F1-score, precision, and recall. The models evaluated include Logistic Regression, Naive Bayes, Random Forest, XGBoost, and Support Vector Machine. The table demonstrates that the XGBoost model exhibits the highest accuracy of 0.956 and F1-score of 0.951. Additionally, the Random Forest model demonstrates the highest precision result of 0.940. Notably, Naive Bayes displays the lowest accuracy score of 0.827 and recall result of 0.741, highlighting inferior performance compared to the other models."
2383,"caption: Comparison of different models based on Accuracy, F1 Score, Precision, Recall.table: Model Name,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.85,0.83,0.87,0.79, Decision Tree,0.80,0.77,0.81,0.74, Random Forest,0.90,0.89,0.91,0.88, Gradient Boosting,0.89,0.87,0.90,0.84, Support Vector Machine,0.87,0.85,0.87,0.83","This table summarizes the performance of five different models - Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Support Vector Machine - based on multiple evaluation metrics. The models were evaluated based on Accuracy, F1 Score, Precision, and Recall using a given dataset. Notably, the Random Forest model achieved the best overall performance, with an accuracy score of 0.90, F1 Score of 0.89, precision of 0.91, and recall of 0.88. The Decision Tree model recorded the lowest accuracy score while the Logistic regression model has the lowest recall score. Overall, the Random Forest model performed the best, followed by Gradient Boosting and Support Vector Machine in terms of accuracy, while Logistic regression and Decision Tree were at the bottom of the table."
2384,"caption: Table 4: Model Performance based on Multiple Evaluation Metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.832,0.818,0.823,0.819, Random Forest,0.847,0.833,0.838,0.836, XGBoost,0.849,0.836,0.840,0.845, Decision Tree,0.771,0.734,0.740,0.733, Naïve Bayes,0.780,0.709,0.732,0.686","Table 4 demonstrates a comparison of multiple models' performances based on several evaluation metric scores. The table displays five benchmark models, including Logistic Regression, Random Forest, XGBoost, Decision Tree, and Naive Bayes. The metrics recorded are Accuracy, F1 Score, Precision, and Recall. The highest accuracy score is achieved by XGBoost with a score of 0.849, while Naive Bayes has the least accuracy score of 0.780. However, the Random Forest model outperformed the other models with the highest F1 Score of 0.833 and Precision of 0.838, in addition to being a close second in accuracy. Nevertheless, other interesting findings, such as the Decision Tree's low scores across all the metrics, can be inferred from the table."
2385,"caption: Model performance of different machine learning algorithms based on four evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.95,0.96,0.93,0.95, Naive Bayes,0.94,0.95,0.91,0.93, Logistic Regression,0.96,0.97,0.93,0.95, Decision Tree,0.92,0.94,0.87,0.90, Random Forest,0.94,0.95,0.91,0.93","The table displays multiple different machine learning algorithms' performances based on four evaluation metrics: Accuracy, Precision, Recall, and F1-score. The models included in the comparison are SVM, Naive Bayes, Logistic Regression, Decision Tree, and Random Forest. The results show that Logistic Regression achieved the highest accuracy score of 0.96, while SVM had the highest precision score of 0.96. On the other hand, Decision Tree recorded the lowest accuracy and F1-score of 0.92 and 0.90, respectively. Overall, the table provides insights into the strengths and weaknesses of each model and can be useful in selecting the appropriate algorithm for classification tasks."
2386,"caption: Table 4: Performance of different models based on different evaluation metricstable: Model,Accuracy,Precision,Recall,F1-score, Model A,0.85,0.87,0.82,0.84, Model B,0.92,0.91,0.89,0.90, Model C,0.78,0.80,0.76,0.78, Model D,0.89,0.91,0.87,0.89, Model E,0.93,0.94,0.92,0.93","Table 4 presents the performance of five different models based on four different evaluation metrics: Accuracy, precision, recall, and F1-Score. Model A, Model B, Model C, Model D, and Model E obtained accuracy scores of 0.85, 0.92, 0.78, 0.89, and 0.93, respectively. Model E shows the best accuracy score. For precision, the scores ranged from 0.80 (Model C) to 0.94 (Model E), with Model E achieving the highest score. The recall scores range from 0.76 (Model C) to 0.92 (Model E), while the F1-Scores ranged from 0.78 (Model C) to 0.93 (Model E). Model E obtained the highest score for all the evaluation metrics, indicating its superior performance compared to the other models."
2387,"caption: Model performance based on different evaluation metricstable: Model,Accuracy,F1 Score,Precision,Recall, Random Forest,0.91,0.89,0.91,0.88, SVM,0.87,0.86,0.88,0.84, KNN,0.86,0.83,0.87,0.80, Naive Bayes,0.82,0.77,0.85,0.70, Decision Tree,0.81,0.73,0.78,0.74","The table provides model performance results using different evaluation metrics. The Random Forest model demonstrates the highest Accuracy (0.91) and F1 Score (0.89) while SVM scored the highest Precision of 0.88. The Naive Bayes model had the lowest accuracy score (0.82) and F1 score (0.77), indicating its low performance. The Decision Tree model scored an accuracy of 0.81, performing poorly in comparison to other models. These results shed light on different models' performance that could be useful in choosing the right model for classification tasks."
2388,"caption: Model evaluation resultstable: Model,Accuracy,Precision,Recall,F1-score, SVM,0.87,0.89,0.85,0.87, KNN,0.82,0.84,0.78,0.81, Naive Bayes,0.79,0.81,0.77,0.79, Decision Tree,0.89,0.90,0.88,0.89, Random Forest,0.91,0.93,0.90,0.91","This table reports the performance results of different machine learning models based on multiple evaluation metrics. The models presented in this table are SVM, K-Nearest Neighbor (KNN), Naive Bayes, Decision Tree, and Random Forest. The evaluation metrics included in the table are accuracy, precision, recall, and F1-score. Random Forest achieved the highest accuracy with a score of 0.91, followed by decision trees with 0.89. The best-performing model for precision is Random Forest with a score of 0.93 while the Naive Bayes model obtained the lowest score with 0.81. SVM and Decision Tree models display almost identical recall scores, with both models achieving >0.88. F-1 score findings mimic accuracy results, with the Random Forest and Decision Tree models being the best performers with scores of 0.91 and 0.89, respectively."
2389,"caption: Table 4: Model performance from various classification models.table: Model,f1-score,precision,recall,accuracy, SVM,0.89,0.92,0.86,0.87, KNN,0.73,0.80,0.68,0.76, DT,0.78,0.81,0.76,0.79, RF,0.87,0.89,0.85,0.86, MLP,0.91,0.93,0.89,0.90","Table 4 compares the performance of different classifiers, including Support Vector Machine (SVM), K-Nearest Neighbor (KNN), Decision Tree (DT), Random Forest (RF), and Multilayer Perceptron (MLP), using various metrics. The evaluation metrics include f1-score, precision, recall, and accuracy. Interestingly, MLP has the highest values for all metrics, scoring an overall f1-score of 0.91, precision of 0.93, recall of 0.89, and accuracy of 0.90. RF also performs competitively with an overall f1-score of 0.87, precision of 0.89, recall of 0.85, and accuracy of 0.86. SVM performs the best in recall score, while KNN has the weakest performance across all metrics."
2390,"caption: Model performance for binary classification problem using different models and evaluation metrics.table: Model Name,F1 Score,Precision,Recall,Accuracy, Logistic Regression,0.81,0.72,0.93,0.85, Decision Tree,0.71,0.68,0.74,0.68, Random Forest,0.83,0.79,0.87,0.77, Gradient Boosting,0.85,0.82,0.88,0.83","The above table presents several binary classification models' performance results with multiple evaluation metrics such as F1 Score, Precision, Recall, and Accuracy. The Logistic Regression model shows good precision but compromised on recall performance. In contrast, the Decision Tree model shows a lower f1 score, precision, and recall. The Random Forest model outperforming other models in F1 Score, recall, and precision. Interestingly, the Gradient Boosting model performs better in all of the evaluation metrics except accuracy compared to other models in the table. Overall, the table demonstrates different models have varied performance based on evaluation metrics."
2391,"caption: Model performances based on various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.80,0.83,0.78,0.80, Naive Bayes,0.72,0.72,0.68,0.70, K-Nearest,0.78,0.79,0.75,0.77, Random FC,0.82,0.82,0.80,0.81, CNN,0.88,0.89,0.87,0.88","Table 4 presents the model performances based on different evaluation metrics, such as accuracy, precision, recall, and F1-Score. The table includes SVM, Naive Bayes, K-Nearest, Random FC, and CNN models' performance. The CNN model demonstrates the best overall performance with an accuracy of 0.88, precision of 0.89, recall of 0.87, and F1-Score of 0.88. In contrast, the Naive Bayes model has the worst performance with an accuracy of 0.72, precision of 0.72, recall of 0.68, and F1-Score of 0.70. Interestingly, the Random FC model shows the second-best performance, with an accuracy of 0.82 and with an F1-Score and precision scores of 0.81 and 0.82, respectively."
2392,"caption: Table 4: Comparison of different models' performance using various evaluation metrics.table: Models,Accuracy,F1-score,Precision,Recall, Log. Reg.,0.84,0.74,0.76,0.72, Random Forest,0.86,0.78,0.81,0.75, AdaBoost,0.85,0.76,0.77,0.75, XGBoost,0.87,0.80,0.82,0.78, SVM,0.82,0.73,0.74,0.72","Table 4 presents a comparison of five models, namely Logistic Regression, Random Forest, AdaBoost, XGBoost, and Support Vector Machine (SVM), on their performance using four evaluation metrics - accuracy, F1-score, precision, and recall. The table indicates that the XGBoost model had the highest accuracy with a score of 0.87, followed by Random Forest with 0.86, while the SVM model had the lowest accuracy with a score of 0.82. XGBoost also reported the highest F1-score, precision, and recall scores of 0.80, 0.82, and 0.78, respectively, making it the best performer overall."
2393,"caption: Table 4: Model performance comparison based on different evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Model A,0.92,0.91,0.93,0.89, Model B,0.86,0.85,0.90,0.80, Model C,0.95,0.94,0.96,0.92, Model D,0.88,0.87,0.91,0.84, Model E,0.90,0.89,0.93,0.85","Table 4 presents a comparison of different models' performances based on various evaluation metrics. The table exhibits five models (Model A - Model E) and their performances based on accuracy, F1 score, precision, and recall. Model C shows the best performance in all metrics, with an accuracy score of 0.95 and F1 score of 0.94. Model E has the second-best performance with an accuracy score of 0.90. However, Model A has the highest precision score of 0.93, whereas Model B has the lowest performance in all metrics. The table provides a comprehensive overview of each model's strengths and weaknesses in different evaluation metrics, allowing researchers to choose the most appropriate model for their specific needs."
2394,"caption: Comparison of Model Performance Using Different Metricstable: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.78,0.74,0.80,0.76, Support Vector Machine,0.82,0.85,0.77,0.81, Random Forest,0.87,0.89,0.84,0.86, Multilayer Perceptron,0.81,0.80,0.83,0.81, Gradient Boosting,0.86,0.87,0.84,0.85","The table presents a comparison of the performance of different models based on multiple evaluation metrics, including Accuracy, Precision, Recall, and F1 Score. The models that were evaluated are Logistic Regression, Support Vector Machine, Random Forest, Multilayer Perceptron, and Gradient Boosting. Notably, the Random Forest model shows the highest accuracy score of 0.87, while the Support Vector Machine had the highest precision score of 0.85. The highest recall score was 0.83, achieved by the Multilayer Perceptron model. Additionally, the Random Forest and Gradient Boosting models show equally high F1 score of 0.86 and 0.85, respectively."
2395,"caption: Model performance comparison using different classifiers and evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.85,0.84,0.87,0.81, Naive Bayes,0.72,0.78,0.63,0.98, Random Forest,0.92,0.93,0.91,0.95, XGBoost,0.94,0.95,0.94,0.96","The table presents the accuracy, F1-score, precision, and recall of four models (SVM, Naive Bayes, Random Forest, and XGBoost) evaluated with different metrics. The Random Forest and XGBoost models demonstrate superior performance, obtaining the highest accuracy of 0.92 and 0.94, respectively. The Random Forest model achieved an F1-Score of 0.93, while the XGBoost model had an F1-Score of 0.95. Interestingly, the Naive Bayes model displayed the highest recall among the four models at 0.98. Finally, the SVM algorithm demonstrated excellent precision with a score of 0.87. Overall, the table suggests that both Random Forest and XGBoost models show the best performance among the four models in all evaluated metrics."
2396,"caption: Table 4: Performance comparison of different classification models based on various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, LogReg,0.85,0.83,0.82,0.83, SVM,0.89,0.88,0.89,0.88, RandomForest,0.91,0.92,0.90,0.91, KNN,0.83,0.81,0.83,0.82, Decision Tree,0.88,0.86,0.88,0.87","Table 4 highlights the performance comparison of various classification models based on four evaluation metrics, namely Accuracy, Precision, Recall and F1-score. The table presents the results of Logistic Regression (LogReg), Support Vector Machine (SVM), Random Forest, K-Nearest Neighbor (KNN), and Decision Tree models. The performance measurements were based on all instances of the data, and the highest score for each metric has been emphasized. Accordingly, the Random Forest model showed the highest accuracy, scoring 0.91, followed by the SVM model, which scored 0.89. Also, the Random Forest model modified best both the precision and F1-score with results of 0.92 and 0.91, respectively. Lastly, the SVM model ranked the highest in terms of recall, scoring 0.89."
2397,"caption: Table 4: Performance evaluation of different models based on different evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.85,0.85,0.84,0.87, Random Forest,0.80,0.81,0.79,0.84, Naive Bayes,0.78,0.80,0.77,0.82, Decision Tree,0.72,0.70,0.71,0.70, Support Vector Machine,0.83,0.83,0.83,0.83","Table 4 shows the performance evaluation of different models based on different evaluation metrics. The table lists the accuracy, F1 Score, Precision, and Recall results for five different models, namely Logistic Regression, Random Forest, Naive Bayes, Decision Tree, and Support Vector Machine. The best-performing model varies based on the evaluation metric considered. For example, Logistic Regression and Support Vector Machine models show the highest accuracy with 0.85 and 0.83, respectively, while the Random Forest model performs the best in terms of F1 Score with a score of 0.81. Additionally, Naive Bayes indicates the highest Recall value of 0.82, and Precision with 0.77. Overall, the table highlights the varying model performances based on the evaluation metrics considered."
2398,"caption: Model performance based on multiple evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score,AUC, Model A,0.92,0.91,0.94,0.92,0.96, Model B,0.86,0.87,0.84,0.84,0.92, Model C,0.95,0.96,0.93,0.95,0.98, Model D,0.89,0.88,0.89,0.89,0.93, Model E,0.91,0.93,0.9,0.91,0.95","Table displays the evaluation metrics' performance results, including Accuracy, Precision, Recall, F1-Score, and Area Under the Curve (AUC), for five different machine learning models: Model A, Model B, Model C, Model D, and Model E. Model C exhibits the highest performance among all models with an Accuracy score of 0.95 and an AUC score of 0.98. Similarly, this model achieved the highest precision with a score of 0.96, while Model E has the highest precision score among models with 0.93. Model A shows the highest recall score with 0.94."
2399,"caption: Table 4: Comparison of different regression models based on multiple evaluation metrics.table: Model,MAE,RMSE,R2, Linear Regression,3.20,4.70,0.60, KNN Regression,3.50,4.90,0.50, Decision Tree Regression,2.80,4.30,0.70, Random Forest Regression,2.70,4.10,0.75, XGBoost Regression,2.60,3.80,0.80","Table 4 presents a comparison of different regression models' performance based on multiple evaluation metrics, including MAE, RMSE, and R2. The table includes Linear Regression, KNN Regression, Decision Tree Regression, Random Forest Regression, and XGBoost Regression models' evaluation scores. The Random Forest Regression model outperformed all other models, achieving the lowest MAE of 2.70, RMSE of 4.10, and the highest R2 of 0.75. Interestingly, the XGBoost Regression model achieved the highest R2 with an accuracy of 0.80. Overall, the table shows that the Random Forest and XGBoost Regression models are the best-performing models for this dataset, producing the most accurate predictions of the response variable."
2400,"caption: Table 4: Classification performance of five different models using multiple evaluation metrics on the same dataset.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.82,0.87,0.74,0.80, KNN,0.71,0.65,0.67,0.66, RF,0.85,0.90,0.79,0.84, XGB,0.87,0.92,0.84,0.87, MLP,0.86,0.89,0.83,0.86","In Table 4, the classification performance of five different models - SVM, KNN, RF, XGB, and MLP - are compared using multiple evaluation metrics, which include Accuracy, Precision, Recall, and F1-Score. The table presents the models' performance scores across all metrics. The RF and XGB models produced the highest scores for all four evaluation metrics, with the XGB model outperforming others with an accuracy of 0.87 and a precision of 0.92. Notably, SVM and KNN models have lower performance scores compared to the rest of the models. However, all models performed comparably well in terms of accuracy, with their scores remaining close to each other."
2401,"caption: Model performance from different approaches based on multiple evaluation metrics.table: Model,Precision,Recall,F1-Score,Accuracy,AUC, Random Forest,0.85,0.72,0.78,0.82,0.88, Neural Network,0.82,0.84,0.83,0.79,0.90, Logistic Regression,0.70,0.93,0.80,0.72,0.77, Decision Tree,0.65,0.74,0.69,0.65,0.71","The table above shows the performance of four different models - Random Forest, Neural Network, Logistic Regression, and Decision Tree - based on multiple evaluation metrics, including Precision, Recall, F1-Score, Accuracy, and AUC. The table shows that the Neural Network model performed the best overall based on the AUC score of 0.90. However, the Random Forest model performed the best in terms of Precision (0.85) and F1-Score (0.78), indicating that it excels in identifying true positives. It is interesting to note that the Logistic Regression model had high scores for Recall (0.93) but low scores for Precision (0.70), indicating that it is better at avoiding false negatives but may classify some false positives. Furthermore, the Decision Tree model had the lowest performance based on all the metrics."
2402,"caption: Table 4. Model performances based on different evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall,AUC-ROC, SVM,0.82,0.80,0.83,0.78,0.89, Random Forest,0.84,0.81,0.87,0.77,0.91, Neural Network,0.87,0.85,0.88,0.83,0.93, Logistic Regression,0.78,0.76,0.80,0.73,0.84","Table 4 presents an overview of multiple models' performances based on different evaluation metrics, including accuracy, F1-score, precision, recall, and AUC-ROC. The SVM model achieved the highest accuracy of 0.82, whereas the neural network model attained the highest F1-score of 0.85. The logistic regression showed the lowest performance in most of the metrics among these models, while the random forest and neural network models achieved better results than other models in terms of precision, recall, and AUC-ROC. Notably, the neural network model achieved the highest AUC-ROC with a score of 0.93, which suggests that it performs well in predicting the probabilities of the binary classification."
2403,"caption: Comparison of F1-Score, Accuracy, Precision, and Recall metrics among different classification models.table: Model,F1-Score,Accuracy,Precision,Recall, Logistical Regression,0.78,0.76,0.75,0.85, Support Vector Machines,0.83,0.81,0.87,0.80, Multi-Layer Perceptron,0.86,0.84,0.89,0.83, Random Forest,0.92,0.91,0.95,0.89, XGBoost,0.95,0.94,0.94,0.96","Table above compares the performance of five different classification models - Logistical Regression, Support Vector Machines, Multi-Layer Perceptron, Random Forest, and XGBoost - based on F1-Score, Accuracy, Precision, and Recall metrics. The results show that XGBoost has the highest F1-Score of 0.95, Accuracy of 0.94, and Recall of 0.96. However, Random Forest has the highest Precision score of 0.95. Moreover, all models exhibit strong results, with the smallest difference between Accuracy and F1-Score being 0.02, indicating that the models can generalize well."
2404,"caption: A comparison of different models based on various evaluation metricstable: Model,Accuracy,Precision,Recall,F1 Score, Model 1,0.90,0.91,0.96,0.93, Model 2,0.85,0.82,0.93,0.87, Model 3,0.76,0.82,0.69,0.75, Model 4,0.83,0.80,0.88,0.84, Model 5,0.94,0.92,0.99,0.95","The table depicts a comparison of multiple models based on accuracy, precision, recall, and F1-score. It is apparent that Model 5 achieved the highest performance with an overall accuracy of 0.94 and an F1 score of 0.95. In contrast, Model 3 had the lowest accuracy of 0.76, with a recall of 0.69 and an F1 score of 0.75. Although Model 1 and Model 4 show comparable overall accuracy, Model 4 obtained relatively lower recall. Interestingly, Model 2 had the highest precision of 0.82, but its overall performance was lower than Model 1 and Model 4."
2405,"caption: Table 4: Model performance based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,Specificity, Model 1,0.85,0.84,0.86,0.84, Model 2,0.81,0.82,0.79,0.83, Model 3,0.89,0.87,0.92,0.87, Model 4,0.83,0.81,0.84,0.82, Model 5,0.79,0.76,0.81,0.78","Table 4 presents the performance of different models based on various evaluation metrics. The table reports Accuracy, Precision, Recall, and Specificity metrics for Model 1 to Model 5. The highest performing model based on Accuracy is Model 3 with an accuracy score of 0.89. However, Model 1 and Model 3 reported the highest values for precision and recall, respectively. Interestingly, all models exhibit specificity values higher than 0.8, indicating a lower false positive rate. These results suggest the necessity of considering various evaluation metrics while comparing the models' performances to choose the best fit model for a specific application."
2406,"caption: Performance comparison of different classification models using various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.82,0.85,0.76,0.80, Decision Tree,0.79,0.72,0.87,0.79, K-Nearest Neighbors,0.69,0.61,0.82,0.70, Naive Bayes,0.76,0.78,0.71,0.74, Support Vector Machine,0.84,0.91,0.78,0.83","The table above compares the performance of multiple classification models using various evaluation metrics. The evaluation metrics used include accuracy, precision, recall, and F1 score. The models compared are Logistic Regression, Decision Tree, K-Nearest Neighbors, Naive Bayes, and Support Vector Machine. From the table, the Support Vector Machine model performs best overall, having the highest accuracy, precision, and F1 score. However, the Decision Tree model has the highest recall score. It can be seen that each model has its strengths and weaknesses in different evaluation metrics."
2407,"caption: Evaluation metrics for different models.table: Model,Precision,Recall,F1-score,Accuracy, Model 1,0.84,0.92,0.88,0.87, Model 2,0.85,0.91,0.87,0.86, Model 3,0.80,0.88,0.81,0.83, Model 4,0.87,0.89,0.88,0.88","The above table illustrates the evaluation metrics - Precision, Recall, F1-score, and Accuracy - for different models. All models were trained on the same dataset and are evaluated against the same set of metrics. Model 4 shows the best Precision score of 0.87, while Model 1 has the highest Recall score of 0.92. Interestingly, Model 1 and Model 2 have a similar F1-score of 0.88 but differ notably in their Accuracy scores (0.87 and 0.86, respectively). Model 3, on the other hand, has a low Precision score of 0.80, which impacts its F1-score that is 0.06 lesser than Model 1 F1-score."
2408,"caption: Model performance comparison based on different evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score, Model 1,0.782,0.775,0.592,0.669, Model 2,0.815,0.795,0.722,0.756, Model 3,0.746,0.716,0.783,0.748, Model 4,0.831,0.827,0.686,0.748, Model 5,0.802,0.773,0.850,0.810","The presented table displays the performance of five different models based on multiple evaluation metrics, including accuracy, precision, recall, and F1-Score. Model 4 achieved the highest accuracy of 0.831 and precision of 0.827. On the other hand, Model 5 has the highest recall and F1-Score of 0.850 and 0.810, respectively. Despite having the highest recall score, Model 5 has the lowest precision score, showing the trade-off between precision and recall. Moreover, Model 3 has the highest precision score of 0.716 but the lowest recall score of 0.783. This table demonstrates the importance of considering multiple evaluation metrics while comparing model performance."
2409,"caption: Model performances of different machine learning algorithms using accuracy, precision, recall, and F1-score as evaluation metrics. All models were tested using the same dataset.table: Model,Accuracy,Precision,Recall,F1-Score, Random Forest,0.92,0.93,0.89,0.91, Logistic Regression,0.84,0.80,0.79,0.78, KNN,0.81,0.79,0.68,0.73, Decision Tree,0.88,0.87,0.82,0.84, SVM,0.85,0.83,0.72,0.77","The table above presents the performance results of different machine learning algorithms based on various evaluation metrics, including accuracy, precision, recall, and F1-score. The Random Forest model achieved the highest accuracy score of 0.92, while the KNN model had the lowest accuracy score of 0.81. However, the Logistic Regression model achieved the highest precision of 0.80, and Decision Tree model achieved the highest recall of 0.82. Interestingly, the Random Forest model achieved the highest F1-score among the models with a score of 0.91, indicating overall better performance. Overall, the table illustrates the different strengths and weaknesses of each model based on the selected evaluation metrics."
2410,"caption: Table 4: Model performance based on accuracy, precision, recall and F1-score.table: Model,Accuracy,Precision,Recall,F1-Score, KNN,0.91,0.91,0.92,0.91, Random Forest,0.94,0.95,0.93,0.94, XGBoost,0.96,0.96,0.96,0.96, SVM,0.89,0.89,0.92,0.90","Table 4 presents the models' performance based on multiple evaluation metrics: accuracy, precision, recall, and F1-score. The table includes the KNN, Random Forest, XGBoost, and SVM models, which were trained and tested on the same dataset. Notably, the XGBoost model is observed to have the best performance across all metrics, with the highest accuracy (0.96), precision (0.96), recall (0.96), and F1-score (0.96) scores. Interestingly, the Random forest model obtained the second best overall performance, with accuracy of 0.94, and precision, recall, and F1-score of 0.95, 0.93, and 0.94, respectively. However, the SVM model exhibits the lowest overall performance in all metrics recorded."
2411,"caption: Model Performance Comparison using Different Metricstable: Model Name,Accuracy,F1 Score,Recall,Precision, Model A,0.85,0.83,0.82,0.85, Model B,0.74,0.71,0.68,0.74, Model C,0.91,0.90,0.92,0.89, Model D,0.79,0.75,0.80,0.72, Model E,0.97,0.96,0.98,0.94","Table presents the performance comparison of five different models using accuracy, F1 score, recall, and precision metrics. Model A and E show the highest overall performance with accuracy scores of 0.85 and 0.97, respectively. Model C has the highest F1 score and recall score, with 0.90 and 0.92, respectively. On the other hand, Model B shows the lowest performance across all the metrics, and with the lowest accuracy score of 0.74. Interestingly, despite Model E's high accuracy score, it shows moderate-to-low scores for F1, recall, and precision metrics. Overall, the table showcases the varying performance of different models, depending on the performance metric being evaluated."
2412,"caption: Table 4: Model Performance Evaluation Using Multiple Metricstable: Model,Accuracy,F1-score,Precision,Recall, Logistic,0.87,0.85,0.88,0.82, Decision Tree,0.82,0.81,0.81,0.83, Naive Bayes,0.74,0.72,0.68,0.78, Random Forest,0.90,0.89,0.91,0.87, Support Vector,0.85,0.83,0.84,0.82","Table 4 compares the performance evaluations of five different machine learning models using different metrics. The evaluated models include Logistic Regression, Decision Tree, Naive Bayes, Random Forest, and Support Vector. The classification performance is evaluated using multiple metrics, including Accuracy, F1-score, Precision, and Recall. The highest accuracy of 0.90 is achieved by Random Forest. However, when considering other metrics, Random Forest also has an excellent score, with the highest F1-score of 0.89 and the highest Precision of 0.91. However, Decision Tree had the highest Recall score of 0.83, and Logistic Regression had the highest precision score of 0.88."
2413,"caption: Performance of different classification models based on different evaluation metrics.table: Model,Accuracy,F1-score,Recall,Precision, Logistic,0.75,0.77,0.78,0.75, Random Forest,0.82,0.82,0.85,0.85, K-Nearest Neighb.,0.69,0.68,0.72,0.65, SVM,0.79,0.78,0.81,0.76, Naïve Bayes,0.72,0.74,0.73,0.75","The table displays the performance of various classification models based on different evaluation metrics. Logistic regression, Random Forest, K-Nearest Neighbor, SVM, and Naïve Bayes models were compared on accuracy, F1-score, recall, and precision metric. Among all models, Random Forest achieved the highest performance with an accuracy of 0.82, F1-score of 0.82, recall of 0.85, and precision of 0.85. SVM obtained the highest recall of 0.81. Logistic regression had moderate performance across all metrics, while K-Nearest Neighbor and Naïve Bayes had lower performances on all metrics."
2414,"caption: Comparison of model performance based on different evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.89,0.87,0.91,0.84, KNN,0.86,0.84,0.87,0.81, Random Forest,0.92,0.91,0.93,0.89, XGBoost,0.93,0.92,0.94,0.90, Naive Bayes,0.80,0.77,0.81,0.74","Table above presents the performances of different models based on various evaluation metrics. The table includes SVM, KNN, Random Forest, XGBoost, and Naive Bayes models' performance results, including accuracy, F1-Score, Precision, and Recall. As per the results shown, the Random Forest model performed best with the highest accuracy (92%) and F1-Score (91%) scores. The XGBoost model performed second-best with an accuracy of 93% and an F1-Score of 92%. SVM, KNN, and Naive Bayes models, on the other hand, show relatively lesser performances in all aspects."
2415,"caption: Model performance comparison for binary classification problem.table: Model Name,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.75,0.74,0.77,0.72, Naive Bayes,0.69,0.71,0.69,0.72, Random Forest,0.84,0.82,0.84,0.83, XGBoost,0.83,0.84,0.84,0.84","The table presents the results of four different models, namely Logistic Regression, Naive Bayes, Random Forest, and XGBoost, on a binary classification problem. The models' performance is evaluated based on four different metrics, including Accuracy, F1 Score, Precision, and Recall. The Random Forest model achieved the highest accuracy of 0.84, while XGBoost achieved the highest F1 score, precision, and recall of 0.84. It is noteworthy that Naive Bayes achieved the lowest accuracy and F1 score, possibly due to its assumption of independence between features that may not always hold in real-world problems."
2416,"caption: A comparison of model evaluation metricstable: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.85,0.84,0.87,0.83, KNN,0.81,0.78,0.82,0.76, Logistic Regression,0.86,0.84,0.86,0.82, Decision Tree,0.78,0.74,0.76,0.73, Random Forest,0.90,0.88,0.91,0.86","The table above compares different models based on their evaluation metrics, including accuracy, F1-score, precision, and recall. The SVM model performed the best in terms of accuracy with a score of 0.85, while Random Forest had the highest accuracy score of 0.90. The Random Forest model also achieved the best F1-score of 0.88. The Logistic Regression and SVM models showed similar performance with accuracy and precision scores of 0.86 and 0.87, respectively. The Decision Tree model performed the lowest among all models, with an accuracy score of 0.78 and an F1-score of 0.74. Overall, the Random Forest model demonstrated superior performance in all evaluation metrics, outperforming other models in this comparison."
2417,"caption: Performance comparison of various machine learning algorithms on dataset XYZ.table: Model,Precision,Recall,F1,AUC, Random Forest,0.91,0.85,0.88,0.92, Gradient Boosting,0.83,0.91,0.87,0.89, Logistic Regression,0.81,0.74,0.77,0.81, SVM,0.89,0.72,0.79,0.81, XGBoost,0.90,0.89,0.89,0.93, Naive Bayes,0.45,0.98,0.62,0.71","The presented table compares the performance of various machine learning algorithms on dataset XYZ regarding Precision, Recall, F1-score, and AUC. The Random Forest model had the highest Precision score of 0.91, while the SVM model achieved the highest Recall score of 0.72. The XGBoost model attained the highest F1-score of 0.89. Additionally, the AUC score for Random Forest is the highest with 0.92, followed by XGBoost (0.93) and Gradient Boosting (0.89), whereas Naive Bayes scored the lowest with 0.71. These results indicate that both Random Forest and XGBoost perform well on the given dataset."
2418,"caption: Model performances of different classification algorithmstable: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.85,0.86,0.87,0.85, Decision Tree,0.82,0.76,0.76,0.78, Random Forest,0.89,0.91,0.92,0.90, Support Vector Machines,0.84,0.87,0.85,0.89, Gradient Boosting,0.90,0.91,0.93,0.89","The table presents a comparison of five different classification models' performances based on four evaluation metrics, namely Accuracy, F1 Score, Precision, and Recall. The models considered for this comparison are Logistic Regression, Decision Tree, Random Forest, Support Vector Machines, and Gradient Boosting. The Gradient Boosting model yields the best accuracy score of 0.90 among these models. Also, the Random Forest model achieves the best F1 Score, Precision, and Recall values of 0.91, 0.92, and 0.90, respectively. The findings suggest that the Gradient boosting and Random forest models may be the preferred models for this classification task."
2419,"caption: Table 4: Performance comparison of different models based on evaluation metrics.table: Model,Precision,Recall,F1-score,Accuracy, SVM,0.89,0.87,0.88,0.92, KNN,0.81,0.84,0.83,0.88, RF,0.91,0.92,0.91,0.95, NB,0.72,0.92,0.81,0.85, CNN,0.86,0.85,0.86,0.90, LSTM,0.88,0.89,0.88,0.93","Table 4 presents the performance comparison of six different models based on multiple evaluation metrics, including precision, recall, F1-score, and accuracy. From the results, all the models exhibit excellent performance. Random forest stands out with the highest precision score of 0.91, whereas SVM achieves the highest accuracy of 0.92. LSTM and RF models tie in their recall scores with 0.89 and 0.92, respectively. The F1-score for all the models except the NB model is above 0.8. The table's findings demonstrate that all the models can be employed effectively for the specific task under consideration."
2420,"caption: The classification performance comparison of various machine learning models based on accuracy, F1-score, precision, and recall.table: Model,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.88,0.90,0.89,0.92, Random Forest,0.91,0.92,0.93,0.91, SVM,0.87,0.89,0.87,0.90, Naive Bayes,0.84,0.86,0.85,0.90, K-Nearest Neighbor,0.82,0.84,0.83,0.87","The table outlines the classification performance of different machine learning models based on four evaluation metrics, namely Accuracy, F1-Score, Precision, and Recall. The models are Logistic Regression, Random Forest, SVM, Naive Bayes, and K-Nearest Neighbor. The Random Forest model outperforms the remaining models in Accuracy (0.91) and F1-Score (0.92) with a Precision score of 0.93 and a slightly lower Recall score of 0.91. The Logistic Regression model also displays strong classification performance with a high F1-score of 0.90 and Recall score of 0.92, although with slightly lower Accuracy and Precision scores. The SVM model demonstrates good Precision performance and a decent Accuracy score of 0.87. However, the Naive Bayes and K-Nearest Neighbor models exhibit comparably lower overall classification performance."
2421,"caption: Comparison of model performance using different evaluation metrics.table: Models,Precision,Recall,F1-score,Accuracy, SVM,0.94,0.80,0.86,0.86, LR,0.92,0.78,0.84,0.84, RF,0.91,0.82,0.86,0.86, KNN,0.79,0.76,0.67,0.67, DT,0.85,0.70,0.75,0.75","Table 1 presents the evaluation metrics of various models, including SVM, LR, RF, KNN, and DT. Precision, recall, F1-score, and accuracy are utilized to compare the models' performance. The results show that SVM demonstrates superior precision of 0.94 and recall of 0.8, outperforming the remaining models. The RF model achieves the highest F1-score of 0.86, with the same score as SVM. Meanwhile, LR and DT models share the same precision of 0.85, with LR having a slightly higher recall and F1-score. On the other hand, KNN exhibits substantially lower performance scores overall. The results indicate that SVM and RF perform well on this dataset, while LR and DT are a close second."
2422,"caption: Model performance based on different evaluation metricstable: Model,Accuracy,F1-Score,Precision,Recall,AUC, Logistic Regression,0.89,0.90,0.92,0.89,0.957, Random Forest,0.93,0.93,0.94,0.93,0.975, Multi-layer Perceptron,0.88,0.89,0.91,0.88,0.956, K-Nearest Neighbors,0.91,0.91,0.91,0.92,0.964","The table shows the performance comparison of four models based on various evaluation metrics. The models include Logistic Regression, Random Forest, Multi-layer Perceptron, and K-Nearest Neighbors. The evaluation metrics used here are Accuracy, F1-Score, Precision, Recall, and AUC. It is observed that the Random Forest model performed best in all the evaluation metrics compared to the other models. It has the highest accuracy of 0.93, F1-score of 0.93, precision of 0.94, recall of 0.93, and AUC of 0.975. Logistic Regression also performs well except for AUC. K-Nearest Neighbors exhibit the second-best performance in all evaluation metrics except precision. Multi-layer Perceptron shows competitive results but is slightly less accurate than the other models."
2423,"caption: Performance comparison of different models based on multiple evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.87,0.85,0.89,0.82, Decision Tree,0.81,0.79,0.80,0.78, Random Forest,0.91,0.90,0.93,0.87, Support Vector Machine,0.89,0.88,0.90,0.87, AdaBoost,0.90,0.89,0.92,0.86","The table presents a comparison of the accuracy, F1-score, precision, and recall evaluation metrics for five models: Logistic Regression, Decision Tree, Random Forest, Support Vector Machine, and AdaBoost. Notably, the Random Forest model demonstrated the highest accuracy (0.91) and F1-score (0.90), while achieving a precision of 0.93 and recall of 0.87. The AdaBoost algorithm also demonstrated strong performance with an accuracy score of 0.90 and F1-score of 0.89. Overall, Random Forest and AdaBoost models outperform the Logistic Regression, Decision Tree, and Support Vector Machine models with respect to all evaluation metrics considered in this study."
2424,"caption: Model performance based on different evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall,AUC, SVM,0.8,0.77,0.72,0.84,0.81, Logistic Regression,0.78,0.75,0.81,0.70,0.79, Random Forest,0.82,0.80,0.86,0.76,0.84, AdaBoost,0.79,0.77,0.80,0.75,0.81, XGBoost,0.84,0.82,0.89,0.77,0.87","The table above presents a comparison of five different models' performance based on varying evaluation metrics, namely Accuracy, F1-Score, Precision, Recall, and AUC. The models evaluated in the table are SVM, Logistic Regression, Random Forest, AdaBoost, and XGBoost. Notably, XGBoost outperforms other models with the highest Accuracy of 0.84, F1-Score of 0.82, Precision of 0.89, Recall of 0.77, and AUC of 0.87. Random Forest was the second-best performing model with the second-highest scores for all performance metrics. Interestingly, Logistic Regression has the highest precision, while SVM has the highest Recall score."
2425,"caption: Table 4: Model performance based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F-1 Score,AUC-ROC, Logistic Reg.,0.85,0.90,0.87,0.88,0.93, Random Forest,0.88,0.91,0.89,0.90,0.95, SVM,0.84,0.86,0.83,0.84,0.92, XGBoost,0.90,0.93,0.91,0.92,0.97","The table 4 presents model performances of four different machine learning models, namely Logistic Regression, Random Forest, SVM, and XGBoost based on different evaluation metrics, including Accuracy, Precision, Recall, F-1 Score, and AUC-ROC. The results show that XGBoost outperformed other models in all metrics except Precision, where Random Forest has a slight edge over XGBoost. Random Forest and Logistic Regression obtained competitive results across all metrics, while SVM showed second-rate performance compared to other models. Overall, XGBoost seems the best performing model among the presented ones."
2426,"caption: Model Performance Comparison using Multiple Metricstable: Model,Accuracy,Precision,Recall,F1-score,AUC, Support Vector Machine,0.95,0.96,0.94,0.95,0.98, Random Forest,0.92,0.93,0.9,0.91,0.94, Neural Network,0.96,0.97,0.96,0.96,0.97","The table compares the performance of three models - Support Vector Machine, Random Forest, and Neural Network - based on different evaluation metrics. The metrics used in the comparison are Accuracy, Precision, Recall, F1-Score, and AUC. The highest accuracy score of 0.96 was achieved by the Neural Network model, followed closely by the Support Vector Machine model with an accuracy of 0.95. While all three models excel in most metrics, the Neural Network model has the best overall performance, with the highest precision, recall, F1-Score, and AUC out of all models."
2427,"caption: Performance of different models on the classification tasktable: Model,Accuracy,Precision,Recall,F1-score, SVM,0.987,0.987,0.974,0.980, Random Forest,0.992,0.993,0.981,0.987, XGBoost,0.994,0.994,0.984,0.989, Multilayer Perceptron,0.998,0.998,0.997,0.998, CNN,0.999,0.999,0.999,0.999","Table presents the performance metrics for five different models, namely SVM, Random Forest, XGBoost, Multilayer Perceptron, and CNN. The models were evaluated on four different metrics, namely Accuracy, Precision, Recall, and F1-score. Results suggest that all models achieved high accuracy levels, with CNN (0.999) showing the best performance. The Multilayer Perceptron exhibited the highest precision, recall, and F1-score, which were 0.998, 0.997, and 0.998, respectively. Of interest, SVM and Random Forest had comparable performance scores across all metrics. Overall, the results suggest the effectiveness of the models in the classification task, with CNN and Multilayer Perceptron exhibiting the best performances in terms of accuracy and other metrics, respectively."
2428,"caption: Table 4: Model performance comparison based on multiple evaluation metricstable: Model,Accuracy,F1-score,Precision,Recall, Random Forest,0.86,0.83,0.90,0.78, Decision Tree,0.71,0.68,0.75,0.63, K-Nearest-Neighbors,0.78,0.74,0.80,0.70, Logistic Regression,0.84,0.81,0.88,0.75, Support Vector Machine,0.83,0.80,0.86,0.74","In table 4, we compare multiple different models' performances based on various evaluation metrics such as accuracy, F1-score, precision, and recall. The table includes models such as Random Forest, Decision Tree, K-Nearest-Neighbors, Logistic Regression, and Support Vector Machine. Notably, the Random Forest model shows the best overall performance, achieving the highest accuracy score of 0.86 and F1-score of 0.83. However, the Decision Tree model shows the lowest performance among the other models, with accuracy, F1-score, precision, and recall scores of 0.71, 0.68, 0.75, and 0.63, respectively. These results suggest that the Random Forest model might be the best model to predict the target variable based on the given dataset."
2429,"caption: Performance of different machine learning models on the datasettable: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.75,0.72,0.68,0.76, Decision Tree,0.70,0.67,0.61,0.75, Random Forest,0.81,0.78,0.75,0.82, XGBoost,0.80,0.76,0.73,0.80, Multi-Layer Perceptron,0.77,0.74,0.70,0.78","The table presents the performance of five different machine learning models on a dataset. The evaluation metrics utilized in the models include accuracy, F1 score, precision, and recall. The models present a mixed bag of results, with both accurate and less accurate models. The Random Forest model achieved the highest score in the Accuracy metric with a score of 0.81 and F1 score with a score of 0.78. The Logistic Regression model was the least accurate, with an accuracy score of 0.75 and an F1 score of 0.72. However, based on Precision and recall scores, the Logistic Regression model outperformed the Decision Tree and Multi-Layer Perceptron models."
2430,"caption: Classification model comparison using different evaluation metricstable: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.91,0.92,0.87,0.89, Naive Bayes,0.84,0.79,0.88,0.82, Random Forest,0.95,0.96,0.93,0.94, KNN,0.88,0.88,0.85,0.86, SVM,0.93,0.94,0.92,0.93, MLP,0.97,0.97,0.95,0.96","The table presents a comparison of six different classification models (Logistic Regression, Naive Bayes, Random Forest, KNN, SVM, and MLP) based on different evaluation metrics. The evaluation metrics used in this study are Accuracy, Precision, Recall, and F1-Score. Notably, the MLP model outperforms all other models in all evaluation metrics with an Accuracy (0.97), Precision (0.97), Recall (0.95), and F1-Score (0.96). The Random Forest model shows the second-best performance in all evaluation metrics, while the Naive Bayes model had the lowest accuracy (0.84). These results provide insights into the comparative performance of the different classification models."
2431,"caption: Performance comparison of different models using multiple evaluation metricstable: Models,Metric 1,Metric 2,Metric 3,Metric 4, Model A,0.75,0.60,0.82,0.65, Model B,0.80,0.62,0.83,0.71, Model C,0.73,0.58,0.81,0.68, Model D,0.78,0.65,0.84,0.74, Model E,0.81,0.67,0.85,0.78","The table displays the performance comparison of five different models based on four evaluation metrics. The evaluation metrics include Metric 1, Metric 2, Metric 3, and Metric 4. Among the five models, Model E shows the best performance in all evaluation metrics, with scores of 0.81, 0.67, 0.85, and 0.78 for Metrics 1 to 4, respectively. Model C ranked the lowest in terms of the evaluation scores for all four metrics. Interestingly, Model D outperformed Model B, indicating that the best performance may not always be dependent on the most complex models."
2432,"caption: Evaluation scores for different models using different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.84,0.80,0.68,0.74, Logistic Regression,0.86,**0.85**,0.72,0.78, Decision Tree,0.74,0.72,0.61,0.65, KNN,0.82,0.78,0.67,0.72, Naive Bayes,0.79,0.82,**0.77**,**0.79**","Table demonstrates the comparison of five different models employed for classification, based on accuracy, precision, recall, and F1-Score. The models utilized in the evaluation are SVM, Logistic Regression, Decision Tree, KNN, and Naive Bayes. Interestingly, the Logistic Regression model attained the highest precision of 0.85, while Naive Bayes achieved the highest score for both Recall and F1-Score with 0.77 and 0.79, respectively. However, the highest accuracy was observed in the Logistic Regression model of 0.86. Additionally, the Decision Tree model showed the lowest performance for all the evaluation metrics employed, especially in terms of recall and F1-Score."
2433,"caption: Comparison of model performance based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 score, Model A,0.92,0.91,0.93,0.92, Model B,0.85,0.87,0.80,0.83, Model C,0.89,0.90,0.88,0.89, Model D,0.94,0.92,0.98,0.95","Table presents the evaluation metrics results for multiple models, including Model A, Model B, Model C, and Model D. The models' performances were evaluated based on Accuracy, Precision, Recall, and F1 score. Notably, Model D exhibited the highest accuracy score of 0.94, while Model B showed the lowest accuracy score of 0.85. Regarding precision scores, Model A, Model C, and Model D demonstrated closely high scores compared to Model B. On the other hand, Model D scored the highest Recall and F1 score values showing the best performance overall. The table results reveal that the comparison of models based on different evaluation metrics is crucial, as it provides more detailed information on the model's actual performance."
2434,"caption: Comparison of Model Performances based on Multiple Evaluation Metrics.table: Model,Metric 1,Metric 2,Metric 3,Metric 4, Logistic Regression,0.84,0.71,0.92,0.65, Random Forest,0.91,0.79,0.93,0.75, K-Nearest Neighbors,0.82,0.64,0.89,0.61, SVM,0.90,0.75,0.91,0.72, Naive Bayes,0.80,0.60,0.85,0.58","The table provides a comparative analysis of five machine learning models (Logistic Regression, Random Forest, K-Nearest Neighbors, SVM, and Naive Bayes) based on four different evaluation metrics (Metric 1, Metric 2, Metric 3, and Metric 4). The table highlights that Random Forest technique performs best in all four evaluation metrics, with the highest Metric 1 (0.91), Metric 2 (0.79), Metric 3 (0.93), and Metric 4 (0.75) scores. The SVM model shows competitive performance as the Random Forest model, with the second-best scores in all four evaluation metrics. The Naive Bayes method has the lowest performance compared to the other models, with the lowest Metric 1 (0.80), Metric 2 (0.60), Metric 3 (0.85), and Metric 4 (0.58) scores."
2435,"caption: Performance comparison of five different models based on different evaluation metricstable: Model,Accuracy,F1-Score,Precision,Recall, Model A,0.92,0.91,0.92,0.90, Model B,0.89,0.88,0.84,0.92, Model C,0.91,0.89,0.93,0.87, Model D,0.93,0.92,0.93,0.91, Model E,0.88,0.87,0.83,0.91","The table presents a performance comparison of five different models based on accuracy, F1-score, precision, and recall evaluation metrics. The models, namely Model A, B, C, D, and E, were evaluated on the same dataset. The highest accuracy score was achieved by Model D with a value of 0.93. In terms of F1-score, Model A got the highest score, scoring 0.91, whereas Model E had the lowest F1-score at 0.87. Precision-wise, Model C exhibited the highest value (0.93), whereas Model E had the lowest precision value of 0.83. Model B had the highest recall score of 0.92, whereas Model C had the lowest recall score of 0.87. Overall, the table suggests that different models may perform differently based on different evaluation metrics."
2436,"caption: Model evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.873,0.858,0.884,0.869, KNN,0.902,0.890,0.905,0.897, LR,0.912,0.897,0.918,0.907, RF,0.919,0.908,0.921,0.913, XGB,0.921,0.913,0.923,0.918","The table above presents the performance of five different models (SVM, KNN, LR, RF and XGB) evaluated using four different evaluation metrics (accuracy, precision, recall, and F1-score). The table demonstrates that the XGB model performs the best with an accuracy of 0.921, precision of 0.913, recall of 0.923, and F1-score of 0.918. In comparison, the SVM model has the lowest performance score with an accuracy of 0.873, precision of 0.858, recall of 0.884 and F1-score of 0.869. Such tables help researchers compare the effectiveness of different models and select the best-suited model for their applications."
2437,"caption: Comparison of different models based on evaluation metrics.table: Model Name,F1 Score,Accuracy,Precision,Recall, Logistic Regression,0.87,91,0.88,0.86, Decision Tree,0.78,78,0.69,0.90, Random Forest,0.92,94,0.91,0.92, Support Vector Machine,0.84,89,0.83,0.86, Artificial Neural Network,0.89,92,0.87,0.91","Table 1 presents a comparison of different models based on different evaluation metrics. The table exhibits Logistic Regression, Decision Tree, Random Forest, Support Vector Machine, and Artificial Neural Network models' performance in terms of F1 Score, Accuracy, Precision, and Recall. In this table, the best performing model is the Random Forest model as it achieved the highest F1 Score of 0.92 among all other models. Interestingly, the second-best performing model was the Artificial Neural Network, which achieved an F1 score of 0.89. However, despite Decision Tree achieving the lowest F1 Score of 0.78, it has the highest Recall score of 0.90."
2438,"caption: Table 4. Model performance using different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, LogReg,0.78,0.75,0.80,0.77, SVM,0.70,0.67,0.73,0.70, KNN,0.63,0.64,0.59,0.61, Naive Bayes,0.75,0.68,0.89,0.77",
2439,"caption: Model Performance Measurement Using Different Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.87,0.87,0.86,0.86, Random Forest,0.89,0.89,0.88,0.88, MLP,0.91,0.91,0.90,0.90, Decision Tree,0.85,0.85,0.84,0.84, K-Nearest Neighbor,0.80,0.80,0.79,0.79","Table presents the model performances of SVM, Random Forest, MLP, Decision Tree, and K-Nearest Neighbor models based on different evaluation metrics. The evaluation metrics include Accuracy, Precision, Recall, and F1-Score, evaluated using the same dataset. The highest Accuracy score of 0.91 was achieved by the MLP model, followed by the Random Forest model with a score of 0.89. The MLP and Random Forest models also achieved the highest Precision scores of 0.91 and 0.89, respectively. The K-Nearest Neighbor model achieved the lowest Accuracy, Precision, Recall, and F1-Score among others. The table provides crucial information on model performance that can be helpful in model selection for different applications."
2440,"caption: Comparison of various models' performance on different evaluation metrics.table: Model,Accuracy,F1-score,Recall,Precision, Model 1,0.85,0.83,0.75,0.92, Model 2,0.83,0.81,0.73,0.90, Model 3,0.89,0.87,0.79,0.96, Model 4,0.81,0.79,0.72,0.88, Model 5,0.87,0.85,0.76,0.96, Model 6,0.84,0.82,0.74,0.91","Table 1 displays the performance scores of multiple models on various evaluation metrics. The presented metrics include Accuracy, F1-score, Recall, and Precision. Model 3 achieved the highest accuracy of 0.89, whereas Model 4 achieved the lowest accuracy (0.81). F1-score, on average, ranges from 0.79 to 0.87. Notably, Model 3 also showed the highest F1-score of 0.87. In terms of Recall scores, Model 5 achieved the highest recall score of 0.76. Lastly, Model 3 achieved the best precision score of 0.96, whereas Model 4 achieved the lowest score of 0.88. Overall, Model 3 performed relatively better than the rest of the models."
2441,"caption: Table 4: Performance evaluation for the LR, DT, and SVM models using different metrics.table: Model,Metric,Result, LR,Accuracy,0.75, LR,Precision,0.70, LR,Recall,0.89, DT,Accuracy,0.65, DT,Precision,0.58, DT,Recall,0.75, SVM,Accuracy,0.80, SVM,Precision,0.75, SVM,Recall,0.87","Table 4 illustrates the performance evaluation of three different models - Logistic Regression (LR), Decision Tree (DT), and Support Vector Machines (SVM) - using three different metrics: Accuracy, Precision, and Recall. The table shows that the SVM model has the highest Accuracy of 0.80, followed by LR at 0.75 and DT at 0.65. On the other hand, the LR model has the highest Precision of 0.70, followed by SVM at 0.75 and DT at 0.58. In terms of Recall, SVM had the highest performance of 0.87, followed by LR at 0.89 and DT at 0.75. Therefore, depending on the evaluation metric, different models may perform better and should be chosen accordingly."
2442,"caption: Table 4: Comparison of various models based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.85,0.85,0.85,0.85, Decision Tree,0.82,0.87,0.72,0.79, K-Nearest Neighbor,0.80,0.84,0.69,0.76, Random Forest,0.90,0.90,0.88,0.89, Support Vector,0.84,0.80,0.81,0.80","Table 4 presents the performance comparison of multiple models using Accuracy, Precision, Recall, and F1 Score evaluation metrics. The table includes Logistic Regression, Decision Tree, K-Nearest Neighbor, Random Forest, and Support Vector models. Random Forest exhibited the highest Accuracy score of 0.90, while Decision Tree got the lowest Accuracy of 0.82. On the other hand, K-Nearest Neighbor had the lowest Recall of 0.69, and Logistic Regression had the highest Precision of 0.85. Interestingly, the F1 Score shows the performance of all models are ranged between 0.76 to 0.89. The table provides comprehensive information to select the best model based on the specific evaluation metric."
2443,"caption: Table 4: Performance comparison of different models based on accuracy, F1 Score, precision, and recall.table: Model,Accuracy,F1 Score,Precision,Recall, Model A,0.89,0.87,0.90,0.84, Model B,0.83,0.80,0.85,0.76, Model C,0.91,0.90,0.92,0.89, Model D,0.87,0.84,0.88,0.80, Model E,0.92,0.91,0.93,0.89","Table 4 displays the performance evaluation of different models based on their accuracy, F1 Score, precision, and recall. Model A scored the highest accuracy of 0.89, while Model C got the highest accuracy rate of 0.91. When evaluating precision, Model E is the leading model with a score of 0.93, and Model B is the weakest model with a score of 0.85. The F1 Score of the models ranges from 0.80 (Model B) to 0.91 (Model E). Notably, Model E is the best-performing model based on F1 Score and recall, with scores of 0.91 and 0.89, respectively. Model B, with a recall score of 0.76, achieves the weakest performance."
2444,"caption: Table 4: Model Evaluation Metrics Comparison between Logistic Regression, Random Forest, and XGBoost.table: Metric\ Model,Logistic Regression,Random Forest,XGBoost, Accuracy,0.85,0.92,0.94, Precision (Class 0),0.88,0.94,0.95, Precision (Class 1),0.78,0.86,0.90, Recall (Class 0),0.82,0.89,0.95, Recall (Class 1),0.74,0.83,0.89, F1-Score (Class 0),0.85,0.92,0.95, F1-Score (Class 1),0.76,0.84,0.89","Table 4 compares the performance of three different models: Logistic Regression, Random Forest, and XGBoost, based on various evaluation metrics. The models were trained and tested using the same dataset. The evaluation metrics include Accuracy, Precision, Recall, and F1-score for both classes (Class 0 and Class 1). Interestingly, XGBoost outperforms other models and achieved the highest accuracy score of 0.94. Random Forest shows excellent performance with higher Precision scores for both classes, while Logistic Regression has relatively lower scores but still exhibits a reasonable degree of performance. Overall, the table provides useful insights into the models' performance and helps to select the most appropriate model based on the required evaluation metrics."
2445,"caption: Table 4: Performance comparison of Multiple Machine Learning Models for Binary Classification.table: Model,Accuracy,Precision,Recall,F1 Score,Time Taken (Seconds), SVM,0.94,0.94,0.88,0.91,56, Random Forest,0.93,0.85,0.90,0.87,34, KNN,0.89,0.85,0.75,0.79,63, Logistic Regression,0.93,0.86,0.95,0.91,45, Decision Tree,0.89,0.81,0.87,0.83,25","Table 4 displays the evaluation of various machine learning algorithms for binary classification on a given dataset. The models were evaluated based on Accuracy, Precision, Recall, F1 Score with Time taken for performance measurement. The experiment demonstrates that SVM model achieved the highest accuracy of 0.94, followed by Logistic Regression with an accuracy of 0.93. In terms of precision, Logistic Regression performed the best with a score of 0.86, while KNN did the worst with a score of 0.85. Interestingly, in terms of recall, Logistic Regression again achieved the best with a score of 0.95, while KNN had the worst of all at 0.75. Finally, the Random Forest algorithm received the best F1 score of 0.87, while KNN had the worst F1 score of 0.79. The time taken to complete the experiment considerably varied among the algorithms, with SVM taking the longest at 56 seconds, while Decision Tree took the shortest at 25 seconds."
2446,"caption: Table 4: Model Performances Based on Accuracy, Precision, Recall, and F1 Score.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.87,0.86,0.88,0.87, Random Forest,0.89,0.88,0.91,0.89, Support Vector Machine,0.85,0.84,0.86,0.85, Multilayer Perceptron,0.84,0.82,0.86,0.84, Naive Bayes,0.82,0.80,0.84,0.81","Table 4 shows the performance comparison of five machine learning models based on accuracy, precision, recall, and F1 score. The models include Logistic Regression, Random Forest, Support Vector Machine, Multilayer Perceptron, and Naive Bayes. The table highlights multiple interesting observations. Firstly, Random Forest shows the best performance, with an accuracy score of 0.89, precision of 0.88, recall of 0.91 and f1-score of 0.89. Secondly, Naive Bayes has the lowest accuracy score of 0.82 and f1-score of 0.81. In contrast, Logistic Regression and Random Forest shows an overall well-balanced performance across all metrics, while Support Vector Machine and Multilayer Perceptron models show a trade-off between precision and recall."
2447,"caption: Table 4: Model performance evaluation using different classification metrics.table: Model,Accuracy,Precision,Recall,F1-score, Random Forest,0.846,0.872,0.828,0.849, Logistic Regression,0.721,0.748,0.639,0.689, Decision Tree,0.765,0.778,0.760,0.768, SVM,0.802,0.816,0.800,0.803, Naive Bayes,0.658,0.618,0.641,0.625, KNN,0.789,0.799,0.780,0.789","Table 4 presents the evaluation results of several machine learning models applied to a binary classification problem. The table displays Accuracy, Precision, Recall, and F1-score for six models evaluated using the same dataset. The Random Forest model delivered the most accurate performance with an accuracy of 0.846. It also showed the highest Precision (0.872) and Recall (0.828) results, thereby resulting in a higher F1-score of 0.849. On the other hand, Naive Bayes showed the weakest performance in all metrics, while Logistic Regression had the second-lowest performance, with an accuracy of 0.721. SVM and Decision Tree both showed comparatively better Precision and Recall results than Naive Bayes and KNN."
2448,"caption: Performance evaluation of five different models using various metricstable: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.84,0.82,0.86,0.78, KNN,0.78,0.77,0.81,0.74, RF,0.86,0.85,0.87,0.83, NN,0.89,0.88,0.91,0.85, XGB,0.87,0.86,0.88,0.85","Table presents the various models' performance based on different evaluation metrics, including accuracy, F1-score, precision, and recall. The models used in the comparison are Support Vector Machine (SVM), K-Nearest Neighbors (KNN), Random Forest (RF), Neural Network (NN), and XGBoost (XGB). Among all models, the Neural Network showed the best performance with accuracy, F1-score, precision, and recall scores of 0.89, 0.88, 0.91, and 0.85, respectively. The Random Forest model showed the most consistent performance across all metrics with accuracy, F1-score, precision, and recall scores of 0.86, 0.85, 0.87, and 0.83, respectively. The SVM model demonstrated the best precision score of 0.86, while KNN had the lowest recall score of 0.74. Overall, the table comparison provides insights into the models' strengths and weaknesses in predicting the outcome variable using different evaluation metrics."
2449,"caption: Table 4: Model performance based on different evaluation metricstable: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.89,0.90,0.93,0.91, K-Nearest Neighbors,0.91,0.92,0.90,0.91, Decision Tree,0.85,0.84,0.85,0.85, Random Forest,0.93,0.93,0.96,0.94, Support Vector Machine,0.87,0.88,0.91,0.89","Table 4 presents an evaluation of multiple models based on different evaluation metrics, including Accuracy, Precision, Recall, and F1 Score. The table shows the results of Logistic Regression, K-Nearest Neighbors, Decision Tree, Random Forest, and Support Vector Machine models. The Random Forest model achieves the highest Accuracy score of 0.93, Precision of 0.93, Recall of 0.96, and F1 Score of 0.94. However, the K-Nearest Neighbors also show similarly high scores for all metrics, with Accuracy of 0.91, Precision of 0.92, Recall of 0.90, and F1 Score of 0.91. Interestingly, Decision Tree shows a balanced performance on all metrics with scores around 0.85, while Support Vector Machine shows slightly lower scores for Precision and F1 Score."
2450,"caption: Table 4: Performance scores of multiple classification modelstable: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.86,0.83,0.87,0.83, Support Vector Machine,0.89,0.87,0.88,0.87, Random Forest,0.92,0.91,0.93,0.91, Gradient Boosting,0.91,0.90,0.92,0.90, MLP,0.87,0.86,0.87,0.86","Table 4 showcases the performance scores of multiple classification models based on various evaluation metrics, including Accuracy, F1-score, Precision, and Recall. The models used are Logistic Regression, Support Vector Machine, Random Forest, Gradient Boosting, and Multi-Layer Perceptron (MLP). Among these models, Random forest achieved the best accuracy score of 0.92, followed by Gradient Boosting with 0.91. However, the best score for F1-score, Precision, and Recall is obtained with Random Forest, which scored 0.91, 0.93, and 0.91, respectively, indicating its overall superior performance compared to other models. Nevertheless, all models illustrated their capability of classification, obtaining scores above 0.80 in all metrics."
2451,"caption: Table 4: Comparison of different models' accuracy, F1-score, recall, and precision.table: Model Name,Accuracy,F1-Score,Recall,Precision, Model A,0.81,0.84,0.82,0.86, Model B,0.78,0.81,0.75,0.88, Model C,0.83,0.86,0.84,0.88, Model D,0.76,0.8,0.77,0.83","In Table 4, we present the comparison of different models' performance using evaluation metrics such as accuracy, F1-score, recall, and precision. Four models, named Model A, B, C, and D, were evaluated. We can see that Model C has the highest accuracy score of 0.83 and F1-score of 0.86, indicating that it outperforms other models. However, Model B has the highest precision score of 0.88, indicating that it can predict the positive instances' probability more accurately than other models. On the other hand, Model D has the lowest accuracy and F1-scores of 0.76 and 0.8, respectively, and it seems to be the worst-performing model in this study. Nonetheless, we can see that different models have their strengths and weaknesses, and the choice of the model depends on the task's specific requirements."
2452,"caption: Table 4: Model performance based on multiple evaluation metricstable: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.897,0.889,0.901,0.876, KNN,0.832,0.815,0.826,0.804, Naive Bayes,0.751,0.739,0.761,0.720, Decision Tree,0.811,0.801,0.814,0.789, Random Forest,0.906,0.902,0.909,0.894, XGBoost,0.912,0.909,0.914,0.903","Table 4 presents the performance of six different models, namely SVM, KNN, Naive Bayes, Decision Tree, Random Forest, and XGBoost based on multiple evaluation metrics. The evaluation metrics include Accuracy, F1-Score, Precision, and Recall. The table highlights that the XGBoost model demonstrated the best performance for all metrics. In contrast, the Naive Bayes model delimited the lowest scores for accuracy, F1-Score, precision, and recall, indicating that the model doesn't perform well. Furthermore, the table indicates that the Random Forest model performs better in accuracy, F1-Score, and recall than the Decision Tree and KNN models."
2453,"caption: Model performance comparison using different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Decision Tree,0.82,0.83,0.82,0.82, Random Forest,0.90,0.90,0.90,0.90, AdaBoost,0.88,0.87,0.88,0.88, SVM,0.86,0.86,0.86,0.86, K-Nearest Neighbor,0.87,0.88,0.87,0.87","Table presents a comparison of model performances using different evaluation metrics, including accuracy, precision, recall, and F1 Score. The table exhibits five different models: Decision Tree, Random Forest, AdaBoost, SVM, and K-Nearest Neighbor. Notably, all models were trained and tested on the same dataset. The table indicates that the performance of the models varies according to the evaluation metric under consideration. Random Forest model shows the highest accuracy score with 0.90, and Decision Tree has the highest precision with 0.83. The K-Nearest Neighbor has the highest precision and F1 Score. On the other hand, AdaBoost has the highest recall with 0.88. Overall, this table could assist decision-makers in identifying the appropriate model for their use case by considering the evaluation metric that is most important to them."
2454,"caption: Performance Metrics for Five Different Modelstable: Model,Accuracy,Precision,Recall,F1 Score, Model 1,0.87,0.86,0.84,0.85, Model 2,0.92,0.91,0.93,0.92, Model 3,0.80,0.81,0.77,0.79, Model 4,0.95,0.94,0.96,0.95, Model 5,0.89,0.87,0.91,0.89","The table shows the accuracy, precision, recall and F1 score for five different models. The models are labeled as Model 1, Model 2, Model 3, Model 4, and Model 5. The evaluation metrics indicate the models' performance in correctly identifying positive class instances. Notably, Model 4 achieved the highest performance results across all evaluation metrics, with an accuracy of 0.95, precision of 0.94, recall of 0.96, and an F1 score of 0.95. Conversely, while Model 3 had the lowest accuracy, precision, and F1 score, it had a respectable recall score of 0.77. Overall, the table provides a helpful insight into the five models' relative performance levels, indicating the superior performance of Model 4."
2455,"caption: Model performance based on accuracy, F1 score, precision and recall.table: Model,Accuracy,F1 Score,Precision,Recall, LogReg,0.87,0.85,0.88,0.83, SVM,0.79,0.71,0.73,0.69, RF,0.91,0.90,0.92,0.89, XGB,0.895,0.88,0.87,0.91","The table above compares the model performance of classification algorithms based on evaluation metrics including accuracy, F1 score, precision, and recall. The models tested in this comparison include LogReg, SVM, RF, and XGB. Notably, the RF model has the highest accuracy, F1 score, precision, and recall with scores of 0.91, 0.90, 0.92, and 0.89 respectively. The LogReg model had the second-highest accuracy and precision score, and the XGB model had the second-highest F1 score and recall score. The SVM model had the lowest accuracy, F1 score, precision, and recall scores among all models."
2456,"caption: Performance metrics of various machine learning models analyzed using the same dataset.table: Model,Precision,Recall,F1-score,AUC-ROC,Accuracy, Logistic Regression,0.75,0.85,0.79,0.82,0.82, Decision Tree,0.73,0.77,0.75,0.78,0.75, Random Forest,0.81,0.85,0.83,0.86,0.84, SVM,0.76,0.83,0.79,0.80,0.80","This table presents the results of four different machine learning models, namely Logistic Regression, Decision Tree, Random Forest, and SVM, tested and trained using the same dataset. The table reports their precision, recall, F1-score, AUC-ROC, and accuracy performance metrics. Interestingly, Random Forest had the highest precision, recall, and F1-score with 0.81, 0.85, and 0.83, respectively. The Random Forest also showed the best performance in AUC-ROC, achieving 0.86, while Logistic Regression achieved the highest accuracy of 0.82. The table's results indicate that Random Forest is the optimal model in this given task, based on the overall performance metrics."
2457,"caption: Model evaluation metrics for different classification modelstable: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.85,0.89,0.87,0.88, Random Forest,0.87,0.82,0.89,0.85, Neural Network,0.90,0.93,0.91,0.92, Naive Bayes,0.75,0.69,0.88,0.77, Decision Tree,0.82,0.80,0.84,0.82","Table presents the evaluation metrics for several classification models, including SVM, Random Forest, Neural Network, Naive Bayes, and Decision Tree. The evaluation metrics for each model include Accuracy, Precision, Recall, and F1-Score. The results show the Neural Network model performed best in all evaluation metrics with an accuracy of 0.90 and an F1-Score of 0.92. The Random Forest classifier had the second-best performance with an accuracy of 0.87 and an F1-Score of 0.85. On the other hand, the Naive Bayes model showed the lowest accuracy of 0.75, but it had the highest Recall score of 0.88. Overall, this table provides an informative overview of the performance differences of multiple models on the same classification task, allowing for optimal model selection."
2458,"caption: Comparison of different machine learning models based on accuracy, F1-score, precision, and recall metrics.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.92,0.89,0.92,0.86, Random Forest,0.91,0.88,0.91,0.85, XGBoost,0.93,0.90,0.93,0.87, KNN,0.89,0.84,0.88,0.80, Naive Bayes,0.86,0.81,0.84,0.78","This table presents a comparison of five different machine learning models based on their performance metrics. The models' accuracy, F1-score, precision, and recall were computed and tabulated. The SVM model achieved the highest accuracy (0.92) and precision (0.92), while XGBoost delivered the highest F1-score (0.90) and recall (0.87). Random forest achieved the second-best performance across all the metrics, while Naive Bayes had the lowest scores across all the performance metrics. The table helps compare the different strengths and weaknesses of each machine learning model based on the evaluation metrics."
2459,"caption: Model performances based on different evaluation metrics.table: Model Name,Accuracy,Recall,Precision,F1-Score, Logistic Regression,0.854,0.839,0.819,0.829, Random Forest,0.895,0.880,0.852,0.865, Decision Tree,0.773,0.654,0.677,0.655, Naive Bayes,0.768,0.759,0.750,0.755, SVM,0.906,0.892,0.885,0.888","Table 4 shows the performances of five machine learning models based on four evaluation metrics: Accuracy, Recall, Precision, and F1-Score. The models include Logistic Regression, Random Forest, Decision Tree, Naive Bayes, and SVM. The table suggests that SVM performs the best in all four evaluation metrics with 0.906 accuracy, 0.892 recall, 0.885 precision, and 0.888 F1-Score. Interestingly, Random Forest is the second-best performing model with impressive values for all four evaluation metrics. In contrast, Decision Tree performs the lowest among all five models. The table emphasizes the significance of evaluating models on multiple evaluation metrics to have a comprehensive understanding of their performances."
2460,"caption: Table 4: Model performance based on different evaluation metricstable: Model,Accuracy,F1-Score,Precision,Recall, Model 1,0.85,0.88,0.94,0.83, Model 2,0.80,0.83,0.91,0.77, Model 3,0.77,0.80,0.87,0.75, Model 4,0.87,0.89,0.93,0.86, Model 5,0.82,0.86,0.92,0.80","Table 4 summarizes the performance of five different models based on multiple evaluation metrics, including accuracy, F1-Score, precision, and recall. The table demonstrates that Model 1 has the highest accuracy of 0.85, whereas Model 4 has the highest precision of 0.93. Additionally, Model 2 has the lowest accuracy of 0.80, while Model 3 has the lowest F1-Score of 0.80. Interestingly, all models achieved a reasonable recall score between 0.75 and 0.86. The table's results suggest that different models may excel in various evaluation metrics, indicating that testers should consider all performance metrics to select the best model suited for the intended application."
2461,"caption: Table 4: Performance metrics of different models on classification task.table: Model,F1 Score,Accuracy Score,Precision Score,Recall Score, Logistic Regression,0.89,0.90,0.87,0.91, Decision Tree,0.70,0.65,0.68,0.73, Random Forest,0.93,0.93,0.94,0.92, Support Vector Machines,0.85,0.87,0.84,0.86, Gradient Boosting,0.92,0.91,0.91,0.93, k-Nearest Neighbors,0.78,0.80,0.77,0.80","Table 4 presents the F1 Score, Accuracy Score, Precision Score, and Recall Score performance metrics of different models on a classification task. The presented models include Logistic Regression, Decision Tree, Random Forest, Support Vector Machines, Gradient Boosting, and k-Nearest Neighbors. Notably, the Random Forest model shows the best F1 Score performance of 0.93, while achieving a high accuracy performance of 0.93, precision score performance of 0.94, and recall score performance of 0.92. Interestingly, the Gradient Boosting model has the highest precision score performance of 0.91, and recall score performance of 0.93, although it falls behind Random Forest in F1 Score and accuracy. Overall, the table provides a comparison of various model performances across multiple metrics."
2462,"caption: Table 4: Model performances based on multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.93,0.95,0.90,0.92, Decision Tree,0.85,0.86,0.88,0.84, Naive Bayes,0.77,0.81,0.74,0.76, Random Forest,0.95,0.96,0.95,0.95, Gradient Boosting,0.94,0.96,0.93,0.94","Table 4 shows the performance results of various models based on different evaluation metrics. The table lists the accuracy, precision, recall, and F1-Score for Logistic Regression, Decision Tree, Naive Bayes, Random Forest, and Gradient Boosting models. The Random Forest model produced the highest accuracy, precision, and F1-Score scores of 0.95, 0.96, and 0.95, respectively, which is followed closely by the Gradient Boosting model. Nevertheless, the Logistic Regression model achieved the highest recall score of 0.90. The Decision Tree model showed a lower score on precision, while Naive Bayes had the lowest scores on accuracy, precision, recall, and F1-Score when compared to other models."
2463,"caption: Performance evaluation of different models based on different evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall,AUC, Model 1,0.89,0.87,0.92,0.83,0.94, Model 2,0.91,0.88,0.88,0.88,0.93, Model 3,0.82,0.74,0.71,0.78,0.84, Model 4,0.93,0.91,0.90,0.92,0.95","The table presents the performance evaluation of four models based on different evaluation metrics, including accuracy, F1-score, precision, recall, and AUC. Model 1 achieved an accuracy of 0.89, an F1-score of 0.87, a precision of 0.92, a recall of 0.83, and an AUC of 0.94. Model 2 had the highest accuracy of 0.91, an F1-score of 0.88, precision of 0.88, recall of 0.88, and an AUC of 0.93. Model 3 performed the lowest among the four models with an accuracy of 0.82, an F1-score of 0.74, precision of 0.71, recall of 0.78, and an AUC of 0.84. Model 4 achieved the highest performance for all evaluation metrics except for precision, with scores of 0.93 for accuracy, 0.91 for F1-score, 0.90 for precision, 0.92 for recall, and 0.95 for AUC."
2464,"caption: Table 4: Model performance comparison based on three different evaluation metrics.table: ```, Model,Metric 1,Metric 2,Metric 3, Model 1,0.75,0.82,0.68, Model 2,0.82,0.79,0.70, Model 3,0.91,0.68,0.73, Model 4,0.77,0.81,0.70, Model 5,0.85,0.72,0.76, Model 6,0.92,0.85,0.80","Table 4 compares six different models' performance based on three evaluation metrics. The models were evaluated using Metric 1, Metric 2, and Metric 3, with each metric representing a different measure of performance. Model 6 achieved the highest performance across all metrics with scores of 0.92, 0.85, and 0.80, respectively. Model 3 also achieved high performance results across Metric 1 and Metric 3 with scores of 0.91 and 0.73, respectively. Interestingly, Model 5 had the highest score for Metric 1 but scored lower on the other two metrics. The table's results can be used to determine the best model for each metric and the overall best performing model."
2465,"caption: Comparison of classification modelstable: Model,Accuracy,F1-score,Precision,Recall, LR,0.87,0.87,0.85,0.90, SVM,0.84,0.83,0.80,0.87, RF,0.83,0.82,0.81,0.84, MLP,0.81,0.81,0.80,0.82, KNN,0.79,0.79,0.76,0.82","The table shows the performances of five different classification models, LR, SVM, RF, MLP, and KNN, based on four different evaluation metrics, accuracy, F1-score, precision, and recall. The highest accuracy score is obtained by the LR model with a score of 0.87, and SVM follows it with 0.84. However, the LR model performs the highest scores in F1-score, precision, and recall. The RF and MLP models obtain a relatively similar performance in all metrics, where RF performs better in accuracy and F1-score and MLP in precision and recall. The KNN model has the lowest performance in all the metrics compared to other models."
2466,"caption: Comparison of multiple models based on different evaluation metricstable: Model,F1-score,Recall,Precision,Accuracy, SVM,0.88,0.90,0.87,0.91, LR,0.87,0.85,0.89,0.90, KNN,0.70,0.75,0.65,0.78, RF,0.92,0.94,0.90,0.93, XGBoost,0.91,0.92,0.90,0.93","Table presents a comparison of five machine learning models' evaluation metrics in terms of F1-score, recall, precision, and accuracy. The models included in the table are SVM, LR, KNN, RF, and XGBoost. The table shows that RF outperforms all other models as it achieves the highest F1-score (0.92), recall (0.94), precision (0.90), and accuracy (0.93). XGBoost also produces very comparable results, with F1-score, recall, precision, and accuracy of 0.91, 0.92, 0.90, and 0.93, respectively. SVM and LR models achieve a similar but lower accuracy compared to RF and XGBoost models. KNN, however, had the poorest performance compared to all others."
2467,"caption: Table 4: Evaluation of five different models based on accuracy, precision, recall, and F1-Score.table: Model Name,Accuracy (%),Precision (%),Recall (%),F1-Score (%), Model A,87.5,95.0,80.0,87.0, Model B,88.2,94.5,83.0,88.3, Model C,89.0,95.7,84.5,89.5, Model D,85.1,92.2,76.3,82.1, Model E,90.5,97.2,89.7,93.3","Table 4 shows the evaluation results of five different models based on multiple evaluation metrics such as accuracy, precision, recall, and F1-Score. Model E achieved the highest performance in all categories with accuracy of 90.5%, the highest precision of 97.2%, highest recall of 89.7%, and highest F1 score of 93.3%. Model C also performed well with accuracy of 89.0%, precision of 95.7%, recall of 84.5%, and F1 score of 89.5%. Model D had the lowest performance in all categories with accuracy of 85.1%, precision of 92.2%, recall of 76.3%, and F1 score of 82.1%. The results suggest that Model E and Model C show better performance for the given dataset."
2468,"caption: Model performances for binary classification on dataset A using accuracy, F1 score, precision, recall, and AUC metrics.table: Model,Accuracy,F1 Score,Precision,Recall,AUC, Logistic Regression,0.78,0.63,0.72,0.57,0.85, Random Forest,0.85,0.74,0.76,0.72,0.93, Gradient Boosting,0.84,0.73,0.77,0.70,0.92, K-Nearest Neighbors,0.72,0.58,0.63,0.54,0.76",
2469,"caption: Performance comparison of different models using various evaluation metrics.table: Models,Accuracy (%),AUC,Recall,Precision,F1-Score, Model 1,84.3,0.69,0.85,0.84,0.83, Model 2,81.1,0.73,0.84,0.88,0.82, Model 3,85.6,0.78,0.80,0.92,0.85, Model 4,82.2,0.71,0.90,0.77,0.83","Table presents the comparison of four different models' performance in terms of accuracy, AUC, recall, precision, and F1-score, where higher values indicate better performance. Model 3 performed best in terms of accuracy, achieving 85.6%, while Model 2 had the highest AUC of 0.73. Model 4 has the highest recall value of 0.90 despite an accuracy score of 82.2%. Model 3 exhibited the best precision score value of 0.92 and F1-score of 0.85. The table demonstrates that a particular model may be optimal depending on the evaluation metric's requirement."
2470,"caption: Table 4: Performance comparison of different models using various metrics.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.85,0.83,0.84,0.82, Naive Bayes,0.81,0.78,0.76,0.81, Random Forest,0.91,0.91,0.92,0.91, Decision Trees,0.83,0.82,0.82,0.84, MLP,0.89,0.89,0.91,0.87","Table 4 compares the performance of various machine learning models, namely SVM, Naive Bayes, Random Forest, Decision Trees, and MLP, using several evaluation metrics. Models' accuracy, F1-Score, precision, and recall are recorded. Random Forest shows the best results, achieving an accuracy score of 0.91, F1-Score of 0.91, precision of 0.92, and recall of 0.91. Meanwhile, MLP also performs impressively, with a high accuracy score of 0.89 and F1-Score of 0.89. Naive Bayes shows the lowest performance with accuracy, F1-Score, precision, and recall scores of 0.81, 0.78, 0.76, and 0.81, respectively. Overall, these results provide insights into different models' robustness and effectiveness in solving classification problems."
2471,"caption: Performance comparison of different models using multiple evaluation metricstable: Model Name,Accuracy,F1 Score,Precision,Recall, Random Forest,0.920,0.834,0.863,0.834, SVM,0.889,0.734,0.788,0.722, Naive Bayes,0.904,0.810,0.847,0.822, Neural Network,0.918,0.826,0.856,0.817","The table compares the performance of four different models based on multiple evaluation metrics. The models are Random Forest, SVM, Naive Bayes, and Neural Network. The evaluation metrics used in the table are Accuracy, F1 Score, Precision, and Recall. Notably, the Random Forest model shows the best performance results in Accuracy, with a score of 0.920. However, the Naive Bayes model outperforms all other models in Precision with a score of 0.847. The Neural Network model achieved the highest Recall among all models, with a score of 0.817. In terms of F1 Score, all models showcase competent results, with scores ranging from 0.734 to 0.834. Overall, the evaluation metrics demonstrate diverse aspects of model performance, with each model showing unique strengths and weaknesses."
2472,"caption: Performance of different classification models using various evaluation metrics.table: Model,Accuracy,F1-score,AUC-ROC,Precision,Recall, Logistic Regression,0.85,0.79,0.89,0.76,0.83, Random Forest,0.88,0.83,0.92,0.81,0.86, Support Vector Machines,0.86,0.80,0.89,0.77,0.84, Gradient Boosting Classifier,0.89,0.84,0.93,0.82,0.88, Decision Tree,0.80,0.72,0.84,0.70,0.75","The table above highlights the accuracy, F1-score, AUC-ROC, Precision, and Recall of multiple classification models. The models considered include Logistic Regression, Random Forest, Support Vector Machines, Gradient Boosting Classifier, and Decision Tree. The performance metrics used to evaluate the models vary. The Gradient Boosting Classifier model had the highest accuracy of 0.89, while the Decision Tree had the lowest accuracy score of 0.80. The Random Forest model achieved an impressive AUC-ROC score of 0.92. Likewise, the Gradient Boosting Classifier had the highest F1-score of 0.84, while the Decision Tree had the lowest F1-score of 0.72. The models' precision and recall vary widely depending on the model. Overall, the table reveals the variance in metrics used to evaluate the effectiveness of classification models."
2473,"caption: Comparison of different models based on multiple evaluation metrics.table: Model,Accuracy,F1-Score,Recall,Precision,AUC, SVM,0.87,0.78,0.72,0.85,0.91, RF,0.85,0.76,0.71,0.82,0.89, KNN,0.80,0.66,0.63,0.74,0.83, MLP,0.89,0.80,0.75,0.87,0.93, DT,0.76,0.68,0.61,0.80,0.82","The table shows the performance comparison of five different models based on five evaluation metrics, namely Accuracy, F1-Score, Recall, Precision, and AUC. The SVM and MLP models exhibit the highest accuracy scores of 0.87 and 0.89, respectively, while the DT model shows the lowest accuracy of 0.76. The MLP model also shows the highest F1-Score and precision scores of 0.80 and 0.87, respectively, and recall score of 0.75. On the other hand, the KNN model shows the lowest F1-Score of 0.66 and recall score of 0.63. The SVM model has the highest recall of 0.72, while the DT model shows the lowest recall of 0.61. The AUC score indicates how well the models can distinguish between the positive and negative classes, and the MLP model shows the highest AUC of 0.93, followed closely by the SVM model with 0.91."
2474,"caption: Model performance based on different evaluation metrics.table: Model Name,Accuracy,Precision,Recall,F1-score, Model 1,0.85,0.82,0.86,0.84, Model 2,0.81,0.75,0.85,0.79, Model 3,0.87,0.81,0.91,0.86, Model 4,0.72,0.67,0.76,0.71, Model 5,0.90,0.88,0.91,0.89","The table showcases the performance of five different models based on various evaluation metrics, including Accuracy, Precision, Recall, and F1-score, respectively. Model 5 achieved the highest overall performance score with an Accuracy of 0.90 and F1-Score of 0.89. Additionally, all models had varying performances, with Model 1 and Model 3 achieving the highest and lowest Precision scores of 0.82 and 0.81, respectively. Model 3 had the highest Recall score of 0.91, and Model 2 had the lowest Recall score of 0.85. Model 4 had the poorest performance of all models with an Accuracy of 0.72 and F1-Score of 0.71."
2475,"caption: Performance Table for Different Classification Modelstable: **Model**,**Accuracy**,**Precision**,**Recall**,**F1 Score**, Logistic Regression,0.85,0.86,0.89,0.87, Decision Tree,0.81,0.76,0.73,0.74, K-Nearest Neighbor,0.89,0.92,0.91,0.91, Naive Bayes,0.78,0.81,0.59,0.68, Random Forest,0.94,0.94,0.97,0.95","The table above provides us with a comparison of the performance of five different classification models based on various evaluation metrics. The evaluation metrics considered are Accuracy, Precision, Recall, and F1 Score. As we can observe, the Random Forest model has the best overall performance in terms of Accuracy, Precision, Recall, and F1 Score, with scores of 0.94, 0.94, 0.97, and 0.95, respectively. K-Nearest Neighbor is the only model that comes close to the Random Forest in terms of the evaluation metrics considered. Interestingly, the Naive Bayes model, while having low Precision and Recall scores, still managed to have a decent Accuracy score of 0.78."
2476,"caption: Performance comparison of various classification modelstable: Model,Accuracy,F1-score,Precision,Recall, SVM,0.85,0.83,0.87,0.81, KNN,0.78,0.77,0.76,0.78, Naive Bayes,0.72,0.70,0.71,0.69, Decision Tree,0.80,0.78,0.81,0.77, Random Forest,0.88,0.87,0.89,0.85, XGBoost,0.90,0.89,0.91,0.88",
2477,"caption: Table 4: Performance comparison of different predictive models using various evaluation metrics.table: Model,F1-score,Sensitivity,Specificity,Precision, Model A,0.72,0.84,0.59,0.63, Model B,0.68,0.74,0.62,0.61, Model C,0.76,0.81,0.66,0.69, Model D,0.62,0.59,0.68,0.55, Model E,0.69,0.79,0.51,0.56","Table 4 presents the performance comparison of multiple predictive models using four different evaluation metrics, namely F1-score, sensitivity, specificity, and precision. The table displays five models, A to E, and their corresponding performance results. Interestingly, Model C exhibited the best overall performance, with an F1-score of 0.76, sensitivity of 0.81, specificity of 0.66, and precision of 0.69. In contrast, Model D had the lowest F1-score of 0.62 and precision of 0.55, reflecting the model's relatively poor performance. However, Model E achieved a high sensitivity of 0.79, while its precision was the lowest in the table at 0.56. Overall, the table demonstrates the varying performance results of the different models when evaluated by multiple metrics."
2478,"caption: Evaluation metrics for different classification models.table: Model,F1-score,Precision,Recall,ROC-AUC, Logistic Regression,0.87,0.89,0.85,0.92, Naive Bayes,0.78,0.83,0.74,0.85, Random Forest,0.91,0.91,0.91,0.93, K-Nearest Neighbors,0.79,0.76,0.84,0.84, Gradient Boosting,0.94,0.92,0.96,0.97","The above table reports the performance of different classification models based on different evaluation metrics, including F1-score, Precision, Recall, and ROC-AUC. Logistic Regression achieved an F1-score of 0.87, Precision of 0.89, Recall of 0.85, and ROC-AUC of 0.92. Random Forest had the highest F1-score of 0.91, Precision of 0.91, Recall of 0.91, and ROC-AUC of 0.93 among all models. Gradient Boosting outperformed other models in terms of F1-score (0.94), Precision (0.92), Recall (0.96), and ROC-AUC (0.97), showing the best overall performance among all models."
2479,"caption: Table 4: Model performance comparison based on evaluation metrics.table: Models,Accuracy,F1-score,AUC, Model 1,0.87,0.89,0.92, Model 2,0.91,0.93,0.85, Model 3,0.83,0.86,0.90, Model 4,0.95,0.94,0.96, Model 5,0.88,0.91,0.87","Table 4 presents a comparison of the performance of five models based on multiple evaluation metrics, including Accuracy, F1-Score, and AUC. Each model's accuracy score ranges from 0.83 to 0.95. Model 4 has the highest accuracy of 0.95, while model 3 has the lowest accuracy of 0.83. For F1-score, the models achieve similar results, with scores ranging from 0.86 to 0.94. Model 1 has the highest F1-score of 0.89, while Model 3 has the lowest score of 0.86. Concerning the AUC score, the models range from 0.85 to 0.96. Model 4 has the highest AUC of 0.96, while Model 2 has the lowest AUC of 0.85."
2480,"caption: Performance comparison of different models using multiple evaluation metrics.table: Model,Test Accuracy,Precision,Recall,F1 Score,ROC-AUC, Model A,0.78,0.79,0.81,0.75,0.83, Model B,0.82,0.85,0.80,0.82,0.88, Model C,0.75,0.81,0.72,0.74,0.77, Model D,0.90,0.91,0.93,0.91,0.95","The table represents the performance comparison of different models using five different evaluation metrics on the test set. The models included are Model A, Model B, Model C, and Model D. Among the models, Model D exhibits the highest test accuracy of 0.90 with the highest precision of 0.91, recall of 0.93, F1 score of 0.91, and ROC-AUC of 0.95. Interestingly, Model B achieved the second-highest test accuracy of 0.82 and the highest ROC-AUC of 0.88 with 0.85 precision, 0.80 recall, and 0.82 F1 score. Model C has the lowest scores among all models."
2481,"caption: Table 4: Model Performance Comparison based on Different Evaluation Metricstable: Model,F1-Score,Accuracy,Precision,Recall, Logistic Regression,0.82,0.87,0.84,0.80, Support Vector Machine,0.83,0.88,0.85,0.81, Random Forest,0.88,0.91,0.90,0.86, Gradient Boosting Machine,0.90,0.92,0.92,0.89, Multi-layer Perceptron,0.87,0.89,0.88,0.86","Table 4 illustrates different models' performances based on different evaluation metrics. The table includes Logistic Regression, Support Vector Machine, Random Forest, Gradient Boosting Machine, and Multi-layer Perceptron models. The table presents each model's F1-Score, Accuracy, Precision, and Recall. The Gradient Boosting Machine shows the highest F1-Score and Accuracy with 0.90 and 0.92, respectively, while the Random Forest has the highest Precision and Recall with 0.90 and 0.86, respectively. Interestingly, Logistic Regression and Support Vector Machine models have almost similar performance results with slight differences."
2482,"caption: Model Performance Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1-Score,AUC, Model A,0.85,0.92,0.83,0.87,0.91, Model B,0.83,0.89,0.84,0.86,0.89, Model C,0.88,0.91,0.86,0.88,0.92, Model D,0.86,0.88,0.88,0.88,0.88, Model E,0.81,0.85,0.82,0.83,0.86",
2483,"caption: Performance comparison of different models using various evaluation metrics.table: Model,Precision,Recall,F1 Score,Accuracy, Logistic Regression,0.89,0.82,0.85,0.87, Decision Tree,0.79,0.76,0.77,0.80, KNN,0.72,0.65,0.68,0.70, SVM (linear),0.82,0.78,0.80,0.83, SVM (rbf),0.81,0.74,0.77,0.80, Random Forest,0.91,0.88,0.89,0.92, XGBoost,0.93,0.91,0.92,0.93","The table compares the performance of different machine learning models using various evaluation metrics. The metrics used in this comparison are precision, recall, F1-score, and accuracy. Seven popular models are evaluated in this comparison. The best performing model is XGBoost, with a precision score of 0.93, a recall of 0.91, an F1-score of 0.92, and accuracy of 0.93. Similarly, Random forest has also performed well in all the metrics with an F1-score of 0.89, recall of 0.88, a precision score of 0.91, and accuracy of 0.92. Notably, KNN has recorded the lowest score in all the criteria, indicating that the model requires further optimization to enhance its performance."
2484,"caption: Table 4: Model performance based on different evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.72,0.73,0.78,0.72, KNN,0.68,0.70,0.72,0.68, RF,0.82,0.82,0.84,0.82, XGB,0.84,0.83,0.86,0.84, DNN,0.79,0.81,0.80,0.79","Table 4 provides a comparison of different models' performance based on multiple evaluation metrics. The models include SVM, KNN, RF, XGB, and DNN, and the evaluation metrics are Accuracy, F1-score, Precision, and Recall. The table shows that XGB has the best Accuracy score of 0.84, while RF has the highest F1-score of 0.82. XGB also has the highest Precision score of 0.86, and SVM has the highest Recall score of 0.72. Interestingly, the DNN model performs well overall but does not achieve the highest scores in any of the evaluation metrics."
2485,"caption: The comparison of classification models on the given dataset using different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.83,0.62,0.71,0.66, Decision Tree,0.78,0.54,0.58,0.56, Random Forest,0.87,0.75,0.77,0.76, Logistic Regression,0.79,0.58,0.68,0.63, KNN,0.81,0.63,0.62,0.62","Table presents a comparison of different classification models based on the given dataset to measure their accuracy, precision, recall, and F1-score. The models include SVM, Decision Tree, Random Forest, Logistic Regression, and KNN. Notably, the Random Forest model shows the highest accuracy of 0.87, while a Decision Tree model achieves the lowest accuracy of 0.78. Additionally, the Random Forest and Logistic Regression models produced the highest precision and recall values, respectively. However, the KNN model recorded the lowest precision and recall scores. Overall, Random Forest is the best-performing model among the given models as it showed the highest F1-score, indicating robust performance."
2486,"caption: Performance comparison of different machine learning models using various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, LR,0.85,0.88,0.84,0.86, SVM,0.78,0.81,0.79,0.80, KNN,0.72,0.75,0.73,0.74, RF,0.90,0.91,0.90,0.90, GB,0.88,0.89,0.88,0.88, MLP,0.82,0.84,0.82,0.83","Table exhibits the evaluation results obtained from different machine learning models, including LR, SVM, KNN, RF, GB, and MLP. The table shows the accuracy, precision, recall, and F1 score of each model. Random Forest (RF) outperformed all other models, with an accuracy score of 0.90, precision of 0.91, recall of 0.90, and F1 score of 0.90. Notably, Gradient Boosting (GB) had the highest scores for accuracy, precision, and recall, except for F1 score, where LR had the highest result of 0.86. The KNN model had the lowest performance on all metrics among the compared models with the accuracy of 0.72, precision of 0.75, recall of 0.73, and F1 score of 0.74."
2487,"caption: Performance of Various Models on Dataset XYZtable: Model,Accuracy,F1-score,Precision,Recall, SVM,0.89,0.85,0.87,0.83, KNN,0.85,0.81,0.82,0.80, RF,0.91,0.87,0.89,0.86, XGB,0.92,0.88,0.90,0.87, ANN,0.90,0.86,0.88,0.85","The table presents the performance comparison of various models on dataset XYZ based on multiple evaluation metrics such as Accuracy, F1-score, Precision, and Recall. The table reveals that the XGB model achieved the highest performance with an Accuracy of 0.92 and F1-score of 0.88. Random forest follows closely in terms of accuracy with 0.91 and an F1-score of 0.87. In contrast, KNN model shows the lowest performance with an Accuracy of  0.85 and F1-score of 0.81, while ANN attains comparable results with an Accuracy of 0.90 and F1-score of 0.86. The Precision and Recall outcomes were consistent with the Accuracy scores."
2488,"caption: Performance comparison of different models on the evaluation metrics.table: Models,Accuracy,Precision,Recall,F1-score, Decision Tree,0.85,0.82,0.84,0.83, Random Forest,0.91,0.88,0.89,0.89, Gradient Boosting,0.90,0.87,0.87,0.86, K-Nearest Neighbor,0.83,0.84,0.81,0.82, Logistic Regression,0.88,0.86,0.85,0.85","The table above compares the performance of five different classification models: Decision Tree, Random Forest, Gradient Boosting, K-Nearest Neighbor, and Logistic Regression. The table exhibits the models' evaluation metrics, including Accuracy, Precision, Recall, and F1-score. It's observed that the Random Forest model achieved the highest scores in all metrics, with an accuracy score of 0.91, precision score of 0.88, recall score of 0.89, and F1-score of 0.89. The Decision tree and Logistic Regression models also performed well with an accuracy score of 0.85 and 0.88, respectively. The K-Nearest Neighbor model showed the lowest performance among all the models, with an accuracy score of 0.83."
2489,"caption: Table 4: Model Performance based on various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.83,0.87,0.76,0.81, Decision Tree,0.78,0.68,0.83,0.74, Support Vector Machine,0.85,0.89,0.81,0.85, Random Forest,0.88,0.91,0.85,0.88, Multi-Layer Perceptron,0.86,0.89,0.83,0.86","Table 4 examines the performance of different machine learning models concerning various evaluation metrics, including Accuracy, Precision, Recall, and F1-Score. The models used in this experiment include Logistic Regression, Decision Tree, Support Vector Machine, Random Forest, and Multi-Layer Perceptron. The best-performed model, Random Forest, achieved an accuracy of 0.88 and the highest precision of 0.91, while the Logistic Regression model obtained the highest recall of 0.76. Although all models achieved relatively high accuracy scores, the Random Forest and Multi-Layer Perceptron models exhibit the strongest overall performance by achieving the highest F1-Score of 0.88 and 0.86, respectively."
2490,"caption: Table 4: Model Performance Based on Different Evaluation Metrics.table: Model,Precision,Recall,F1 Score,Accuracy, SVM,0.90,0.80,0.85,0.87, Naive Bayes,0.89,0.82,0.84,0.86, Gradient Boosting,0.92,0.87,0.89,0.91, K-NN,0.88,0.77,0.82,0.84, Multilayer Perceptron,0.93,0.92,0.92,0.94","Table 4 showcases the performance of different models based on various evaluation metrics. The performance of each model is represented by Precision, Recall, F1 Score, and Accuracy. The table shows that Multilayer perceptron had the best performance for all evaluation metrics, with its F1 score of 0.92, being the highest among the models in the table. Moreover, the table also highlights that Precision and Recall had the highest values for the Gradient Boosting model. Additionally, SVM, Naive Bayes, and K-NN models' performance is close to each other with accuracy scores of 0.87, 0.86, and 0.84, respectively."
2491,"caption: Comparison of different models' performance based on various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Model A,0.84,0.81,0.62,0.70, Model B,0.82,0.77,0.60,0.68, Model C,0.79,0.73,0.63,0.67","The table presents a comparison of three models (Model A, Model B, and Model C) based on their performance on different evaluation metrics (Accuracy, Precision, Recall, and F1-Score). The best-performing model on accuracy is Model A with a score of 0.84, while Model C has the lowest accuracy score of 0.79. Model A also shows the highest precision score of 0.81, while Model C has the lowest precision score of 0.73. As for recall, Model A has a score of 0.62, while Model C scored the highest on recall with 0.63. Finally, Model A has the highest F1-Score of 0.70, while the lowest score belongs to Model B with a score of 0.68. Overall, Model A appears to be the best-performing model across multiple metrics, while Model C shows a relatively balanced performance."
2492,"caption: Model performance based on different evaluation metricstable: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.85,0.84,0.86,0.83, Decision Tree,0.78,0.76,0.81,0.72, Random Forest,0.91,0.91,0.92,0.90, Support Vector Machine,0.84,0.82,0.85,0.80, Gradient Boosting,0.89,0.89,0.90,0.88","The table above displays the performance of five different models based on multiple evaluation metrics. The evaluation metrics shown in the table are Accuracy, F1-score, Precision, and Recall. The Logistic Regression, Support Vector Machine, and Gradient Boosting models all showcase good accuracy, with the Random Forest model exhibiting the best accuracy of 0.91. The Random Forest model exceeds across all four metrics, with an F1-score, Precision, and recall score of 0.91, 0.92, and 0.90, consecutively. The Decision Tree model exhibits the lowest accuracy of 0.78 and the weakest F1-score, Precision, and Recall scores of 0.76, 0.81, and 0.72. Hence, this table shows that the Random Forest model outperforms the other models in terms of all evaluation metrics evaluated."
2493,"caption: Table 4: Model performance based on different evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score,AUC, Random Forest,0.874,0.908,0.708,0.794,0.934, XGBoost,0.867,0.901,0.681,0.775,0.925, Logistic Regression,0.849,0.874,0.651,0.742,0.907, SVM,0.825,0.860,0.546,0.669,0.895, K-Nearest Neighbor,0.812,0.843,0.488,0.617,0.873","Table 4 shows the performance of five different models evaluated based on the accuracy, precision, recall, F1-score, and AUC. The Random Forest model outperformed the other models in terms of accuracy, precision, and AUC, with the highest accuracy (0.874) and AUC score (0.934) and the second-highest precision score (0.908) after Logistic Regression's (0.874). The XGBoost model also performed well, with the second-highest accuracy (0.867) and AUC score (0.925). However, both SVM and K-Nearest Neighbor models had relatively low recall scores: 0.546 and 0.488, respectively, indicating the models' tendency to miss the positive cases."
2494,"caption: Table 4. Various models' performance based on multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.92,0.93,0.90,0.91, Decision Tree,0.85,0.83,0.88,0.83, Random Forest,0.95,0.95,0.93,0.94, Neural Network,0.91,0.90,0.92,0.91","Table 4 presents the model performances based on multiple evaluation metrics, including accuracy, precision, recall, and F1-score. The table compares the four models: SVM, Decision Tree, Random Forest, and Neural Network. Notably, the Random Forest model had the highest accuracy score of 0.95, while the SVM model had the lowest accuracy score of 0.92. Interestingly, the Random Forest model had high precision with 0.95 and a recall value of 0.93, suggesting the model's strong ability to classify the dataset's positive and negative cases correctly. Additionally, the Neural Network model performed consistently well across all metrics with an F1-score of 0.91."
2495,"caption: Evaluation results of various classification models.table: Model,Accuracy,Recall,Precision,F1 Score, SVM,0.80,0.77,0.85,0.81, KNN,0.76,0.73,0.81,0.76, Random Forest,0.86,0.83,0.90,0.86, Decision Tree,0.81,0.77,0.88,0.82, Logistic Regression,0.83,0.80,0.87,0.84","The table above compares the performance of five different classification models. The models SVM, KNN, Random Forest, Decision Tree, and Logistic Regression were evaluated against four different evaluation metrics: accuracy, recall, precision, and F1 score. Random Forest shows the highest accuracy score of 0.86, while SVM has the highest Recall score of 0.77. Logistic Regression achieves the highest Precision score of 0.87, and Random Forest again takes the lead in F1 score with a score of 0.86. Interestingly, the decision tree model had a high recall and precision score but gets outperformed by other models in overall accuracy and F1 scores."
2496,"caption: Model performances based on different evaluation metrics.table: Model,F1-score,Precision,Recall,AUC-ROC,Accuracy, Logistic Regression,0.84,0.81,0.87,0.92,0.82, Decision Tree,0.72,0.69,0.75,0.78,0.69, Random Forest,0.88,0.87,0.90,0.96,0.87, Linear SVM,0.85,0.91,0.80,0.91,0.82, XGBoost,0.92,0.93,0.91,0.97,0.93","The above table shows the performance of different models based on various evaluation metrics. We have considered five models: Logistic Regression, Decision Tree, Random Forest, Linear SVM, and XGBoost. In terms of f1-score, the XGBoost model outperformed other models, with an f1-score of 0.92. For precision, XGBoost (0.93) and Linear SVM (0.91) reported the highest scores. The Random Forest model received the highest recall score of 0.90. Additionally, the AUC-ROC metric is higher for Random Forest (0.96) and XGBoost (0.97) models compared to the other models. Finally, XGBoost model demonstrated the highest accuracy (0.93)."
2497,"caption: Table 4: Model performance through different evaluation metrics.table: Model,Accuracy,F1 score,AUC, SVM,0.83,0.81,0.92, KNN,0.72,0.64,0.76, RF,0.94,0.92,0.99, MLP,0.91,0.88,0.97, DT,0.80,0.76,0.86, NB,0.62,0.58,0.58","Table 4 represents different models' performances based on multiple evaluation metrics. The models' performances have been evaluated using accuracy, F1 score, and AUC, providing comprehensive insights into each model's strength and weaknesses. Among all models, the Random Forest model exhibits the highest accuracy score of 0.94, followed closely by the Multi-Layer Perceptron (MLP) model with an accuracy score of 0.91. In terms of F1 score, the highest score was produced by the Random Forest model with a score of 0.92, followed by MLP with a score of 0.88. Finally, for AUC, Random Forest once again presented the highest score with 0.99, while KNN showcased the lowest AUC score of 0.76. Overall, Random Forest proved to be the model that yielded the best results across various evaluation metrics."
2498,"caption: Table 4: Model performances based on accuracy, precision, recall, F1-score and AUC.table: Model,Accuracy,Precision,Recall,F1-Score,AUC, Log Reg,0.85,0.86,0.78,0.82,0.92, SVM (linear),0.83,0.82,0.76,0.78,0.89, Decision Trees,0.80,0.81,0.72,0.76,0.88, Random Forest,0.89,0.91,0.86,0.88,0.95, Gradient Boost,0.91,0.92,0.88,0.90,0.96","Table 4 presents a comparison of five different models based on accuracy, precision, recall, F1-score, and AUC. The table displays Log Reg, SVM (linear), Decision Trees, Random Forest, and Gradient Boost models with their respective performance results. Notably, the Random Forest and Gradient Boost models outperformed the rest in all metrics, with a high accuracy of 0.89 and 0.91, respectively. Besides, the Random Forest model achieved the highest AUC score of 0.95, while the Gradient Boost model had a close score of 0.96. The Decision trees model had the lowest accuracy, recall, F1-Score and AUC score of 0.80, 0.72, 0.76, and 0.88, respectively."
2499,"caption: Comparison of performance metrics from different models.table: Model,Accuracy,Precision,Recall,F1-score,AUC-ROC, Model 1,0.93,0.95,0.97,0.96,0.85, Model 2,0.89,0.88,0.95,0.91,0.81, Model 3,0.94,0.96,0.92,0.94,0.87, Model 4,0.85,0.86,0.88,0.87,0.70, Model 5,0.91,0.93,0.94,0.94,0.80","The table provides a comparison of multiple models based on various evaluation metrics, including accuracy, precision, recall, F1-score, and AUC-ROC. Model 1 has the best overall performance with an accuracy score of 0.93 and an F1-score of 0.96. Model 3 also shows excellent results with a precision score of 0.96 and an AUC-ROC of 0.87. Notably, Model 4 has the lowest accuracy score of 0.85 and AUC-ROC score of 0.70. Interestingly, Model 2 shows a good precision score of 0.88 and a high recall score of 0.95. Overall, the table provides an insightful comparison of the models' performances based on multiple evaluation metrics."
2500,"caption: Comparison of performance metrics across different modelstable: Model,Accuracy,Precision,Recall,F1 Score, Decision Tree,0.67,0.64,0.72,0.66, Random Forest,0.78,0.77,0.84,0.80, Logistic Regression,0.8,0.76,0.90,0.82, Neural Network,0.75,0.69,0.84,0.76, Support Vector Machine,0.76,0.68,0.93,0.78","The table represents a comparison of various models' performance metrics, including Accuracy, Precision, Recall, and F1 Score. The table contains five models, namely Decision Tree, Random Forest, Logistic Regression, Neural Network, and Support Vector Machine. The metrics indicate classification models' effectiveness in recognising the label of a given dataset. Out of the five models, Logistic Regression achieved the highest Accuracy score of 0.8 and highest Precision score of 0.76. On the other hand, Support Vector Machine achieved the highest Recall score of 0.93 and noticeably higher than other models. The F1 scores show that Logistic Regression performed the best with F1 score of 0.82, while Decision Tree had the lowest F1 score of 0.66."
2501,"caption: Performance evaluation of different machine learning models.table: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.87,0.83,0.85,0.84, K-Nearest Neighbors,0.81,0.78,0.79,0.78, Decision Tree,0.75,0.73,0.72,0.73, Random Forest,0.89,0.88,0.87,0.88, XGBoost,0.91,0.91,0.90,0.90","The above table depicts the accuracy, precision, recall, and F1-score values of different machine learning models, namely logistic regression, K-nearest neighbors, decision tree, random forest, and XGBoost. The models were trained and tested on the same dataset, and the evaluation metrics were calculated for the test set. XGBoost outperformed all other models with an accuracy score of 0.91, followed by random forest with an accuracy score of 0.89. XGBoost and random forest also had the highest values for the precision, recall, and F1-score metrics, demonstrating their superior performance in the classification task analyzed."
2502,"caption: Table 4: Model Performance Evaluation Metrics on different Modelstable: Model Name,Accuracy,Precision,Recall,F1-Score, Model1,0.547,0.60,0.48,0.52, Model2,0.837,0.95,0.80,0.87, Model3,0.920,0.92,0.95,0.93, Model4,0.635,0.71,0.50,0.59, Model5,0.930,0.95,0.92,0.93","Table 4 compares different models' performance based on evaluation metrics like Accuracy, Precision, Recall, and F1-score. Model3 shows the best result across all the evaluation criteria, with a prediction accuracy of 0.920, precision of 0.92, recall of 0.95, and F1-score of 0.93. Model5 and Model2 also showed good performance, with F1-scores of 0.93 and 0.87, respectively. While Model1 and Model4 showed moderate performance, their F1-scores were 0.52 and 0.59, respectively, indicating that they would require further improvement. Overall, the table highlights the differences in various models' performance on different evaluation metrics, signifying the need for tailored model selection based on the use case."
2503,"caption: Table 4: Model performance based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1,AUC, SVM,0.79,0.84,0.77,0.8,0.73, Decision Tree,0.83,0.89,0.81,0.85,0.74, Random Forest,0.89,0.93,0.88,0.90,0.91, Gradient Boosting,0.91,0.94,0.90,0.92,0.94, Neural Network,0.88,0.91,0.86,0.88,0.91","Table 4 displays the models' performance based on different evaluation metrics such as accuracy, precision, recall, F1, and AUC. The table contains five different models: SVM, Decision Tree, Random Forest, Gradient Boosting, and Neural Network. Notably, the Gradient Boosting model showcases an outstanding performance with an accuracy score of 0.91, precision of 0.94, recall of 0.90, F1 of 0.92, and an AUC of 0.94. The Random Forest model also demonstrated a good performance with a relatively high AUC of 0.91. Overall, this table's results indicate that Gradient Boosting and Random Forest are the most promising models in the task at hand."
2504,"caption: Table 4: Model performance comparison with respect to accuracy, F1-score, precision, and recall.table: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.85,0.88,0.89,0.87, Decision Tree,0.79,0.81,0.83,0.79, Random Forest,0.92,0.93,0.94,0.92, XGBoost,0.91,0.92,0.93,0.92, Support Vector Machine,0.87,0.90,0.91,0.89","Table 4 compares the model performances of Logistic Regression, Decision Tree, Random Forest, XGBoost, and Support Vector Machine based on four evaluation metrics: Accuracy, F1-score, Precision, and Recall. The Random Forest model shows the best performance in all metrics, including accuracy (0.92), F1-score (0.93), Precision (0.94), and Recall (0.92). The XGBoost model follows closely, with comparable results in all metrics. The Logistic Regression and Support Vector Machine models show good performances, especially in terms of precision (0.89 and 0.91, respectively). The Decision Tree model lags behind the other models in all metrics, achieving the lowest accuracy (0.79), F1-score (0.81), Precision (0.83), and Recall (0.79)."
2505,"caption: Table 4: Comparison of multiple different models in terms of their performance metrics.table: Model,Accuracy,Precision,Recall,F1 Score, LogisticRegression,0.85,0.83,0.87,0.85, SVM,0.89,0.91,0.85,0.88, DecisionTree,0.77,0.76,0.79,0.76, RandomForest,0.92,0.91,0.93,0.92, XGBoost,0.93,0.92,0.95,0.93, MLP,0.94,0.94,0.94,0.94","Table 4 shows the comparison of various machine learning models based on their accuracy, precision, recall, and F1 score performance metrics. The models involved in the comparison are Logistic Regression, SVM, Decision Tree, Random Forest, XGBoost, and MLP. The best-performing model based on the accuracy metric is MLP with a score of 0.94, while Random Forest obtained the highest F1 Score with a score of 0.92. Interestingly, the MLP and XGBoost models show almost similar results in all metrics. However, the SVM model portrays the largest difference in recall and precision scores with 0.85 and 0.91, respectively."
2506,"caption: Performance comparison of different models on evaluation metricstable: Model,Accuracy,F1-score,Precision,Recall, Model A,0.83,0.75,0.82,0.69, Model B,0.87,0.81,0.87,0.76, Model C,0.90,0.86,0.90,0.83, Model D,0.85,0.79,0.85,0.73, Model E,0.91,0.87,0.92,0.82","Table depicts the comparison of different models' performances on evaluation metrics such as Accuracy, F1-score, Precision, and Recall. Model A achieved an accuracy of 0.83 and an F1-score of 0.75 with a precision of 0.82 and a recall of 0.69. Model E performed the best among all models with the highest accuracy of 0.91 and the highest F1-score of 0.87. Interestingly, Model C also performed quite well, achieving an accuracy of 0.90 and an F1-score of 0.86. Model C also achieved the highest precision of 0.90 and the second-highest recall of 0.83, second only to Model E in both aspects. Overall, the table helps in selecting the best model for specific evaluation metrics among multiple models."
2507,"caption: Model performance using various evaluation metricstable: Model,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.81,0.82,0.86,0.8, Naïve Bayes,0.72,0.67,0.78,0.62, SVM,0.88,0.89,0.90,0.88, Decision Tree,0.79,0.76,0.75,0.78, Random Forest,0.91,0.92,0.94,0.90","The above table presents the performance of five different models using accuracy, F1-Score, precision, and recall evaluation metrics. The models include Logistic Regression, Naïve Bayes, SVM, Decision Tree, and Random Forest models. The Random Forest model exhibits the best performance across all evaluation metrics, with the highest accuracy of 0.91, the highest F1-Score of 0.92, the highest precision of 0.94, and the highest recall of 0.90. Meanwhile, the SVM model also performs well, achieving high scores in accuracy, F1-Score, and precision. In contrast, the Naïve Bayes model shows the lowest performance across all evaluation metrics."
2508,"caption: Model performance using different evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.85,0.83,0.82,0.83, Decision Tree,0.71,0.62,0.61,0.62, Random Forest,0.92,0.91,0.90,0.91, Naive Bayes,0.80,0.75,0.74,0.74, Support Vector Machines,0.89,0.87,0.86,0.87","The table above presents a comparison of multiple models' performances using different evaluation metrics: Accuracy, Precision, Recall, and F1-Score. The models considered in the analysis include Logistic Regression, Decision Tree, Random Forest, Naive Bayes, and Support Vector Machines. Notably, the Random Forest model achieved the highest Accuracy score of 0.92, followed by Support Vector Machines with a score of 0.89. On the other hand, the Decision Tree model had the least Accuracy score of 0.71. Furthermore, the Random Forest model obtained the highest Precision, Recall, and F1-Score, implying that it performed the best on all the analyzed metrics. However, it's essential to emphasize that considering only one evaluation metric may not be enough to draw performance conclusions."
2509,"caption: Table 4: Model Performance Comparison.table: Model,Accuracy,F1-Score,AUC-ROC,Precision,Recall, Logistic,0.875,0.858,0.940,0.904,0.815, Naive Bayes,0.800,0.723,0.932,0.953,0.610, Decision Tree,0.834,0.810,0.812,0.780,0.899, KNN,0.881,0.867,0.893,0.841,0.902, SVM,0.889,0.878,0.941,0.928,0.832","Table 4 illustrates the comparison of different machine learning models based on multiple evaluation metrics, including Accuracy, F1-Score, AUC-ROC, Precision, and Recall. The table presents the results of five classification models: Logistic, Naive Bayes, Decision Tree, KNN, and SVM. The performance of the models varies from metric to metric. Notably, the KNN model shows the highest Accuracy and F1-Score with scores of 0.881 and 0.867, respectively. At the same time, the SVM model achieved the highest AUC-ROC score of 0.941. However, the Naive Bayes model exhibits the highest Precision score among all the models with a value of 0.953."
2510,"caption: Table 4: Model evaluation metrics comparisontable: Model type,Accuracy,F1 score,Precision,Recall, Model A,0.85,0.81,0.88,0.76, Model B,0.79,0.68,0.72,0.64, Model C,0.91,0.89,0.92,0.87, Model D,0.86,0.84,0.89,0.80, Model E,0.93,0.91,0.94,0.88","Table 4 provides a comparison of different models' evaluation metrics, including Accuracy, F1 score, Precision, and Recall. Five different models have been evaluated to measure their performances. Model E demonstrated the best results across all evaluation metrics, including the highest accuracy of 0.93 and F1 score of 0.91. However, Model C was not far behind; it achieved an accuracy of 0.91 and an F1 score of 0.89. Model A demonstrated the highest Precision score of 0.88. Overall, the table highlights the variability of model performances across different evaluation metrics and emphasizes the importance of considering all metrics when choosing the most optimal model for the task at hand."
2511,"caption: Performance comparison of five different machine learning algorithms using various metrics for binary classification.table: Model,Accuracy,F1 Score,Precision,Recall,AUC Score, Logistic Regression,0.85,0.83,0.85,0.88,0.92, Decision Tree,0.80,0.78,0.75,0.82,0.75, Random Forest,0.91,0.89,0.91,0.92,0.96, Support Vector Machine,0.86,0.85,0.86,0.88,0.92, Multi-Layer Perceptron,0.87,0.86,0.86,0.87,0.93","This table presents the model performances of five machine learning algorithms in binary classification based on multiple evaluation metrics, including accuracy, F1 score, precision, recall, and AUC score. Among all models, Random Forest achieved the highest accuracy (0.91) and AUC score (0.96), indicating its excellent performance in classification. On the other hand, the Decision Tree performed the least among all models with an accuracy of 0.8, showing a need for improvement. Overall, the models exhibited relatively similar performances based on various metrics, necessitating cautious selection between them to optimize classification."
2512,"caption: Performance comparison of Different Models using Multiple Evaluation Metrics.table: Model,Accuracy,Recall,Precision,F1-Score, Model A,0.89,0.85,0.95,0.90, Model B,0.91,0.81,0.98,0.89, Model C,0.92,0.88,0.92,0.90, Model D,0.85,0.94,0.76,0.83, Model E,0.93,0.84,0.98,0.90","The table above presents a performance comparison of five different models based on various evaluation metrics such as accuracy, recall, precision, and F1-Score. All models were trained and evaluated using the same data. Notably, Model E achieved the highest accuracy score of 0.93, while Model D had the highest recall score of 0.94. Model B showed the best precision performance of 0.98, followed closely by Model E with a precision score of 0.98. Finally, Model C had the best F1-Score of 0.90, followed by Model A and E with an F1-score of 0.90 as well."
2513,"caption: Performance comparison of different models on the classification task using multiple evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, LogisticRegression,0.82,0.80,0.86,0.75, Decision Tree,0.72,0.67,0.73,0.62, Random Forest,0.77,0.72,0.76,0.68, XGBoost,0.80,0.76,0.81,0.72","Table presents the performance comparison of different models on the classification task based on different evaluation metrics that include accuracy, F1 Score, precision, and recall. The table includes four models: LogisticRegression, Decision Tree, Random Forest, and XGBoost. The analysis depicts that LogisticRegression has the highest accuracy of 0.82 and precision score of 0.86, while XGBoost has the highest F1 score of 0.76 and recall of 0.72. Besides, Decision Tree shows the lowest performance across all evaluation metrics, obtaining an accuracy, F1 Score, precision, and recall of 0.72, 0.67, 0.73, and 0.62, respectively. Overall, the comparison highlights the model-specific performance and gives valuable insights into model selection for the classification task."
2514,"caption: Performance of Different Classification Models on Evaluation Metrics.table: ```, Accuracy,F1 Score,AUC-ROC, Model 1,0.82,0.79,0.89, Model 2,0.87,0.86,0.93, Model 3,0.91,0.92,0.97, Model 4,0.89,0.85,0.94","The table presents the performance of four different classification models on three evaluation metrics: accuracy, F1 score, and AUC-ROC. The table's observation suggests that Model 3 achieved the best performance with the highest score in all metrics. Specifically, Model 3 achieved 0.91 accuracy, 0.92 F1 score, and 0.97 AUC-ROC. On the other hand, Model 1 had the lowest performance scores in all metrics with accuracy, F1 score, and AUC-ROC scores of 0.82, 0.79, and 0.89, respectively. Overall, the table's displays a clear comparison of the models' performance on the different evaluation metrics."
2515,"caption: Comparison of different models based on Accuracy, Precision, and Recall.table: **Model Name**,**Accuracy**,**Precision**,**Recall**, Logistic Regression,80%,0.73,0.85, Decision Tree,75%,0.63,0.75, Random Forest,86%,0.81,0.91, Gradient Boosting,88%,0.83,0.92","The table presents a comparison of the performance of four machine learning models: Logistic Regression, Decision Tree, Random Forest, and Gradient Boosting. The models were evaluated based on Accuracy, Precision, and Recall metrics. Notably, the Random Forest model outperformed the other models in terms of Accuracy, achieving an 86% accuracy score. The Gradient Boosting model had the highest Accuracy score of 88% and the second-highest Precision and Recall scores of 0.83 and 0.92, respectively. The Logistic Regression model had an Accuracy score of 80% and the highest Precision score of 0.73, while the Decision Tree model had the lowest accuracy of 75%. Overall, the table illustrates the varying performances of each model across multiple evaluation metrics."
2516,"caption: Model performance using different evaluation metrics.table: Model Name,Precision,Recall,F1-score,Support, SVM,0.71,0.82,0.76,192, Logistic Regression,0.63,0.68,0.66,192, Naive Bayes,0.45,0.38,0.41,192, Decision Tree,0.61,0.50,0.55,192, Random Forest,0.80,0.79,0.80,192","Table presents a comparison of five models' performance evaluated by using multiple metrics. The evaluation metrics are precision, recall, F1-score, and support. SVM model achieved the highest precision with 0.71 and the highest recall with 0.82 among the other models. Additionally, Random Forest outperforms others with F1-score and achieved the highest F1-score of 0.80. Interestingly, Naive Bayes model exhibits the difficulties in modeling this classification task and achieved the lowest precision, recall, and F1-score among other models with 0.45, 0.38, and 0.41, respectively."
2517,"caption: Table 4: Comparison of model performance using different evaluation metricstable: Model,F1-score,Accuracy-score,PR-AUC, Logistic Regression,0.83,0.72,0.87, Naive Bayes,0.72,0.65,0.77, Decision Tree,0.91,0.77,0.88, Random Forest,0.94,0.81,0.92","Table 4 presents a comparison of the performance of different models based on three evaluation metrics. The table shows F1-score, accuracy score, and PR-AUC score for Logistic Regression, Naive Bayes, Decision Tree and Random Forest models. Notably, Random Forest attain the highest F1-score with a score of 0.94 and an accuracy score of 0.81. Similarly, the Decision Tree received the highest accuracy score of 0.77, while the Logistic Regression model achieved the highest PR-AUC score of 0.87. Interestingly, the Naive Bayes model had the lowest scores for all three evaluation metrics. Overall, the table shows that different models perform differently based on evaluation metrics, and no single model performs best in all three evaluation metrics."
2518,"caption: Comparison of different models using multiple evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.81,0.79,0.81,0.80, Decision Tree,0.88,0.87,0.88,0.88, Random Forest,0.91,0.90,0.91,0.91, Support Vector Machine,0.78,0.76,0.78,0.77","The table presents a comparison of four different models: Logistic Regression, Decision Tree, Random Forest, and Support Vector Machine(SVM). The models' performances were evaluated based on different metrics, including Accuracy, F1 Score, Precision, and Recall. The Random Forest model achieved the highest results across all evaluation metrics with Accuracy of 0.91, F1 Score of 0.90, Precision of 0.91, and Recall of 0.91. The Decision Tree model also performed well with an Accuracy of 0.88 and F1 Score, Precision, and Recall of 0.87, 0.88, and 0.88, respectively. On the other hand, the Logistic Regression model had the lowest Accuracy of 0.81 and F1 Score, Precision, and Recall of 0.79, 0.81, and 0.80, respectively. Finally, Support Vector Machine (SVM) Model had moderate performance with Accuracy of 0.78 and other metrics (F1 Score, Precision, and Recall) of 0.76, 0.78, and 0.77, respectively."
2519,"caption: Performance comparison of different models with multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score,AUC, Model A,0.85,0.86,0.84,0.85,0.92, Model B,0.88,0.89,0.87,0.88,0.94, Model C,0.92,0.91,0.94,0.92,0.95, Model D,0.78,0.79,0.75,0.76,0.87","The table provides a performance comparison of four different models, namely Model A, Model B, Model C, and Model D. The table presents their accuracy, precision, recall, F1-score, and AUC. Model C showed the best overall performance with an accuracy of 0.92, precision of 0.91, recall of 0.94, F1-score of 0.92, and AUC of 0.95. Model B had the highest AUC of 0.94, while Model D had the lowest performance across all evaluation metrics. The table highlights that Model C is the most effective model based on overall performance across all evaluation metrics."
2520,"caption: Performance metrics of different machine learning models.table: Model,Precision,Recall,F1-score,Accuracy, SVM,0.80,0.75,0.77,0.85, KNN,0.72,0.79,0.75,0.80, Naive Bayes,0.87,0.63,0.73,0.83, Decision Tree,0.67,0.64,0.65,0.72","The table compares four different machine learning models' performances based on four evaluation metrics: Precision, Recall, F1-score, and Accuracy. The evaluation metrics were obtained using the same dataset. SVM achieved the best precision score, while Naive Bayes achieved the best F1-score. KNN obtained the highest recall score, followed closely by SVM, while Decision Tree had the lowest recall score. Accuracy score shows that SVM has the most accurate model."
2521,"caption: Comparison of different machine learning models based on evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.80,0.75,0.80,0.73, Random Forest,0.82,0.77,0.85,0.81, XGBoost,0.85,0.80,0.87,0.83, Multilayer Perceptron,0.78,0.74,0.81,0.75, Support Vector Machine,0.81,0.76,0.84,0.80","The table presents the performance results of various machine learning models. The models include Logistic Regression, Random Forest, XGBoost, Multilayer Perceptron, and Support Vector Machines. The evaluation metrics considered are Accuracy, Precision, Recall, and F1-Score. Based on the results, XGBoost achieved the highest accuracy of 0.85, while Random Forest achieved the highest Precision (0.77) and Recall (0.85). Furthermore, the F1-Scores for all models are relatively close, with XGBoost having the highest F1-Score of 0.83, followed closely by the Random Forest model (0.81). Overall, the Random Forest and XGBoost models demonstrate superior performance compared to the other models."
2522,"caption: Table 4: Model evaluation metrics across different models.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic regression,0.867,0.870,0.780,0.822, Support Vector Machine,0.876,0.890,0.780,0.832, Random Forest,0.882,0.900,0.810,0.853, XGBoost,0.895,0.920,0.825,0.870","Table 4 shows the model evaluation metrics of four models: Logistic regression, Support Vector Machine, Random Forest, and XGBoost. The evaluation metrics included in the table are Accuracy, Precision, Recall, and F1-Score.  The models were evaluated on a single dataset. The XGBoost model achieved the highest accuracy of 0.895, followed by the Random Forest with 0.882 accuracy. The highest precision score was achieved by XGBoost with 0.92, and the highest recall score achieved was 0.825 by XGBoost as well. Finally, XGBoost achieved the highest F1-Score of 0.870."
2523,"caption: Table 4: Model performance comparison based on different evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.89,0.8,0.87,0.75, Random Forest,0.91,0.82,0.86,0.78, Support Vector Machine,0.87,0.76,0.82,0.71, XGBoost,0.92,0.85,0.89,0.81, Multi-Layer Perceptron,0.90,0.83,0.87,0.79","Table 4 compares the performance of different models based on multiple evaluation metrics, namely Accuracy, F1-score, Precision, and Recall. The table shows that XGBoost performs the best in terms of accuracy with a score of 0.92, followed by Random Forest with a score of 0.91. XGBoost also achieved the highest F1-score of 0.85, whereas Random Forest and Multi-Layer Perceptron models were relatively close. Logistic Regression accomplished the highest precision score of 0.87, while SVM had the highest recall of 0.71. While each model performs differently, the table highlights the best performing model based on each evaluation metric."
2524,"caption: Model Performance Metrics for Different Classification Modelstable: Model,Accuracy,Precision,Recall,F1-score,AUC, Logistic Regression,0.89,0.85,0.82,0.83,0.92, Random Forest,0.92,0.90,0.85,0.87,0.94, Decision Tree,0.85,0.76,0.79,0.75,0.88, XGBoost,0.93,0.92,0.87,0.89,0.95, Multilayer Perceptron,0.91,0.88,0.84,0.86,0.93","Table showing the performance of different classification models evaluated using accuracy, precision, recall, F1-score, and AUC metrics. The table shows that XGBoost achieved the best overall performance across all metrics, with an accuracy of 0.93, precision of 0.92, recall of 0.87, F1-score of 0.89, and AUC of 0.95. Logistic regression achieved the best precision (0.85), whereas the random forest model exhibited the highest recall (0.85). Interestingly, the multilayer perceptron model showed good performance across all metrics and achieved an accuracy of 0.91 and an AUC of 0.93. The decision tree model performed the worst among the models, achieving the lowest accuracy, recall, F1-score, and AUC."
2525,"caption: Model performance using different evaluation metrics.table: Model,F1-score,Accuracy,Precision,Recall, Logistic Regression,0.86,0.88,0.85,0.87, Random Forest,0.88,0.91,0.89,0.87, Support Vector Machine,0.89,0.92,0.92,0.86, Neural Network,0.87,0.90,0.85,0.89, k-Nearest Neighbor,0.84,0.86,0.81,0.87","The table presents the performance of various models using different evaluation metrics such as F1-score, Accuracy, Precision, and Recall. The evaluation was done on the same dataset. The models include Logistic Regression, Random Forest, Support Vector Machine, Neural Network, and k-Nearest Neighbor. The Support Vector Machine shows the highest F1-score and Accuracy scores with a value of 0.89 and 0.92, respectively. However, it has the lowest Recall score of 0.86. The Random Forest model has the highest precision score of 0.89 and scored an F1-score of 0.88 and Accuracy score of 0.91. The k-Nearest Neighbor model has the lowest scores in all the metrics."
2526,"caption: Table 4: Model Performance based on Different Metricstable: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.85,0.79,0.80,0.79, KNN,0.75,0.63,0.64,0.62, MLP,0.82,0.74,0.73,0.72, DT,0.72,0.67,0.60,0.63, RF,0.87,0.81,0.82,0.81","Table 4 provides a performance comparison of five different models - Support Vector Machines (SVM), K-Nearest Neighbor (KNN), Multi-Layer Perceptron (MLP), Decision Tree (DT), and Random Forest (RF) - based on different metrics, including Accuracy, Precision, Recall, and F1-Score. Notably, RF achieved the highest accuracy of 0.87. SVM had the highest precision of 0.79, while RF had the highest recall of 0.82. Focusing on the F1-Score, RF had the best-performing model with a score of 0.81. Overall, RF shows the best results compared to other models, indicating its effectiveness in the given problem domain."
2527,"caption: Comparison of Model A, Model B, and Model C performance across multiple evaluation metrics.table: Metric,Model A,Model B,Model C, Accuracy,0.85,0.92,0.87, Precision,0.80,0.95,0.81, Recall,0.89,0.84,0.92, F1-score,0.84,0.89,0.86, Area under ROC,0.95,0.97,0.94","This table presents a comparison of three different models' performance, Model A, Model B, and Model C, evaluated across multiple metrics. The evaluation metrics include Accuracy, Precision, Recall, F1-Score, and Area under ROC, which are commonly used to evaluate classification models. Model B exhibits the best performance across all evaluation metrics, with the highest Accuracy (0.92), Precision (0.95), F1-Score (0.89), and Area under ROC (0.97) scores. Notably, Model A and Model C scored closest in terms of evaluation metrics, except for Area under ROC, where Model C scored the poorest (0.94). These results suggest that Model B likely outperforms Model A and Model C in classifying the target variable."
2528,"caption: Comparison of various machine learning models using different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.92,0.90,0.94,0.92, KNN,0.84,0.83,0.85,0.84, Random Forest,0.95,0.94,0.96,0.95, Naive Bayes,0.73,0.72,0.77,0.74, MLP,0.90,0.88,0.92,0.90","The presented table provides a clear comparison of different machine learning models' performances in terms of various evaluation metrics: Accuracy, Precision, Recall, and F1-Score. The models included in the table are SVM, KNN, Random Forest, Naive Bayes, and MLP. The table shows that the Random Forest achieved the best overall performance in all evaluation metrics with an accuracy of 0.95, precision of 0.94, recall of 0.96, and F1-Score of 0.95. Interestingly, the Naive Bayes model shows relatively weak overall performance compared to other models with an accuracy of 0.73, precision of 0.72, recall of 0.77, and F1-Score of 0.74."
2529,"caption: Table 4: Model performances based on accuracy, f1-score, precision, recall, ROC-AUC, and PR-AUC.table: Model,Accuracy,f1-score,Precision,Recall,ROC-AUC,PR-AUC, Logistic Regression,0.82,0.78,0.84,0.75,0.84,0.64, Decision Tree,0.75,0.68,0.71,0.71,0.68,0.45, Random Forest,0.87,0.81,0.89,0.74,0.88,0.57, Gradient Boosting,0.89,0.83,0.90,0.76,0.89,0.65, Support Vector,0.78,0.74,0.79,0.69,0.77,0.54","Table 4 compares the performance of five machine learning models, namely Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Support Vector. The table reports the models' accuracy, f1-score, precision, recall, ROC-AUC, and PR-AUC evaluation metrics. Gradient Boosting shows the best performance across most measures, with its highest accuracy and f1-score of 0.89 and 0.83, respectively, while Random Forest has the highest precision, 0.89. However, Logistic Regression achieved the highest PR-AUC score of 0.64. This table shows that each model has its strengths, and the appropriate model should be selected based on the problem requirement."
2530,"caption: Performance evaluation of different classification models on the datasettable: Model,Precision,Recall,F1-score,Accuracy, Logistic Regression,0.80,0.76,0.78,0.85, Naive Bayes,0.74,0.82,0.78,0.81, Decision Tree,0.81,0.79,0.80,0.86, Random Forest,0.83,0.85,0.84,0.87, XGBoost,0.87,0.88,0.87,0.90","Table 4 presents the performance evaluation of five distinct classification models, namely Logistic Regression, Naive Bayes, Decision Tree, Random Forest, and XGBoost, using multiple evaluation metrics such as precision, recall, F1-score, and accuracy. The table shows that all models performed well, with accuracy ranging between 0.81 to 0.90. The XGBoost model performed the best with the highest precision score of 0.87, recall score of 0.88, F1-score of 0.87, and accuracy of 0.90. The Random Forest model also showed good performance with a precision score of 0.83, recall score of 0.85, F1-score of 0.84, and accuracy of 0.87. The Naive Bayes model had the lowest accuracy score of 0.81 but still achieved a decent F1-score of 0.78."
2531,"caption: Performance Metrics for Different Machine Learning Modelstable: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.827972,0.787547,0.787031,0.882, Logistic Regression,0.823021,0.776102,0.779788,0.869999, Naive Bayes,0.804588,0.685778,0.75688,0.636, Decision Tree,0.781222,0.686868,0.66485,0.711666, Random Forest,0.839129,0.803306,0.814639,0.87083","This table summarizes the performance of five different machine learning models using different evaluation metrics, namely Accuracy, F1 Score, Precision, and Recall. SVM and Random Forest produced the highest accuracy of 82.8% and 83.9%, respectively. Random Forest also had the highest F1 score of 0.803, while Logistic Regression had the lowest F1 score of 0.776. Interestingly, Naive Bayes had the highest Precision of 0.756 but had the lowest Recall of 0.636. Overall, the table indicates that SVM and Random Forest are the best models for this particular dataset."
2532,"caption: Comparison of accuracy, precision, recall, and F1-Score for various classification models.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.95,0.91,0.90,0.91, Random Forest,0.96,0.93,0.93,0.93, Decision Tree,0.89,0.85,0.84,0.84, Naive Bayes,0.88,0.82,0.89,0.83, Support Vector Machine,0.94,0.91,0.90,0.91","The table highlights the comparison of accuracy, precision, recall, and F1-Score for five different classification models. The models are Logistic Regression, Random Forest, Decision Tree, Naive Bayes, and Support Vector Machine. It can be observed that Random Forest has the highest accuracy of 0.96, while Decision Tree has the lowest accuracy of 0.89. In terms of precision, Random Forest and Logistic Regression provide the highest precision score of 0.93 and 0.91, respectively. Naive Bayes's recall score is 0.89, which is higher than other models, while Decision Tree has the lowest recall score of 0.84. Lastly, F1-Score shows Random Forest is the best-performing model with a score of 0.93, while Decision Tree has the lowest F1-Score of 0.84."
2533,"caption: Comparison of Multiple Models Based on Different Evaluation Metrics.table: Metric,Model1,Model2,Model3,Model4,Model5, F1-score,0.71,0.63,0.65,0.78,0.53, Accuracy,0.83,0.79,0.72,0.89,0.65, Precision,0.78,0.67,0.58,0.89,0.75","The table above highlights the comparison of multiple models across different evaluation metrics. Five models are presented in the table, and the performance is reported in terms of F1-score, accuracy, and precision. Model 4 demonstrates the best performance in F1-score with a score of 0.78, followed by model 1 with a score of 0.71. In terms of accuracy, model 4 again outperforms others with a score of 0.89. For precision, model 4 shows the best performance with a score of 0.89, while model 5 has the lowest performance with a score of 0.75. Overall, the table suggests that model 4 is the best-performing model across all evaluation metrics."
2534,"caption: Table 4: Model performance based on different evaluation metrics in binary classification.table: Model Name,Accuracy,Precision,Recall,F1,G-Mean, Model 1,0.94,0.96,0.92,0.94,0.94, Model 2,0.92,0.95,0.90,0.92,0.92, Model 3,0.93,0.94,0.93,0.93,0.93, Model 4,0.91,0.91,0.87,0.89,0.91, Model 5,0.95,0.97,0.95,0.96,0.94, Model 6,0.90,0.88,0.84,0.86,0.90","Table 4 presents the performance of six different models based on various evaluation metrics for binary classification. The evaluation metrics include Accuracy, Precision, Recall, F1-score, and G-Mean, with each model's corresponding score in each metric represented in the table. We can observe that Model 5 performed the best, achieving the highest accuracy of 0.95, precision of 0.97, recall of 0.95, F1-score of 0.96, and G-Mean of 0.94. Contrarily, Model 6 achieved the lowest performance in all the evaluation metrics. Overall, these results suggest that Model 5 could be the best choice for binary classification."
2535,"caption: Model performance on test data using multiple evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, Logistic,0.82,0.71,0.80,0.64, SVM,0.81,0.70,0.78,0.64, Random Forest,0.87,0.77,0.86,0.70, Gradient Boosting,0.89,0.81,0.89,0.75, XGBoost,0.88,0.79,0.87,0.72","The table presents the performance of different models on test data evaluated using accuracy, F1-score, precision, and recall evaluation metrics. The results demonstrate that Gradient Boosting has the best accuracy of 0.89, while Random Forest had the highest F1-score with a score of 0.77. Regarding precision, Gradient Boosting, Random Forest, and XGBoost models showed similar performances with scores of 0.89, 0.86, and 0.87, respectively. On the other hand, the SVM and Logistic Regression models were better regarding recall's prediction with scores of 0.64 and 0.70, respectively. Overall, the models showed competitive results with each other, and the selection of the best model for deployment would require deeper analysis of application-specific requirements."
2536,"caption: Performance metrics of different machine learning modelstable: Model,Accuracy,F1-Score,Precision,Recall, Model A,0.78,0.64,0.71,0.63, Model B,0.82,0.70,0.72,0.78, Model C,0.75,0.62,0.67,0.65, Model D,0.85,0.72,0.76,0.79, Model E,0.88,0.78,0.81,0.78","The table displays the performance of different machine learning models based on Accuracy, F1-Score, Precision, and Recall. Model E achieved the highest accuracy of 0.88, while Model A has the lowest accuracy at 0.78. Model B has the highest F1-score of 0.70, followed by Model D with 0.72. In terms of precision, Model E obtained the highest precision of 0.81, and Model D was also noteworthy with a 0.76 score. Model B got the highest recall score of 0.78, which indicates that it has the best ability to identify all relevant instances of data."
2537,"caption: Performance Metrics of Classification Modelstable: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.90,0.91,0.92,0.90, Random Forest,0.92,0.92,0.90,0.94, Support Vector Machine,0.89,0.90,0.91,0.89, K-Nearest Neighbors,0.87,0.88,0.86,0.92, Decision Tree,0.89,0.89,0.87,0.91","The table presents the accuracy, F1 score, precision, and recall of five classification models: Logistic Regression, Random Forest, Support Vector Machine, K-Nearest Neighbors, and Decision Tree. All models have been evaluated on the same dataset. The Random Forest model performs the best with an accuracy score of 0.92 and F1 score of 0.92, while K-Nearest Neighbors model performed the worst with an accuracy score of 0.87 and F1 score of 0.88, respectively. Logistic Regression showed the highest precision of 0.92, while the Random Forest model showed the highest recall of 0.94. Overall, the Random Forest model appears to be the best performer of the five classification models based on the evaluated metrics."
2538,"caption: Comparison of Different Models Performance based on Classification Metricstable: Model,Accuracy (%),Precision (%),Recall (%),F1 Score (%), Logistic Regression,82.4,83.1,80.8,81.9, Support Vector Machines,83.9,82.3,84.9,83.6, Random Forest,88.1,87.9,87.3,87.6, K-Nearest Neighbors,85.7,84.6,85.1,84.9, Neural Network,88.5,88.8,87.3,87.9","The table above compares the performance of five different classification models based on various evaluation metrics. These metrics include accuracy, precision, recall, and F1 score, which are commonly used to evaluate classification models. The five different models are Logistic Regression, Support Vector Machines, Random Forest, K-Nearest Neighbors, and Neural Network. Based on the results, the Neural Network model achieved the highest accuracy score of 88.5%, while the Logistic Regression model achieved the lowest with 82.4%. The Random Forest model achieved the highest precision and recall score of 87.9% and 87.3%, respectively. Additionally, the F1 score ranges from 81.9% to 87.9%, indicating considerable differences in performance among the different models and the importance of careful model selection."
2539,"caption: Model's classification performance based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, CNN,0.87,0.80,0.89,0.84, SVM,0.80,0.78,0.69,0.73, MLP,0.92,0.85,0.94,0.89, LR,0.78,0.66,0.81,0.72, RF,0.84,0.76,0.87,0.81","The table shows the performance of five different models - CNN, SVM, MLP, LR, and RF based on different evaluation metrics - accuracy, precision, recall, and F1-score. MLP achieved the highest accuracy with 0.92, followed by CNN with 0.87. However, CNN obtained the best performance in precision (0.80) and recall (0.89). MLP achieved the best performance in F1-score with 0.89, followed by CNN with 0.84. LR performed the worst with the lowest scores in accuracy, precision, and F1-score. On the other hand, SVM performed poorly regarding recall. Interestingly, RF showed good performance in all metrics without outperforming any other model in any specific metric."
2540,"caption: Model performances comparison using multiple metrics.table: Model,Accuracy,F1 score,Precision,Recall, LR,0.87,0.85,0.88,0.84, SVM (linear kernel),0.85,0.83,0.86,0.82, SVM (rbf kernel),0.82,0.80,0.85,0.76, RF,0.90,0.89,0.91,0.88, XGB,0.92,0.91,0.92,0.91",
2541,"caption: Performance comparison of different machine learning models for binary classification task.table: Model,Accuracy,Precision,Recall,F1 Score, Decision Tree,0.81,0.73,0.70,0.71, Random Forest,0.92,0.87,0.86,0.86, Support Vector Machine,0.89,0.85,0.78,0.79, Logistic Regression,0.94,0.92,0.90,0.91","The table presents the performances of different machine learning models based on multiple evaluation metrics, namely accuracy, precision, recall, and F1 Score, for a binary classification task. The models compared are Decision Tree, Random Forest, Support Vector Machine, and Logistic Regression. The Random Forest model shows the highest accuracy of 0.92, while Logistic Regression achieves the highest precision, recall, and F1 Score values of 0.92, 0.90, and 0.91, respectively. These results demonstrate the importance of carefully selecting the appropriate machine learning model based on the evaluation metrics of interest in a given classification task."
2542,"caption: Model performance measured using different evaluation metrics.table: Model,Precision,Recall,F1-score, Decision tree,0.71,0.68,0.67, Random forest,0.83,0.72,0.77, SVM,0.79,0.67,0.72, XGBoost,0.87,0.81,0.84, Adaboost,0.80,0.75,0.76, Neural Network,0.89,0.84,0.86","The table above shows the evaluation metrics of Precision, Recall, and F1-score of different models used in the classification task. The Decision tree model shows a Precision score of 0.71, Recall score of 0.68, and F1-score of 0.67. The Random forest model scores the highest in Precision metric with a score of 0.83, while the Neural Network model excelled in Precision metric with a score of 0.89. The Adaboost model shows a balanced performance in all metrics. This table could provide insight into the model's strengths or areas for improvement while selecting the appropriate model for the desired task."
2543,"caption: Comparison of performance results for different models.table: Model name,F1-Score,Precision,Recall,Train Time, Model A,0.76,0.79,0.74,362 sec, Model B,0.78,0.82,0.76,478 sec, Model C,0.72,0.87,0.62,836 sec, Model D,0.81,0.75,0.86,667 sec","Table presents a comparison of model performances in terms of F1-score, Precision, Recall, and Training time. The table shows four different models, namely Model A, Model B, Model C, and Model D. Model B exhibited the highest F1-score of 0.78 and the highest Precision of 0.82. On the other hand, Model D achieved the highest Recall of 0.86. Additionally, Model C shows the highest Precision value of 0.87. Regarding training time, Model A took the lowest time of 362 seconds, while Model C took the highest training time of 836 seconds. Overall, Model B performed best, achieving good scores across the metrics compared to other models, except Recall."
2544,"caption: Table 4: Model performance comparison using different evaluation metricstable: Model,Accuracy,F1-score,Precision,Recall, SVM with RBF kernel,0.972,0.972,0.971,0.974, Decision Tree Classifier,0.920,0.918,0.921,0.916, Random Forest Classifier,0.984,0.985,0.982,0.989, Logistic Regression,0.940,0.938,0.936,0.942, Multilayer Perceptron,0.965,0.964,0.964,0.965","Table 4 presents a comparison of different machine learning models in terms of their performance on multiple evaluation metrics. The models compared are SVM with RBF kernel, Decision Tree Classifier, Random Forest Classifier, Logistic Regression, and Multilayer Perceptron. The evaluation metrics considered are Accuracy, F1-score, Precision, and Recall. The highest accuracy and F1-score were achieved by the Random Forest Classifier with 0.984 and 0.985, respectively. The best precision score was achieved by SVM with RBF kernel, while the best recall score was achieved by Random Forest Classifier. The results suggest that Random Forest Classifier is the best performing model overall."
2545,"caption: Comparison of different models based on various evaluation metrics.table: Model,Accuracy,F1 Score,Sensitivity,Specificity, Logistic Regression,0.8758,0.8797,0.8531,0.8989, SVM,0.8546,0.8432,0.8201,0.8787, Random forest,0.9072,0.9061,0.8836,0.9308, KNN,0.8335,0.8216,0.7856,0.8587, Decision tree,0.8772,0.8745,0.8721,0.8826","The table compares the performances of different models using evaluation metrics such as accuracy, F1 score, sensitivity, and specificity. The models listed are Logistic regression, SVM, Random forest, KNN, and Decision tree. Random forest achieved the highest accuracy score of 0.9072, followed closely by Decision tree with an accuracy score of 0.8772. Notably, Random forest also showed the highest F1 score of 0.9061 and sensitivity score of 0.8836. Logistic regression performed well in specificity, with a score of 0.8989. KNN showed the lowest accuracy of 0.8335, and the lowest sensitivity of 0.7856. Overall, Random forest performed the best among all the models."
2546,"caption: Table 4: Performance comparison of different models based on multiple evaluation metrics.table: Model,Precision@1,Precision@3,Accuracy,F1-score, Model 1,0.86,0.70,0.75,0.78, Model 2,0.83,0.68,0.80,0.77, Model 3,0.87,0.71,0.73,0.80, Model 4,0.91,0.76,0.78,0.82, Model 5,0.80,0.63,0.70,0.73","Table 4 showcases the performance comparison of five different models based on four different evaluation metrics: Precision@1, Precision@3, Accuracy, and F1-score. The table highlights that Model 4 outperformed the other models in all metrics, with the highest Precision@1 of 0.91, Precision@3 of 0.76, Accuracy of 0.78, and F1-score of 0.82. Model 1, Model 2, and Model 3 obtained good performance scores and were relatively close in their results. However, Model 5 struggled to achieve competitive results, with the lowest scores in all metrics among the compared models."
2547,"caption: Performance comparison of different models using multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Model A,0.89,0.85,0.92,0.88, Model B,0.91,0.90,0.91,0.90, Model C,0.87,0.92,0.82,0.87, Model D,0.93,0.94,0.92,0.93","Table presents the performance comparison of four different models, Model A, B, C, and D, using multiple evaluation metrics, including accuracy, precision, recall, and F1 score. The models were evaluated using the same dataset to ensure a fair comparison. Model D achieved the highest overall performance with an accuracy of 0.93 and F1 score of 0.93. Model C, on the other hand, achieved the highest precision of 0.92, while Model A had the highest recall of 0.92. The results show that different models have varying performance on different evaluation metrics, providing useful insights for model selection and improvement."
2548,"caption: Performance comparison of different models using multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score,AUC, SVM,0.82,0.78,0.88,0.83,0.94, Logistic Regression,0.79,0.75,0.85,0.79,0.92, Random Forest,0.85,0.81,0.90,0.85,0.93, K-Nearest Neighbor,0.77,0.72,0.81,0.75,0.89, Decision Tree,0.74,0.65,0.78,0.71,0.86","The table displays the accuracy, precision, recall, F1-Score, and AUC for five different models: SVM, Logistic Regression, Random Forest, K-Nearest Neighbor, and Decision Tree. The best performer for accuracy was Random Forest with a score of 0.85. Similarly, Random Forest showed the best performance for Precision (0.81) and AUC (0.93). However, the SVM model shows the best Recall with a score of 0.88, while the Logistic Regression model demonstrated the best F1-score of 0.79. Overall, the results suggest that Random Forest is the best-performing model among the five models."
2549,"caption: Model Performance on Different Evaluation Metricstable: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.85,0.82,0.82,0.84, Decision Tree,0.81,0.75,0.74,0.76, Random Forest,0.87,0.85,0.85,0.86, Gradient Boosting,0.88,0.87,0.86,0.89, Artificial Neural Net,0.89,0.88,0.87,0.90, Support Vector Machine,0.78,0.75,0.76,0.74","The table presents the performances of six different models, namely Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, Artificial Neural Net, and Support Vector Machine. The models were evaluated on multiple metrics, including Accuracy, F1 Score, Precision, and Recall. Interestingly, all models exhibit high accuracy, with the Artificial Neural Network delivering the best score of 0.89. On the other hand, the Decision Tree model demonstrates the weakest performance, with the lowest values in the four metrics. The Gradient Boosting model also exhibits notable performance, with high scores in the four metrics, except for the Precision, where it records 0.86, lower than the Random Forest's score of 0.85. The Support Vector Machine model delivers the lowest Accuracy score of 0.78, while the Random Forest and Gradient Boosting models lead with an Accuracy score of 0.87 and 0.88 consecutively."
2550,"caption: Comparison of Model Performance Based on Various Evaluation Metricstable: Model,Accuracy,F1 Score,Precision,Recall, Model 1,0.85,0.86,0.87,0.86, Model 2,0.84,0.85,0.85,0.86, Model 3,0.84,0.84,0.87,0.81, Model 4,0.88,0.89,0.90,0.87, Model 5,0.89,0.89,0.90,0.88","The table compares the performance of five different models with different evaluation metrics, namely Accuracy, F1 Score, Precision, and Recall. Model 1 and Model 2 both show similar results, with an accuracy of 0.85 and 0.84, respectively. However, Model 1 has a higher F1 score, Precision, and Recall compared to Model 2. Model 3 achieved an accuracy score of 0.84, while its F1 Score, Precision, and Recall are lower than Model 1. Model 4 shows the highest accuracy (0.88) among the five models and maintains a high F1 Score, Precision, and Recall. Finally, Model 5 displays an accuracy score of 0.89, slightly better than Model 4, but with a similar F1 score, Precision, and Recall. Overall, Model 4 and Model 5 show the best performance in all evaluation metrics."
2551,"caption: Performance Comparison of Different Models based on Various Metricstable: Models,F1 Score,Precision,Recall,Accuracy, Model 1,0.81,0.86,0.77,0.82, Model 2,0.87,0.89,0.85,0.88, Model 3,0.66,0.71,0.62,0.68, Model 4,0.92,0.93,0.91,0.92, Model 5,0.78,0.79,0.77,0.79, Model 6,0.95,0.93,0.97,0.94","The table above presents a comparison of multiple models' performance results based on various evaluation metrics such as F1 score, precision, recall, and accuracy. The table includes six different models, all tested on the same dataset. model 6 shows the highest F1 score of 0.95, with precision of 0.93 and recall of 0.97, whereas model 3 exhibits the lowest F1 score (0.66) with precision of 0.71 and recall of 0.62. Model 4 shows the highest precision (0.93), recall (0.91), and accuracy (0.92) compared to all other models. In contrast, Model 5 exhibits the lowest precision (0.79), and accuracy (0.79) among all models."
2552,"caption: Model Performance Metrics Tabletable: Model,Accuracy,Precision,Recall,F1-score, SVM,0.89,0.90,0.87,0.88, KNN,0.82,0.83,0.79,0.81, Naive Bayes,0.73,0.75,0.70,0.72, Random Forest,0.95,0.96,0.94,0.95, XGBoost,0.94,0.95,0.93,0.94",
2553,"caption: Model Performance Comparison based on Various Evaluation Metrics.table: Model,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.87,0.78,0.82,0.84, Support Vector Machine,0.85,0.80,0.78,0.82, Decision Tree,0.82,0.71,0.75,0.69, Random Forest,0.92,0.87,0.91,0.84, XGBoost Classifier,0.94,0.90,0.91,0.91","Table presents the results of different classification models based on multiple evaluation metrics. These models include Logistic Regression, Support Vector Machine, Decision Tree, Random Forest, and XGBoost. The evaluation metrics used are Accuracy, F1-Score, Precision, and Recall. Interestingly, Random Forest and XGBoost classifiers exhibit the highest Accuracy with 0.92 and 0.94, respectively. Similar to Accuracy, F1-Score, Precision and Recall for Random Forest and XGBoost were also the highest among all the models. Precision for Logistic Regression is the second-best with 0.82, while Recall for XGBoost shows the highest score with 0.91. The results show that Random Forest and XGBoost are outperforming other models for all evaluation metrics."
2554,"caption: Performance of Different Models on Classification Task using Multiple Evaluation Metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Naive Bayes,0.87,0.91,0.87,0.88, Decision Tree,0.9,0.93,0.9,0.9, SVM,0.92,0.95,0.91,0.93, Random Forest,0.93,0.95,0.93,0.94","The table displays a comparison of four different models' performance on a classification task using four different evaluation metrics. The evaluation metrics include accuracy, precision, recall, and F1-Score. The different models compared include Naive Bayes, Decision Tree, SVM, and Random Forest. The results show that all models perform reasonably well with accuracy ranging from 0.87 to 0.93. The Random Forest model is the best performer, with an accuracy of 0.93 and F1-Score and Precision of 0.94 and 0.95, respectively. Overall, the results suggest Random Forest as the most promising model for this classification task."
2555,"caption: Performance comparison of the evaluation metrics of different models.table: Model,Accuracy,F1-Score,Precision,Recall, Model 1,0.86,0.83,0.89,0.80, Model 2,0.82,0.81,0.85,0.78, Model 3,0.89,0.87,0.91,0.84, Model 4,0.91,0.90,0.92,0.89","Table presents a performance comparison of multiple models based on different evaluation metrics, including Accuracy, F1-Score, Precision, and Recall. The table consists of four different models: Model 1, Model 2, Model 3, and Model 4. Notably, Model 4 shows to have the highest performance in all the evaluation metrics, while Model 2 performed the lowest in all the evaluation metrics. Interestingly, Model 3 shows exceptional performance and has the highest accuracy, precision, and recall after Model 4. However, when analyzing the F1-Score, Model 4 remains to have the highest score, only marginally better than Model 3."
2556,"caption: Table 4: Performance metrics of different models on test dataset.table: Model,Accuracy,Precision,Recall,F1-score,AUC, Logistic Regression,0.92,0.90,0.87,0.88,0.95, Decision Tree,0.89,0.85,0.82,0.83,0.91, Random Forest,0.93,0.92,0.88,0.90,0.96, XGBoost,0.94,0.93,0.92,0.92,0.98, LightGBM,0.95,0.94,0.93,0.93,0.98","Table 4 presents a comparison of different models based on multiple performance metrics, including Accuracy, Precision, Recall, F1-score, and AUC, obtained from the test dataset. The table includes five models: Logistic Regression, Decision Tree, Random Forest, XGBoost, and LightGBM. The LightGBM model achieved the highest performance results, with Accuracy of 0.95, Precision of 0.94, Recall of 0.93, F1-score of 0.93, and AUC of 0.98. Moreover, the Random Forest and XGBoost models show relatively high model performances, ranging between 0.92 and 0.94 in Accuracy metrics, while Decision Tree and Logistic Regression show slightly lower results."
2557,"caption: Performance comparison of different models based on multiple evaluation metrics.table: Model,Precision,F1-score,AUC,Accuracy, Ridge,0.85,0.86,0.92,0.86, Naive Bayes,0.80,0.81,0.81,0.79, SVM,0.87,0.88,0.88,0.87, Random Forest,0.90,0.91,0.94,0.90, XGBoost,0.91,0.92,0.96,0.91","The table presents the comparison of five different models based on four evaluation metrics, precision, F1-score, AUC, and accuracy. The Ridge model achieved the highest precision of 0.85, followed closely by SVM and XGBoost models with 0.87 and 0.91 precision scores, respectively. Random Forest and XGBoost models demonstrate the highest F1-score of 0.91 and 0.92, respectively. Notably, The XGBoost model exhibits the highest AUC score of 0.96, while Random Forest model achieved the highest accuracy score of 0.90. The table demonstrates the importance of using multiple evaluation metrics to analyze model performance while considering the application."
2558,"caption: Comparison of model performances based on various evaluation metrics.table: Model,F1-Score,Accuracy,AUC,Precision,Average Precision, Model A,0.85,0.89,0.93,0.83,0.76, Model B,0.83,0.87,0.92,0.80,0.72, Model C,0.88,0.90,0.94,0.85,0.80, Model D,0.87,0.89,0.93,0.82,0.77, Model E,0.82,0.85,0.89,0.78,0.69","Table X presents a comparison of different models' performances based on F1-score, accuracy, AUC, precision, and average precision metrics. Performance scores were obtained through training and testing on the same dataset. Model C shows the highest F1-score of 0.88, while Model A and Model D report the highest accuracy and AUC scores of 0.89 and 0.93, respectively. Model C also has the highest precision score of 0.85, while Model A exhibits the highest average precision score of 0.76. Overall, the results suggest that each model has strengths and weaknesses in specific metrics, indicating that an appropriate model must be chosen based on the evaluation metric(s) of interest."
2559,"caption: Comparison of different classification models' performances based on evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.78,0.79,0.77,0.81, Random Forest,0.88,0.89,0.86,0.91, Gradient Boost,0.85,0.86,0.83,0.91, AdaBoost,0.84,0.85,0.82,0.90","Table presents the evaluation results of multiple classification models. The table shows the accuracy, F1-score, precision, and recall metrics for SVM, Random Forest, Gradient Boost, and AdaBoost models. It is noteworthy that the Random Forest model achieved the highest accuracy, F1-score and recall scores, all around 0.88, 0.89, and 0.91, respectively. Meanwhile, the SVM model scored 0.81 for recall and 0.77 for precision, which were the lowest scores for these two parameters among the models. The Gradient Boost and AdaBoost models achieved moderate scores for all metrics, with accuracy ranging from 0.84 to 0.85 and F1-score from 0.85 to 0.86. Overall, the table suggests that the Random Forest model outperforms other models based on the chosen evaluation metrics."
2560,"caption: Performance Metrics of Various Classification Models on Dataset X.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.844,0.857,0.854,0.872, KNN,0.811,0.749,0.784,0.723, RF,0.886,0.900,0.921,0.881, XGBoost,0.893,0.904,0.928,0.887, MLP,0.874,0.888,0.915,0.862","The table above presents the classification models' evaluation metrics on dataset X using the accuracy, F1-score, precision, and recall metrics. The SVM model achieved the highest accuracy score of 0.844 and recall score of 0.872. The KNN model had the lowest accuracy score of 0.811, whereas the RF and XGBoost models had the highest accuracy scores of 0.886 and 0.893, respectively. The RF model had the highest F1-Score and Precision with scores of 0.900 and 0.921, respectively, on the other hand, XGBoost had the highest Recall score of 0.887. Finally, the MLP model had a moderate performance for all the evaluation metrics."
2561,"caption: Comparison of model performances using multiple different evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.78,0.77,0.78,0.79, Random Forest,0.73,0.72,0.74,0.73, AdaBoost,0.75,0.73,0.76,0.71, KNN,0.69,0.68,0.70,0.67","Table X shows the comparison of four different models' performances using multiple different evaluation metrics, including Accuracy, F1-Score, Precision, and Recall. The SVM model exhibited the best accuracy score of 0.78, while the AdaBoost model showed the highest precision of 0.76. The Random Forest model had the highest F1-Score of 0.72, whereas the SVM had the best recall score of 0.79. Notably, the KNN model shows generally lower scores compared to other models across all evaluation metrics. Overall, the table highlights the importance of considering different evaluation metrics while comparing the performance of different machine learning models."
2562,"caption: Model performance evaluation using accuracy, precision, recall, and F1-score metrics.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.89,0.92,0.88,0.90, Naive Bayes,0.83,0.85,0.81,0.83, Decision Tree,0.78,0.77,0.80,0.78, Random Forest,0.91,0.93,0.91,0.92, AdaBoost,0.87,0.89,0.87,0.88","The table compares the performance results of five different models for the given task using multiple evaluation metrics such as Accuracy, Precision, Recall, and F1-Score. Models, namely SVM, Naive Bayes, Decision Tree, Random Forest, and AdaBoost were evaluated in terms of their accuracy in predicting the outcome. Random Forest showed the highest accuracy score with a value of 0.91, while Decision Tree exhibited the lowest score with 0.78. Furthermore, all the models demonstrated precision scores above 0.75, but Random Forest and SVM achieved the highest precision score of 0.93 and 0.92, respectively. Interestingly, Naive Bayes, Decision Tree, and AdaBoost exhibited similar recall and f1-score metrics, whereas SVM and Random Forest obtained the highest scores."
2563,"caption: Table 4: Model classification performance based on different evaluation metricstable: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.845,0.846,0.865,0.828, KNN,0.784,0.776,0.801,0.753, Naive Bayes,0.692,0.681,0.697,0.665, Decision tree,0.803,0.801,0.805,0.794, Random forest,0.873,0.872,0.883,0.862, XGBoost,0.887,0.885,0.896,0.875","Table 4 presents the classification performance results of six different models based on different evaluation metrics, namely accuracy, F1 score, precision, and recall. SVM had the highest accuracy of 0.845, whereas Random forest achieved the highest F1 score, Precision, and recall of 0.872, 0.883, and 0.862, respectively. XGBoost was the second-best model, producing the second-highest accuracy score of 0.887 and other three metrics ranging from 0.875 to 0.896. Naive Bayes appeared to be the underperformer among the six models, achieving the lowest score in all the metrics. Decision tree, on the other hand, emerged with an average performance. Overall, Random forest and XGBoost can be a good choice of models for classification tasks based on these results."
2564,"caption: Model performance evaluation on different algorithmstable: Model,Accuracy,Precision,Recall,F1-Score,AUC, RF,0.94,0.89,0.97,0.93,0.98, SVM,0.87,0.80,0.91,0.85,0.92, LR,0.89,0.83,0.92,0.87,0.94, NN,0.93,0.88,0.95,0.91,0.97","Table presents the accuracy, precision, recall, F1-Score, and AUC of four algorithms, including Random Forest (RF), Support Vector Machine (SVM), Logistic Regression (LR), and Neural Networks (NN). The table exhibits that RF has the highest accuracy of 0.94, while SVM achieved the lowest accuracy of 0.87. The NN model shows the highest AUC score of 0.97, while the SVM model has the lowest AUC score of 0.92. Precision scores range from 0.80 to 0.89, recall scores range from 0.91 to 0.97, and F1-Score scores range from 0.85 to 0.93. Therefore, the results indicate that the NN model is the best performing model in this experiment."
2565,"caption: Table 4: Performance Metrics for different models.table: Model,Precision,Recall,F1 Score,Accuracy, Support Vector Machine,0.84,0.65,0.73,0.81, Decision Tree,0.76,0.79,0.77,0.79, Random Forest,0.83,0.75,0.78,0.82, Gradient Boosting,0.82,0.68,0.74,0.81, Naïve Bayes,0.69,0.85,0.76,0.73","Table 4 shows the performance metrics of different models. The evaluation metrics used for comparison include Precision, Recall, F1 Score, and Accuracy. The table includes five models, namely Support Vector Machine, Decision Tree, Random Forest, Gradient Boosting, and Naïve Bayes. Notably, the highest precision score of 0.84 was recorded by the Support Vector Machine model. Moreover, the Naïve Bayes algorithm achieved the highest recall score of 0.85 and F1 score of 0.76. However, the highest accuracy score of 0.82 was recorded by the Random Forest algorithm. The table's result can be of significant contribution to selecting a suitable model for future studies or applications."
2566,"caption: Performance of different classification models on a sentiment analysis task.table: Model,Precision,Recall,F1-score,Accuracy, Random Forest,0.90,0.92,0.91,0.89, SVM,0.88,0.86,0.87,0.85, Decision Tree,0.82,0.87,0.84,0.80, Naive Bayes,0.75,0.62,0.67,0.70, Multilayer Perceptron,0.85,0.83,0.84,0.83, K-Nearest Neighbors,0.79,0.76,0.77,0.75",
2567,"caption: Performance metrics of different models.table: Model,Accuracy,Precision,Recall,F1-Score, A,0.80,0.82,0.75,0.78, B,0.85,0.80,0.81,0.81, C,0.87,0.84,0.83,0.83, D,0.90,0.89,0.88,0.88","The table presents the evaluation metrics, including Accuracy, Precision, Recall, and F1-Score, of four different models named A, B, C, and D. All of the models were trained and tested on the same dataset. Model D exhibits the highest Accuracy score of 0.9 and F1-Score of 0.88, while model C has the highest Precision and Recall scores of 0.84 and 0.83, respectively. In contrast, model A has the lowest performance concerning all the metrics, although its Accuracy and Precision scores are relatively high. Model B shows reasonably good performance concerning all the metrics, with an Accuracy score of 0.85 and an overall F1-Score of 0.81."
2568,"caption: Evaluation metrics of different modelstable: Model,Accuracy,F1 Score,Precision Score,Recall Score, SVM,0.73,0.70,0.68,0.73, KNN,0.72,0.68,0.65,0.72, Decision Tree,0.71,0.69,0.65,0.71, Random Forest,0.79,0.78,0.77,0.79, Gradient Boosting,0.75,0.73,0.71,0.75","The table above showcases the comparison of five different models' performance based on evaluation metrics such as Accuracy, F1 Score, Precision Score, and Recall Score. The models used are SVM, KNN, Decision Tree, Random Forest, and Gradient Boosting. The table exhibits that the Random Forest model outperforms the other models across all metrics with an Accuracy score of 0.79, F1 Score of 0.78, Precision Score of 0.77, and Recall Score of 0.79. Interestingly, KNN had the lowest accuracy score but had a close F1 score of 0.68 and a Precision Score of 0.65. The other models had relatively similar performances with Accuracy scores ranging from 0.73 to 0.75."
2569,"caption: Table 4: Model performance based on accuracy, F1-Score, precision, and recall metrics.table: Model,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.85,0.83,0.87,0.79, Decision Tree,0.80,0.75,0.79,0.72, Random Forest,0.88,0.87,0.92,0.82, Support Vector Machines,0.81,0.77,0.83,0.71","Table 4 shows the model performance measured by multiple evaluation metrics, including accuracy, F1-Score, precision, and recall. The table depicts Logistic Regression, Decision Tree, Random Forest, and Support Vector Machines models, and their respective performance results."
2570,"caption: Comparison of Model Performance on Different Metricstable: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.87,0.85,0.90,0.80, Naive Bayes,0.81,0.79,0.82,0.76, Decision Tree,0.79,0.78,0.76,0.80, Random Forest,0.92,0.91,0.93,0.90, AdaBoost,0.89,0.88,0.87,0.90","The presented table provides a comparison of the classification models, including SVM, Naive Bayes, Decision Tree, Random Forest, and AdaBoost, based on various classification metrics, including Accuracy, F1 Score, Precision, and Recall. The models were trained and tested on the same dataset, fitting the stringent experimental condition. The Random Forest model showed the best performance in all metrics with an accuracy of 0.92, followed by AdaBoost with an accuracy of 0.89. Notably, Naive Bayes had the lowest accuracy of 0.81 but still maintained a competitive F1 score of 0.79. Interestingly, the Decision Tree model showed the lowest performance in all metrics, implying that a more complex model is necessary to achieve better results."
2571,"caption: Model performance evaluation using different evaluation metricstable: Model,Accuracy,F1-score,Precision,Recall, Logistic regression,0.82,0.79,0.85,0.74, SVM,0.80,0.77,0.80,0.75, Decision tree,0.76,0.72,0.75,0.70, Naive Bayes,0.72,0.68,0.76,0.62, Random forest,0.87,0.85,0.89,0.82","The table above shows the performance of five different models concerning different evaluation metrics, such as Accuracy, F1-score, Precision, and Recall. The models evaluated are Logistic regression, SVM, Decision tree, Naive Bayes, and Random forest. The best-performing model is Random forest, which achieved an accuracy score of 0.87, F1-score of 0.85, Precision score of 0.89, and Recall score of 0.82. In terms of the evaluation metrics, the models follow the rankings: Logistic regression, SVM, Decision tree, Naive Bayes, and Random forest. Interestingly, the weakest model, Naive Bayes, achieved the highest Precision score, while the strongest model, Random forest, achieved the highest Recall score."
2572,"caption: Comparison of different machine learning models based on evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score,AUC, Logistic Regression,0.819,0.768,0.654,0.706,0.879, SVM with RBF kernel,0.785,0.732,0.556,0.621,0.773, Random Forest,0.847,0.793,0.742,0.765,0.919, MLP,0.810,0.711,0.610,0.650,0.866, XGBoost,0.879,0.825,0.778,0.788,0.930, CatBoost,0.870,0.807,0.788,0.779,0.925","The table demonstrates the comparison of various machine learning models based on multiple metrics such as accuracy, precision, recall, F1-score, and area under the curve (AUC). The models were trained and tested on the same dataset. From the table, it can be observed that Catboost and XGboost performed the best in terms of accuracy, attaining scores of 0.870 and 0.879, respectively. Random Forest attained the highest AUC of 0.919. Furthermore, the Precision, Recall, and F1-score varied depending on the model used. Logistic regression shows a higher Precision score of 0.768 compared to the other models. Overall, the table demonstrates the differences in performance across diverse evaluation metrics and models."
2573,"caption: Table 4: Model performance based on multiple evaluation metrics.table: Model,Precision,Recall,Accuracy,F1 Score, Logistic Regression,0.90,0.85,0.94,0.87, Decision Tree,0.87,0.86,0.92,0.86, Random Forest,0.94,0.89,0.96,0.91, Support Vector Machine,0.91,0.87,0.94,0.88, Neural Network,0.96,0.92,0.98,0.94","Table 4 provides a comparative analysis of models' performance based on different evaluation metrics. It consists of five models, including Logistic Regression, Decision Tree, Random Forest, Support Vector Machine (SVM), and Neural Network (NN). The evaluation metrics include Precision, Recall, Accuracy and F1 Score. The results show that the Neural Network model outperforms other models, obtaining the highest Precision, Recall, Accuracy, and F1 Score of 0.96, 0.92, 0.98, and 0.94 respectively. The Random Forest model is also notable, achieving the second-highest Precision, Recall, Accuracy, and F1 Score values. Meanwhile, Logistic Regression and SVM models record lower scores."
2574,"caption: Comparison of performance metrics of various classification models.table: Model Name,Metric,Result, Logistic Regression,Accuracy,0.89, SVM,Accuracy,0.87, Decision Tree,F1-Score,0.76, Random Forest,F1-Score,0.82, XGBoost,Precision,0.85, Neural Network,Precision,0.81","The table above reports the results of six models on various metrics. The models include Logistic Regression, SVM, Decision Tree, Random Forest, XGBoost, and Neural Network. Each model has been evaluated on different metrics such as Accuracy, F1-Score, and Precision. The results show that Logistic Regression achieved the highest accuracy score of 0.89, followed by SVM at 0.87. Random Forest outperformed the other models in terms of the F1-Score with a value of 0.82, and XGBoost had the highest precision of 0.85. The Neural Network model's precision comes in close at 0.81. Overall, the table provides a comprehensive comparison of different models and reveals each model's strengths and weaknesses based on the selected metrics."
2575,"caption: Model performance comparison across evaluation metricstable: Model,F1-score,Accuracy,Precision,Recall, Logistic Regression,0.938,0.945,0.926,0.951, Decision Tree,0.910,0.912,0.896,0.925, Random Forest,0.946,0.948,0.928,0.965, Gradient Boosting,0.949,0.952,0.935,0.964, Support Vector Machine,0.921,0.928,0.912,0.931","The table exhibits a model performance comparison across multiple evaluation metrics such as F1-score, accuracy, precision, and recall. The table shows the results of five different models, including Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Support Vector Machine. Among all the models, Gradient Boosting has the highest F1-score of 0.949 and accuracy of 0.952. Comparatively, Logistic Regression achieved the highest precision of 0.926, while the Random Forest model has the highest recall of 0.965. The results suggest that Gradient Boosting and Random Forest are the best models for the given dataset, depending on the evaluation metric selected."
2576,"caption: Performance comparison of different models using various evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, Model 1,0.76,0.74,0.71,0.77, Model 2,0.78,0.77,0.74,0.81, Model 3,0.81,0.80,0.78,0.83, Model 4,0.75,0.73,0.70,0.78, Model 5,0.82,0.81,0.79,0.84","The table above presents a performance comparison of five different models based on different evaluation metrics. The metrics evaluated are Accuracy, F1-score, Precision, and Recall. Model 5 outperformed all other models across all metrics, achieving the highest accuracy score of 0.82, the highest F1-score of 0.81, the highest precision score of 0.79, and the highest recall score of 0.84. Model 3 also performed remarkably, achieving the second-highest scores across all metrics. Conversely, Model 1 performed the worst, achieving the lowest scores across all metrics. Overall, the table highlights that different models can exhibit varying performance metrics, and it is essential to evaluate multiple metrics to assess overall model performance."
2577,"caption: Comparison of different models' performances based on multiple evaluation metrics.table: Model,MCC,F1 Score,Precision,Recall,AUC,Accuracy, Random forest,0.813,0.788,0.805,0.772,0.932,0.804, XGBoost,0.803,0.775,0.792,0.759,0.929,0.794, SVM,0.748,0.698,0.691,0.705,0.912,0.707, Decision tree,0.720,0.710,0.717,0.703,0.856,0.708, Logistic regression,0.682,0.646,0.661,0.631,0.887,0.646","Table 4 compares different machine learning models by evaluating their performances based on MCC, F1 Score, Precision, Recall, AUC, and Accuracy metrics. The Random forest model obtained the highest MCC score of 0.813, while the Logistic regression obtained the lowest score of 0.682 among the compared models. In terms of F1 score, the Decision tree model scored the highest of 0.710, while the SVM model scored the lowest of 0.698. Notably, the Random forest and XGBoost models are the only models that scored above 0.9 on AUC. On Accuracy, the Random forest model scored the highest of 0.804, while the Logistic regression model scored the lowest of 0.646. Overall, the Random forest and XGBoost models showed better performance based on most evaluation metrics."
2578,"caption: Performance of different models based on multiple evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, Logistic regression,0.89,0.90,0.88,0.92, Random Forest,0.92,0.93,0.91,0.94, Neural Network,0.91,0.92,0.90,0.93, SVM,0.88,0.89,0.87,0.92","Table presents the evaluation performance of logistic regression (LR), random forest (RF), neural network (NN), and support vector machine (SVM) based on different evaluation metrics. The models' performances are measured using accuracy, F1-score, precision, and recall. The Random Forest model outperformed the other models in accuracy, F1-score, precision, and recall. The neural network model had the second-best performance overall, while SVM had the lowest performance among all the models across all evaluation metrics. These findings suggest that the Random Forest and Neural Network models could be worth considering for further analysis."
2579,"caption: Table 4: Performance of different models across multiple metrics.table: Model,F1-score,Precision,Recall, SVM,0.862,0.913,0.818, Random Forest,0.908,0.876,0.944, Neural Net,0.896,0.935,0.864, Naive Bayes,0.784,0.736,0.840, Decision Tree,0.892,0.860,0.926","Table 4 highlights the performance of different classification models using various evaluation metrics. The table presents F1-score, precision, and recall for SVM, Random Forest, Neural Net, Naive Bayes, and Decision Tree models. The Random Forest model shows the highest F1-score of 0.908 with precision and recall scores of 0.876 and 0.944, respectively. Notably, the Naive Bayes model has the lowest F1-score, i.e., 0.784, with the precision and recall scores of 0.736 and 0.840, respectively. Overall, this table provides a comprehensive comparison of different models that can help researchers choose the most appropriate model for their specific requirements."
2580,"caption: Table 4: Model comparison using different evaluation metricstable: Model,Accuracy,Precision,Recall,F-1 Score, Logistic Regression,0.82,0.74,0.81,0.77, Random Forest,0.85,0.79,0.83,0.81, SVM,0.79,0.71,0.76,0.74, Naive Bayes,0.65,0.55,0.72,0.62, AdaBoost,0.86,0.81,0.83,0.82",
2581,"caption: Evaluation metrics for different classification models.table: Model,Precision,Recall,F1 Score,ROC, Logistic Regression,0.94,0.68,0.78,0.85, Decision Tree,0.77,0.75,0.76,0.70, Random Forest,0.88,0.92,0.90,0.94, K-Nearest Neighbors,0.72,0.82,0.77,0.56, Naive Bayes,0.63,0.97,0.77,0.82, Support Vector Machine,0.89,0.70,0.79,0.88","Table presents the performance metrics of six different classification models, including Logistic Regression, Decision Tree, Random Forest, K-Nearest Neighbors, Naive Bayes, and Support Vector Machine. The models were evaluated across multiple evaluation metrics, including Precision, Recall, F1 Score, and ROC. Interesting observations can be made when comparing the models' performance. The Random Forest model outperforms other models in three of the four metrics, boasting high scores for Precision, Recall, and ROC with a score of 0.88, 0.92, and 0.94. In contrast, the K-Nearest Neighbors model has a relatively low ROC of 0.56 and the Naive Bayes model had the highest Recall at 0.97."
2582,"caption: Table 4: The performance of different models using various evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, Decision Tree,0.78,0.75,0.75,0.76, Logistic Regression,0.85,0.84,0.84,0.84, KNN,0.81,0.80,0.81,0.80, SVM,0.84,0.83,0.83,0.82, Random Forest,0.89,0.88,0.89,0.87","Table 4 presents the performances of different machine learning models using various evaluation metrics. Accuracy, F1-score, Precision, and Recall are used to evaluate the models. The table shows that the Random Forest model has the highest accuracy of 0.89 and F1-score of 0.88. Logistic Regression model follows with an accuracy of 0.85 and F1-score of 0.84. All models have a higher precision score compared to their recall score, indicating that the models are more likely to predict the positive class correctly. Overall, the Random Forest model performs the best in terms of accuracy and F1-score."
2583,"caption: Model performances based on different evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score,AUC Score, Model 1,0.85,0.73,0.89,0.80,0.91, Model 2,0.81,0.67,0.80,0.73,0.82, Model 3,0.87,0.78,0.82,0.80,0.90, Model 4,0.78,0.69,0.72,0.70,0.75, Model 5,0.90,0.83,0.93,0.87,0.94","The table above shows model performances based on five different evaluation metrics (Accuracy, Precision, Recall, F1-Score, and AUC Score) for five different models. Model 1 has the highest accuracy score of 0.85, followed by Model 3 with a score of 0.87. Model 5 has the highest Precision, Recall, F1-Score, and AUC scores, with 0.83, 0.93, 0.87, and 0.94, respectively. Model 4 has the lowest scores among the models in all evaluation metrics. Interestingly, Model 1 has a relatively high Recall score of 0.89 despite having a low Precision score of 0.73. Meanwhile, Model 2 has a moderate performance, with an Accuracy score of 0.81 and scores of other evaluation metrics relatively close to each other."
2584,"caption: Performance comparison of multiple models on various evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, Model 1,0.85,0.87,0.89,0.86, Model 2,0.82,0.80,0.83,0.76, Model 3,0.89,0.91,0.88,0.93, Model 4,0.76,0.63,0.72,0.63, Model 5,0.91,0.94,0.89,0.99","The table displays the results of multiple models' performances based on different evaluation metrics, including accuracy, F1-score, precision, and recall. Among the five models, Model 5 achieved the highest accuracy of 0.91 and the highest F1-score of 0.94, while also having the highest recall score of 0.99. Model 1 achieved the highest precision score of 0.89, while Model 4 had the lowest performance in all metrics, with an accuracy of 0.76, F1-score of 0.63, precision of 0.72, and recall of 0.63. The results suggest that Model 5 performed the best overall, while Model 4 performed the worst among the five models."
2585,"caption: Table 4: Performance of different models using various evaluation metrics.table: Model,F1-score,Accuracy,Precision,Recall,ROC-AUC,PR-AUC, Logistic Regression,0.85,0.91,0.87,0.84,0.95,0.88, Random Forest,0.88,0.93,0.91,0.85,0.97,0.92, Gradient Boosting,0.89,0.94,0.92,0.87,0.96,0.94, K-Nearest Neighbor,0.80,0.89,0.82,0.78,0.91,0.84, Naive Bayes,0.78,0.88,0.80,0.76,0.90,0.81","Table 4 reports the outcomes of different models based on six different performance metrics, including F1-score, Accuracy, Precision, Recall, ROC-AUC, and PR-AUC. The models evaluated were Logistic Regression, Random Forest, Gradient Boosting, K-Nearest Neighbor, and Naive Bayes. The evaluation results demonstrate that Gradient Boosting achieved the best F1-score of 0.89 and Accuracy of 0.94, whereas Random Forest excelled in Precision and PR-AUC with 0.91 and 0.92, respectively. The Naive Bayes model had the lowest performances across all the metrics. The results exhibit that different models’ performances vary, and the best model selection hugely relies on the intended analysis."
2586,"caption: Comparison of model performances based on multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.84,0.85,0.82,0.83, KNN,0.79,0.71,0.88,0.79, NB,0.72,0.76,0.68,0.71, RF,0.89,0.91,0.87,0.88, ANN,0.91,0.93,0.90,0.91","Table presents the performances of different classification models based on multiple evaluation metrics. The models include Support Vector Machine (SVM), K-Nearest Neighbors (KNN), Naive Bayes (NB), Random Forest (RF), and Artificial Neural Network (ANN) classifiers. The evaluation metrics are accuracy, precision, recall, and F1-score. The best performing model is ANN with an overall accuracy of 0.91, followed by RF with an accuracy of 0.89. SVM, KNN, and NB models exhibit lower overall accuracy scores with relatively lower precision, recall, and F1-score scores compared to the top-performing models. Interestingly KNN shows the highest recall score of 0.88; however, it comes with the cost of lower precision and accuracy. Overall, the ANN model shows the best performance across all evaluation metrics."
2587,"caption: Table 4: Model Performance Comparison based on Multiple Evaluation Metricstable: Model,Accuracy,F1-score,AUC, LR,0.89,0.86,0.95, SVM,0.85,0.82,0.93, KNN,0.79,0.77,0.91, RF,0.92,0.89,0.96, MLP,0.91,0.88,0.95","Table 4 presents the performance comparison of different models based on multiple evaluation metrics, including accuracy, F1-score, and AUC. The models compared in the table include logistic regression (LR), support vector machine (SVM), K-nearest neighbor (KNN), random forest (RF), and multi-layer perceptron (MLP). The highest performing model is the RF with an accuracy of 0.92, F1-score of 0.89, and an AUC of 0.96. LR also shows good performance with an accuracy of 0.89 and an AUC of 0.95. Notably, KNN had the lowest performance among the models with an accuracy of 0.79 and an F1-score of 0.77. Additionally, MLP shows competitive performance with an accuracy of 0.91 and an F1-score of 0.88."
2588,"caption: Performance of Different Classification Modelstable: Model,Accuracy,Precision,Recall,F1-Score, Support Vector Machine,0.78,0.88,0.73,0.79, Random Forest,0.81,0.86,0.81,0.83, Naïve Bayes,0.72,0.89,0.58,0.70, Logistic Regression,0.76,0.83,0.70,0.74","Table presents performance results for multiple different classifiers evaluated on different metrics. The models include Support Vector Machine, Random Forest, Naïve Bayes, and Logistic Regression. The evaluation metrics are Accuracy, Precision, Recall, and F1-Score. Notably, Random Forest achieved the highest Accuracy of 0.81, Precision of 0.86, Recall of 0.81, and F1-Score of 0.83 out of the models. Support Vector Machine and Logistic Regression models had similar Accuracy, Precision, and Recall scores; however, Logistic Regression model scored the highest F1-Score of 0.74. Interestingly, Naïve Bayes model achieved the highest Precision but the lowest Recall and F1-Score."
2589,"caption: Table 4: Model Performance Comparison Using Different Evaluation Metricstable: Model,Accuracy,F1 score,Precision,Recall, Decision Tree,0.78,0.79,0.76,0.81, Naive Bayes,0.72,0.68,0.73,0.63, Random Forest,0.86,0.87,0.87,0.87, SVM,0.81,0.81,0.84,0.78","Table 4 presents the performances of several models based on different evaluation metrics of accuracy, F1 score, precision, and recall. The models evaluated are decision tree, Naive Bayes, Random Forest, and SVM. Interestingly, Random Forest has the highest accuracy (0.86), F1 score (0.87), precision (0.87), and recall (0.87) among all the models. SVM achieves the second-best score of accuracy, precision, and F1 score, with a relatively lower recall score than the Random Forest. Decision Tree performs well with a good recall score of 0.81, but its precision score is relatively lower than the Random Forest and SVM. Naive Bayes shows the lowest performance across all evaluation metrics."
2590,"caption: Table 4: Model performance based on accuracy, precision, recall and F1-score.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.84,0.87,0.82,0.84, Random Forest,0.87,0.89,0.85,0.87, Naive Bayes,0.78,0.83,0.75,0.78, XGBoost,0.92,0.93,0.91,0.92","Table 4 presents a comparison of multiple models' performance based on four evaluation metrics, including accuracy, precision, recall, and F1-score. The models presented in the table are SVM, Random Forest, Naive Bayes, and XGBoost. Overall, XGBoost exhibits the best performance in all four evaluation metrics, achieving an accuracy of 0.92, precision of 0.93, recall of 0.91, and F1-score of 0.92. Notably, Random Forest achieved the second-best performance with an overall accuracy of 0.87, followed by SVM with an accuracy of 0.84. Despite having a relatively lower accuracy compared to other models, Naive Bayes had a reasonable performance across all metrics, achieving an accuracy of 0.78, precision of 0.83, recall of 0.75, and F1-score of 0.78."
2591,"caption: Model Performance Evaluation Metricstable: Model,Accuracy,Precision,Recall,ROC-AUC, SVM,0.89,0.91,0.85,0.92, KNN,0.81,0.78,0.82,0.84, Random Forest,0.92,0.94,0.91,0.96, Logistic Reg,0.89,0.91,0.85,0.92, MLP,0.93,0.95,0.91,0.96","The table presents the model performances of SVM, KNN, Random Forest, Logistic Regression, and MLP based on different evaluation metrics. These different evaluation metrics include Accuracy, Precision, Recall, and Receiver Operating Characteristic Area Under the Curve (ROC-AUC). Interestingly, the MLP model remarkably outperformed other models across all evaluation metrics (Accuracy=0.93, Precision=0.95, Recall=0.91, ROC-AUC=0.96). The Random Forest model also performed significantly well, with high Accuracy, Precision, and ROC-AUC (0.92, 0.94, and 0.96, respectively). Conversely, KNN showed relatively poor performance compared to other models, with the lowest Accuracy and ROC-AUC (0.81 and 0.84, respectively). Overall, the MLP model stood out as the top-performing model among the models evaluated here for this task."
2592,"caption: Table 4: Model evaluation metrics for different machine learning algorithms.table: Model Name,Accuracy,F1-Score,Sensitivity,Specificity, Support Vector Machine,0.89,0.87,0.86,0.91, Naïve Bayes,0.82,0.79,0.81,0.83, Decision Tree,0.77,0.76,0.79,0.74, Random Forest,0.93,0.92,0.92,0.94, XGBoost,0.95,0.94,0.95,0.96","Table 4 summarizes the evaluation metrics (Accuracy, F1-Score, Sensitivity, and Specificity) for different machine learning algorithms including Support Vector Machine, Naïve Bayes, Decision Tree, Random Forest, and XGBoost. All models were trained and evaluated on the same dataset. Interestingly, the XGBoost model shows the best performance with the highest accuracy (0.95) and F1-Score (0.94) compared to all other models. The Support Vector Machine and Random Forest models also performed well, achieving accuracy scores of 0.89 and 0.93, respectively. Overall, the table highlights the strengths and weaknesses of each machine learning algorithm in classifying the dataset."
2593,"caption: Table 4: Model Comparison for Binary Classification Tasktable: Model,F1 Score,Accuracy,Precision,Recall, Logistic Regression,0.82,0.78,0.75,0.91, Random Forest,0.84,0.83,0.79,0.89, Support Vector Machines,0.81,0.77,0.73,0.91, Multi-layer Perceptron,0.85,0.84,0.83,0.87","Table 4 shows a comparison of multiple models' performance results on a binary classification task. The table presents four different models, including Logistic Regression, Random Forest, Support Vector Machines, and Multi-layer Perceptron. The models' performance is evaluated using multiple different metrics such as F1 Score, Accuracy, Precision, and Recall, each of different relevance in specific contexts. Interestingly, the Random Forest model achieved the highest F1 Score and Accuracy with the scores of 0.84 and 0.83, respectively, followed closely by the Multi-layer Perceptron model with an F1 Score of 0.85 and Accuracy of 0.84. Therefore, Random Forest and Multi-layer Perceptron models could be considered as the best performing models for this classification task based on the results presented in this table."
2594,"caption: Comparison of various models based on F1-macro, F1-micro, precision, and recall evaluation metrics.table: Model,F1-Macro,F1-Micro,Precision,Recall, Logistic Regression,0.77,0.82,0.80,0.77, Support Vector Machines,0.71,0.79,0.75,0.72, Random Forest,0.84,0.89,0.87,0.85, Gradient Boosting,0.80,0.87,0.83,0.81",
2595,"caption: Table 4: Performance comparison of different classification models based on multiple evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall,AUC_ROC, SVM,0.92,0.93,0.95,0.91,0.98, Random Forest,0.93,0.94,0.96,0.92,0.97, Logistic Regression,0.86,0.88,0.91,0.85,0.91, Gradient Boosting,0.91,0.93,0.94,0.92,0.95","Table 4 presents a comparison of four classification models based on evaluation metrics such as accuracy, F1-score, precision, recall and AUC_ROC. The table shows the SVM model yields the highest performance on AUC_ROC (0.98) and Random Forest performed the highest on accuracy (0.93) and F1-score (0.94). Meanwhile, Gradient Boosting achieved a high F1-score (0.93), precision (0.94) and recall (0.92). Furthermore, Logistic Regression yielded the lowest accuracy (0.86), but it presented a competitive performance with other models based on F1-score, precision and recall."
2596,"caption: Comparison of different models in terms of Precision, Recall, F1 Score and Accuracy.table: Model Name,Precision,Recall,F1 Score,Accuracy, Logistic Regression,0.78,0.74,0.76,0.73, Decision Tree,0.76,0.72,0.73,0.72, Random Forest,0.85,0.82,0.83,0.80, Support Vector Machines,0.77,0.76,0.75,0.74, K-Nearest Neighbor,0.69,0.68,0.67,0.65","The table presents the performance of five different classification models- Logistic Regression, Decision Tree, Random forest, Support Vector Machines, and K-Nearest Neighbor with precision, recall, F1 score, and accuracy measures. The Random forest model performed best, achieving the highest precision of 0.85, recall of 0.82, F1 score of 0.83, and accuracy of 0.80. K-Nearest Neighbor model depicts the lowest performance compared to other models, achieving the lowest measures in precision, recall, F1 score and accuracy."
2597,"caption: Model Evaluation Metricstable: Model,Accuracy,F1-Score,Precision,Recall, A,85.2,0.80,0.82,0.78, B,84.5,0.79,0.80,0.78, C,81.0,0.74,0.70,0.78, D,79.2,0.72,0.68,0.76","The table presents different models' performances based on various evaluation metrics. The models were evaluated based on their accuracy, F1-score, precision, and recall. The results show that model A had the highest accuracy of 85.2%, while model D had the lowest accuracy of 79.2%. Similarly, model A had the highest F1-score of 0.80, while model D had the lowest F1-score of 0.72. Model A also achieved the highest precision of 0.82, while model D had the lowest precision of 0.68. However, model C had the highest recall of 0.78, while models A and B had the lowest recall of 0.78. Overall, the table highlights the need to evaluate machine learning models using various metrics to obtain a comprehensive understanding of their performance."
2598,"caption: Table 4: Model Performance using Multiple Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1-score, SVM,0.867,0.881,0.846,0.863, Logistic Reg.,0.845,0.848,0.831,0.839, KNN,0.811,0.789,0.812,0.775, Decision Tree,0.824,0.806,0.798,0.802, Random Forest,0.889,0.880,0.891,0.884, XGBoost,0.895,0.882,0.900,0.890","Table 4 compares different models based on their accuracy, precision, recall, and F1-score evaluation metrics. The SVM model achieved the highest accuracy of 0.867. The Random Forest and XGBoost models both outperformed the rest in precision and recall metrics, with the Random Forest having a precision of 0.880 and recall of 0.891, and XGBoost having a precision of 0.882 and recall of 0.900. The F1-score results also show that both models have the highest scores: Random Forest with 0.884 and XGBoost with 0.890. The Logistic Regression and Decision Tree models obtained lower scores, while the KNN model had the lowest scores in all evaluation metrics."
2599,"caption: Table 4: Performance metrics for different modelstable: Model Name,Accuracy,Precision,Recall,F1-Score, Model 1,0.84,0.85,0.83,0.84, Model 2,0.86,0.79,0.91,0.84, Model 3,0.80,0.72,0.85,0.78, Model 4,0.90,0.87,0.92,0.89, Model 5,0.91,0.90,0.91,0.90","Table 4 depicts a comparison of multiple different models based on various evaluation metrics. The models were trained and tested using the same dataset. The evaluation metrics involve Accuracy, Precision, Recall, and F1-Score. Notably, Model 5 reflects the highest accuracy score of 0.91, while Model 1 records the lowest score of 0.84. In addition, Model 5 exhibits the highest precision and recall scores of 0.90 and 0.91, respectively, while Model 3 reflects the lowest precision and recall scores of 0.72 and 0.85, respectively. Furthermore, Model 4 attains the highest F1-Score of 0.89, while Model 3 exhibits the lowest score of 0.78."
2600,"caption: Performance Metrics of Various Machine Learning Modelstable: Model,Accuracy,Precision,Recall,F1-score,AUC, LR,0.89,0.90,0.83,0.86,0.94, KNN,0.86,0.81,0.87,0.84,0.82, SVM,0.90,0.93,0.85,0.89,0.94, RF,0.91,0.91,0.88,0.89,0.96, XGB,0.91,0.93,0.89,0.91,0.95","The table displays the performance of different machine learning models based on multiple evaluation metrics, namely Accuracy, Precision, Recall, F1-score, and AUC. The evaluation of the models was conducted on a common dataset. The LR model shows a high accuracy of 0.89 but has lower precision, recall, and F1-score. In contrast, the SVM model achieved a high score in precision with a value of 0.93, followed by the XGB model with a precision value of 0.93. On the other hand, the best performance according to the AUC score is observed in the RF model with a 0.96 score, while both SVM and LR models achieved a high AUC score of 0.94. It is essential to consider all evaluation metrics while selecting the best model, and the results suggest that the RF, SVM, and XGB outperformed the other models."
2601,"caption: Table 4: Model Performance using different evaluation metricstable: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.84,0.81,0.79,0.84, Random Forest,0.91,0.89,0.88,0.92, AdaBoost,0.87,0.85,0.84,0.87, XGBoost,0.92,0.91,0.90,0.93, SVM,0.88,0.86,0.85,0.87","Table 4 shows the comparison of multiple machine learning models' performances based on four different evaluation metrics: Accuracy, F1-score, Precision, and Recall. The table exhibits five machine learning models, including Logistic Regression, Random Forest, AdaBoost, XGBoost, and SVM. Interestingly, the XGBoost model shows the best performance in all four metrics. It has the highest accuracy score of 0.92, the highest F1-score, precision, and recall scores of 0.91, 0.90, and 0.93, respectively. Meanwhile, the Random Forest model shows competitive performance with high scores in all metrics besides Recall. The Logistic Regression and AdaBoost models also show reasonable performance in all four metrics. The SVM model achieved the lowest performance among the models."
2602,"caption: Model evaluation metrics for different classification models.table: **Model**,**Accuracy**,**Precision**,**Recall**,**F1-Score**, SVM,0.915,0.919,0.890,0.904, Naive Bayes,0.812,0.846,0.661,0.745, Random Forest,0.948,0.953,0.937,0.944, XGBoost,0.949,0.951,0.939,0.944","Table X exhibits the performance comparison for each classification model using various metrics, namely accuracy, precision, recall, and F1-score. The table includes SVM, Naive Bayes, Random Forest, and XGBoost. Notably, the Random Forest and XGBoost models exhibit the highest accuracy scores of 0.948 and 0.949, correspondingly. Also, both models exhibited similar precision, recall, and F1-scores. On the other hand, the SVM model produced a slightly lower accuracy score but had the highest precision score of 0.919- implying that the model labels data with higher accuracy. Naive Bayes, however, had the lowest performance for all metrics. Overall, the table reveals that Random Forest and XGBoost are promising models for classification tasks, while SVM outperforms others in terms of precision."
2603,"caption: Model performance using different machine learning algorithms on the test dataset.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.92,0.95,0.90,0.92, Logistics Regression,0.90,0.93,0.87,0.90, Decision Tree,0.81,0.81,0.76,0.78, Random Forest,0.86,0.88,0.83,0.85, XGBoost,0.87,0.89,0.85,0.87","The table shows the accuracy, precision, recall, and F1-score of five different machine learning algorithms' performances on the test dataset. From the table, SVM model performs the best with the highest accuracy of 0.92, followed by Logistics Regression with an accuracy of 0.90. The Decision Tree model shows the lowest performance with an accuracy of 0.81. Additionally, Random Forest and XGBoost models achieve similar performance in the evaluation metrics. Overall, the table highlights the differences in performance between popular machine learning algorithms in classification tasks."
2604,"caption: Performance Metrics for Different Models.table: Model,Precision,Recall,F1-Score,ROC-AUC, SVM,0.88,0.93,0.9,0.94, RF,0.92,0.84,0.88,0.91, DT,0.84,0.76,0.8,0.79, KNN,0.91,0.78,0.83,0.88, MLP,0.94,0.89,0.91,0.92","The table displays the performance metrics, including Precision, Recall, F1-Score, and ROC-AUC, for multiple different models. The models included in the table are SVM, RF, DT, KNN, and MLP. The best performing model, based on the available metrics, is the MLP model, which achieved the highest Precision score of 0.94 and an F1-Score of 0.91. However, the SVM model achieved the highest Recall of 0.93 and ROC-AUC of 0.94. It is interesting to note that the MLP model showed the highest performance in all the metrics except Recall, where the SVM model outperformed it."
2605,"caption: Comparison of different classification models.table: Model,Accuracy,Precision,Recall,F1-score,AUC, Logistic Regression,0.894,0.903,0.884,0.893,0.919, Support Vector Machine,0.879,0.889,0.876,0.882,0.899, Random Forest,0.908,0.912,0.909,0.910,0.945, Gradient Boosting,0.901,0.906,0.901,0.903,0.943, Neural Network (2-layer),0.890,0.904,0.878,0.890,0.925","The table demonstrates the performance of different classification models based on several evaluation metrics, including Accuracy, Precision, Recall, F1-score, and AUC. The models evaluated were Logistic Regression, Support Vector Machine, Random Forest, Gradient Boosting, and Neural Network (2-layer). The Random Forest and Gradient Boosting models achieved the highest performance with an accuracy of 0.908 and 0.901, respectively, while the Support Vector Machine model had the lowest accuracy of 0.879. The Random Forest model achieved the highest AUC score of 0.945, and Logistic Regression and Support Vector Machine had the lowest AUC scores of 0.919 and 0.899, respectively. Notably, all models showed fairly high scores for all evaluation metrics."
2606,"caption: Performance results of multiple models based on multiple evaluation metrics.table: Model Name,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.87,0.86,0.84,0.88, Random Forest,0.89,0.88,0.86,0.90, Naive Bayes,0.82,0.81,0.79,0.84, Support Vector Machine,0.88,0.87,0.85,0.89","The table presents the performance of four different models such as Logistic Regression, Random Forest, Naive Bayes, and Support Vector Machine based on evaluation metrics such as accuracy, F1-Score, precision, and recall. The Random Forest model has the highest accuracy and F1-Score compared to the other models with a score of 0.89 and 0.88, respectively. On the other hand, the Naive Bayes model has the lowest accuracy and the F1-Score. Additionally, the Support Vector Machine model performs well in terms of precision and recall with scores of 0.85 and 0.89, respectively."
2607,"caption: Model performances of different classification algorithms based on evaluation metrics.table: Model,Accuracy,F1-Score,Recall,Precision, Logistic Regression,0.92,0.90,0.88,0.92, Decision Tree,0.89,0.86,0.86,0.87, Random Forest,0.95,0.94,0.93,0.95, Support Vector Machines,0.93,0.92,0.91,0.93, Gradient Boosting,0.94,0.93,0.93,0.94","Table depicts the performances of different classification algorithms, including Logistic Regression, Decision Tree, Random Forest, Support Vector Machines, and Gradient Boosting. The table displays accuracy, F1-Score, Recall, and Precision metrics of all models. The Random Forest model outperformed other models in terms of accuracy, F1-Score, Recall, and Precision, achieving scores of 0.95, 0.94, 0.93, and 0.95, respectively. Interestingly, the Decision Tree model had the least accuracy of 0.89 and F1-Score of 0.86. The results demonstrate that the Random Forest model could be the optimum solution for the classification task given this dataset."
2608,"caption: A comparison of various models' accuracy, precision, recall, and F1-score.table: Model,Accuracy,Precision,Recall,F1-Score, Model 1,0.87,0.92,0.86,0.89, Model 2,0.91,0.93,0.93,0.93, Model 3,0.89,0.88,0.92,0.90, Model 4,0.90,0.91,0.87,0.89",
2609,"caption: Performance comparison of different machine learning models for anomaly detection in financial transactions.table: Model Name,Total Anomalies Detected,Precision,Recall,F1-Score, Random Forest,60,0.81,0.80,0.80, K-Nearest Neighbor,57,0.77,0.75,0.74, Logistic Regression,68,0.85,0.78,0.80, Naive Bayes,42,0.66,0.60,0.63, Decision Tree,51,0.69,0.65,0.64","The table above presents a comparison of different machine learning models' performance for anomaly detection in financial transactions. The table exhibits the total number of anomalies detected, precision, recall, and F1-score of each model. Notably, the Random Forest model detected the highest total number of anomalies at 60 with a precision score of 0.81, recall of 0.80, and F1-score of 0.80. However, the Logistic Regression model had the highest precision score at 0.85 with a slightly lower recall and F1-score of 0.78 and 0.80, respectively. Interestingly, the Naive Bayes model detected the lowest number of anomalies but had the lowest performance with precision, recall, and F1-scores of 0.66, 0.60, and 0.63, respectively."
2610,"caption: Comparison of different classifiers performance on the test data.table: Models,Precision,Recall,F1-score,AUC, Logistic,0.78,0.69,0.73,0.856, K-NN,0.74,0.68,0.71,0.832, SVM,0.82,0.72,0.76,0.848, Decision Trees,0.79,0.67,0.72,0.824, Random Forest,0.85,0.74,0.78,0.871, XGBoost,0.86,0.76,0.80,0.892","Table presents the performance of different classifiers on the test data using precision, recall, F1-score, and AUC as evaluation metrics. It shows that Random Forest and XGBoost models outperformed all other models with precision scores of 0.85 and 0.86, respectively. Similarly, XGBoost achieved the highest recall score of 0.76. Furthermore, the XGBoost model also exhibited the best F1-score (0.80) and AUC (0.892) among all models tested. However, the Logistic regression model performed relatively worse among all models with an F1-score of 0.73 and an AUC of 0.856. Overall, this table suggests that the XGBoost classifier is the most effective for a given task among the other models used."
2611,"caption: Performance comparison of different classification models on a dataset.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.83,0.82,0.85,0.80, KNN,0.81,0.80,0.79,0.83, Naive Bayes,0.76,0.67,0.78,0.60, Decision Tree,0.90,0.89,0.88,0.90, Random Forest,0.92,0.91,0.92,0.90","The table presents a comparison of classification models' performance on a given dataset using evaluation metrics such as Accuracy, F1 Score, Precision and Recall. SVM model performed the best in terms of accuracy (0.83) and precision(0.85), while Decision Tree model performed best in terms of F1 Score and Recall (0.89 and 0.90 respectively). The Random Forest model achieves the highest accuracy of 0.92 and F1 Score of 0.91, which is the best performance result in the table. Although Naive Bayes's accuracy is lower than other models, it had a good F1 score of 0.67."
2612,"caption: Comparison of Multiple Models' Performance Across Different Evaluation Metrics.table: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.83,0.82,0.88,0.77, Random Forest,0.85,0.84,0.86,0.82, K-Nearest Neighbors,0.77,0.76,0.79,0.73, Naive Bayes,0.79,0.78,0.86,0.71, Support Vector Machine,0.81,0.79,0.85,0.74, Neural Network,0.86,0.85,0.89,0.82","The table above presents a comparison of six different models' performances based on several evaluation metrics, including Accuracy, F1-score, Precision, and Recall. The models include Logistic Regression, Random Forest, K-Nearest Neighbors, Naive Bayes, Support Vector Machine, and Neural Network. Notably, the Random Forest model shows the best overall performance with an accuracy of 0.85 and F1-score of 0.84. Interestingly, the Neural Network model achieved the highest precision score of 0.89, while the Logistic Regression model achieved the highest recall score of 0.77. It is essential to note that the evaluation metrics' results vary significantly depending on the models, highlighting the importance of selecting an appropriate model based on the evaluation metrics' requirements."
2613,"caption: Comparison of different models' performance using different evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.85,0.76,0.82,0.72, SVM,0.87,0.77,0.83,0.73, Random Forest,0.88,0.79,0.88,0.72, XGBoost,0.89,0.81,0.83,0.80","Table presents the performances of four different models, Logistic Regression, SVM, Random Forest, and XGBoost, on a dataset using different evaluation metrics: Accuracy, F1 Score, Precision, and Recall. Interestingly, Random Forest exhibited the highest Accuracy of 0.88, whereas XGBoost achieved the highest F1 Score of 0.81. However, it is notable that Logistic Regression and SVM performed relatively well on all the evaluation metrics. Random Forest also achieved the highest Precision score of 0.88, while XGBoost showed the highest Recall score of 0.80. Overall, the table's results suggest that XGBoost might be the best model for this dataset due to its high F1 Score and decent scores on other metrics."
2614,"caption: Table 4: Performance evaluation of different models based on the accuracy, precision, recall and F1-score metrics.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.93,0.89,0.89,0.89, Naive Bayes,0.85,0.80,0.80,0.80, Logistic Regression,0.90,0.86,0.86,0.86, Decision Tree,0.84,0.8,0.82,0.79","Table 4 displays the performance evaluation of different models based on the accuracy, precision, recall, and F1-score metrics. The models included in the table are SVM, Naive Bayes, Logistic Regression, and Decision Tree. Notably, SVM performed the best with the highest accuracy of 0.93. However, Naive Bayes had the lowest accuracy of 0.85. The precision, recall, and F1-score of all models are observable in the table with differences in performance among the models. Logistic Regression model exhibits a good performance with a precision, recall, and F1-score of 0.86, whereas, Decision Tree model's precision, recall, and F1-score is comparatively lower."
2615,"caption: Performance metrics of different modelstable: Model,Accuracy,Precision,Recall,F1-Score, Model A,0.73,0.68,0.75,0.71, Model B,0.76,0.70,0.81,0.75, Model C,0.72,0.75,0.59,0.66, Model D,0.80,0.78,0.84,0.81, Model E,0.77,0.72,0.86,0.78","Table presents the performances of five models, namely Model A, B, C, D and E, in terms of accuracy, precision, recall and F1-score. Evaluation metrics are used to measure the models' predictive power based on distinct aspects of measures. Model D performed the best with an accuracy of 0.80, precision of 0.78, recall of 0.84 and F1-score of 0.81. Model B displayed good performance compared to the rest of the models with accuracy of 0.76, precision of 0.70, recall of 0.81 and F1-score of 0.75. Notably, Model C indicates a relatively low recall of 0.59 that drags down its performance."
2616,"caption: Table 4: Performance comparison of different classification models with multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score,AUC, Model A,0.91,0.83,0.94,0.88,0.96, Model B,0.88,0.85,0.84,0.84,0.92, Model C,0.89,0.80,0.94,0.86,0.93, Model D,0.93,0.91,0.86,0.88,0.95","Table 4 displays the performance comparison of four different classification models using various evaluation metrics (Accuracy, Precision, Recall, F1-score, and AUC). The table indicates that Model D has achieved the highest accuracy score of 0.93, followed by Model A with a score of 0.91. However, Model A has the highest precision score of 0.83, whereas Model D has the highest precision score of 0.91. Furthermore, Model C has shown the highest recall score of 0.94. Considering F1-score, Model A's score is the highest among all the models. Finally, the AUC metric shows that Model D has the best performance with a score of 0.95."
2617,"caption: Model performances based on different evaluation metrics using the same dataset.table: Model,Precision,Recall,F1-Score,Accuracy, SVM,0.912,0.844,0.877,0.896, KNN,0.853,0.794,0.820,0.858, Neural Network,0.940,0.928,0.934,0.936, Decision Tree,0.740,0.728,0.734,0.732","The table highlights the performance results of four different models such as Support Vector Machine (SVM), K-Nearest Neighbors (KNN), Neural Network, and Decision Tree. Each model was evaluated based on different metrics such as Precision, Recall, F1-Score, and Accuracy, and all models used the same dataset. The Neural Network model demonstrated the overall highest performance accuracy score of 0.936, proving to be the most efficient model in comparison to the other models. On the other hand, the SVM model outperformed the other models in terms of precision with a score of 0.912 and recall with a score of 0.844. However, the Decision Tree model had the lowest performance results achieving an accuracy score of 0.732."
2618,"caption: Performance comparison of different models based on multiple evaluation metrics.table: Model Name,Accuracy,F1-Score,Recall,Precision, Model A,0.876,0.805,0.802,0.828, Model B,0.903,0.832,0.821,0.847, Model C,0.879,0.819,0.844,0.809, Model D,0.912,0.873,0.865,0.882, Model E,0.895,0.844,0.844,0.863",
2619,"caption: Model performance based on accuracy, precision, recall, and F1-score.table: Model,Accuracy,Precision,Recall,F1-Score, Model 1,0.75,0.8,0.6,0.67, Model 2,0.84,0.78,0.87,0.82, Model 3,0.79,0.74,0.82,0.78, Model 4,0.87,0.92,0.83,0.87, Model 5,0.91,0.94,0.88,0.91",
2620,"caption: Comparison of different machine learning models for document classificationtable: Model,F1-Score,Accuracy,Precision,Recall, SVM-linear,0.758,0.795,0.764,0.752, Naive Bayes,0.675,0.703,0.713,0.644, RandomForest,0.845,0.817,0.831,0.862, DNN(2 hidden layers),0.796,0.814,0.820,0.774, CNN,0.825,0.803,0.821,0.828",
2621,"caption: Model performance based on different evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.75,0.81,0.62,0.70, Naive Bayes,0.80,0.78,0.84,0.80, Random Forest,0.82,0.85,0.76,0.80, Multi-layer Perceptron,0.76,0.68,0.87,0.77, AdaBoost,0.79,0.80,0.75,0.77","The table presents model performance from five different approaches evaluated using accuracy, precision, recall, and F1-score metrics. The SVM model achieved an accuracy of 0.75, with precision and recall of 0.81 and 0.62, respectively, and an F1-Score of 0.70. Overall, the Random forest model obtained the highest accuracy score of 0.82, with the highest precision of 0.85. The MLP algorithm achieved the highest recall of 0.87, followed closely by Naive Bayes, with 0.84. AdaBoost showed the lowest but still satisfactory performance metrics, with an accuracy of 0.79, a precision of 0.80, a recall of 0.75, and an F1-Score of 0.77. This information could assist the model selection process for classification tasks."
2622,"caption: Evaluation Metrics for Multiple Modelstable: Model Name,F1-Score,Accuracy,Precision,Recall, Random Forest,0.95,0.96,0.97,0.93, Logistic Regression,0.83,0.89,0.85,0.81, Support Vector Machine,0.79,0.81,0.78,0.80, K Nearest Neighbors,0.73,0.76,0.74,0.72","Table above shows the F1-Score, Accuracy, Precision, and Recall evaluated for four different models. The evaluation metrics were computed on the same dataset, and the best hyperparameters for each model were used. The Random Forest model demonstrates the highest F1-Score of 0.95, the highest Accuracy of 0.96, and the highest Precision of 0.97. The Logistic Regression model has the lowest F1-Score of 0.83, while the K nearest neighbors' model has the lowest accuracy of 0.76. Overall, the Random Forest model outperforms the other models in all evaluated metrics."
2623,"caption: Evaluation metrics results for different models.table: Model,Accuracy,Precision,Recall,F1 Score, Model 1,0.89,0.88,0.91,0.89, Model 2,0.92,0.89,0.92,0.91, Model 3,0.85,0.83,0.88,0.86, Model 4,0.91,0.92,0.89,0.91, Model 5,0.90,0.88,0.91,0.89","The presented table depicts the evaluation result metrics, including accuracy, precision, recall, and F1 score of five different models. Interestingly, Model 2 has the highest accuracy score of 0.92, following Model 4 with an accuracy score of 0.91. On the other hand, Model 3 has the lowest accuracy score of 0.85, indicating that it may not be suitable for the given dataset. However, Model 4 has the highest precision score of 0.92, while Model 2 and Model 5 have the highest recall scores of 0.92 and 0.91, respectively. Also, Model 2 has the highest F1 score of 0.91, making it the best-performing model in the overall evaluation."
2624,"caption: Table 4: Model performances based on different evaluation metrics.table: Models,Accuracy,F1-score,Precision,Recall, LR (baseline),0.84,0.86,0.87,0.85, KNN,0.79,0.81,0.78,0.85, SVM,0.87,0.88,0.89,0.88, Random Forest,0.92,0.93,0.92,0.94, XGBoost,0.94,0.95,0.94,0.95","Table 4 presents a comparison of model performances based on different evaluation metrics, including accuracy, F1-score, precision, and recall. The table includes LR (baseline), KNN, SVM, Random Forest, and XGBoost models. The Random Forest and XGBoost models achieve the highest accuracy score of 0.92 and 0.94, respectively. Moreover, the XGBoost model demonstrates consistently excellent performance in all metrics, with F1-score, precision, and recall scores at 0.95. In terms of the baseline LR model, it has a relatively lower performance in terms of the F1-score, recall, and precision compared to other models. The table suggests that the Random Forest and XGBoost models outperform the other models in terms of overall performance."
2625,"caption: Evaluation metrics of different models.table: Model Name,Accuracy,Precision,Recall,F1-score, Model 1,0.91,0.92,0.89,0.91, Model 2,0.89,0.87,0.92,0.89, Model 3,0.92,0.94,0.90,0.92, Model 4,0.87,0.83,0.92,0.87, Model 5,0.90,0.91,0.89,0.90","The table above shows the comparison of different models' performance based on various evaluation metrics. The models were evaluated based on their accuracy, precision, recall, and f1-score. The results show that model 3 outperforms the other models with a high accuracy of 0.92, precision of 0.94, recall of 0.90, and f1-score of 0.92. Model 1 and model 5 were also among the top-performing models, with accuracy scores of 0.91 and 0.90, respectively. On the other hand, model 4 showed the worst performance compared to other models, with an accuracy score of only 0.87. Overall, the results demonstrate the importance of evaluating models based on multiple metrics to get a comprehensive view of their performance."
2626,"caption: Evaluation metrics of multiple classification models on a test dataset.table: Model,F1-score,Precision,Recall,AUC-ROC,Accuracy, Random Forest,0.84,0.85,0.84,0.92,0.84, Support Vector Machine,0.77,0.80,0.77,0.79,0.78, K-Nearest Neighbors,0.70,0.87,0.70,0.75,0.70, Logistic Regression,0.82,0.83,0.82,0.90,0.82, Decision Tree,0.68,0.68,0.68,0.71,0.68","The table presents five different classification models' evaluation metrics on a test dataset. The models' performances are assessed based on five evaluation metrics, including F1-score, precision, recall, AUC-ROC, and accuracy. The Random Forest achieved the highest F1-score of 0.84, while the Support Vector Machine obtained the lowest F1-score of 0.77. The Logistic Regression model produced the highest AUC-ROC value of 0.90. The K-Nearest Neighbors model demonstrated the highest precision of 0.87, but it has the lowest performance scores for all other metrics. Finally, the Decision Tree model showed the lowest performances across all five evaluation metrics."
2627,"caption: Comparative performance of different classifiers based on evaluation metricstable: Model,Accuracy,F1-score,Precision,Recall, SVM,0.89,0.88,0.91,0.85, KNN,0.82,0.80,0.76,0.86, DT,0.75,0.72,0.70,0.74, RF,0.92,0.91,0.93,0.90","Table above compares different classifiers' performance based on accuracy, F1-score, precision, and recall evaluation metrics. It is evident that the Random Forest (RF) model achieves the highest accuracy, F1-score, precision, and recall at 0.92, 0.91, 0.93, and 0.90 respectively. The SVM classifier also exhibits good performance with an overall accuracy of 0.89 and similar F1-score, precision, and recall scores. However, the K-Nearest Neighbors (KNN) and Decision Tree (DT) models show lower accuracy scores, suggesting less effective classification for the dataset."
2628,"caption: Performance evaluation of different models using multiple metrics.table: Model,Accuracy,Precision,Recall,F1-score, Model A,0.85,0.80,0.75,0.77, Model B,0.89,0.89,0.82,0.84, Model C,0.92,0.91,0.92,0.91, Model D,0.86,0.85,0.93,0.83, Model E,0.88,0.93,0.87,0.89","The table displays an evaluation of five different models A, B, C, D, and E, based on four different metrics: accuracy, precision, recall, and F1-score. Each model's performance is shown in terms of the four considered metrics. Model C achieved the best overall performance, achieving an accuracy of 0.92 and a high recall score of 0.92, illustrating that it has excellent predictive power. Model D achieved the highest precision score of 0.85 and the highest recall score of 0.93, which indicates its ability to identify most of the true positives while maintaining a low false positive rate. Interestingly, Model E yields the highest precision score of 0.93 but with a lower recall score of 0.87. Therefore, the table suggests Model C might be a more suitable choice for a higher recall, while Model D might be the optimal choice when higher precision values are preferred."
2629,"caption: Model performance based on different evaluation metricstable: Model,Accuracy (%),Precision (%),Recall (%),F1-Score (%), SVM,75.3,76.1,73.4,74.7, KNN,64.5,64.1,63.9,63.9, RF,82.7,81.2,84.4,82.8, Ada,79.3,81.7,75.8,78.6, XGB,84.9,83.2,88.6,85.7, MLP,83.1,81.6,85.2,83.4",
2630,"caption: Table 4: Evaluation metrics of different models.table: Model,Accuracy,Precision,Recall,F1-score,AUC, Model 1,0.95,0.91,0.87,0.89,0.948, Model 2,0.93,0.84,0.82,0.83,0.925, Model 3,0.89,0.79,0.81,0.80,0.876, Model 4,0.91,0.80,0.83,0.81,0.903, Model 5,0.94,0.92,0.89,0.90,0.939","Table 4 presents evaluation metrics, including Accuracy, Precision, Recall, F1-score, and AUC of different models. These models were trained and tested using the same dataset, consisting of binary classification tasks. The table highlights that Model 1 and Model 5 achieved the highest Accuracy of 0.95 and 0.94, respectively. However, Model 5 used the highest Precision of 0.92, while Model 1 had the highest Recall of 0.87. Interestingly, Model 1, Model 4, and Model 5 showed similar performance with the highest F1-score of 0.89, 0.81, and 0.90, respectively. Lastly, the AUC values suggested that Model 1 was the best model, while Model 3 showed the lowest performance among all models."
2631,"caption: Table 4: Performance results for multiple models based on different evaluation metrics.table: Models,Accuracy,F1 Score,Precision,Recall, Model 1,0.82,0.81,0.80,0.83, Model 2,0.81,0.80,0.82,0.78, Model 3,0.85,0.82,0.84,0.80, Model 4,0.87,0.85,0.83,0.87, Model 5,0.80,0.79,0.81,0.77","Table 4 compares the performances of five different models based on multiple evaluation metrics. The table reports evaluation metrics such as Accuracy, F1 Score, Precision, and Recall. Among the models, Model 4 achieved the highest accuracy with a score of 0.87, followed closely by Model 3 with a score of 0.85. Interestingly, Model 1 had the highest F1 Score of 0.81, while Model 4 and Model 3 had the lowest precision and recall scores, respectively. Overall, the table shows that there is no 'best' model as each model performed differently based on the evaluation metric used."
2632,"caption: Model performance comparisontable: Model,Accuracy,F1-score,Precision,Recall, Multinomial Naive Bayes,0.74,0.71,0.71,0.71, Random Forest,0.81,0.77,0.78,0.80, Logistic Regression,0.76,0.73,0.73,0.73, Support Vector Machine,0.79,0.75,0.76,0.76","The table showcases a comparison of different models' performances in terms of accuracy, F1-score, precision, and recall. The Multinomial Naive Bayes model achieved an accuracy score of 0.74. The Random Forest model performed slightly better in accuracy with 0.81 and had the best F1-score of 0.77. The Support Vector Machine and Logistic Regression models also showed promising F1-scores of 0.75 and 0.73, respectively. In terms of precision and recall, the Random Forest and Support Vector Machine models performed the best with scores ranging between 0.76 and 0.80. Overall, the results suggest that the Random Forest model performs better than the other models, particularly in terms of F1-score with an accuracy of 0.81."
2633,"caption: Table 4: Model evaluation metrics for various machine learning models.table: Model,Precision,Recall,F1-score,Accuracy, Logistic Regression,0.75,0.85,0.80,0.90, Naïve Bayes,0.81,0.88,0.84,0.87, Random Forest,0.90,0.92,0.91,0.88, Decision Tree,0.70,0.80,0.75,0.82, SVM,0.84,0.87,0.86,0.89","Table 4 presents the evaluation metrics of multiple machine learning models such as Logistic Regression, Naïve Bayes, Random Forest, Decision Tree, and SVM. The metrics included in the table are Precision, Recall, F1-score, and Accuracy. Out of all the models, Random Forest outperformed the other models in terms of Precision, Recall, F1-score and Accuracy with values of 0.90, 0.92, 0.91 and 0.88, respectively. SVM also performed well with Precision, Recall, F1-score and Accuracy of 0.84, 0.87, 0.86, and 0.89, respectively. Conversely, Decision Tree performed less favorably compared to other models. Overall, Random Forest and SVM models seem to be suitable for the classification task based on these evaluation metrics."
2634,"caption: Table 4: Evaluation metrics for different classification models.table: Model,Accuracy,F1-score,Precision,Recall, Model 1,0.85,0.87,0.86,0.89, Model 2,0.82,0.76,0.83,0.72, Model 3,0.91,0.92,0.90,0.94, Model 4,0.76,0.80,0.79,0.81, Model 5,0.88,0.90,0.87,0.92","Table 4 presents the performance evaluation metrics for different classification models. The table includes five models, and the evaluation metrics are Accuracy, F1-score, Precision, and Recall. Model 3 has the highest accuracy score of 0.91, and it is followed by Model 5 with an accuracy score of 0.88. However, Model 5 achieved the highest F1-score of 0.90, followed closely by Model 3 with an F1-score of 0.92. Interestingly, Model 4 scores the lowest accuracy score of 0.76, but it has an F1-score of 0.80, which is the second-highest F1-score among all models. These results show the importance of considering multiple evaluation metrics when comparing the performance of classification models."
2635,"caption: Model Performance Metrics for Different Approachestable: Model,Accuracy,F1-Score,Precision,Recall,AUC, Logistic Regression,0.85,0.84,0.78,0.91,0.91, Decision Tree,0.81,0.80,0.76,0.86,0.82, Random Forest,0.91,0.91,0.89,0.93,0.94, Support Vector Machine,0.87,0.86,0.83,0.89,0.91, Gradient Boosting,0.90,0.90,0.89,0.91,0.93","The table presents the performance results of multiple models, including Logistic Regression, Decision Tree, Random Forest, Support Vector Machine, and Gradient Boosting. These models were examined against different evaluation metrics, including Accuracy, F1-Score, Precision, Recall, and AUC. The table highlights the highest performance results through bolded numbers. Notably, the Gradient Boosting model showed the best performance amongst the models in terms of AUC (0.93) with similar results for other metrics, such as Accuracy (0.90), F1-Score (0.9), Precision (0.89), and Recall (0.91). The Random Forest model obtained second best performance with an AUC of 0.94. In contrast, the Decision Tree model showed the lowest performance in terms of F1-Score (0.80). The analysis emphasizes the importance of selecting the proper model based on the evaluation metric that best suits the research objective."
2636,"caption: Performance of various models based on accuracy, precision, and recall.table: Models,Accuracy,Precision,Recall, SVM,0.85,0.88,0.82, KNN,0.75,0.79,0.68, Naive Bayes,0.90,0.92,0.87, Decision Tree,0.88,0.86,0.90, Random Forest,0.93,0.96,0.90","The table compares the performance of SVM, KNN, Naive Bayes, Decision Tree, and Random Forest models on a given dataset. The evaluation metrics reported for each model include Accuracy, Precision, and Recall. The Random Forest model shows the best accuracy, precision, and recall scores with an accuracy score of 0.93, a precision score of 0.96, and a recall score of 0.90. Naive Bayes and SVM models also exhibit high performance with accuracy scores of 0.90 and 0.85, respectively. Interestingly, the KNN model had the lowest performance, with the lowest accuracy, precision, and recall scores among all models."
2637,"caption: Table 4: Model performance based on different evaluation metricstable: Model,Accuracy,F1-score,Precision,Recall, SVM,0.73,0.70,0.62,0.80, Logistic Regression,0.69,0.67,0.60,0.76, Random Forest,0.81,0.78,0.70,0.89, XGBoost,0.84,0.81,0.74,0.91","Table 4 shows a comparison of four different models' performances based on various evaluation metrics: Accuracy, F1-score, Precision, and Recall. The models included in this table are SVM, Logistic Regression, Random Forest, and XGBoost. All models were trained and tested using the same dataset. The Random Forest model has the highest Accuracy score of 0.81, followed by XGBoost with 0.84. Similarly, XGBoost has the highest F1-score of 0.81, followed closely by Random Forest at 0.78. In terms of Precision, XGBoost stands out with a score of 0.74, while SVM has the highest Recall score of 0.80. Overall, the table suggests that XGBoost and Random Forest models performed better than SVM and Logistic Regression based on the evaluation metrics."
2638,"caption: A performance comparison of various classification models with multiple evaluation metrics.table: Model,Accuracy,F1 Score,AUC,Precision, SVM,0.82,0.82,0.67,0.87, KNN,0.81,0.81,0.63,0.83, Naive Bayes,0.75,0.73,0.58,0.80, Decision Tree,0.78,0.79,0.57,0.76, Random Forest,0.83,0.84,0.69,0.9, XGBoost,0.88,0.87,0.74,0.93","The table above presents a performance comparison of six different models - SVM, KNN, Naive Bayes, Decision Tree, Random Forest, and XGBoost based on four evaluation metrics, namely, Accuracy, F1-Score, Area Under the Curve (AUC), and Precision. Notably, all models were tested and trained using the same dataset. Interestingly, the XGBoost model outperforms all other models in all evaluation metrics, with an accuracy score of 0.88, F1-Score of 0.87, AUC of 0.74, and Precision of 0.93. The Naive Bayes model showed the lowest performance among all models for all evaluation metrics."
2639,"caption: Table 1: Model performance measured by various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, SVM,0.85,0.86,0.84,0.85, Random Forest,0.87,0.89,0.84,0.86, Logistic Reg.,0.84,0.87,0.82,0.84, Decision Tree,0.80,0.81,0.79,0.80","Table 1 presents model performances of SVM, Random Forest, Logistic Regression, and Decision Tree classifiers in terms of Accuracy, Precision, Recall, and F1-Score on a given dataset. Interestingly, the Random Forest model performed the best concerning Accuracy, scoring 0.87, closely followed by SVM with an Accuracy score of 0.85. However, the Logistic Regression model performed the best concerning Precision, scoring 0.87, followed by the Random Forest and SVM models with Precision scores of 0.89 and 0.86, respectively. The Decision Tree model achieved the lowest performance results with an Accuracy score of 0.80. Additionally, all models achieved comparable Recall and F1-Scores. Overall, these results suggest that the Random Forest classifier was the most balanced classifier, giving decent performance results for all monitored evaluation metrics."
2640,"caption: Table 4: Model performance comparison based on accuracy, F1-score, precision, and recall.table: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression (C=0.1),0.864,0.869,0.879,0.860, Decision Tree (max-depth=5),0.742,0.692,0.764,0.637, Random Forest (n_estimators=100),0.908,0.912,0.925,0.899, XGBoost (learning rate=0.05),0.912,0.917,0.928,0.906","Table 4 compares the performance of multiple models based on accuracy, F1-score, precision, and recall metrics. The table presents the performance of Logistic Regression, Decision Tree, Random Forest, and XGBoost models. Random Forest and XGBoost models show the highest accuracy, F1-score, precision, and recall scores. XGBoost achieved the highest accuracy score of 0.912, F1-score of 0.917, precision of 0.928, and recall of 0.906. Logistic regression had a high precision score of 0.879, whereas Decision tree had the lowest accuracy of 0.742 and recall of 0.637. These results indicate that XGBoost and Random Forest models outperform Logistic Regression and Decision Tree in terms of all four evaluation metrics."
2641,"caption: Evaluation metrics of different classification modelstable: Model,F1-Score,Accuracy,Precision,Recall, SVM,0.89,0.91,0.92,0.87, Random Forest,0.92,0.94,0.93,0.91, Logistic Regression,0.87,0.90,0.85,0.89, Multi-layer Perceptron,0.93,0.96,0.92,0.94, K-Nearest Neighbors,0.88,0.89,0.87,0.89","Table presents a comparison of five different classification models' performance, evaluated using four different metrics - F1-Score, Accuracy, Precision, and Recall. The table exhibits SVM, Random Forest, Logistic Regression, Multi-layer Perceptron, and K-Nearest Neighbors models' performance results. Interestingly, the Multi-layer Perceptron model shows the best performance among all models with an F1-Score of 0.93 and an accuracy score of 0.96. On the other hand, the Logistic Regression model achieved the lowest F1-Score of 0.87. Nevertheless, all models demonstrate good performance scores based on the metrics presented."
2642,"caption: Model performance using different evaluation metricstable: Model,Accuracy,Precision,Recall,F1 Score, Model 1,0.85,0.82,0.89,0.85, Model 2,0.81,0.86,0.74,0.80, Model 3,0.87,0.88,0.84,0.86, Model 4,0.83,0.79,0.91,0.84",
2643,"caption: Performance comparison of different models using various evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.85,0.82,0.87,0.79, Random Forest,0.95,0.94,0.92,0.97, Naive Bayes,0.78,0.79,0.85,0.73, SVM,0.90,0.88,0.91,0.86","The table presents a comparison of model performances for different classification algorithms, including logistic regression, random forest, naive bayes, and support vector machine (SVM). Various evaluation metrics, such as accuracy, F1-score, precision, and recall, have been used to assess model performance. Interestingly, Random forest model shows the best performance on all metrics, achieving the highest accuracy of 0.95 and the highest F1-score of 0.94. In contrast, Naive Bayes model shows the lowest performance on all metrics, with the lowest accuracy of 0.78 and the lowest F1-score of 0.79. The results suggest that Random forest and SVM are good models for this classification task."
2644,"caption: Table 4: Evaluation metrics for multiple models.table: Model,Accuracy,F1 Score,Precision,Recall, Model 1,0.85,0.84,0.86,0.83, Model 2,0.78,0.76,0.81,0.72, Model 3,0.91,0.90,0.92,0.89, Model 4,0.88,0.87,0.89,0.84","Table 4 depicts a comparison of evaluation metrics computed across four different models. The models are identified in the first column, while the remaining columns contain various 'Accuracy', 'F1 Score', 'Precision', and 'Recall' metrics. Notably, Model 3 demonstrates excellent performance compared to the other models, with the highest 'Accuracy' of 0.91, 'F1 Score' of 0.90, 'Precision' of 0.92, and 'Recall' of 0.89. Conversely, Model 2 exhibits the poorest performance on all measurements, with an 'Accuracy' of 0.78, 'F1 Score' of 0.76, 'Precision' of 0.81, and 'Recall' of 0.72. Model 1 and Model 4 each have their strengths and weaknesses, with Model 1 having the highest 'Precision' score at 0.86 and Model 4 having the highest 'Recall' of 0.84."
2645,"caption: Evaluation metrics for multiple models on a classification task.table: Model,Accuracy,Precision,Recall,F1-score, Model A,0.87,0.84,0.90,0.87, Model B,0.91,0.89,0.92,0.91, Model C,0.84,0.82,0.85,0.83, Model D,0.93,0.91,0.94,0.93","The table displays multiple models' evaluation metrics on a classification task, considering accuracy, precision, recall, and F1-score. Model A obtained an accuracy of 0.87 and had a precision of 0.84, recall of 0.90 and F1-score of 0.87. Model B achieved the best result among all models, with an accuracy of 0.91, precision of 0.89, recall of 0.92, and F1-score of 0.91. Model D came in second place with accuracy of 0.93, precision of 0.91, recall of 0.94, and F1-score of 0.93, while Model C obtained the lowest results in all metrics."
2646,"caption: Model Performances of Four Algorithms Based on Precision, Recall, F1 Score, and Accuracytable: Model,Precision,Recall,F1 Score,Accuracy, Logistic Regression,0.85,0.76,0.80,0.83, Naive Bayes,0.71,0.60,0.65,0.70, Random Forest,0.91,0.92,0.92,0.91, XGBoost,0.88,0.85,0.86,0.88",
2647,"caption: Comparison of different models based on evaluation metrics accuracy, precision, recall, and F1-score.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.89,0.77,0.92,0.84, LR,0.88,0.79,0.85,0.82, KNN,0.79,0.81,0.63,0.71, RF,0.91,0.88,0.88,0.88, XG,0.92,0.91,0.88,0.89","The table presents the evaluation metrics accuracy, precision, recall, and F1-Score for the SVM, LR, KNN, RF, and XG model performances. The models are compared using the same dataset and evaluated against the same evaluation metrics. Interestingly, the RF and XG models show the highest accuracy with scores of 0.91 and 0.92, respectively. The XG model ranks the highest in precision, while the SVM model scores best in recall. The F1-score reveals the RF model as the best-performing model with a score of 0.88. In conclusion, the RF and XG models perform best overall, each excelling in different evaluation metrics."
2648,"caption: Performance results of various models using different evaluation metrics.table: Model,Precision,Recall,Accuracy,F1-Score,AUC, SVM,89.3,93.1,92.3,91.1,0.961, Decision Tree,85.1,86.8,88.9,85.7,0.926, Random Forest,91.1,94.5,93.2,92.2,0.972, Gradient Boost,92.9,95.1,94.5,93.9,0.983, Neural Network,91.8,94.9,93.9,93.1,0.978","The table above shows the performance results of five different classification models, namely SVM, Decision Tree, Random Forest, Gradient Boost, and Neural Network. Each model's performance is evaluated using five different evaluation metrics, namely Precision, Recall, Accuracy, F1-Score, and AUC. Interestingly, the Random Forest and the Gradient Boost models show better results across all evaluation metrics compared to the other models. The Gradient Boost model, in particular, achieves the highest F1-Score and the highest AUC score of 93.9 and 0.983, respectively. These results suggest that these two models can be effective choices when working with the given dataset."
2649,"caption: Performance comparison of different models on evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.85,0.88,0.81,0.84, LR,0.82,0.83,0.82,0.81, RF,0.87,0.87,0.87,0.87, KNN,0.79,0.80,0.79,0.78","Table displays the performance comparison of SVM, LR, RF, and KNN models on evaluation metrics such as Accuracy, Precision, Recall, and F1-Score. Among all models, RF model scored highest accuracy of 0.87 and equal precision and recall scores of 0.87 each. SVM model had the highest precision score of 0.88 and recall score of 0.81. LR model had the lowest accuracy score of 0.82 and the lowest F1-score of 0.81 among all the models. The KNN model had the lowest accuracy score of 0.79, lowest precision score of 0.80, and lowest recall score of 0.79."
2650,"caption: Table 4: Model Performance Results for binary classification task on the test dataset judged with different metrics.table: Model,Accuracy,Precision,Recall,F1-Score,AUC-ROC, Logistic Reg.,0.89,0.87,0.91,0.89,0.945, Decision Tree,0.83,0.79,0.87,0.83,0.871, Random Forest,0.92,0.91,0.93,0.92,0.967, SVM,0.87,0.85,0.89,0.87,0.926, Naive Bayes,0.78,0.71,0.86,0.77,0.834","Table 4 presents the evaluation metrics, namely, Accuracy, Precision, Recall, F1-Score, and AUC-ROC, of five models: Logistic Regression, Decision Tree, Random Forest, SVM, and Naive Bayes, for binary classification on the test dataset. The table shows that the best accuracy was achieved by the Random Forest model with a score of 0.92. The same model also generated the highest precision and recall scores of 0.91 and 0.93, respectively. The SVM model produced the highest F1-Score of 0.87, while the AUC-ROC metric was highest for the Random Forest model with a score of 0.967. Notably, Logistic Regression and SVM outperformed Naive Bayes and Decision Tree models in all metrics."
2651,"caption: Evaluation metrics of different modelstable: Model,Accuracy,Precision,Recall,F1-score, SVM,0.85,0.86,0.84,0.85, KNN,0.80,0.81,0.83,0.82, MLP,0.91,0.92,0.91,0.91, RF,0.92,0.93,0.92,0.92, XGB,0.90,0.91,0.90,0.90","The 'Evaluation metrics of different models' table presents a comparison of model evaluation metrics, including Accuracy, Precision, Recall, and F1-score. The table includes SVM, KNN, MLP, RF, and XGB models, with their respective metrics scores. The RF model performed better than other models with an accuracy of 0.92 and other evaluation metrics, including Precision, Recall, and F1-score, also outperformed the other models. Interestingly, the MLP model also had a high accuracy score of 0.91 and scored well with all the evaluation metrics. The KNN model, on the other hand, had a relatively lower accuracy score of 0.80 and only performed well with Recall and F1-score. The SVM and XGB models scored similarly, with an accuracy of 0.85 and 0.90, respectively, and also performed similarly across the other evaluation metrics."
2652,"caption: Performance of different models based on classification metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.82,0.74,0.87,0.80, Random Forest,0.88,0.80,0.89,0.84, K-Nearest Neighbors,0.79,0.69,0.86,0.76, Support Vector Machine,0.85,0.77,0.90,0.83, XGBoost,0.90,0.83,0.92,0.87","The table shows the summarized performance of five different models based on classification metrics, namely Accuracy, Precision, Recall, and F1 Score. The Logistic Regression model shows the lowest performance results in all evaluation metrics, except for Recall, where it has the highest score of 0.87. Random Forest shows higher performance than Logistic Regression in all evaluation metrics, while the Support Vector Machine model achieves the highest accuracy and F1 Score after the XGBoost model. Interestingly, the XGBoost model shows the best performance in all evaluation metrics, with 0.90 accuracy, 0.83 precision, 0.92 recall, and 0.87 F1 Score."
2653,"caption: F1-score, Precision, and Recall evaluation metrics for different models.table: Model,F1-score,Precision,Recall, Model1,0.88,0.90,0.86, Model2,0.79,0.74,0.84, Model3,0.93,0.91,0.95, Model4,0.76,0.85,0.70","The table compares the performance of four different models, showcasing their F1-score, precision, and recall evaluation metrics. We observe that Model3 outperforms the other models with the highest F1-score of 0.93, and a precision score of 0.91 and recall score of 0.95. Meanwhile, Model4 performs the worst, with an F1-score of just 0.76. Interestingly, Model2 achieves the highest precision score of 0.74. However, it has a lower F1-score and recall score of 0.79 and 0.84, respectively. This table provides valuable insights into model performances with multiple metrics that can be useful for choosing the most appropriate model for the given task."
2654,"caption: Table 4: Summary of model performances based on various evaluation metricstable: Model,Accuracy,F1-score,Precision,Recall, SVM,0.854,0.853,0.875,0.835, KNN,0.811,0.810,0.822,0.799, Random Forest,0.945,0.945,0.949,0.940, Naive Bayes,0.746,0.742,0.767,0.719, Logistic Regression,0.832,0.830,0.844,0.817, XGBoost,0.950,0.950,0.954,0.947","Table 4 presents a detailed summary of model performances based on various evaluation metrics. The models used for the experiment include Support Vector Machines (SVM), K-Nearest Neighbors (KNN), Random Forest, Naive Bayes, Logistic Regression, and XGBoost. The table shows the evaluation metrics for each model, including Accuracy, F1-score, Precision, and Recall. Interestingly, the Random Forest model displays the highest accuracy of 0.945, and the XGBoost model obtained the highest performance with an accuracy of 0.950."
2655,"caption: A comparison of different models based on multiple evaluation metrics.table: Model,F1-Score,Precision,Recall,Accuracy,AUC-ROC, SVM,0.86,0.88,0.84,0.89,0.91, Naïve Bayes,0.79,0.82,0.76,0.86,0.87, Deep Neural Net,0.90,0.88,0.92,0.91,0.93, Random Forest,0.84,0.81,0.88,0.88,0.89, k-NN,0.75,0.72,0.78,0.80,0.81","The table above compares five different models' performances on multiple evaluation metrics. The models include SVM, Naïve Bayes, Deep Neural Net, Random Forest, and k-NN. The evaluation metrics used in the table include F1-Score, Precision, Recall, Accuracy, and AUC-ROC. The Deep Neural Net model performs the best across all metrics, achieving the highest F1-score of 0.90, the highest Recall of 0.92, and the highest AUC-ROC of 0.93. Interestingly, the SVM model performs relatively well in accuracy and AUC-ROC, achieving 0.89 and 0.91, respectively. In contrast, the Naïve Bayes model has the lowest performance, with an F1-Score of 0.79 and AUC-ROC of 0.87."
2656,"caption: Performance results of multiple modelstable: Models,Accuracy,F1-Score,Recall,Precision, Model 1,0.85,0.89,0.82,0.96, Model 2,0.78,0.83,0.72,0.97, Model 3,0.90,0.92,0.91,0.96, Model 4,0.82,0.88,0.78,0.96, Model 5,0.88,0.91,0.87,0.96","The table shows different models' accuracy, F1-score, recall, and precision evaluated on the same dataset. Model 3 achieved the highest accuracy score of 0.90, whereas Model 2 had the lowest accuracy of 0.78. Model 5 has the highest F1-score of 0.91, implying that it balances precision and recall better than other models. Interestingly, Model 1 and Model 3 show comparable precision scores of 0.96 despite their difference in performance in other metrics. Model 2 has the highest precision score of 0.97 and has the lowest recall score of 0.72 among the other models. Overall, the table highlights the differences in performance metrics among multiple models."
2657,"caption: Comparison of different machine learning models.table: Model,Accuracy,Precision,Recall,F1-Score,AUC, SVM,0.91,0.92,0.94,0.93,0.85, KNN,0.87,0.88,0.83,0.85,0.76, RF,0.93,0.96,0.90,0.93,0.87, XGB,0.91,0.94,0.87,0.90,0.84","The table above presents a comparison of different machine learning models' performance on the evaluation metrics, including Accuracy, Precision, Recall, F1-Score, and AUC. The models presented here are SVM, KNN, RF, and XGB. Based on the results, RF exhibits the best performance on all metrics except for Accuracy, where it had a slightly worse result than SVM. In contrast, SVM had the best AUC score. Interestingly, KNN had the lowest AUC score in all models, while XGB had the second-best F1-Score and Precision score. Overall, this table provides useful insights into different models' performance and can aid researchers in identifying the best model for their classification tasks."
2658,"caption: Model performances based on different evaluation metricstable: Model,Precision,Recall,F1-Score,Accuracy, SVM,0.827,0.727,0.773,0.866, KNN,0.759,0.646,0.692,0.815, RF,0.892,0.817,0.841,0.922, MLP,0.863,0.793,0.807,0.900","The table displays the performance results of four different models, SVM, KNN, RF, and MLP, based on different evaluation metrics, including precision, recall, F1-score, and accuracy. Performance metrics were calculated based on the models' predictions on the test data. The RF model performed best on multiple metrics, achieving high precision, recall, and F1-Score values, while also showing the highest accuracy of 0.922. MLP yielded similar results, obtaining high precision, recall, and accuracy values, while SVM and KNN had lower scores for certain metrics. These results can assist in choosing a suitable model for a classification task based on a specific evaluation metric."
2659,"caption: Performance metrics for different machine learning models.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.86,0.85,0.87,0.83, KNN,0.80,0.75,0.79,0.71, Random Forest,0.91,0.90,0.92,0.88, Naive Bayes,0.79,0.76,0.80,0.72, Neural Network,0.87,0.86,0.87,0.85","Table illustrates the performance of five different machine learning models; SVM, KNN, Random Forest, Naive Bayes, and Neural Network, on a given dataset. The models were evaluated based on four different metrics: Accuracy, F1-Score, Precision, and Recall. The Random Forest model performed the best among the models with an accuracy of 0.91 and an F1-Score of 0.9. Interestingly, the Naive Bayes models had the lowest accuracy (0.79) but managed to achieve the highest precision (0.8) than other models. Overall, the table demonstrates the different aspects of model performances based on the specific method for evaluation."
2660,"caption: Table 4: Evaluation metrics of different machine learning models applied on a binary classification task.table: Models,Precision,Recall,F1 Score,Accuracy, Decision Tree,0.86,0.76,0.79,0.89, Random Forest,0.90,0.82,0.84,0.91, Support Vector Machine,0.89,0.75,0.79,0.90, Adaboost,0.88,0.80,0.82,0.89, Gradient Boosting,0.91,0.86,0.87,0.92","Table 4 presents a comparison of several machine learning models' performance on a binary classification task using multiple evaluation metrics. The evaluation metrics Precision, Recall, F1 Score, and Accuracy are used in this comparison. The models include Decision Tree, Random Forest, Support Vector Machine, Adaboost, and Gradient Boosting. Notably, the Gradient Boosting model achieved the highest scores for all the evaluation metrics, with the highest precision of 0.91, recall of 0.86, F1 score of 0.87, and accuracy of 0.92. The Random Forest model also performed well, achieving second-best scores for all metrics, followed closely by the Adaboost model. The Decision Tree and Support Vector Machine models obtained the lowest scores for all evaluation metrics."
2661,"caption: Performance of different models based on different evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, Log. Regression,0.75,0.72,0.73,0.73, Random Forest,0.82,0.79,0.82,0.77, Decision Tree,0.79,0.76,0.79,0.74, SVM,0.77,0.75,0.74,0.78","The table illustrates the performance of four different models (Logistic Regression, Random Forest, Decision Tree, and Support Vector Machine) based on multiple evaluation metrics, including Accuracy, F1-score, Precision, and Recall. The Random Forest model shows the highest performance in terms of Accuracy (0.82), F1-score (0.79), and Precision (0.82). The Decision tree model had the lowest performance in all evaluation metrics, particularly in terms of Recall (0.74). SVM achieved the highest Recall (0.78), but it had lower accuracy (0.77), precision (0.74), and F1-score (0.75) than the Random Forest model."
2662,"caption: Performance results of different models based on multiple evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.92,0.94,0.93,0.95, KNN,0.87,0.90,0.88,0.91, RF,0.90,0.92,0.91,0.94, GB,0.91,0.93,0.92,0.95, MLP,0.89,0.91,0.90,0.92","Table presents the performance results of five different machine learning models on a given dataset, based on multiple evaluation metrics- Accuracy, F1-Score, Precision, and Recall. The Support Vector Machine (SVM) model performed the best in all the four metrics with an accuracy score of 0.92, F1-Score of 0.94, Precision of 0.93, and Recall of 0.95 closely followed by Gradient Boosting (GB) model. In contrast, K-Nearest Neighbors (KNN) had the lowest score in all metrics. These results help to deduce suitable model performance metrics based on the analysis requirements."
2663,"caption: Table 4: Performance evaluation for various models using different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, Model 1,0.92,0.91,0.93,0.92, Model 2,0.95,0.94,0.94,0.94, Model 3,0.88,0.85,0.90,0.87, Model 4,0.97,0.96,0.98,0.97","Table 4 above summarizes the performance of multiple models using different evaluation metrics. The metrics considered are Accuracy, Precision, Recall, and F1-score. Model 4 shows the highest performance across all four evaluation metrics. With an Accuracy score of 0.97, Precision score of 0.96, Recall score of 0.98, and F1-score of 0.97, it was the best-performing model. Interestingly, Model 2 shows the second-best performance with an Accuracy score of 0.95 and an F1-score of 0.94. In contrast, Model 3 performs worst across all the four evaluation metrics, with an Accuracy score of 0.88, Precision score of 0.85, Recall score of 0.90, and F1-score of 0.87."
2664,"caption: Table 4: Model performance based on evaluation metricstable: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.875,0.843,0.847,0.848, Decision Tree,0.845,0.798,0.792,0.807, Random Forest,0.905,0.897,0.890,0.925, Gradient Boosting,0.911,0.898,0.893,0.904, Support Vector Machines,0.874,0.823,0.825,0.830","Table 4 presents a comparison of different models' performances based on accuracy, F1 Score, precision, and recall evaluation metrics. The models evaluated in this table are Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Support Vector Machines. The table illustrates that the Gradient Boosting model shows the best performance overall, with accuracy, F1 Score, precision, and recall scores of 0.911, 0.898, 0.893 and 0.904, respectively. Moreover, the Random Forest model demonstrates better performance in terms of accuracy, F1 Score, precision, and recall than Logistic Regression and Decision Tree models. Finally, Support Vector Machines (SVM) achieved comparable results with Logistic Regression in regards to the evaluation metrics."
2665,"caption: Performance results of different models using different evaluation metrics.table: Model,Precision,Recall,F1-Score,PR-AUC,ROC-AUC, Logistic Regression,0.72,0.82,0.76,0.80,0.85, Decision Tree,0.74,0.70,0.72,0.78,0.80, Naive Bayes,0.62,0.88,0.73,0.76,0.82, Random Forest,0.86,0.83,0.84,0.94,0.92, Gradient Boosting,0.83,0.81,0.82,0.89,0.91, Support Vector Machines,0.75,0.77,0.76,0.84,0.88","Table presented above shows the results of different models on different evaluation metrics. We can see that Random Forest model outperforms all other models in all metrics. It achieves the highest precision of 0.86, recall of 0.83, F1-Score of 0.84, PR-AUC of 0.94, and ROC-AUC of 0.92. This highlights the Random Forest model's superiority over the other models under consideration. The Gradient Boosting model follows the Random Forest and achieves good performance in all metrics, except for the PR-AUC score. Naive Bayes has the least performance among the given models."
2666,"caption: Comparison of different machine learning models on their precision, recall, F1-score, and accuracy.table: Model,Precision,Recall,F1-score,Accuracy, SVM,0.83,0.75,0.78,0.85, NaiveBayes,0.74,0.82,0.76,0.80, DecisionTree,0.85,0.74,0.77,0.83, Random Forest,0.89,0.78,0.82,0.87, KNN,0.79,0.76,0.74,0.78","The table above shows the comparison of different machine learning models' performances for a binary classification task. The table exhibits SVM, NaiveBayes, DecisionTree, Random Forest, and KNN models and their respective precision, recall, F1-score, and accuracy calculated from the test set. The Random Forest model shows the best F1-score of 0.82, while KNN has the lowest one with 0.74. On the other hand, SVM shows the highest precision among the models with 0.83 and NaiveBayes the highest recall with 0.82. Overall, the Random Forest model shows the best performance across all measured metrics, while NaiveBayes shows the worst precision but best recall."
2667,"caption: Performance comparison of different models based on multiple evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.946,0.895,0.921,0.872, RF,0.958,0.914,0.940,0.890, KNN,0.930,0.865,0.884,0.848, DT,0.916,0.832,0.863,0.804, NB,0.883,0.773,0.819,0.731","The table presents a comparative analysis of different classification models' performance based on accuracy, F1-score, precision, and recall. The models included are SVM, Random Forest (RF), K-Nearest Neighbors (KNN), Decision Trees (DT), and Naive Bayes (NB).  The RF model proved to be the most accurate with a score of 0.958, achieving the highest accuracy, F1-score, precision, and recall scores than the other models with a considerable margin. Though the SVM model followed closely in terms of overall performance with an accuracy score of 0.946, the DT model displayed the lowest performance in terms of all the metrics tested. Overall, the table presents a comprehensive overview of the overall performance of different models on classification tasks."
2668,"caption: Table 4: Performance measures using different models on classification task.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.80,0.70,0.95,0.80, K-Nearest Neighbors,0.85,0.72,0.92,0.80, Decision Tree,0.77,0.65,0.85,0.70, Random Forest,0.90,0.84,0.95,0.89, Gradient Boosting,0.89,0.83,0.93,0.88","Table 4 presents the performance measures using different models on a classification task. The different models presented are Logistic Regression, K-Nearest Neighbors, Decision Tree, Random Forest, and Gradient Boosting. The table includes the evaluation metrics accuracy, precision, recall, and F1-score. The Random Forest has the highest accuracy (0.90) and F1-Score (0.89), indicating its performance is the best among all models. The Decision Tree model shows the lowest accuracy of 0.77 and F1-score of 0.70. However, the K-Nearest Neighbors model had the lowest precision of 0.72."
2669,"caption: Table 4: Model Performance Based on Different Evaluation Metricstable: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.85,0.82,0.86,0.8, Random Forest,0.83,0.8,0.82,0.79, Logistic Regression,0.81,0.77,0.79,0.76, Naive Bayes,0.79,0.75,0.77,0.74, Neural Network,0.87,0.84,0.88,0.81, K-Nearest Neighbor,0.76,0.72,0.75,0.71","Table 4 shows the performance results of six models based on different evaluation metrics. The models are SVM, Random Forest, Logistic Regression, Naive Bayes, Neural Network, and K-Nearest Neighbor. The evaluation metrics used are Accuracy, F1-Score, Precision, and Recall. The table exhibits that the highest Accuracy of 0.87 was achieved by the Neural Network model, followed by the SVM model with an Accuracy of 0.85. Conversely, the K-Nearest Neighbor model has the lowest Accuracy of 0.76. Additionally, all models have the best F1-Score in comparison to the other evaluation metrics. Finally, the Neural Network model shows the highest Precision of 0.88, while the Recall shows the lowest score across all models."
2670,"caption: Table 4: Performance comparison of different models based on multiple evaluation metrics.table: Model,Precision,Recall,F1-Score,Accuracy, SVM,0.82,0.78,0.80,0.85, Logistic Regression,0.81,0.79,0.80,0.84, Decision Tree,0.73,0.72,0.72,0.75, Random Forest,0.85,0.87,0.86,0.87, XGBoost,0.88,0.89,0.88,0.89","Table 4 showcases the comparison of different models based on multiple evaluation metrics. The models evaluated in the table are SVM, Logistic Regression, Decision Tree, Random Forest, and XGBoost. Precision, recall, F1-Score, and Accuracy have been used to evaluate the model performances. The Random Forest model achieved the highest performance with 0.85 precision, 0.87 recall, 0.86 F1-Score, and 0.87 accuracy. The XGBoost model shows promising results with a close second position in all metrics. The Decision Tree model had the lowest performance compared to the other models."
2671,"caption: Performance comparison of various classification models on the given dataset.table: Model,Accuracy,Precision,F1-Score,AUC,Recall, SVM,0.84,0.85,0.82,0.74,0.81, KNN,0.71,0.62,0.64,0.56,0.57, Naive Bayes,0.89,0.92,0.88,0.77,0.87, Random Forest,0.96,0.97,0.96,0.93,0.95, Decision Tree,0.87,0.85,0.86,0.69,0.87","The above table showcases the performance comparison of the Support Vector Machine (SVM), K- Nearest Neighbour (KNN), Naive Bayes, Random Forest, and Decision Tree models on a given dataset. The table highlights various evaluation metrics like accuracy, precision, F1-score, area under the curve (AUC), and recall. Interestingly, the Random Forest model showed the highest overall performance with the highest accuracy (0.96), precision (0.97), F1-score (0.96), and AUC (0.93). On the other hand, KNN presented the lowest performance with the lowest accuracy (0.71), precision (0.62), and AUC (0.56). The Naive Bayes model showed a commendable performance with a good balance of all metrics."
2672,"caption: Table 4: Model Performance based on multiple evaluation metricstable: Model,PR-AUC,ROC-AUC,F1-score,Accuracy, Logistic Regression,0.63,0.72,0.48,0.76, Random Forest,0.75,0.80,0.56,0.81, K-Nearest Neighbors,0.59,0.66,0.41,0.73, XGBoost,0.78,0.83,0.60,0.83, Support Vector Machine,0.64,0.75,0.49,0.77","Table 4 presents a comparison of multiple models' performances based on various evaluation metrics. The models used in the table are Logistic Regression, Random Forest, K-Nearest Neighbors, XGBoost and Support Vector Machine. The evaluation metrics include PR-AUC, ROC-AUC, F1-score and accuracy. Notably, the Random Forest and XGBoost models consistently show the highest scores across all metrics. The Random Forest model achieved the highest PR-AUC, ROC-AUC, and F1-score with 0.75, 0.80, and 0.56, respectively. While the XGBoost model showed the highest accuracy score of 0.83. The Logistic Regression model had the lowest performance across all metrics."
2673,"caption: Model Performance Metrics Comparisontable: Model,Precision,Recall,F1-score,PR-AUC,ROC-AUC, A,0.78,0.85,0.81,0.91,0.80, B,0.89,0.76,0.82,0.90,0.85, C,0.92,0.82,0.86,0.89,0.87, D,0.80,0.92,0.85,0.88,0.84, E,0.86,0.91,0.88,0.92,0.90","The table above shows the comparison of multiple models' performances based on various evaluation metrics. The models are represented by letters A-E. The table demonstrates the models' precision, recall, F1-Score, PR-AUC, and ROC-AUC performance. Interestingly, model E performed the best in all evaluation metrics, achieving the highest precision, recall, F1-Score, PR-AUC, and ROC-AUC scores of 0.86, 0.91, 0.88, 0.92, and 0.90, respectively. It is essential to note that although model C had the second-highest precision score of 0.92, it achieved the lowest ROC-AUC score of 0.87 amongst the models. Models A, B, and D showed relatively similar performances."
2674,"caption: Performance evaluation of different models using multiple metrics.table: Model,Precision@10,Recall@10,F1@10,NDCG@10, Logistic regression,0.32,0.45,0.36,0.48, SVM,0.45,0.47,0.46,0.53, Random forest,0.48,0.50,0.49,0.56, XGBoost,0.50,0.51,0.50,0.58, Neural Network,0.52,0.53,0.53,0.60","The table presents the performance evaluation of five different models based on the precision@10, recall@10, F1@10, and NDCG@10 metrics. The models include Logistic regression, SVM, Random forest, XGBoost, and Neural Network. From the table, it is evident that the Neural Network model performed the best, achieving the highest precision@10 of 0.52 and NDCG@10 of 0.60. Likewise, the XGBoost model performed exceptionally well with a precision@10 of 0.50 and recall@10 of 0.51. On the other hand, the Logistic regression model had the lowest precision@10 and NDCG@10 scores, indicating that it is the least effective model for the given task."
2675,"caption: Comparison of different models based on various evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.85,0.76,0.81,0.72, Decision Tree,0.71,0.60,0.56,0.65, Random Forest,0.93,0.89,0.92,0.87, KNN,0.82,0.74,0.79,0.70, SVM,0.87,0.78,0.82,0.75, Naive Bayes,0.74,0.60,0.68,0.53, Gradient Boosting,0.91,0.86,0.89,0.83","Table presents the performance of different models, including Logistic Regression, Decision Tree, Random Forest, KNN, SVM, Naive Bayes, and Gradient Boosting. The table depicts the evaluation metrics such as Accuracy, F1-Score, Precision, and Recall for each model. Random Forest demonstrates the best Accuracy with 0.93, followed by Gradient Boosting with 0.91. On the other hand, Decision Tree shows the lowest Accuracy with 0.71. For F1-Score, Gradient Boosting and Random forest models achieve the highest score with 0.86 and 0.89, respectively. Logistic Regression, SVM, and Random Forest models show the highest values for Precision, and Random Forest model stands out for Recall with 0.87. The table reveals that Random Forest and Gradient Boosting are the best-performing models based on various evaluation metrics."
2676,"caption: Comparison of multiple classification models on different evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.76,0.76,0.78,0.79, Decision Tree,0.72,0.73,0.75,0.72, Random Forest,0.85,0.84,0.89,0.81, Naive Bayes,0.68,0.69,0.63,0.81","The table above displays the performance of four different classification models, namely Logistic Regression, Decision Tree, Random Forest, and Naive Bayes, with respect to different evaluation metrics such as Accuracy, F1-Score, Precision, and Recall. Notably, the Random Forest model achieved the highest accuracy of 0.85 while the Logistic Regression model had the highest Precision score at 0.78. Despite the high accuracy of the Random Forest model, its recall value was the lowest among all models at 0.81. Additionally, the Naive Bayes model displayed relatively lower performance scores compared to the other models on all metrics."
2677,"caption: Evaluation of different models based on multiple metrics.table: Model,F1-Score,Accuracy,Precision,Recall, Model A,0.90,0.87,0.92,0.88, Model B,0.82,0.77,0.83,0.81, Model C,0.92,0.89,0.95,0.89, Model D,0.78,0.82,0.77,0.84, Model E,0.85,0.81,0.90,0.81",
2678,"caption: Table 4: Model evaluation results based on accuracy and F1-score.table: Model,Accuracy (Avg),F1-score (Avg), 0,LogisticReg,0.85,0.82, 1,SVM,0.87,0.86, 2,RF,0.90,0.89, 3,MLP,0.91,0.90","Table 4 presents the evaluation results of four different models based on accuracy and F1-score metrics. The models include Logistic Regression (LogisticReg), Support Vector Machine (SVM), Random Forest (RF), and Multi-Layer Perceptron (MLP). The table indicates that MLP has the highest accuracy score (0.91) and the highest F1-score (0.90) among all models. The RF has the second-best accuracy (0.90) and F1-score (0.89). The LogisticReg has the lowest accuracy (0.85) and F1-score (0.82) among the models. Interestingly, SVM has a slightly better accuracy score than LogisticReg and RF, with a score of 0.87. However, its F1-score of 0.86 is lower than the other two models. Overall, the results suggest that MLP is the best performer, followed by RF."
2679,"caption: Table 4: Comparison of different models' performance based on Accuracy, F1 Score, Precision, and Recall metrics.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.85,0.84,0.88,0.80, Random Forest,0.81,0.82,0.81,0.83, Gradient Boosting,0.83,0.81,0.86,0.77, Decision Tree,0.76,0.68,0.74,0.67, k-NN,0.80,0.78,0.83,0.74","Table 4 presents a comparison of different models' performance based on Accuracy, F1 Score, Precision, and Recall metrics. The table exhibits SVM, Random Forest, Gradient Boosting, Decision Tree, and k-NN models. Notably, SVM shows the highest accuracy with a score of 0.85, whereas Random Forest has the highest F1 Score of 0.82. On the other hand, the Precision metric shows that SVM performs the best with a score of 0.88, whereas Gradient Boosting has the highest Recall metric score of 0.77. Therefore, depending on the choice of evaluation metric, the models can be selected accordingly."
2680,"caption: Table 4: Model performance based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score,MCC, Logistic Regression,0.90,0.87,0.92,0.89,0.79, KNN,0.88,0.82,0.94,0.87,0.74, Decision Tree,0.84,0.79,0.89,0.83,0.71, Random Forest,0.93,0.92,0.95,0.93,0.87, XGBoost,0.92,0.89,0.96,0.92,0.84","The table shows the performance of five different models, measured by multiple evaluation metrics. The evaluation metrics used are Accuracy, Precision, Recall, F1-Score, and Matthews Correlation Coefficient (MCC). The models evaluated include Logistic Regression, K-Nearest Neighbors (KNN), Decision Tree, Random Forest, and XGBoost. Notably, the Random Forest model demonstrates the best overall performance, achieving an accuracy of 0.93 and an MCC of 0.87. Meanwhile, the KNN model exhibited the highest recall value of 0.94, and the Decision Tree model showed the lowest accuracy value of 0.84. The results indicate that the Random Forest model may perform better in this context than the other models."
2681,"caption: Table 4: Model performances on different evaluation metricstable: Model,Accuracy,F1-score,Precision,Recall, SVM,0.85,0.83,0.79,0.88, LR,0.82,0.78,0.85,0.72, RF,0.87,0.84,0.84,0.85, XGB,0.88,0.86,0.84,0.88","Table 4 depicts the model performances of SVM, LR, RF, and XGB on different evaluation metrics, including accuracy, F1-score, precision, and recall. The accuracy metric indicates how correctly the model predicts the classes' labels. RF showed the highest accuracy of 0.87 and XGB the highest with 0.88. The F1-score quantifies the ability of the model to balance between precision and recall. Again, XGB showed the highest F1-score with 0.86. SVM achieved the highest precision of 0.79, while LR achieved the lowest precision of 0.85. Lastly, recall which is the proportion of positives that are correctly identified as positive has its highest and lowest scores for XGB and LR models, respectively. In conclusion, different evaluation metrics show that the performance of the models varies depending upon the evaluation metric."
2682,"caption: Comparison of different classification models based on various evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.89,0.89,0.89,0.89, KNN,0.85,0.85,0.84,0.86, Naive Bayes,0.79,0.77,0.74,0.81, Decision Tree,0.88,0.88,0.89,0.87, Random Forest,0.91,0.91,0.92,0.90","The table above presents a comparison of five distinct classification models based on diverse evaluation metrics, namely Accuracy, F1-Score, Precision, and Recall. The SVM model had the highest Accuracy score of 0.89, tied with Recall, Precision, and F1=Score. The Random Forest followed with an Accuracy score of 0.91 and F1-Score of 0.91, the highest score among all the models. Also, the Random Forest showcased the best Precision score of 0.92. Noteably, the Naive Bayes performed the lowest, with an Accuracy score of 0.79 and F1-Score of 0.77."
2683,"caption: Performance table of different machine learning models on the given dataset.table: Model,F1 Score,Accuracy,Precision,Recall, Random Forest,0.92,0.91,0.89,0.94, SVM,0.87,0.85,0.86,0.89, XGBoost,0.93,0.92,0.91,0.95, Naive Bayes,0.75,0.79,0.80,0.73, Decision Tree,0.77,0.78,0.75,0.78","Table above presents the performance metrics, including F1 Score, Accuracy, Precision, and Recall of several machine learning models, including Random Forest, SVM, XGBoost, Naive Bayes, and Decision Trees. The higher the value of the performance metric, the better the model's performance. Out of the five models, XGBoost shows the highest F1 Score of 0.93, while Random Forest has the highest Precision value of 0.89. Naive Bayes has the lowest F1 score and Precision value of 0.75 and 0.80, respectively. Overall, XGBoost outperforms all other models in terms of all four performance metrics."
2684,"caption: A comparison of accuracy, precision, recall, and F1 score for different classification models on the testing dataset.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic regression,0.82,0.85,0.88,0.86, Random forest,0.89,0.91,0.92,0.91, Support vector machines (SVM),0.83,0.88,0.85,0.86, Gradient Boosting,0.91,0.93,0.94,0.93, Neural network,0.90,0.92,0.93,0.92","The table shows the evaluation results of various models, including Logistic regression, Random forest, Support vector machines (SVM), Gradient Boosting, and Neural network, on the testing dataset using accuracy, precision, recall, and F1 score. The Gradient Boosting model shows the highest overall performance, demonstrating the best values in accuracy (0.91), precision (0.93), recall (0.94), and F1 score (0.93). The Random forest model also demonstrates outstanding results with the second-highest scores in all four metrics. The Logistic regression model has the lowest scores for both precisions while the SVM model shows the lowest recall. Overall, the results suggest that the Gradient Boosting model is the best performing algorithm for the given dataset."
2685,"caption: Table 4: Model performances based on different evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Random Forest,0.897,0.864,0.872,0.857, Logistic Regression,0.892,0.855,0.878,0.836, K-Nearest Neighbor,0.834,0.791,0.783,0.804, Decision Tree,0.846,0.790,0.811,0.771, Naive Bayes,0.802,0.760,0.739,0.784","Table 4 compares the performance of five different models based on multiple evaluation metrics. The evaluation metrics consist of accuracy, F1 score, precision, and recall. The table shows that the Random Forest model performs the best on all measures attaining an accuracy score of 0.897, F1 score of 0.864, precision of 0.872, and recall of 0.857. The logistic regression model came second in all scores, while both K-Nearest Neighbor and Decision Tree models performed almost equally on all measures, but lower than the Random Forest and logistic regression models. Interestingly, the Naive Bayes model performed the worst, obtaining the lowest score on all metrics."
2686,"caption: Model performance based on different evaluation metricstable: Model,Accuracy,F1-score,Recall,Precision, SVM,0.93,0.93,0.94,0.92, KNN,0.89,0.88,0.85,0.91, Naive Bayes,0.87,0.88,0.85,0.91, Random Forest,0.92,0.92,0.94,0.90, XGBoost,0.93,0.93,0.94,0.92","The table above showcases the performance of various classification models based on different evaluation metrics that include accuracy, F1-score, recall, and precision. The five different models compared are SVM, KNN, Naive Bayes, Random Forest, and XGBoost. Notably, all models had high performance with accuracy and F1-score scores above 0.87, indicating that they had a good classification performance. The model with the highest accuracy score was XGBoost with 0.93, and the model with the highest F1-score was also XGBoost with 0.93. The Random Forest and SVM models showcase high recall scores of 0.94, while the Naive Bayes and XGBoost models have the highest precision scores of 0.91."
2687,"caption: Table 4: Comparative evaluation of different models based on various performance metrics.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.843,0.829,0.851,0.820, LR,0.812,0.802,0.814,0.791, KNN,0.788,0.764,0.789,0.741, RF,0.878,0.872,0.882,0.863, XGBoost,0.896,0.890,0.898,0.881","Table 4 compares the performance of different models based on Accuracy, F1-score, Precision, and Recall. The table includes Support Vector Machine (SVM), Logistic Regression (LR), k-Nearest Neighbors (KNN), Random Forest (RF), and XGBoost classifiers. The Random Forest model shows the highest performance in all evaluation metrics, except for Accuracy, where the XGBoost model demonstrates a better score of 0.896. The SVM classifier has the second-best performance, with an accuracy of 0.843. Interestingly, XGBoost's F1-score, Precision, and Recall are higher than those of the SVM model, despite SVM having better accuracy. Overall, the table shows that both Random Forest and XGBoost models achieve the highest performance in different measures, emphasizing the importance of comparing multiple metrics when evaluating models."
2688,"caption: Table 4: Performance of different models using different evaluation metrics.table: Model Name,MAE,MSE,R2-score, Linear regression,0.405,0.243,0.589, Lasso regression,0.550,0.380,0.397, Ridge regression,0.416,0.250,0.565, Decision tree,0.529,0.374,0.410, Random forest,0.359,0.207,0.652","Table 4 compares the performance of different models using different evaluation metrics, namely Mean Absolute Error (MAE), Mean Squared Error (MSE), and R2-score. The models included in the table are Linear regression, Lasso regression, Ridge regression, Decision tree, and Random forest. The results show that Random forest achieved the best performance with the lowest MAE of 0.359 and the highest R2-score of 0.652. Notably, all models' performances are significantly different, with different trade-offs, which should be considered during the model selection process based on specific research objectives."
2689,"caption: Table 4: Model Performances based on different evaluation metricstable: Model,Accuracy,F1 Score,Log Loss, Logistic Regression,0.82,0.82,0.42, Naive Bayes,0.72,0.74,0.83, Decision Tree,0.71,0.67,1.08, Random Forest,0.85,0.84,0.39, Support Vector Machine,0.80,0.79,0.49","Table 4 presents various models' performances based on multiple evaluation metrics. The models, logistic regression, Naive Bayes, decision tree, random forest, and support vector machine, are evaluated based on accuracy, F1 score, and log loss metrics. Notably, the random forest model achieved the highest accuracy score of 0.85, and F1 score of 0.84, while logistic regression attained the lowest log loss score of 0.42. It is interesting to observe that the Naive Bayes model's performance was inferior to the other models based on all evaluation metrics. The findings suggest that, among the models presented, logistic regression and random forest can be considered the best performers."
2690,"caption: Performance comparison of different models using multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,88.90%,0.89,0.88,0.882, Support Vector Machine,89.20%,0.91,0.89,0.898, Random Forest,90.10%,0.91,0.90,0.903, Gradient Boosting,91.00%,0.92,0.91,0.912",
2691,"caption: Performance metrics of different classification modelstable: Model,Accuracy,F1 Score,Precision,Recall,AUC Score, Logistic Regression,0.83,0.82,0.81,0.85,0.91, Decision Tree,0.70,0.68,0.60,0.78,0.70, SVM,0.79,0.77,0.75,0.80,0.86, Random Forest,0.91,0.90,0.88,0.92,0.97, XGBoost,0.90,0.88,0.87,0.89,0.94","Table above presents the classification models' performance using different evaluation metrics, including Accuracy, F1 Score, Precision, Recall, and AUC Score. The table shows that the Random Forest model performs amazingly well, with the highest Accuracy, F1 Score, Precision, Recall, and AUC Score of 0.91, 0.9, 0.88, 0.92, and 0.97, respectively. Similarly, the XGBoost model also performs well with all metrics ranging from 0.87 to 0.94. On the other hand, Decision Tree has the lowest score with all metrics below 0.8, while SVM and Logistic Regression models show reasonable performance in terms of Accuracy, F1 Score, Precision, Recall, and AUC Score."
2692,"caption: Performance comparison of different models based on multiple evaluation metrics.table: Model Name,F1-Score,Precision,Recall,Accuracy, Model_A,0.85,0.90,0.81,0.91, Model_B,0.82,0.85,0.80,0.89, Model_C,0.76,0.81,0.73,0.84, Model_D,0.89,0.87,0.91,0.90, Model_E,0.90,0.93,0.88,0.92","Table displays the F1-Score, Precision, Recall, and Accuracy of five different models (Model_A, Model_B, Model_C, Model_D, and Model_E). All the models were tested on the same dataset. The table depicts that Model_E performed the best in terms of F1-Score (0.90). Meanwhile, Model_A had the highest Precision value of 0.90. Model_D scored the highest recall of 0.91, and Model_E scored the highest accuracy of 0.92. Interestingly, Model_E shows the highest scores among all evaluation metrics compared to other models, demonstrating its overall best performance among all models."
2693,"caption: Table 4: Model performance with multiple metricstable: Model,Accuracy,F1-Score,Precision,Recall,AUC, SVM,0.86,0.84,0.85,0.83,0.94, Logistic Regression,0.81,0.78,0.79,0.77,0.88, Random Forest,0.90,0.88,0.89,0.86,0.96, XGBoost,0.92,0.90,0.91,0.88,0.97, Neural Network,0.89,0.87,0.88,0.85,0.95","Table 4 compares multiple models' performance in a binary classification task. The models' performance was evaluated based on different metrics such as accuracy, F1-score, precision, recall, and AUC. The table exhibits SVM, Logistic regression, Random forest, XGBoost, and Neural network models' evaluation results. Notably, all models achieved high accuracy values above 0.81. The XGBoost model shows the best performance in terms of accuracy, F1-score, precision, recall, and AUC, with the highest value of 0.92, 0.90, 0.91, 0.88, and 0.97, respectively. The Random forest model also demonstrates comparable performance with a high AUC of 0.96. Overall, the results suggest that the XGBoost model is the preferred model for this binary classification task."
2694,"caption: Comparison of the performance of different models using various evaluation metricstable: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.75,0.70,0.75,0.68, Random Forest,0.79,0.74,0.78,0.71, Multilayer Perceptron,0.72,0.67,0.73,0.63, Naive Bayes,0.64,0.53,0.67,0.48, Decision Tree,0.71,0.65,0.68,0.63","The table presents the performance evaluation of multiple models using various evaluation metrics such as accuracy, F1-score, precision, and recall. The models SVM, Random Forest, MLP, Naive Bayes, and Decision Tree were trained and tested on the same dataset. Based on the table, Random Forest showed the highest accuracy of 0.79 and F1-score of 0.74. Naive Bayes had the lowest performance, achieving an accuracy of 0.64 and F1-score of 0.53. The precision and recall results of the models were varied, highlighting the importance of using multiple evaluation metrics to measure performance accurately."
2695,"caption: Performance comparison of different machine learning models using various evaluation metrics.table: Model,Accuracy,Recall,Precision,F1-score, Logistic Regression,0.84,0.83,0.86,0.83, Naive Bayes,0.76,0.70,0.80,0.73, Decision Tree,0.79,0.78,0.82,0.77, Random Forest,0.89,0.87,0.91,0.88, Gradient Boosting,0.91,0.90,0.92,0.91, Support Vector Machines,0.88,0.85,0.91,0.87","The table above presents a performance comparison of six machine learning models, namely logistic regression, Naive Bayes, decision tree, random forest, gradient boosting, and support vector machines. The models' performances are evaluated using four metrics, namely accuracy, recall, precision, and F1-score. Notably, the gradient boosting model shows the best performance in all metrics, having 0.91 accuracy, 0.90 recall, 0.92 precision, and 0.91 F1-score, while the naive Bayes model has the lowest accuracy, recall, and F1-score at 0.76, 0.70, and 0.73, respectively. Also, the support vector machines had the highest precision of 0.91."
2696,"caption: Table 4: Model comparison based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.85,0.86,0.84,0.84, Random Forest,0.79,0.85,0.71,0.75, Logistic Regression,0.81,0.82,0.80,0.80, XGBoost,0.87,0.86,0.87,0.87, Naive Bayes,0.76,0.79,0.71,0.73","Table 4 presents a comparison of different machine learning models based on various evaluation metrics. The table's models include SVM, Random Forest, Logistic Regression, XGBoost, and Naive Bayes. The evaluation metrics used to compare the models are accuracy, precision, recall, and F1-score. XGBoost outperforms all models with the highest accuracy, precision, and F1-score of 0.87 with an equal recall of 0.87. SVM had the highest precision and recall of 0.86 and 0.84, respectively. Logistic Regression had the second-highest accuracy of 0.81, and Random Forest had the second-highest precision of 0.85. Naive Bayes had the lowest performance in all evaluation metrics, with the accuracy of 0.76 and the lowest precision, recall, and F1-scores."
2697,"caption: Table 4: Comparison of different models' performance based on accuracy, F1-score, precision, and recall metrics.table: Model Name,Accuracy,F1-Score,Precision,Recall, Decision Tree,0.87,0.88,0.85,0.92, Support Vector Machine,0.93,0.94,0.91,0.97, Logistic Regression,0.92,0.93,0.90,0.95, Random Forest,0.95,0.96,0.94,0.98, Gradient Boosting,0.94,0.95,0.92,0.97","Table 4 presents a comparison of various machine learning models' performance based on multiple evaluation metrics, including accuracy, F1-score, precision, and recall. The models included in the table are Decision Tree, Support Vector Machine, Logistic Regression, Random Forest, and Gradient Boosting. The results reveal that the Random Forest model has the highest accuracy, F1-score, precision, and recall metrics, with a score of 0.95, 0.96, 0.94, and 0.98, respectively. The Support Vector Machine also performed well and achieved the highest overall accuracy of 0.93. Interestingly, despite having high accuracy, Gradient Boosting model scored lower compared to the Random Forest in the F1-score, precision, and recall metrics."
2698,"caption: Model comparison based on multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.89,0.85,0.92,0.88, Random Forest,0.93,0.91,0.95,0.93, SVM,0.92,0.88,0.96,0.92, XGBoost,0.95,0.93,0.96,0.95, Naive Bayes,0.86,0.81,0.94,0.86","The table presents a performance comparison of different machine learning models based on multiple evaluation metrics. The models with their respective accuracy, precision, recall, and F1 scores are Logistic Regression, Random Forest, SVM, XGBoost, and Naive Bayes. The XGBoost model has the highest accuracy score of 0.95, while the Naive Bayes model has the lowest accuracy score of 0.86. The Random Forest model performs the best with the highest scores in precision, recall and F1. Interestingly, the Logistic Regression and SVM models have a similar pattern of scores across all metrics."
2699,"caption: Comparison of model performances using different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.88,0.89,0.92,0.90, Decision Tree,0.74,0.79,0.80,0.77, Random Forest,0.90,0.91,0.94,0.93, K-Nearest Neighbors,0.78,0.83,0.85,0.84, Gradient Boosting,0.92,0.93,0.96,0.94","The table above compares the performances of five different models using various evaluation metrics: Accuracy, Precision, Recall, and F1-Score. The Logistic regression model showed the highest Accuracy score of 0.88, while the Gradient Boosting model had a better overall performance, with the highest Precision (0.93), Recall (0.96), and F1-Score (0.94). Notably, the Random Forest model achieved a high precision score of 0.91, while the Decision Tree model achieved the lowest scores in all evaluation metrics among the models."
2700,"caption: Table 4: Model Evaluation Metrics for Four Different Modelstable: Model,Accuracy,Precision,Recall,F1-score, Model 1,0.81,0.82,0.68,0.74, Model 2,0.84,0.74,0.89,0.81, Model 3,0.86,0.73,0.94,0.82, Model 4,0.88,0.87,0.83,0.85","Table 4 displays the evaluation metrics of four different models, including accuracy, precision, recall, and F1-score. The metrics represent the performance of each model, trained and tested on the same dataset. Each metric score represents the average result across all test instances. Notably, Model 4 performed the best with an accuracy score of 0.88 and an F1-score of 0.85. Model 2 achieved the lowest accuracy, but with the highest recall score of 0.89. Model 3 showed the highest precision, but with a slightly lower F1-score than Model 4. This table provides important insights into the strengths and weaknesses of each model's performance, which can be useful in selecting the most appropriate model for specific tasks."
2701,"caption: Comparison of classification models' performances on a given dataset using multiple metrics.table: Model,Accuracy,Precision,Recall,F1-score,AUC-ROC, SVM,0.945,0.900,0.950,0.924,0.943, RFC,0.927,0.853,0.942,0.822,0.921, NB,0.865,0.859,0.673,0.756,0.794, ANN,0.952,0.922,0.956,0.935,0.947","This table compares different classification models' accuracy, precision, recall, F1-score, and AUC-ROC on a given dataset. The dataset used for training and testing is not mentioned. Four models- Support Vector Machine (SVM), Random Forest Classifier (RFC), Naive Bayes (NB), and Artificial Neural Network (ANN) are evaluated on their performance. The ANN model outperforms all other models with an accuracy of 0.952 and AUC-ROC of 0.947. SVM has the highest precision and recall score of 0.9 and 0.95, respectively. The NB model's precision score is almost equal to SVM, but its recall is low, resulting in less F1-score. The RFC model shows low performance on all metrics compared to other models."
2702,"caption: Model Performance Comparison on Evaluation Metricstable: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.89,0.88,0.89,0.89, KNN,0.82,0.80,0.84,0.81, LR,0.85,0.84,0.86,0.85, RF,0.91,0.91,0.92,0.91, DT,0.84,0.83,0.84,0.85","The table above shows the comparative performance of several models, including SVM, KNN, LR, RF, and DT, based on different evaluation metrics, including Accuracy, F1 Score, Precision, and Recall. Each model's different performance measures are displayed in the respective cells of the table. The Random Forest (RF) model achieved the highest accuracy, F1 score, and recall with scores of 0.91, 0.91, and 0.91, respectively. The Support Vector Machine (SVM) model also performed exceptionally well, achieving the highest precision score of 0.89. Overall, the table provides a useful comparison of the evaluated models based on various performance measures."
2703,"caption: Table 4. Model performance based on different evaluation metrics.table: Model,F1-score,Specificity,Accuracy,Precision,Recall, Logistic Regression,0.837 +- 0.02,0.931 +- 0.01,0.875 +- 0.01,0.853 +- 0.03,0.829 +- 0.02, Support Vector Machines,0.798 +- 0.03,0.901 +- 0.02,0.805 +- 0.07,0.712 +- 0.02,0.816 +- 0.03, Random Forest,0.907 +- 0.01,0.925+-0.02,0.905+-0.02,0.902+-0.02,0.906+-0.02, Gradient Boosting,0.854 +- 0.05,0.913 +- 0.01,0.874 +- 0.02,0.842 +- 0.03,0.871 +- 0.04, K-Nearest Neighbors,0.694 +- 0.07,0.589 +- 0.03,0.701 +- 0.02,0.677 +- 0.04,0.637 +- 0.05","Table 4 shows the performances of different models based on different evaluation metrics. The metrics measured are F1-score, Specificity, Accuracy, Precision, and Recall. The models used for comparison are Logistic Regression, Support Vector Machines, Random Forest, Gradient Boosting, and K-Nearest Neighbors. The results present the mean values with the standard deviation of each metric. As observed from the table, the Random Forest model outperforms all other models across all metrics, with the highest F1-score(0.907+-0.01), Specificity (0.925+-0.02), Accuracy (0.905+-0.02), Precision (0.902+-0.02), and Recall (0.906+-0.02). On the other hand, K-Nearest Neighbors shows the lowest performance across all evaluated metrics."
2704,"caption: Model performance on a classification task using four different models, evaluated with three different metrics.table: Model,Accuracy,Recall,F1-Score, SVM,0.87,0.89,0.85, Naive Bayes,0.82,0.85,0.79, Random Forest,0.92,0.94,0.91, XGBoost,0.93,0.95,0.92","The table summarizes the performance of four models on a binary classification task. The models include SVM, Naive Bayes, Random Forest, and XGBoost. Each model was evaluated using three different metrics: accuracy, recall, and F1-score. The results indicate that the Random Forest model achieved the highest accuracy (0.92), recall (0.94), and F1-score (0.91) compared to other models. The XGBoost model also performed well in all metrics, achieving an accuracy of 0.93, a recall of 0.95, and an F1-score of 0.92. The SVM model achieved an accuracy of 0.87, a recall of 0.89, and an F1-score of 0.85, while the Naive Bayes model achieved an accuracy of 0.82, a recall of 0.85, and an F1-score of 0.79."
2705,"caption: Model performance based on different evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, Model 1,0.83,0.85,0.90,0.81, Model 2,0.79,0.77,0.86,0.71, Model 3,0.88,0.90,0.85,0.95, Model 4,0.91,0.93,0.96,0.89, Model 5,0.85,0.87,0.89,0.85","The presented table demonstrates the performance of five models based on multiple evaluation metrics, namely accuracy, F1-score, precision, and recall. Model 4 has the best overall model performance with an accuracy of 0.91, an F1-score of 0.93, precision of 0.96, and recall of 0.89. Model 3 has the highest recall score of 0.95, which highlights its ability to identify actual positive instances. On the other hand, Model 2 has the lowest accuracy and F1-score, indicating the model's poor overall performance. Meanwhile, Model 1 and Model 5 have relatively balanced scores, although they still perform worse than Model 3 and Model 4. Overall, the table underscores the variation in model performance across multiple evaluation metrics."
2706,"caption: Table 4: Model performance comparison based on precision, recall, and F1-score.table: Model,Precision,Recall,F1-Score, SVM,0.84,0.78,0.81, LR,0.82,0.79,0.80, RF,0.92,0.87,0.89, k-NN,0.77,0.75,0.76, NB,0.72,0.83,0.77","Table 4 compares the performance of five different models based on their precision, recall, and F1-score. The models include SVM, LR, RF, k-NN, and NB.  The table shows that RF outperforms the other models with the highest Precision of 0.92, Recall of 0.87, and F1-Score of 0.89. SVM and LR have comparable performance with Precision scores of 0.84 and 0.82, Respectively. NB has the lowest Precision score of 0.72, but it achieved the highest Recall scores of 0.83.  Overall, the table displays models' performances and highlights areas for improvement in the models' performance."
2707,"caption: Table 4: Model performance using different evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.9317,0.9352,0.9251,0.93, Random Forest,0.9384,0.9412,0.9319,0.94, Neural Network,0.9205,0.9308,0.9056,0.91, Naive Bayes,0.8957,0.8924,0.9121,0.90, Decision Tree,0.9011,0.9025,0.8995,0.90","In Table 4, the performances of SVM, Random Forest, Neural Network, Naive Bayes, and Decision Tree models in binary classification tasks are compared based on their accuracy, precision, recall, and F1-score. SVM and Random Forest models yielded the best results in terms of accuracy, achieving 0.9317 and 0.9384, respectively. Random Forest and Neural Network models performed best in terms of Precision, with scores of 0.9412 and 0.9308, respectively. The Naive Bayes model achieved the highest recall of 0.9121 while the Precision-Recall tradeoff favored Random forest and Neural Network. Finally, F1-Score shows a moderate performance for all the models, with the Random forest and SVM having the best results of 0.94 and 0.93, respectively."
2708,"caption: Table showing the evaluation metrics results among four different models.table: ```, Model,Accuracy,F1-score,Precision,Recall, Model A,0.92,0.85,0.82,0.89, Model B,0.87,0.76,0.79,0.73, Model C,0.95,0.89,0.91,0.86, Model D,0.86,0.73,0.81,0.67","The table illustrates the performance of four different models based on various evaluation metrics - accuracy, F1-score, precision, and recall. The highest accuracy of 0.95 is achieved by Model C, while Model A achieves the highest F1-score of 0.85 and Model D the lowest F1-score of 0.73. Model C also obtained the highest precision score of 0.91, while Model B obtained the lowest precision score of 0.79. Interestingly, Model A scores the highest recall value of 0.89, and Model B scores the lowest recall value of 0.73. These results suggest that Model C is the best-performing model in terms of accuracy, F1-score, and precision. However, Model A performs the best on recall."
2709,"caption: Table 4: Model evaluation metrics of different models.table: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.89,0.92,0.86,0.89, Naïve Bayes,0.78,0.74,0.84,0.78, Random Forest,0.95,0.97,0.94,0.95, XGBoost,0.94,0.96,0.93,0.94, Decision Tree,0.92,0.93,0.91,0.92","Table 4 shows the model evaluation metrics of different models such as Logistic Regression, Naïve Bayes, Random Forest, XGBoost, and Decision Tree. The table provides the accuracy, precision, recall, and F1-score of each model. The Random Forest model got the highest accuracy score of 0.95. It also has the highest precision score of 0.97 and the F1-score of 0.95, which indicates the best-performing model. However, Naïve Bayes has the highest recall score of 0.84. In conclusion, Random Forest would be the recommended model due to its high overall performance across all the metrics."
2710,"caption: Model comparison based on accuracy, F1-Score, precision, and recall.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.895,0.899,0.906,0.893, MLP,0.905,0.901,0.908,0.896, Random Forest,0.896,0.902,0.899,0.905, KNN,0.885,0.891,0.896,0.886, XGBoost,0.898,0.905,0.902,0.910","Table presents a comparison of different models' performance using multiple evaluation metrics, including accuracy, F1-Score, precision, and recall. The SVM model has achieved the highest Precision score of 0.906 and achieved promising results with accuracy, F1-Score, and Recall of 0.895, 0.899, and 0.893, respectively. On the other hand, MLP outperformed with a higher accuracy of 0.905 and better F1-Score, Precision, and Recall of 0.901, 0.908, and 0.896, respectively. Interestingly, the Random Forest model achieved remarkable Precision and Recall of 0.899 and 0.905, respectively, with a moderate performance with accuracy and F1-score. Whereas, K-nearest neighbors (KNN) and XGBoost models showed moderate performances with different evaluation metrics."
2711,"caption: Table 4: Model Performance on Multiple Evaluation Metrics.table: Model,Metric,Result, Decision Tree,Accuracy,0.86, F1 Score,0.84, AUC,0.92, Random Forest,Accuracy,0.92, F1 Score,0.91, AUC,0.96, Support Vector Machine,Accuracy,0.89, F1 Score,0.87, AUC,0.93, Multi-layer Perceptron,Accuracy,0.88, F1 Score,0.86, AUC,0.92","Table 4 presents a comparison of different models' performances based on multiple evaluation metrics, namely accuracy, F1 score and AUC. The table shows the results for Decision Tree, Random Forest, Support Vector Machine and Multi-layer Perceptron models. Interestingly, the Random Forest model performs best across all three metrics, with an accuracy of 0.92, F1 score of 0.91, and AUC of 0.96. The Decision Tree model also performs relatively well, performing second-best with an accuracy of 0.86, F1 score of 0.84, and AUC of 0.92."
2712,"caption: The table presents performance results of different models on a classification task.table: Model,Acc,F1,Precision,Recall,AUC, Model 1,0.894,0.744,0.682,0.821,0.872, Model 2,0.919,0.809,0.818,0.801,0.906, Model 3,0.899,0.752,0.692,0.825,0.884, Model 4,0.921,0.811,0.840,0.784,0.912, Model 5,0.917,0.808,0.861,0.761,0.909","The table illustrates the performance comparison of five models based on multiple evaluation metrics: Accuracy, F1-score, Precision, Recall, and AUC. All models were trained and tested using the same dataset. Model 4 achieved the highest Accuracy score of 0.921, while Model 5 shows the highest Precision score of 0.861. Surprisingly, Model 1 had the highest Recall score of 0.821, which was continued with a decent F1-score of 0.744. Moreover, Model 4 had the highest AUC score of 0.912, which signifies its good discriminatory power between positive and negative classes, while Model 1 had the lowest AUC score of 0.872. Overall, Model 4 appears to be the most robust model based on its AUC score, Accuracy, and Precision."
2713,"caption: Performance comparison of decision tree, logistic regression, and random forest models.table: Model,Metric,Result, Decision tree,Accuracy,0.799, F1 score,0.661, Precision,0.706, Recall,0.622, Logistic regression,Accuracy,0.832, F1 score,0.749, Precision,0.814, Recall,0.696, Random forest,Accuracy,0.867, F1 score,0.798, Precision,0.853, Recall,0.750","The table compares the performance of the decision tree, logistic regression, and random forest classifiers using multiple evaluation metrics. These models were applied to the same dataset, and their accuracy, F1 score, precision, and recall were calculated. Notably, the random forest model outperformed the other models in all metrics. For instance, it attained the highest accuracy of 0.867, followed by logistic regression with 0.832 and decision tree with 0.799. Similarly, the random forest had the highest F1 score of 0.798 as compared to logistic regression with 0.749 and decision tree with 0.661. Finally, the precision and recall scores for all three models followed the same trend, with random forest achieving the highest scores and decision tree with the lowest score."
2714,"caption: Table 4. Performance evaluation of five different models based on precision, recall, F1-score, ROC-AUC, and PR-AUC.table: Model,Precision,Recall,F1-Score,ROC-AUC,PR-AUC, Model_A,0.89,0.92,0.90,0.78,0.85, Model_B,0.92,0.87,0.89,0.80,0.87, Model_C,0.78,0.91,0.83,0.73,0.80, Model_D,0.87,0.85,0.86,0.82,0.83, Model_E,0.91,0.82,0.86,0.84,0.89","Table 4 presents the comparison of five models' performance evaluated based on precision, recall, F1-score, ROC-AUC, and PR-AUC metrics. The table shows that Model_B has the highest precision score of 0.92, whereas Model_A achieved the highest recall rate of 0.92. The F1-score indicates Model_A's highest score of 0.90, while Model_B shows the highest ROC-AUC score of 0.80. On the other hand, Model_E exhibited the highest PR-AUC score with 0.89. Therefore, depending on the evaluation metric prioritized by the user, a specific model could be preferred over the others."
2715,"caption: Table 4: Performance comparison of different classification modelstable: Model,Accuracy,F1-score,Precision,Recall, Logistic,0.92,0.78,0.76,0.80, SVM,0.90,0.70,0.72,0.68, Random Forest,0.94,0.83,0.81,0.85, KNN,0.86,0.60,0.62,0.58, Neural Network,0.93,0.80,0.78,0.82","Table 4 presents the performance comparison of various classification models in terms of Accuracy, F1-score, Precision, and Recall metrics. The table shows five different models; Logistic Regression, Support Vector Machine (SVM), Random Forest, k-Nearest Neighbors (KNN), and Neural Network. Each model's corresponding performances are recorded within the table with a dataset of equal size and class distribution. Notably, the Random Forest model shows the highest accuracy score of 0.94 and F1-score of 0.83, while KNN achieved the lowest scores with 0.86 and 0.60 for accuracy and F1-score, respectively. The comparison can help in selecting the most suitable model for a particular classification task based on the evaluation metrics of interest."
2716,"caption: Model performance metrics for different Machine Learning modelstable: Model,Accuracy,F1 score,Precision,Recall, Logistic Regression,0.82,0.70,0.84,0.60, Decision Tree,0.75,0.63,0.58,0.70, Random Forest,0.86,0.74,0.82,0.25, SVM,0.79,0.68,0.79,0.59, MLP Neural Network,0.87,0.73,0.86,0.62","The table shows different Machine Learning models' performance metrics based on five evaluation metrics, namely accuracy, F1 score, precision, recall, and cross-validation. The models are Logistic Regression, Decision Tree, Random Forest, SVM, and MLP Neural Network. The highest accuracy was obtained by the MLP Neural Network with 0.87, followed by Random Forest (0.86). The highest values for F1 score, precision, and recall were obtained for Logistic Regression (0.70, 0.84, and 0.60, respectively). Interestingly, Random Forest obtained the highest precision of 0.82, while SVM achieved the highest recall rate of 0.59. Overall, the results indicate that the MLP Neural Network and Random Forest models were excellent performers, while the Decision Tree model exhibited a lower performance."
2717,"caption: Table 4. Comparison of model evaluation metrics for different classification algorithms.table: Model,Accuracy,F1-Score,AUC-ROC, Decision Tree,0.82,0.83,0.73, K-NN,0.78,0.79,0.66, SVM,0.87,0.88,0.81, Random Forest,0.91,0.91,0.85",
2718,"caption: Table 4: Performance evaluation of different classification models using various metrics.table: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.82,0.84,0.81,0.87, Decision Tree,0.74,0.73,0.71,0.76, Random Forest,0.87,0.87,0.84,0.90, Naive Bayes,0.76,0.78,0.77,0.80, Gradient Boosting,0.86,0.86,0.84,0.90, Support Vector Machine,0.80,0.80,0.79,0.81","Table 4 displays the evaluation of multiple classification models using various metrics. The metrics used for evaluation include accuracy, F1-score, precision, and recall. The models evaluated in the table are Logistic Regression, Decision Tree, Random Forest, Naive Bayes, Gradient Boosting, and Support Vector Machine. The best overall-performing model in the table is the Random Forest, with an accuracy of 0.87, an F1-score of 0.87, a precision of 0.84, and a recall of 0.90. It is interesting to note that models like Logistic Regression, Gradient Boosting, and Support Vector Machine have similar performance with accuracy scores ranging from 0.80 to 0.82. However, the F1-scores, precision, and recall of these models are different."
2719,"caption: Performance metrics of different modelstable: Model,Accuracy,F1 Score,AUC-ROC,Precision,Recall, Model A,0.95,0.95,0.97,0.94,0.96, Model B,0.89,0.88,0.92,0.90,0.87, Model C,0.83,0.79,0.88,0.77,0.82, Model D,0.91,0.90,0.93,0.89,0.91","The table presents a comparison of multiple models' performance using Accuracy, F1 Score, AUC-ROC, Precision, and Recall. Model A achieved the highest scores across all metrics, with 0.95 accuracy, 0.95 F1 score, and 0.97 AUC-ROC. Notably, Model B had a 0.90 precision score and Model D had a 0.91 recall score, both achieving the highest score in those metrics. However, Model C lagged behind in all metrics compared to the others, with the lowest score across all metrics. The table provides a quick and easy comparison of model performances across various metrics."
2720,"caption: Table 4: Model evaluation metrics results for different models.table: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.81,0.77,0.86,0.81, Random Forest,0.84,0.80,0.90,0.85, SVM,0.77,0.73,0.81,0.77, MLP,0.82,0.78,0.87,0.82, XGBoost,0.86,0.83,0.91,0.87","Table 4 presents a comparison of performance metrics of different machine learning models, including Logistic Regression, Random Forest, SVM, MLP, and XGBoost. The table reports the accuracy, precision, recall, and F1-score for each model. It is observed that all models have relatively high accuracy, with XGBoost outperforming others with an accuracy of 0.86. Moreover, the Random Forest model had the best precision score of 0.80. The highest recall score of 0.91 was obtained by XGBoost, while the F1-score shows the models' balance in precision and recall, with Random Forest having the best F1-score of 0.85."
2721,"caption: A comparison of various models' evaluation metrics on a classification tasktable: Model,Accuracy,Precision,Recall,F1 Score, SVM,0.92,0.93,0.91,0.91, Decision tree,0.85,0.78,0.90,0.82, K-Nearest Neighbors,0.88,0.84,0.92,0.87, Random Forest,0.95,0.94,0.97,0.95, Gradient Boosting,0.93,0.93,0.93,0.92","The table above shows the accuracy, precision, recall, and F1 score metrics for five different models: SVM, Decision tree, K-Nearest Neighbors, Random Forest, and Gradient Boosting. The models were evaluated on a classification task, and the results indicate that the Random Forest model had the highest accuracy, precision, and F1 score, showing the best performance overall in all metrics. Interestingly, the Gradient Boosting model had identical precision and recall of 0.93, while SVM had the highest recall score of 0.91. The Decision tree model had the lowest precision score of 0.78. Overall, the Random Forest model seems to be the most appropriate for the classification task based on the presented evaluation metrics."
2722,"caption: Table 1: Model performance based on different evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.89,0.88,0.83,0.85, KNN,0.87,0.84,0.84,0.82, RF,0.93,0.92,0.93,0.92, Naive Bayes,0.85,0.82,0.87,0.82, ANN,0.91,0.91,0.89,0.90",
2723,"caption: Evaluation of Multiple Models on Given Datatable: Model,Accuracy,Precision,Recall,F1-Score,AUC-ROC, Logistic regression,0.897,0.898,0.898,0.894,0.923, Random forest,0.912,0.912,0.913,0.911,0.945, XGBoost,0.914,0.915,0.915,0.914,0.950, Support Vector Machine (SVM),0.890,0.898,0.900,0.885,0.917","The table represents the performance of four different models on the given dataset. Five performance metrics, accuracy, precision, recall, F1-score, and AUC-ROC were used to evaluate these models. The table indicates that the Random Forest and XGBoost models outperform the other two models with the highest accuracy, precision, recall, F1-Score, and AUC-ROC values. The Random Forest model achieved an accuracy of 0.912, while XGBoost achieved 0.914. Furthermore, both models' precision, recall, F1-Score, and AUC-ROC are also higher than other models. Although SVM performed with a lower accuracy metric, it's performance in other metrics is still significant."
2724,"caption: Performance comparison of different machine learning models on the dataset.table: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.85,0.84,0.86,0.82, KNN,0.80,0.78,0.79,0.77, Naive Bayes,0.75,0.72,0.73,0.71, Decision tree,0.82,0.82,0.83,0.81, Random forest,0.88,0.87,0.88,0.86, Gradient boosting,0.89,0.88,0.89,0.87","The table summarizes the performance of various machine learning models with different evaluation metrics on a given dataset. It compares the accuracy, F1-Score, Precision, and Recall of SVM, KNN, Naive Bayes, Decision tree, Random forest, and Gradient boosting models. The results show that the Gradient boosting model performs the best with the highest accuracy (0.89) and F1-Score (0.88) among all models. Meanwhile, SVM and Random forest models also show decent performance. However, the KNN and Naive Bayes models exhibit relatively lower scores in all metrics. Overall, the table demonstrates that different machine learning models have varied performance on different metrics, and one needs to select the appropriate model for the specific evaluation metric of interest."
2725,"caption: Performance comparison of different models using various evaluation metrics.table: Model,Precision,Recall,F1-Score,AUC, Model-A,0.85,0.78,0.81,0.92, Model-B,0.81,0.76,0.79,0.89, Model-C,0.88,0.66,0.76,0.90, Model-D,0.80,0.85,0.82,0.87, Model-E,0.89,0.89,0.89,0.91","The above table presents a comparison of five models, Model-A through Model-E, using different evaluation metrics. The evaluation metrics captured include precision, recall, F1-score, and area under the curve (AUC). Model-E ranked first in all metrics, achieving the best precision score of 0.89, recall score of 0.89, F1-score of 0.89, and AUC score of 0.91. Model-C outperformed Model-A and Model-B in terms of precision and F1-score but scored the lowest recall score of 0.66. Model-D performed well in terms of recall, but its precision score was the lowest among all models. Overall, the results indicate that Model-E shines with the overall best performance, while Model-D ranked last with the lowest evaluation metrics scores."
2726,"caption: Model performance using different classifiers on the test datasettable: Model Name,Accuracy,Precision,Recall,F1-Score, KNN,0.832,0.82,0.776,0.796, Decision Tree,0.737,0.714,0.544,0.616, Logistic Regression,0.846,0.828,0.802,0.815, SVM,0.854,0.839,0.812,0.818, Random Forest,0.897,0.894,0.856,0.875","The table presents the accuracy, precision, recall, and F1-score of different models trained on the same dataset. The models include KNN, Decision Tree, Logistic Regression, SVM, and Random Forest. Random Forest showed the highest accuracy score of 0.897. Also, Random Forest and Logistic Regression scored the highest precision values with 0.894 and 0.828, respectively. SVM and Logistic Regression achieved the highest recall scores with 0.812 and 0.802, respectively. The Random Forest model performed best across metrics with the highest F1-Score of 0.875. However, KNN model also showed a decent performance with the accuracy of 0.832, precision of 0.82 and F1-score of 0.796."
2727,"caption: Performance metrics of different models on a binary classification task.table: ```, Models,Precision,Recall,F1-score,Accuracy, SVM,0.85,0.94,0.89,0.93, RandomForest,0.81,0.88,0.84,0.90, GradientBoost,0.83,0.86,0.84,0.88, MultiNomialNB,0.66,0.93,0.77,0.80, AdaBoost,0.71,0.70,0.70,0.70","Table presents multiple different models' performance on a binary classification task using various evaluation metrics, including Precision, Recall, F1-score, and Accuracy. SVM shows the best Precision of 0.85 and Recall of 0.94 among all the models. MultiNomialNB obtained the best F1-score, with a score of 0.77; however, the model's Accuracy was only 0.80. Besides, the AdaBoost model shows the lowest metrics among all, with an Accuracy of only 0.70. It is noteworthy that SVM and RandomForest models' F1-scores are close and GradientBoost's metrics values are also fair. Therefore, based on these results, the SVM model could be considered the best-performing model on the binary classification task."
2728,"caption: Table 4: Model Comparison using multiple evaluation metricstable: Model,Accuracy,F1-Score,AUC-ROC, Model A,0.82,0.79,0.76, Model B,0.75,0.67,0.62, Model C,0.89,0.85,0.92, Model D,0.91,0.87,0.86","The table above compares the performances of four different models using various evaluation metrics, including Accuracy, F1-score, and AUC-ROC. Model A achieved the highest accuracy score of 0.82 with F1-score and AUC-ROC scores of 0.79 and 0.76, respectively. Model D shows overall good performance with an accuracy score of 0.91 and F1-score score of 0.87. However, it has the lowest AUC-ROC score of 0.86. Model C demonstrated superior performance overall, obtaining an accuracy score of 0.89 and the highest AUC-ROC score of 0.92 while achieving an F1-score of 0.85. Model B performed the worst among the models evaluated, with an accuracy score of 0.75, F1-score of 0.67, and AUC-ROC of 0.62."
2729,"caption: Table 4: Model Performance Evaluation using Multiple Metricstable: Model Name,F1 Score,Accuracy,Precision,Recall, Model A,0.85,0.91,0.87,**0.83**, Model B,0.76,0.78,0.78,**0.78**, Model C,0.94,**0.97**,**0.95**,0.93, Model D,0.82,0.88,0.85,**0.80**, Model E,0.91,0.94,0.92,**0.90**, Model F,**0.96**,0.93,0.94,**0.98**","Table 4 reports the performance of six different models evaluated using multiple metrics, including F1 score, accuracy, precision, and recall. Model F attained the best F1 score of 0.96, while Model C achieved the highest accuracy with 0.97. Model F achieved the highest Recall of 0.98. Model C performed the best for precision with a score of 0.95. Interestingly, Model A had the highest recall score with 0.83, though it had a lower F1 score. The results of this table suggest that choosing a model solely based on its F1 score may not be appropriate for some tasks."
2730,"caption: Performance comparison of different classification modelstable: Model Name,Accuracy,F1-Score,Precision,Recall, SVM,0.89,0.85,0.88,0.85, Random Forest,0.85,0.82,0.83,0.81, XGBoost,0.88,0.84,0.87,0.84, Naive Bayes,0.82,0.77,0.79,0.76, KNN,0.80,0.76,0.77,0.76","The table provides the performance comparison of various classification models including SVM, Random Forest, XGBoost, Naive Bayes, and KNN based on different evaluation metrics such as accuracy, F1-Score, precision, and recall. Among all models, SVM has recorded the highest accuracy of 0.89. Random Forest and XGBoost have comparable accuracy of 0.85 and 0.88, respectively. In terms of F1-Score, Random Forest shows the lowest score of 0.82, while SVM shows the highest of 0.85. The results of all models for precision and recall are also interesting as they demonstrate their individual strengths and weaknesses. KNN and Naive Bayes have recorded the lowest and second-lowest accuracy, respectively. However, their simplicity and lower computational requirements make them useful in some contexts."
2731,"caption: Comparison of different models' performance using multiple evaluation metrics.table: Metrics,Logistic Regression,Decision Tree,Random Forest,XGBoost,SVM, Accuracy,0.75,0.79,0.85,0.89,0.81, F1-Score,0.69,0.76,0.84,0.88,0.80, Precision,0.68,0.77,0.85,0.90,0.82, Recall,0.73,0.74,0.85,0.87,0.77, ROC-AUC,0.80,0.74,0.88,0.93,0.81","The table shows a comparison of different machine learning models based on various evaluation metrics, including accuracy, F1-Score, precision, recall, and ROC-AUC. The models include Logistic Regression, Decision Tree, Random Forest, XGBoost, and SVM. Notably, XGBoost achieved the highest performance results across all metrics, followed by Random Forest. Specifically, XGBoost exhibited the highest accuracy, F1-Score, and precision (0.89, 0.88, and 0.90, respectively) and the second-highest recall of 0.87. Random Forest, on the other hand, had the highest ROC-AUC scores of 0.88. Interestingly, the Decision Tree model shows the least impressive results across all the performance metrics."
2732,"caption: Table 4. Model performance comparison using different evaluation metrics.table: Model,F1-Score,Accuracy,Precision,Recall, LogReg,0.86,0.91,0.86,0.86, SVM,0.87,0.93,0.84,0.91, RF,0.91,0.94,0.89,0.93, XGB,0.90,0.93,0.88,0.93","Table 4 shows a comparison of the performance of four classification models, LogReg, SVM, RF, and XGB, with different evaluation metrics including F1-score, accuracy, precision, and recall. The table indicates that the RF model achieves the best performance with the highest F1-score (0.91) and accuracy (0.94) compared to the other models. The SVM model shows the best precision (0.84), while both the RF and SVM models have the highest recall (0.93). The LogReg model performed slightly lower than the other models for all evaluation metrics. The XGB model performed similarly to the RF model, except for inferior precision (0.88) compared to the RF model."
2733,"caption: Performance of different classification models on the dataset.table: Model Name,F1-Score,AUC,Precision,Recall,Accuracy, Logistic Regression,0.79,0.89,0.84,0.75,0.83, Random Forest,0.83,0.92,0.81,0.86,0.85, Support Vector Machine,0.68,0.71,0.63,0.73,0.70, Artificial Neural Networks,0.82,0.90,0.77,0.88,0.84, Gradient Boosting,0.84,0.94,0.86,0.81,0.86","This table presents the performance of five classification models: Logistic Regression, Random Forest, SVM (Support Vector Machine), Artificial Neural Networks and Gradient Boosting on a dataset. Five evaluation metrics including F1-Score, AUC, Precision, Recall, and Accuracy were used to compare the models' performances. The Gradient Boosting model resulted in the best overall performance, with the highest F1-Score (0.84) and AUC (0.94). Notably, Random Forest model results were also prominent with an F1-Score of 0.83 and AUC of 0.92. On the other hand, SVM performed the worst, with the lowest F1-score (0.68) and AUC (0.71). The Artificial Neural Network model achieved the highest precision of 0.77, while the Logistic Regression model had the highest recall of 0.75. The results indicate that Gradient Boosting and Random Forest models have the potential to be utilized for classification tasks on similar datasets."
2734,"caption: Comparison of different models based on multiple evaluation metrics.table: Model,Accuracy,F1-Score,AUC-ROC, Logistic Regression,0.82,0.79,0.88, Random Forest,0.85,0.81,0.89, Support Vector Machine,0.80,0.76,0.87, Gradient Boosting,0.86,0.83,0.90, Neural Network,0.87,0.84,0.91","The above table compares the performances of five different models based on accuracy, F1-Score, and AUC-ROC. The Logistic Regression model performed consistently well, achieving an accuracy score of 0.82, F1-Score of 0.79, and AUC-ROC of 0.88. The Neural Network model demonstrated the highest accuracy (0.87) and F1-Score (0.84). Interestingly, the Gradient Boosting model achieved the highest AUC-ROC score of 0.90. Overall, all models achieved good performances, with the lowest accuracy being 0.80 from the Support Vector Machine model."
2735,"caption: Table 4: Model comparison based on different evaluation metrics.table: Model,Accuracy,F1_score,Precision,Recall, Logistic Regression,0.92,0.88,0.89,0.89, Support Vector Machine (RBF kernel),0.89,0.85,0.85,0.86, Random Forest,0.93,0.90,0.92,0.91, Gradient Boosting,0.92,0.88,0.91,0.87, Extreme Gradient Boosting,0.94,0.91,0.93,0.92","Table 4 depicts a comparison of five different models' performances based on diverse evaluation metrics. The evaluation metrics used in this table are Accuracy, F1_score, Precision, and Recall. The table suggests that the Extreme Gradient Boosting model outperforms all other models in all the evaluation metrics, with the highest Accuracy score of 0.94, F1_Score of 0.91, Precision of 0.93, and Recall of 0.92. The Random Forest model performs decently well, with the second-highest scores in all metrics except Recall, where the Logistic Regression model performs the second-best. The Support Vector Machine with an RBF kernel and Gradient Boosting models also exhibit good performances."
2736,"caption: Evaluation Metrics for Different Modelstable: Model Name,Precision,Recall,F1-Score,Accuracy, Model 1,0.68,0.72,0.70,0.60, Model 2,0.73,0.78,0.76,0.63, Model 3,0.79,0.82,0.81,0.70, Model 4,0.77,0.80,0.79,0.68, Model 5,0.84,0.87,0.85,0.75","The table above indicates the performance of five different models on four evaluation metrics, including Precision, Recall, F1-score, and Accuracy. Model 5 outperformed all other models on every evaluation metric with Precision, Recall, F1-Score, and Accuracy scores of 0.84, 0.87, 0.85, and 0.75, respectively. Models 3 and 4 also performed reasonably well compared to other models, both achieving a Precision score of at least 0.77 and Recall score of at least 0.80. Overall, the table highlights the importance of comparing model performances based on multiple evaluation metrics."
2737,"caption: Table 4: Evaluation metrics for different classification models.table: Model,Accuracy,F1 Score,Precision,Recall,AUC Score, Logistic Regression,0.75,0.71,0.69,0.74,0.82, Random Forest,0.80,0.75,0.76,0.74,0.84, Gradient Boosting,0.78,0.74,0.73,0.77,0.81, SVM (linear),0.72,0.67,0.64,0.72,0.79, SVM (Radial Basis Fn),0.74,0.69,0.67,0.71,0.80","Table 4 illustrates the performance evaluation of various classification models. The table reports the models' accuracy, F1 score, precision, recall, and AUC score. The evaluation was conducted on a specific dataset, and the models under comparison include Logistic Regression, Random Forest, Gradient Boosting, SVM (linear), and SVM (Radial Basis Fn). Interestingly, the Random Forest model shows the highest Accuracy score (0.80) and AUC score (0.84), while the Gradient Boosting model has the highest Recall score (0.77). On the other hand, the Logistic Regression model performs better in terms of Precision than the other models with a score of 0.69. Finally, the SVM (linear) model shows the least performance overall among the compared models."
2738,"caption: Comparison of Model Performances using Different Evaluation Metricstable: Model,Precision,Recall,F1-Score,AUC-ROC, Model A,0.85,0.82,0.83,0.91, Model B,0.88,0.74,0.80,0.87, Model C,0.74,0.93,0.82,0.89, Model D,0.91,0.85,0.88,0.92","Table presents performances of four different models, Model A, Model B, Model C, and Model D, based on various evaluation metrics such as Precision, Recall, F1-Score, and AUC-ROC. Model D attained the highest scores in all the metrics, with the highest precision (0.91), recall (0.85), and F1-Score (0.88). Additionally, Model D also exhibited the highest AUC-ROC (0.92), indicating that it performed the best. However, Model B, despite having the lowest F1-Score, registered a high-precision score of 0.88, which could suggest that the model suffered from overfitting. Overall, the results demonstrate the importance of using multiple evaluation metrics to gauge model performance."
2739,"caption: Comparison of model performances using different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.85,0.87,0.78,0.82, Decision Tree,0.74,0.72,0.67,0.69, Random Forest,0.92,0.92,0.89,0.90, XGBoost,0.95,0.94,0.95,0.94","Table presents a comparison of different models' performances using multiple evaluation metrics such as Accuracy, Precision, Recall, and F1-score. Logistic Regression, Decision Tree, Random Forest, and XGBoost models are evaluated on the same dataset to obtain the results. It can be observed that XGBoost has the highest Accuracy of 0.95, while Random Forest has the second-highest Accuracy of 0.92. The Precision, Recall, and F1-score of Random Forest and XGBoost are significantly higher than those of the Logistic Regression and Decision Tree models. Overall, the Random Forest and XGBoost models outperform Logistic Regression and Decision Tree models in terms of all the evaluation metrics used in this study."
2740,"caption: Table 4: Evaluation of different models using multiple metrics including accuracy, precision, recall and F1 score.table: Models,Accuracy,Precision,Recall,F1 Score, Model A,0.82,0.89,0.76,0.82, Model B,0.84,0.87,0.82,0.84, Model C,0.83,0.85,0.85,0.85, Model D,0.80,0.78,0.89,0.83, Model E,0.85,0.83,0.87,0.85","Table 4 displays the performance of different models based on multiple metrics including accuracy, precision, recall, and F1 score. The table highlights that Model E demonstrates the highest accuracy of 0.85, whereas Model D exhibits the lowest accuracy of 0.80. Model A and Model B show similar accuracy scores of 0.82 and 0.84, respectively. Model A achieved the highest precision of 0.89, while Model D achieved the lowest precision of 0.78. Model C and Model E demonstrate similar precision rates. Model D has the highest recall of 0.89, while Model C has the lowest recall of 0.85. Model B has the highest F1 score of 0.84, while Model A achieved the lowest F1 score of 0.82. Overall, among the models evaluated, Model B produces the best performance outcome based on the F1 score."
2741,"caption: Performance result of different machine learning models on a binary classification problem.table: Model,Accuracy,Precision,Recall,F1-score, Logistic regression,0.89,0.87,0.78,0.82, Decision Tree,0.91,0.87,0.85,0.86, Support Vector Machine,0.88,0.86,0.79,0.81, Random Forest,0.93,0.92,0.89,0.90, Gradient Boosting,0.92,0.90,0.87,0.88","Table 1 shows the performance result of five different machine learning models on a binary classification task evaluated using accuracy, precision, recall, and F1-score metrics. The highest accuracy score among all the models belongs to the Random Forest model, which has scored 0.93. Similarly, the Random Forest model has the best precision score of 0.92 and recall score of 0.89. Notably, the Decision Tree and Gradient Boosting models show competitive performance outcomes, with the Decision Tree model having an accuracy score of 0.91 and Gradient Boosting having an accuracy score of 0.92. The Support Vector Machine shows the lowest recall score of 0.79. Overall, the results indicate that Random Forest is the most effective model for this binary classification task."
2742,"caption: Table 4. Model performances on the classification task using various metrics.table: Model,Accuracy,Precision,Recall,F1-score, Decision Tree,0.96,0.94,0.95,0.94, Random Forest,0.98,0.97,0.98,0.97, Support Vector Machine,0.92,0.89,0.92,0.90, K-Nearest Neighbor,0.93,0.90,0.92,0.91, Logistic Regression,0.95,0.93,0.94,0.94","Table 4 shows the performance of five different models for a classification task. The models evaluated include Decision Tree, Random Forest, Support Vector Machine (SVM), K-Nearest Neighbor (KNN), and Logistic Regression. Accuracy, precision, recall, and F1-score are the evaluation metrics reported in the table. Random Forest achieves high scores in all metrics, having the highest accuracy of 0.98 and F1-score of 0.97. Decision Tree performs the worst amongst all models, yielding the lowest F1-score of 0.94. Notably, the SVM model yields the lowest accuracy of 0.92, despite having a comparable F1-score to logistic regression, which achieves the second-best accuracy among all models, yielding 0.93."
2743,"caption: Table 4: Model performance comparison based on different evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.82,0.88,0.76,0.81, Random Forest,0.84,0.88,0.82,0.85, Naive Bayes,0.76,0.72,0.85,0.78, Logistic Regression,0.81,0.82,0.77,0.79, Decision Tree,0.72,0.73,0.78,0.72","Table 4 showcases the performance comparison of five different models based on various evaluation metrics. The evaluation metrics include accuracy, precision, recall, and F1-score. The table demonstrates that the most accurate model is Random Forest, with an accuracy score of 0.84. In contrast, the least accurate model is Decision Tree, with an accuracy score of 0.72. Additionally, Random Forest also has the highest precision score of 0.88, whereas Naive Bayes has the highest recall score of 0.85. Furthermore, while Random Forest has the highest F1-score, SVM and Logistic Regression models report the closest values to Random Forest. Overall, the table shows that each model has different strengths and weaknesses based on the evaluation metric."
2744,"caption: Table 1: Model Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1-Score,AUC, SVM,0.89,0.88,0.91,0.89,0.95, KNN,0.84,0.82,0.86,0.84,0.91, Logistic Regression,0.87,0.84,0.90,0.87,0.94, Random Forest,0.92,0.91,0.93,0.91,0.96, Neural network,0.93,0.93,0.93,0.92,0.97","Table 1 presents the evaluation metrics of different models. The table compares model performances based on Accuracy, Precision, Recall, F1-Score, and AUC. SVM, KNN, Logistic Regression, Random Forest, and Neural Network models were evaluated using the same dataset. The highest accuracy of 0.93 was achieved by the Neural Network model, followed by the Random Forest model with an accuracy of 0.92. Interestingly, all models achieved F1-Score above 0.89, while the AUC scores ranged from 0.91 to 0.97. Overall, this table provides comprehensive performance comparisons of different models which can be helpful in choosing the best model for a particular task."
2745,"caption: Model performance of different models based on various evaluation metrics.table: Model Name,Accuracy,F1-Score,Recall,Precision, Model 1,0.87,0.78,0.84,0.74, Model 2,0.89,0.81,0.86,0.78, Model 3,0.93,0.89,0.91,0.87, Model 4,0.85,0.76,0.83,0.70, Model 5,0.92,0.88,0.90,0.86","The table shows the performance of multiple models based on different evaluation metrics, including accuracy, F1-score, recall, and precision. Model 3 outperforms all other models with an accuracy of 0.93, F1-score of 0.89, recall of 0.91, and precision of 0.87. Meanwhile, Model 4 has the lowest performance with an accuracy of 0.85, F1-score of 0.76, recall of 0.83, and precision of 0.70. Model 2 shows the second-best performance with an accuracy of 0.89 and a high F1-score, recall, and precision. The table exhibits the variation in model performance for various metrics and can be used by researchers to compare the different models."
2746,"caption: Table 4: Performance Metrics of Different Models on Test Settable: Model,Precision,Recall,F1-Score,AUC-ROC,AUC-PR, Decision Tree,0.85,0.89,0.87,0.91,0.81, Naive Bayes,0.71,0.94,0.81,0.83,0.77, SVM,0.94,0.89,0.91,0.96,0.88, Random Forest,0.95,0.98,0.96,0.98,0.94, XGBoost,0.96,0.97,0.96,0.97,0.95",
2747,"caption: Model Performances for Different Classification Models Using Various Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1-score, Naive Bayes,0.74,0.76,0.73,0.74, Logistic Regression,0.82,0.83,0.81,0.81, Decision Tree,0.78,0.81,0.77,0.77, Random Forest,0.84,0.85,0.83,0.83","The table presents four different models' performances using various evaluation metrics. The models include Naive Bayes, Logistic Regression, Decision Tree, and Random Forest. Each model's accuracy, precision, recall, and F1-score are reported for comparison purposes. The Logistic Regression model stands out as the best model, achieving the highest accuracy of 0.82. It was also the most precise model when compared to the others, reaching a score of 0.83. However, when it comes to recall and F1-score, Random Forest outperforms the other models, achieving a score of 0.83 for both metrics. The least performing model was the Naive Bayes model, which had an accuracy, precision, recall, and F1-score of 0.74, 0.76, 0.73, and 0.74, respectively."
2748,"caption: Comparison of different models based on evaluation metricstable: Model,Precision,Recall,F1-score,AUC Score, Logistic Regression,0.719,0.786,0.730,0.812, K-Nearest Neighbors (KNN),0.635,0.711,0.643,0.701, Decision Tree,0.766,0.784,0.770,0.739, Random Forest,0.818,0.849,0.827,0.891, Support Vector Machine (SVM),0.781,0.831,0.794,0.865","The table presents a comparison of the performance of five different machine learning models on a classification task based on multiple evaluation metrics, namely precision, recall, F1-score, and AUC score. The models include Logistic Regression, K-Nearest Neighbors (KNN), Decision Tree, Random Forest, and Support Vector Machine (SVM). A notable observation from the table is that the Random Forest model outperformed the other models with the highest precision, recall, and F1-score. On the other hand, the SVM model shows the highest AUC score. Overall, the Random Forest model demonstrates the most optimal performance for this particular classification task based on the evaluation metrics in this table."
2749,"caption: Performance comparison of different machine learning models using multiple evaluation metrics.table: Model,Accuracy,F1 Score,AUC Score,Precision, Logistic Regression,0.82,0.80,0.89,0.84, Random Forest,0.92,0.91,0.98,0.93, Gradient Boosting,0.90,0.88,0.95,0.91, Decision Tree,0.85,0.82,0.88,0.86, Support Vector Machine,0.81,0.79,0.87,0.82","The table above shows the performance comparison of different machine learning models using multiple evaluation metrics. The models' accuracy, F1 Score, AUC score, and precision metrics were evaluated. The Random Forest model outperformed the other models, achieving the highest accuracy score of 0.92 and F1 Score of 0.91. The Decision Tree model recorded the lowest AUC Score of 0.88 compared to other models. The results indicate that Random Forest and Gradient Boosting models are the top-performing models, improving the chances of correctly classifying the target variable."
2750,"caption: Comparison of multiple models based on various evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, Model A,0.85,0.83,0.88,0.78, Model B,0.83,0.81,0.84,0.79, Model C,0.81,0.78,0.83,0.73, Model D,0.85,0.83,0.89,0.76, Model E,0.87,0.84,0.88,0.80","The presented table compares multiple models based on various evaluation metrics. The accuracy, F1-Score, precision, and recall are used as performance evaluation matrices. Model A achieved the highest accuracy (0.85) and precision (0.88) among all compared models, while Model E had the best F1-score (0.84) and recall (0.80). Interestingly, Models A and D had the same accuracies of 0.85 but achieved different F1-scores and recalls. On the other hand, Model E had a high accuracy of 0.87 and the best F1-Score of 0.84, which indicates its robustness in performance."
2751,"caption: Evaluation Metrics of Different Machine Learning Algorithmstable: Model,precision,recall,F1-score,AUC, Logistic Regression,0.84,0.88,0.86,0.75, SVM,0.81,0.76,0.78,0.88, Random Forest,0.86,0.82,0.84,0.78, Naive Bayes,0.68,0.97,0.80,0.65, KNN,0.78,0.73,0.75,0.63","Table 4 compares the performance of various machine learning algorithms based on different evaluation metrics, such as precision, recall, F1-score, and the area under the curve (AUC). The models enumerated in the table include Logistic Regression, Support Vector Machine (SVM), Random Forest, Naive Bayes, and K-Nearest Neighbor (KNN). Interestingly, the Naive Bayes algorithm had the highest recall score of 0.97, indicating that it correctly identified almost all the true positives. In contrast, the Random Forest algorithm showed the highest precision score of 0.86, indicating that it had the lowest rate of false positives among all the models. The AUC values for the models ranged from 0.63 to 0.88, with SVM showing the highest AUC score and KNN showing the lowest."
2752,"caption: Model performance using different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Random Forest,0.89,0.91,0.82,0.86, SVM,0.79,0.74,0.95,0.83, Logistic,0.87,0.89,0.81,0.85, Decision Tree,0.81,0.83,0.79,0.81, Naive Bayes,0.77,0.72,0.91,0.81","Table 4 shows the performances of five different models on a given dataset using multiple evaluation metrics. The models are Random Forest, SVM, Logistic Regression, Decision Tree, and Naive Bayes. The evaluation metrics used are Accuracy, Precision, Recall, and F1-Score. Random Forest achieved the highest Accuracy of 0.89 and Precision of 0.91, while SVM achieved the highest Recall of 0.95, and Naive Bayes achieved the highest F1-Score of 0.81. Interestingly, SVM's Recall score is exceptionally high at 0.95, far higher than the other models. It should also be noted that Logistic Regression scores moderately high on all metrics. The results can be used to select the appropriate model based on the evaluation metric that's important for a specific project."
2753,"caption: Table 4: Performance evaluation of different model algorithms based on multiple evaluation metrics.table: **Model Name**,**Metric 1**,**Metric 2**,**Metric 3**, Logistic Regression,0.82,0.70,0.65, Decision Tree,0.74,0.73,0.71, Random Forest,0.85,0.80,0.79, XGBoost,0.87,0.83,0.80, SVM,0.84,0.81,0.77","Table 4 presents a comparison of different models' performances based on multiple evaluation metrics. The table involves several models, including Logistic Regression, Decision Tree, Random Forest, XGBoost, and SVM, assessed through three diverse metrics. The three metrics used in this study include Metric 1, Metric 2, and Metric 3, and all models were tested using the same dataset. The Random Forest and XGBoost models outperformed other models in all evaluation metrics, with the highest scores of 0.85 and 0.87 for Metric 1 and 0.80 and 0.83 for Metric 2, respectively. The Decision Tree and SVM showed comparable results with the Random Forest and XGBoost models, respectively, with relatively lower scores. Nonetheless, the Logistic Regression showed the lowest score of all models in all evaluation metrics."
2754,"caption: Table 4: Model performances with different evaluation metricstable: Models,Accuracy,F1-score,Precision,Recall,AUC, Model A,0.87,0.89,0.91,0.87,0.91, Model B,0.84,0.85,0.93,0.79,0.87, Model C,0.91,0.92,0.88,0.96,0.95, Model D,0.80,0.81,0.92,0.73,0.85","Table 4 presents the performances of four models with different evaluation metrics. The table shows accuracy, F1-score, precision, recall, and AUC of each model. Model C is the most accurate and shows the highest AUC score of 0.95. Model A demonstrates high F1-score and precision values, while Models B and D receive comparatively low accuracy scores. Interestingly, Model D exhibits the lowest performance result in all metrics. The table implies that Model C should be preferred if prioritizing the AUC metric, while Model A is better if precision and F1-score are more important."
2755,"caption: Table 4: Evaluation of different models using various metricstable: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.84,0.82,0.78,0.80, KNN,0.78,0.72,0.70,0.71, Decision Tree,0.81,0.80,0.75,0.77, Random Forest,0.89,0.88,0.86,0.87, SVM,0.82,0.81,0.75,0.77","Table 4 compares the performance of five models using multiple evaluation metrics, including accuracy, precision, recall, and F1-score. The models include logistic regression, K-Nearest Neighbors (KNN), decision tree, random forest, and support vector machine (SVM). The results demonstrate that the random forest model achieved the highest accuracy score of 0.89. Moreover, it had the best precision score of 0.88 and recall score of 0.86. However, in terms of the F1-score, the decision tree had the second-best result of 0.77. Overall, the table highlights the importance of selecting appropriate metrics while evaluating different models."
2756,"caption: Table 4: Performance of different models using various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.85,0.84,0.85,0.84, KNN,0.81,0.78,0.81,0.79, Naive Bayes,0.87,0.85,0.87,0.85, Decision Tree,0.82,0.80,0.80,0.80, Random Forest,0.89,0.87,0.89,0.88, XGBoost,0.90,0.89,0.89,0.89","Table 4 illustrates the performance comparison of different models through various evaluation metrics, including Accuracy, Precision, Recall, and F1-Score. The table presents results for SVM, KNN, Naive Bayes, Decision Tree, Random Forest, and XGBoost models. Among all models, the best accuracy score was attained by XGBoost with a score of 0.90. Meanwhile, the Random Forest model achieved the highest F1-score of 0.88 which is equally competitive. Interestingly, the Naive Bayes model yielded good performance across all metrics, with scores of 0.87, 0.85, 0.87, and 0.85 for accuracy, precision, recall, and F1-score, respectively. These results suggest that the different models have their respective strength and can be utilized for different tasks based on specific needs."
2757,"caption: Performance of different models using multiple evaluation metricstable: Model,Accuracy,F1 Score,Precision,Recall,AUC Score, Logistic Reg.,0.80,0.78,0.83,0.74,0.89, Decision Trees,0.70,0.71,0.75,0.68,0.75, SVM,0.83,0.79,0.86,0.73,0.91, Random Forest,0.89,0.88,0.92,0.85,0.94, XGBoost,0.92,0.91,0.93,0.89,0.97","Table presents a performance comparison of different models, namely, Logistic Regression, Decision Trees, SVM, Random Forest, and XGBoost models based on various evaluation metrics. The table shows Accuracy, F1 Score, Precision, Recall, and AUC Score of each model. Interestingly, the XGBoost model achieved the highest accuracy and other evaluation metrics, except for the AUC score, with scores of 0.92, 0.91, 0.93, and 0.89, respectively. The Random Forest model achieved the highest AUC score of 0.94, followed by the XGBoost model with 0.97. The Logistic Regression model showed the highest precision of 0.83, while the SVM model showed the highest recall of 0.73."
2758,"caption: Model Performance Evaluation using multiple Evaluation Metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.89,0.91,0.92,0.919, SVM,0.91,0.93,0.94,0.936, Random Forest,0.92,0.94,0.93,0.936, XGBoost,0.93,0.95,0.95,0.952, Naive Bayes,0.87,0.89,0.87,0.878","The table provides a comparison of model performances for Logistic Regression, SVM, Random Forest, XGBoost, and Naive Bayes. Each model is evaluated using multiple metrics, including Accuracy, Precision, Recall, and F1-Score. The Random Forest and XGBoost showed the highest F1-Score (0.936 and 0.952) and Accuracy (0.92 and 0.93) among other models. The Logistic Regression model demonstrates the highest Precision (0.91), while the SVM model exhibited the highest Recall (0.94). The Naive Bayes model, despite having the lowest performance measures compared to other models, still achieved decent F1-Score (0.878) and Accuracy (0.87)."
2759,"caption: Table 4: Performance evaluation of multiple models using different evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Model1,0.85,0.84,0.84,0.85, Model2,0.86,0.82,0.86,0.80, Model3,0.82,0.81,0.83,0.80, Model4,0.90,0.88,0.88,0.89, Model5,0.87,0.85,0.85,0.87","Table 4 outlines the performance evaluation of multiple models using different evaluation metrics. The table presents the accuracy, F1 score, precision, and recall of Model 1 to Model 5. Model 4 demonstrates the highest accuracy score of 0.90, followed by Model 2 with an accuracy score of 0.86. Model 5 and Model 1 both have a close accuracy score of 0.87 and 0.85, respectively. However, Model 1 displays the highest F1 score and recall of 0.84 and 0.85. On the other hand, Model 4 resulted in the highest precision score of 0.88. Therefore, selecting the best-performing model in this scenario may require prioritizing different metrics, depending on the problem's nature."
2760,"caption: Table 4: Performance comparison of different models based on multiple evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.85,0.84,0.81,0.87, Random Forest,0.88,0.87,0.87,0.88, Naive Bayes,0.79,0.80,0.77,0.82, Support Vector Machine (SVM),0.81,0.81,0.82,0.80, Multi-layer Perceptron (MLP),0.90,0.90,0.90,0.91","Table 4 presents a comparison of model performance based on multiple evaluation metrics, including Accuracy, F1 Score, Precision, and Recall. The table exhibits the performance results of Logistic Regression, Random Forest, Naive Bayes, Support Vector Machine (SVM), and Multi-layer Perceptron (MLP) models. From the table, MLP outperforms all other models with the highest Accuracy, F1 Score, Precision, and Recall scores of 0.90, 0.90, 0.90, and 0.91, respectively. Random Forest is the next-best performer, achieving an Accuracy, F1 Score, Precision, and Recall of 0.88, 0.87, 0.87 and 0.88, respectively. The Naive Bayes model has the lowest Accuracy and F1 score of 0.79 and 0.80, while Support Vector Machine (SVM) has the lowest Precision and MLP has the lowest Recall score."
2761,"caption: Classification Model Performances on Test Set.table: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.91,0.92,0.89,0.90, Decision Tree,0.85,0.84,0.86,0.85, Random Forest,0.92,0.94,0.89,0.91, SVM,0.88,0.91,0.86,0.88","The table presents the evaluation metrics and performance results for different classification models, Logistic Regression, Decision Tree, Random Forest, and SVM on the test set. The evaluation metrics included Accuracy, Precision, Recall, and F1-score. The Random Forest model achieves the highest accuracy score of 0.92, followed by Logistic Regression with an accuracy of 0.91. On the other hand, Random Forest is also the best in Precision with a score of 0.94, and Logistic Regression is the best in Recall with a score of 0.89. Finally, Logistic Regression has the highest F1-score with 0.90. The table provides an overview of different models' performances and their relative strengths in classification problems."
2762,"caption: Performance comparison of different machine learning models in classification task.table: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.82,0.81,0.88,0.75, Random Forest,0.84,0.83,0.87,0.79, Support Vector Machines,0.81,0.80,0.86,0.76, Multilayer Perceptron,0.81,0.80,0.86,0.75, Naive Bayes,0.78,0.77,0.82,0.72","Table's caption provides a glimpse of the table's content containing the results of different machine learning models to solve a classification problem. The performance comparison is based on different evaluation metrics such as Accuracy, F1 Score, Precision, and Recall. The table highlights that the Random Forest model outperformed the other models in terms of accuracy with a score of 0.84. Moreover, Random Forest and Logistic Regression models show the best F1 score of 0.83 and Precision (0.87), respectively. Naive Bayes, on the other hand, shows the lowest performance in all performance metrics. In conclusion, Random Forest and Logistic Regression perform well in this classification task and could be considered for practical application."
2763,"caption: The table depicts the evaluation metrics of SVM, KNN, Decision Tree, and Random Forest models in a classification task. The evaluation metrics include accuracy, precision, recall, F1-score, and AUC.table: Model,Accuracy,Precision,Recall,F1-score,AUC, SVM,0.82,0.85,0.75,0.80,0.87, KNN,0.76,0.72,0.90,0.80,0.75, Decision Tree,0.73,0.65,0.72,0.68,0.70, Random Forest,0.88,0.87,0.92,0.89,0.95","The table presents the performance of different models in a classification task, showing various evaluation metrics. The Random Forest model outperformed the other models with an accuracy score of 0.88 and an AUC score of 0.95. The SVM model shows the highest precision score of 0.85, while the KNN model shows a high recall rate of 0.90. Interestingly, the decision tree model achieves the lowest performance among all models, with an accuracy score of 0.73 and an AUC score of 0.70. Overall, the table highlights the importance of evaluating models using different metrics to obtain an in-depth understanding of their performance."
2764,"caption: Table 4: Model Evaluation Metrics Resultstable: Model,Accuracy,F1-score,AUC-ROC,Sensitivity,Specificity, Logistic Regression,0.862,0.845,0.922,0.832,0.892, Decision Tree,0.812,0.792,0.786,0.784,0.796, Random Forest,0.912,0.904,0.965,0.901,0.957, Support Vector Machine,0.890,0.882,0.936,0.872,0.901, XGBoost,0.920,0.913,0.974,0.910,0.956","Table 4 summarizes the evaluation metrics results for five different models, namely Logistic Regression, Decision Tree, Random Forest, Support Vector Machine, and XGBoost. The evaluation metrics include Accuracy, F1-score, AUC-ROC, Sensitivity, and Specificity. Random Forest and XGBoost performed the best among these models across all evaluation metrics with an accuracy of 0.912 and 0.920, respectively. They also achieved the highest F1-score of 0.904 and 0.913, respectively. Moreover, both Random Forest and XGBoost also achieved promising AUC-ROC scores of 0.965 and 0.974, respectively. Logistic regression also performed quite well with a high AUC-ROC score of 0.922."
2765,"caption: Model Performance using Multiple Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.90,0.91,0.93,0.92, SVM (linear),0.89,0.92,0.87,0.89, SVM (RBF),0.85,0.84,0.89,0.86, Random Forest,0.93,0.93,0.94,0.94, MLP,0.94,0.94,0.94,0.94","The table shows the different models' accuracy, precision, recall, and F1-score evaluation metrics. The Logistic regression model presented the highest accuracy score of 0.90, closely followed by SVM (linear) and Random forest with scores of 0.89 and 0.93, respectively. The MLP model achieved the highest accuracy score of 0.94. In terms of precision, Random Forest and MLP achieved the highest scores with 0.93 and 0.94, respectively. The Recall metric shows SVM (linear) as the best performer with a score of 0.87. Finally, the F1-Score, which is a measure of the model's overall performance, presents all models with high scores above 0.86, indicating their all-around good performance."
2766,"caption: Comparison of model performance using different evaluation metricstable: Model,F1-Score,Accuracy,Precision,Recall, Logistic Regression,0.78,0.81,0.82,0.75, Decision Tree,0.69,0.72,0.73,0.65, Random Forest,0.82,0.84,0.84,0.81, SVM,0.75,0.73,0.72,0.78, Naive Bayes,0.63,0.68,0.71,0.56","Table presents a comparison of different models' performance using metrics F1-score, accuracy, precision, and recall. The table lists logistic regression, decision tree, random forest, SVM, and naive bayes models, with the evaluation metrics recorded for each. It is observed that the random forest model performs best across all the metrics, with F1-score, accuracy, precision, and recall values of 0.82, 0.84, 0.84, and 0.81, respectively. While the decision tree model has the lowest performance among all models, it is interesting to note that the logistic regression model has a higher recall but a lower precision, whereas the SVM model has a higher precision and a lower recall."
2767,"caption: Table 4: Model performances measured in terms of precision, recall, F1-Score, and ROC-AUC score.table: Model,Precision Score,Recall Score,F1-Score,ROC-AUC Score, SVM,0.86,0.80,0.83,0.92, Random Forest,0.87,0.92,0.89,0.93, Gradient Boost,0.88,0.90,0.89,0.92, Neural Network,0.90,0.89,0.89,0.94, Decision Tree,0.75,0.85,0.79,0.89","Table 4 depicts the performance of different models. Precision, Recall, F1-Score, and ROC-AUC Score metrics are used to evaluate the models. The table includes SVM, Random Forest, Gradient Boost, Neural Network, and Decision Tree models, each demonstrating their strengths and weaknesses across the evaluation metrics. Interestingly, Gradient Boost and Neural Network models had the highest precision score of 0.88 and 0.90, respectively. Random forest model achieved the highest recall and F1-score of 0.92 and 0.89, respectively. Furthermore, Neural Network attained the best ROC-AUC score of 0.94, outdoing the other models."
2768,"caption: Comparison of different machine learning models based on evaluation metrics.table: Model,F1-Score,Precision,Recall,Accuracy, Logistic Regression,0.895,0.892,0.898,0.891, Random Forest,0.913,0.910,0.916,0.909, Gradient Boosting,0.893,0.899,0.888,0.889, Support Vector Machine,0.901,0.895,0.908,0.893, K-Nearest Neighbors,0.880,0.869,0.892,0.865","The table displays the comparative performance of five different machine learning models based on F1-Score, precision, recall, and accuracy evaluation metrics. The models employed are Logistic Regression, Random Forest, Gradient Boosting, Support Vector Machine, and K-Nearest Neighbors. The Random Forest model had the highest F1-Score performance of 0.913, while the K-Nearest Neighbors had the lowest F1-Score of 0.880. The Support Vector Machine model had the highest precision score of 0.895, while Random Forest had the highest accuracy score of 0.909. Furthermore, K-Nearest Neighbors had the highest recall score of 0.892. Overall, this table shows the diversified evaluation metrics and performance scores of the various models employed."
2769,"caption: Table 4. Performance of Different Models on Evaluation Metrics for Binary Classificationtable: Models,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.86,0.88,0.84,0.86, Naive Bayes,0.84,0.86,0.82,0.84, Random Forest,0.89,0.90,0.88,0.89, Gradient Boosting,0.91,0.92,0.90,0.91, Support Vector Machine,0.88,0.87,0.89,0.88","Table 4 presents the performance of five different models on multiple evaluation metrics for binary classification. The evaluation metrics include accuracy, precision, recall, and F1-Score. The table shows that the Gradient Boosting model performed the best across all metrics with accuracy of 0.91, precision of 0.92, recall of 0.90, and F1-Score of 0.91. The Random Forest model also performed well with accuracy of 0.89, precision of 0.90, recall of 0.88, and F1-Score of 0.89. Interestingly, the Naive Bayes model achieved a higher precision score than the Logistic Regression model, despite the latter achieving higher accuracy, recall, and F1-Score."
2770,"caption: Model performance based on different evaluation metrics.table: Models,F1-score,Precision,Recall,AUC, SVM,0.76,0.72,0.81,0.82, KNN,0.64,0.70,0.52,0.63, Decision Tree,0.72,0.68,0.76,0.72, Random Forest,0.78,0.78,0.79,0.85, XGBoost,0.82,0.80,0.84,0.86","This table presents a comparison of the model performance of SVM, KNN, Decision Tree, Random Forest, and XGBoost based on four different evaluation metrics, namely F1-score, Precision, Recall, and AUC. Interestingly, the XGBoost model achieved the highest F1-score, Precision, and Recall with scores of 0.82, 0.80, and 0.84, respectively, and the second-best AUC of 0.86. The Random Forest model performed the best regarding AUC, with a score of 0.85, and an F1-score of 0.78. On the other hand, KNN appears to be the worst-performing model based on all evaluation metrics except Recall, where it performed slightly better than SVM."
2771,"caption: Model performance based on different evaluation metrics from various models.table: Metric,Model 1,Model 2,Model 3,Model 4,Model 5, Accuracy,0.85,0.80,0.83,0.81,0.84, F1 Score,0.75,0.77,0.80,0.72,0.78, AUC Score,0.92,0.88,0.91,0.89,0.92, Recall,0.80,0.73,0.79,0.82,0.81","The table above presents a comparison of multiple models based on different evaluation metrics. Model 1, Model 3, and Model 5 showcase the highest AUC score of 0.92, with Model 2 and Model 4 achieving 0.88 and 0.89, respectively. The highest accuracy score is from Model 1 with 0.85, while the F1 score is highest in Model 3 with 0.8. Model 4 has the lowest F1 score of 0.72 compared to others. Interestingly, Model 2 has the lowest recall score of 0.73, while Model 4 has the highest recall score of 0.82. Overall, the table highlights the different strengths and weaknesses of models based on the evaluation metrics."
2772,"caption: Table 4: Evaluation metrics for different machine learning modelstable: Model,Accuracy,Precision,Recall,F1, Logistic Regression,0.824,0.833,0.789,0.809, Support Vector Machine,0.836,0.849,0.799,0.817, Random Forest,0.85,0.856,0.822,0.827","In Table 4, we report the performance results for three different machine learning models - Logistic Regression, Support Vector Machine and Random Forest. We evaluated the models using various metrics, including Accuracy, Precision, Recall, and F1. Notably, Random Forest achieved the highest Accuracy of 0.85, whereas SVM obtained the highest Precision score of 0.849. However, Logistic Regression demonstrated the highest Recall score of 0.789 and F1 score of 0.809. These findings suggest that selecting the best model depends on considering the evaluation metrics that are most relevant to the research question or application at hand."
2773,"caption: Model performance using various evaluation metrics.table: Model,Accuracy,F1-score,AUC-ROC,AUC-PR, Logistic Regression,0.874,0.892,0.901,0.817, Decision Tree,0.912,0.920,0.875,0.825, Random Forest,0.940,0.938,0.934,0.898, Gradient Boosting,0.945,0.943,0.948,0.924, Support Vector Classification,0.904,0.918,0.912,0.810","The table summarizes the performance of the five different models in terms of accuracy, F1-score, AUC-ROC, and AUC-PR. All of the models have been trained and tested on the same dataset. Interestingly, the Gradient Boosting model has achieved the highest performance across all evaluation metrics, achieving the highest accuracy, the highest F1-score, and the highest AUC-ROC and AUC-PR scores. The Random Forest model has also achieved high performance across all evaluation metrics. Meanwhile, the Logistical Regression model has the lowest performance across all evaluation metrics. These results demonstrate that utilizing different models, even on the same dataset, can yield significantly different performances."
2774,"caption: Comparison of different classifiers' performance on binary classification task.table: Models,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.84,0.88,0.72,0.79, Support Vector Machine,0.87,0.89,0.79,0.82, Decision Tree,0.73,0.68,0.76,0.71, Random Forest,0.93,0.95,0.89,0.92, AdaBoost Classifier,0.79,0.75,0.84,0.79, Gradient Boosting Classifier,0.94,0.94,0.92,0.93","The table showcases the evaluation metrics of six classifiers, namely Logistic Regression, SVM, Decision Tree, Random Forest, AdaBoost, and Gradient Boosting Classifier, on a binary classification task. The evaluation metrics such as Accuracy, Precision, Recall, and F1 Score are computed utilizing a test dataset. Interestingly, Random Forest and Gradient Boosting Classifier show the best accuracy of 0.93 and 0.94, respectively. Moreover, Gradient Boosting Classifier demonstrates superior performance with the highest precision, recall, and F1 Score. In contrast, Decision Tree classifier exhibits a low accuracy score of 0.73 and the lowest F1 Score of 0.71."
2775,"caption: Classification performance results of different machine learning models.table: Model,Accuracy,F1-score,Precision,Recall, Logistic regression,0.85,0.86,0.87,0.85, Random forest,0.92,0.92,0.93,0.92, Support Vector Machine,0.87,0.88,0.87,0.87, Multilayer perceptron,0.91,0.90,0.91,0.92, Gradient Boosting,0.93,0.93,0.94,0.93","The table presents the classification performance results of five different machine learning models - Logistic regression, Random forest, Support Vector Machine, Multilayer perceptron, and Gradient Boosting - based on various evaluation metrics. The evaluation metrics included in the table are Accuracy, F1-score, Precision, and Recall. From the table, it is evident that Random forest and Gradient Boosting models achieved the highest accuracy scores of 0.92 and 0.93, respectively. Meanwhile, Multilayer perceptron has the highest recall score of 0.92. Furthermore, Gradient Boosting has outperformed other models in terms of precision and F1-score, having achieved a score of 0.94 and 0.93, respectively."
2776,"caption: Table 4: Performance comparison of different models using multiple evaluation metrics.table: Model,Precision,Recall,F1 Score,Accuracy, Logistic Regression,0.85,0.91,0.88,0.89, Random Forest,0.92,0.89,0.91,0.91, Support Vector Machines (SVM),0.87,0.92,0.89,0.90, Naive Bayes,0.81,0.88,0.84,0.85, Decision Tree,0.86,0.84,0.85,0.86","Table 4 presents a performance comparison of five different models for a binary classification task based on multiple evaluation metrics. The evaluated models and their respective evaluation metrics are Logistic Regression (Precision, Recall, F1 Score, and Accuracy), Random Forest (Precision, Recall, F1 Score, and Accuracy), Support Vector Machines (SVM) (Precision, Recall, F1 Score, and Accuracy), Naive Bayes (Precision, Recall, F1 Score, and Accuracy), and Decision Tree (Precision, Recall, F1 Score, and Accuracy). Based on the results, Random Forest obtained the best Precision, F1 score, and Accuracy scores, while SVM model achieved the best recall score."
2777,"caption: Table 4: Model performances based on different evaluation metricstable: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.82,0.76,0.83,0.79, Decision Tree,0.78,0.65,0.74,0.69, Random Forest,0.84,0.79,0.86,0.82, Support Vector Machine,0.81,0.75,0.80,0.77, Multilayer Perceptron,0.80,0.74,0.79,0.76","Table 4 presents a comparison of five classification models based on different evaluation metrics. The table displays the performance results, including accuracy, precision, recall, and F1 score, achieved by the Logistic Regression, Decision Tree, Random Forest, Support Vector Machine, and Multilayer Perceptron models. The Random Forest model obtained the highest accuracy score of 0.84. In contrast, the model with the best precision, recall, and F1 Score was the Support Vector Machine with scores of 0.75, 0.80, and 0.77, respectively. Interestingly, the Decision Tree model showed relatively low precision but achieved better recall and F1 score than Logistic Regression and Multilayer Perceptron. The results suggest that choosing the best model depends on the evaluation metric used."
2778,"caption: Performance comparison of different classification models.table: Model,Accuracy,Precision,Recall,F1 Score, SVM,0.899,0.908,0.886,0.897, Decision Tree 1,0.743,0.745,0.738,0.728, Decision Tree 2,0.812,0.825,0.802,0.807, Random Forest,0.925,0.930,0.921,0.924, XGBoost,0.934,0.941,0.931,0.933","Table illustrates the accuracy, precision, recall score and the F1 score of SVM, Decision Tree 1, Decision Tree 2, Random Forest, and XGBoost models. The results show that XGBoost model outperforms all other models with the highest accuracy score of 0.934, with a precision score of 0.941, recall score of 0.931, and F1 score of 0.933. The second-best model is Random Forest with an accuracy score of 0.925 and F1 score of 0.924. SVM and Decision Tree 2 models had also competitive results. Interestingly, Decision Tree 1 showed the lowest results across all the metrics, indicating a poor performance."
2779,"caption: Model performance using various evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.852,0.857,0.819,0.837, Decision Tree,0.812,0.794,0.814,0.802, Random Forest,0.896,0.910,0.881,0.888, Naive Bayes,0.773,0.775,0.758,0.764","The table demonstrates the performance evaluation of various models using different metrics such as accuracy, precision, recall, and F1-score. The models included are Logistic Regression, Decision Tree, Random Forest, and Naive Bayes. The highest overall accuracy score was achieved by the Random Forest model with a score of 0.896. Moreover, the Random Forest model also outperformed other models with the best precision score of 0.910, followed closely by the Logistic Regression model. However, the Decision Tree model received the highest recall score of 0.814, while the Logistic Regression model achieved the highest F1-Score of 0.837."
2780,"caption: Table 4: Model performance comparison using varied evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.93,0.94,0.95,0.96, Logistic Regression,0.88,0.89,0.91,0.87, Neural Network,0.89,0.93,0.90,0.96, Random Forest,0.92,0.93,0.94,0.96, Naive Bayes,0.79,0.81,0.77,0.92","Table 4 presents a comparison of five different models: SVM, Logistic Regression, Neural Network, Random Forest, and Naive Bayes. The models evaluated based on different evaluation metrics such as Accuracy, F1-Score, Precision, and Recall. It is interesting to note that the SVM model achieves the highest accuracy of 0.93 and F1-Score of 0.94. However, the Neural Network performs the best in terms of F1-Score and Recall, with scores of 0.93 and 0.96, respectively. The Logistic Regression and Random Forest models also display promising results, with accuracy scores of 0.88 and 0.92, respectively. The Naive Bayes model, although showing lower performance, performs the best in terms of Recall, scoring 0.92."
2781,"caption: Table 4: Model evaluation metrics based on different classifiers.table: Model,Metric,Result, Logistic Regression,Accuracy,0.78, F1 Score,0.83, Precision,0.86, Recall,0.80, SVM,Accuracy,0.81, F1 Score,0.84, Precision,0.89, Recall,0.80, Random Forest,Accuracy,0.85, F1 Score,0.88, Precision,0.87, Recall,0.89, Gradient Boosting,Accuracy,0.86, F1 Score,0.89, Precision,0.88, Recall,0.90","Table 4 presents the comparative performance of four different classifiers, namely Logistic Regression, SVM, Random Forest, and Gradient Boosting based on different evaluation metrics. The evaluation metrics include Accuracy, F1 Score, Precision, and Recall. From the table, it can be observed that Gradient Boosting has the highest accuracy, F1 Score, precision, and recall among all the models, followed by Random Forest. Interestingly, the Logistic Regression and the SVM models have identical accuracy and recall metrics of 0.78 and 0.80, respectively. The Random Forest model has the highest precision metrics of 0.87, while the SVM model showed the highest precision of 0.89. Overall, the Gradient Boosting classifier appears to outperform others, having the highest mean scores across all evaluation metrics."
2782,"caption: Table 4: Model Evaluation Metrics of Five Different Models.table: Model,Accuracy,F1-score,Precision,Recall, Logistic Regression,0.85,0.77,0.82,0.73, Random Forest,0.87,0.80,0.85,0.76, Support Vector Machine,0.82,0.73,0.80,0.68, Naive Bayes,0.79,0.69,0.76,0.63, Neural Network,0.88,0.81,0.86,0.77","Table 4 presents model evaluation metrics of five different models, including Logistic Regression, Random Forest, Support Vector Machine, Naive Bayes, and Neural Network. The metrics evaluated include accuracy, F1-score, precision, and recall. The results show that the Neural Network had the best accuracy score of 0.88, while the Random Forest model had the best F1-score of 0.80. The precision score was highest for the Logistic Regression model at 0.82, and the Random Forest model had the best recall score of 0.76. Overall, the table shows varying performance results across different evaluation metrics and models."
2783,"caption: Table 4: Model performance for different evaluation metrics.table: Model,Accuracy,F1 Score,Recall,Precision, Logistic Regression,0.83,0.83,0.84,0.84, K Nearest Neighbors,0.80,0.79,0.77,0.84, Decision Tree,0.77,0.74,0.76,0.76, Random Forest,0.85,0.85,0.86,0.85, XGBoost,0.88,0.88,0.88,0.89","Table 4 compares the model performance for different evaluation metrics such as accuracy, F1 score, recall, and precision. The table consists of five different models including Logistic Regression, K Nearest Neighbors, Decision Tree, Random Forest, and XGBoost. The best-performing model varies according to the evaluation metrics. The XGBoost model showcases the best classification performance with the highest accuracy (0.88), F1 score (0.88), recall (0.88), and precision (0.89), while the Logistic Regression model illustrates the second-best classification performance. The Decision Tree model shows the least classification performance by all evaluation metrics."
2784,"caption: Evaluation metrics for different models over a binary classification task.table: Model,Accuracy,F1-Score,Precision,Recall,Specificity, LR,0.88,0.88,0.85,0.92,0.82, SVM,0.89,0.88,0.88,0.89,0.90, RF,0.93,0.93,0.92,0.93,0.93, XGB,0.92,0.92,0.91,0.92,0.92, MLP,0.90,0.90,0.87,0.94,0.83","The table above summarizes the performance of different models over a binary classification task based on various evaluation metrics. The evaluation metrics in the table include accuracy, F1-score, precision, recall, and specificity. The models considered are Logistic Regression (LR), Support Vector Machine (SVM), Random Forest (RF), Extreme Gradient Boost (XGB), and Multilayer Perceptron (MLP). Notably, the Random Forest model shows the best results in all performance metrics, achieving the highest accuracy, F1-score, precision, recall and specificity, matching its sole purpose of providing high performance consistently. The MLP model provides a good recall score of 0.94, highlighting its capability of successful prediction of true positives. Additionally, the SVM and XGB models show competitive performance across all evaluation metrics."
2785,"caption: Model performance comparison using different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.79,0.75,0.83,0.79, Random Forest,0.85,0.82,0.89,0.85, K-Nearest Neighbor,0.73,0.66,0.81,0.73, Support Vector Machine (SVM),0.87,0.85,0.89,0.87, Gradient Boosting Decision Tree,0.88,0.87,0.89,0.88","The table presents a comparison of five different models based on their accuracy, precision, recall, and F1-score. The models are Logistic Regression, Random Forest, K-Nearest Neighbor, Support Vector Machine (SVM), and Gradient Boosting Decision Tree. The evaluation metrics measure the models' performance in terms of correctly predicted instances, true positives, false positives, and false negatives in a binary classification task. The Gradient Boosting Decision Tree exhibits the best overall performance, scoring the highest in all evaluation metrics, with an F1-score of 0.88. The SVM and Random Forest models also display strong performances, with accuracy scores of 0.87 and 0.85, respectively."
2786,"caption: Table 4: Model performances based on multiple evaluation metricstable: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.78,0.75,0.81,0.78, Random Forest,0.82,0.80,0.84,0.82, MLP,0.79,0.77,0.83,0.80, KNN,0.75,0.71,0.80,0.75, Naïve Bayes,0.81,0.82,0.75,0.78","Table 4 displays several machine learning models with their performance evaluation metrics. The models include SVM, Random Forest, MLP, KNN, and Naïve Bayes. The evaluation metrics include accuracy, precision, recall, and F1-Score. The best performance is achieved by Random Forest with accuracy of 0.82, precision of 0.80, recall of 0.84, and F1-Score of 0.82. Surprisingly, Naïve Bayes achieved better precision than all other models, but its recall is by far the lowest. While KNN has the low F1-Score, SVM has the lowest recall. Therefore, this table provides a comprehensive analysis of the performance of different models using multiple evaluation metrics."
2787,"caption: Model performance on the test set based on various evaluation metrics.table: Model,Accuracy,F1 score,Precision,Recall, Model A,0.85,0.78,0.84,0.73, Model B,0.91,0.86,0.89,0.83, Model C,0.72,0.58,0.63,0.54, Model D,0.93,0.89,0.92,0.86, Model E,0.87,0.82,0.85,0.81, Model F,0.69,0.53,0.61,0.49","The table displays the accuracy, F1 score, precision, and recall of six different models on the test set. Notably, Model D attained the highest accuracy of 0.93, and F1 score of 0.89, and precision of 0.92. On the other hand, Model C's performance was the least with an accuracy of 0.72, F1 score of 0.58, precision of 0.63, and recall of 0.54. Although Model B also performed well with accuracy of 0.91, F1 score of 0.86, precision of 0.89, and recall of 0.83, Model A, and E's performance results were also quite impressive. Model A attained an accuracy of 0.85, F1 score of 0.78, precision 0.84, and recall 0.73, whereas Model E achieved an accuracy of 0.87, F1 score of 0.82, precision of 0.85, and recall of 0.81."
2788,"caption: Performance summary of different models based on accuracy, F1-score, precision, and recall metrics.table: Model,Accuracy,F1-Score,Precision,Recall, Model 1,0.75,0.70,0.68,0.72, Model 2,0.80,0.78,0.75,0.80, Model 3,0.82,0.80,0.79,0.81, Model 4,0.84,0.82,0.81,0.83, Model 5,0.85,0.84,0.83,0.84","The table shows the comparison of multiple models based on their accuracy, F1-score, precision, and recall metrics. Five different models are evaluated, and each model has unique performance scores for each evaluation metric. Model 5 has the best performance in all four evaluation metrics, with an accuracy of 0.85, F1-score of 0.84, precision of 0.83, and recall of 0.84. Interestingly, model 4 ranked second with slight differences in all metrics. This table highlights the importance of reporting multiple evaluation metrics while comparing different models."
2789,"caption: Performance of different models with multiple evaluation metrics.table: Model name,Accuracy,F1 Score,Precision,Recall,AUC, SVM,0.87,0.85,0.84,0.87,0.93, Random Forest,0.92,0.90,0.91,0.92,0.94, KNN,0.85,0.83,0.82,0.85,0.90, Naive Bayes,0.76,0.73,0.75,0.76,0.80","Table demonstrates a comparison of multiple models' performances using evaluation metrics such as Accuracy, F1-Score, Precision, Recall, and AUC. Here, SVM, Random Forest, KNN, and Naive Bayes models were evaluated based on these criteria. As demonstrated, the Random Forest model delivered the best performance with the highest Accuracy (0.92), F1-Score (0.90), Precision (0.91), Recall (0.92), and AUC (0.94). In contrast, Naive Bayes delivered the worst performance in all evaluation metrics with the lowest Accuracy (0.76), F1-Score (0.73), Precision (0.75), Recall (0.76), and AUC (0.80). Interestingly, KNN had the same Accuracy and Recall as SVM, but SVM showed slightly better results in all the other evaluation metrics."
2790,"caption: Comparison of the performance of different models based on Accuracy, F1 Score, and Cohens Kappa.table: Model,Accuracy,F1 Score,Cohens Kappa, Model A,0.85,0.80,0.65, Model B,0.76,0.68,0.53, Model C,0.92,0.89,0.80, Model D,0.95,0.93,0.88, Model E,0.81,0.76,0.59",
2791,"caption: Table 4: Performance Metrics of Different Modelstable: Model,Accuracy,F1-score,Precision,Recall, SVM,0.82,0.81,0.81,0.82, KNN,0.81,0.79,0.78,0.81, RF,0.85,0.84,0.83,0.85, XGB,0.83,0.82,0.81,0.83, MLP,0.84,0.83,0.82,0.84","Table 4 presents an evaluation of different models using multiple performance metrics, including accuracy, F1-score, precision, and recall. The table illustrates the performance of SVM, KNN, RF, XGB, and MLP models. Notably, the RF model presents the best performance in terms of accuracy, F1-score, precision, and recall, achieving results of 0.85, 0.84, 0.83, and 0.85, respectively. The MLP model also shows competitive performance with an accuracy of 0.84 and respective metrics of 0.83, 0.82, and 0.84 for F1-score, precision, and recall metrics. On the other hand, the KNN model presents the least performance among other models, achieving an accuracy of 0.81 and F1-score, precision, and recall results of 0.79, 0.78, and 0.81, respectively."
2792,"caption: Comparison of different models based on evaluation metricstable: Model,Precision,Recall,F1 Score,AUC Score, Model 1,0.85,0.90,0.87,0.92, Model 2,0.89,0.85,0.87,0.94, Model 3,0.81,0.91,0.85,0.91, Model 4,0.90,0.86,0.88,0.94, Model 5,0.86,0.88,0.87,0.93","Table compares the performance of different models in terms of precision, recall, F1 score, and AUC score. The table exhibits five models' (Model 1 to Model 5) evaluation metrics. It is observed that Model 4 shows the highest precision score of 0.90 and recall score of 0.86. Conversely, the highest F1 score is obtained with Model 2, which achieves a score of 0.87. It is worth noting that Model 2 also obtains the highest AUC score of 0.94. Meanwhile, Model 3 shows the lowest precision score, whereas Model 1 has showcased the lowest recall score. Overall, the table shows a clear variation between models that can help researchers make an informed decision about which model to use for their study."
2793,"caption: Table 1: Model Evaluation Metricstable: Models,Accuracy,Precision,Recall,F1 Score,AUC Score, Logistic Regression,0.874,0.753,0.787,0.767,0.843, Random Forest,0.906,0.814,0.842,0.828,0.919, XGBoost,0.902,0.803,0.835,0.818,0.914, Naive Bayes,0.834,0.689,0.735,0.705,0.798, Support Vector,0.898,0.798,0.821,0.809,0.907","Table 1 shows a comparison of five models measured by various evaluation metrics on a particular dataset. These models include Logistic Regression, Random Forest, XGBoost, Naive Bayes, and Support Vector. The evaluation metrics used were Accuracy, Precision, Recall, F1 Score, and AUC Score. Notably, the Random Forest model had the best performance on all the evaluation metrics, achieving the highest Accuracy (0.906), Precision (0.814), Recall (0.842), F1 Score (0.828), and AUC Score (0.919) among the models. In contrast, the Naive Bayes model had the lowest performance compared to other models, achieving an accuracy score of 0.834 and the least value for the other four evaluation metrics."
2794,"caption: Model Performance Comparison on Different Evaluation Metrics.table: Model,F1-Score,MCC,Brier score, SVM,0.75,0.51,0.178, Logistic regression,0.78,0.54,0.157, Decision tree,0.63,0.38,0.210, Random Forest,0.84,0.68,0.108, XGBoost,0.86,0.71,0.101","The table presents the performance comparison of different models based on multiple evaluation metrics—the models include SVM, Logistic Regression, Decision tree, Random Forest, and XGBoost. The evaluation metrics for comparison include F1-Score, MCC, and Brier Score. The results displayed in the table indicates that the XGBoost outperformed other models, achieving the best results for all the metrics used. Random Forest performed well, too with substantial scores. However, SVM, Logistic Regression, and Decision tree models didn't perform as well as expected. The table shows that the performance of models can vary depending on the evaluation metric used."
2795,"caption: Performance comparison of different models using multiple evaluation metrics.table: Model,Accuracy,F1-Score,Recall,Precision, Logistic Regression,0.78,0.75,0.70,0.81, SVM,0.82,0.79,0.75,0.84, Random Forest,0.88,0.87,0.84,0.91, XGBoost,0.89,0.88,0.86,0.90, Neural Network,0.86,0.85,0.81,0.89","The table compares the performance of five different models based on four evaluation metrics: Accuracy, F1-Score, Recall, and Precision. The models evaluated were Logistic Regression, SVM, Random Forest, XGBoost, and Neural Network. The Random Forest and XGBoost models stand out with the highest accuracy result of 0.88 and 0.89, respectively. However, The Neural Network model has the highest precision result of 0.89, whereas SVM has the highest recall of 0.75. Interestingly, the XGBoost has the most consistent performance across all four evaluation metrics, indicating its suitability for the task at hand."
2796,"caption: Table 4: Comparison of classification model performances using multiple evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall,AUC, LogisticRegression,0.89,0.91,0.89,0.95,0.968, DecisionTree,0.79,0.80,0.78,0.83,0.822, SVM,0.92,0.94,0.93,0.96,0.981, NaiveBayes,0.85,0.86,0.84,0.91,0.912, Random Forest,0.93,0.94,0.95,0.94,0.983","Table 4 compares different classification models' performances using multiple evaluation metrics, including Accuracy, F1-Score, Precision, Recall, and AUC. The table displays the results for Logistic Regression, Decision Tree, Support Vector Machine (SVM), Naive Bayes, and Random Forest. The Random Forest model achieves the highest Accuracy and F1-Score of 0.93 and 0.94, respectively, and outperforms the other models in terms of Precision, Recall, and AUC, with scores of 0.95, 0.94, and 0.983, respectively. SVM also performs well in all metrics, except Precision, achieving scores of 0.92, 0.94, 0.93, 0.96, and 0.981 in Accuracy, F1-Score, Precision, Recall, and AUC, respectively. The Decision Tree model had the lowest scores in all metrics, except for Recall, with a score of 0.83."
2797,"caption: Table 4: Performance comparison of multiple models based on various evaluation metrics.table: Model,Accuracy,F1-score,Precision,Recall, SVM,0.928,0.935,0.941,0.929, Random Forest,0.918,0.931,0.941,0.921, K-Nearest Neighbor,0.88,0.891,0.912,0.879, Multinomial Naive Bayes,0.89,0.906,0.919,0.89","The table presents a performance comparison of four models based on different evaluation metrics. The evaluation metrics included accuracy, F1-Score, precision, and recall. The SVM model achieved the highest accuracy and F1-score with a score of 0.928 and 0.935, respectively. Meanwhile, Random Forest yielded the second-highest accuracy of 0.918 and F1-score of 0.931. However, in terms of precision, SVM and Random Forest models performed similarly with a score of 0.941, while K-Nearest Neighbor obtained the lowest precision score (0.912). Finally, overall, the SVM model outperformed all the other models for the evaluation metrics presented in the table."
2798,"caption: Model performance comparison based on F1-score, Accuracy, Precision and Recall scores.table: Model,F1-score,Accuracy,Precision,Recall, SVM,0.85,0.83,0.88,0.82, KNN,0.79,0.80,0.83,0.76, Naive Bayes,0.71,0.72,0.79,0.66, Random Forest,0.91,0.89,0.92,0.89, XGBoost,0.92,0.91,0.93,0.91","The table summarizes the performance metrics of SVM, KNN, Naive Bayes, Random Forest, and XGBoost models. The models were trained and tested using the same dataset. The evaluation metrics are F1-score, Accuracy, Precision, and Recall. Notably, the Random Forest and XGBoost models demonstrate the highest F1-score values, with 0.91 and 0.92, respectively. The Random Forest model shows the highest accuracy, precision, and recall scores than the other models. The SVM model manifests better performance than KNN and Naive Bayes based on all metrics. Overall, the Random Forest and XGBoost models could be the potential choices for further optimization due to their superior performance in multiple metrics."
2799,"caption: Performance of different models based on multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, Model 1,0.907,0.891,0.897,0.894, Model 2,0.916,0.904,0.902,0.903, Model 3,0.892,0.879,0.882,0.880, Model 4,0.912,0.897,0.899,0.898, Model 5,0.905,0.897,0.893,0.895","The presented table compares the performance of five different models on multiple evaluation metrics. The models' accuracy, precision, recall, and F1-score are shown. The results indicate that Model 2 achieved the best performance across all metrics, with an accuracy of 0.916, precision of 0.904, recall of 0.902, and F1-score of 0.903. However, Model 4 and Model 1 also performed well, with an F1-score of 0.898 and 0.894, respectively. Interestingly, although Model 5 achieved the lowest accuracy of 0.905, it had the highest precision score of 0.897."
2800,"caption: Table 4: Model performances in terms of Accuracy, Precision, Recall, and F1-score.table: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.85,0.85,0.83,0.84, Random Forest,0.92,0.93,0.91,0.92, Gradient Boosted Trees,0.90,0.91,0.90,0.90, Support Vector Machines,0.89,0.88,0.91,0.89","Table 4 shows the model performances' evaluation metrics, including Accuracy, Precision, Recall, and F1-score. Different machine learning models were trained and tested on the same dataset: Logistic Regression, Random Forest, Gradient Boosted Trees, and Support Vector Machines. Random Forest achieved the highest accuracy score of 0.92, followed by Gradient Boosted Trees with 0.90. For Precision and Recall, Random Forest outperformed all models with scores of 0.93 and 0.91, respectively. However, for F1-score, Logistic Regression achieved the highest score of 0.84, followed closely by Random Forest at 0.92. Support Vector Machines had a good recall score of 0.91, but its precision score was relatively lower than the other models, resulting in a lower F1-Score of 0.89."
2801,"caption: Performance of different classification models on the test dataset.table: Model,Accuracy,F1 Score,Precision,Recall, Model 1,84.1%,0.78,0.82,0.76, Model 2,86.7%,0.86,0.85,0.87, Model 3,81.2%,0.74,0.79,0.72, Model 4,88.6%,0.89,0.88,0.90, Model 5,84.9%,0.83,0.84,0.82","The table compares five different classification models' performance on a test dataset using various evaluation metrics such as accuracy, F1 score, precision, and recall. Model 2 shows the highest accuracy of 86.7% and F1 score of 0.86. Model 4 exhibits the highest precision and recall scores with 0.88 and 0.90, respectively. Interestingly, Model 3 with the lowest accuracy score of 81.2% could still achieve a relatively good F1 score of 0.74. This table provides valuable information for selecting the models that best fit specific project goals and requirements."
2802,"caption: Performance comparison of several machine learning modelstable: Model name,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.83,0.85,0.76,0.80, Random Forest,0.92,0.93,0.88,0.90, K-Nearest Neighbor,0.81,0.84,0.71,0.77, Decision Trees,0.87,0.89,0.82,0.85, Gradient Boosting,0.93,0.93,0.89,0.91","The table exhibits the performance comparison of various machine learning models based on four evaluation metrics: accuracy, precision, recall, and F1-score. The Logistic Regression model attained an accuracy of 0.83 and outperformed other models with a precision score of 0.85. In contrast, the Gradient Boosting model recorded the highest accuracy of 0.93 and attained the same precision score of 0.93 with the Random Forest model. The K-Nearest Neighbor model recorded the lowest performance on all evaluation metrics, with an accuracy of 0.81 and an F1-score of 0.77. Overall, the table provides insights into the strengths and weaknesses of each model based on each metric, which could guide the selection of models for specific applications."
2803,"caption: Comparison of different classification models based on multiple evaluation metrics.table: Model,Precision,Recall,F1-Score,Accuracy, Logistic Regression,0.88,0.89,0.879,0.884, Decision Tree,0.67,0.55,0.549,0.672, Naive Bayes,0.83,0.90,0.856,0.857, SVM,0.86,0.92,0.873,0.876","The table displays a comparison of four different classification models based on different evaluation metrics such as Precision, Recall, F1-Score and Accuracy. The models displayed in this table are Logistic Regression, Decision Tree, Naive Bayes and Support Vector Machines (SVM). The table shows the precision, recall, F1-score, and accuracy for each model. The precision and recall for the Naive Bayes model are the highest with scores of 0.83 and 0.90, respectively. The highest accuracy is achieved by SVM with a score of 0.876. In contrast, the Decision Tree model was underperforming in all aspects as compared to other models."
2804,"caption: Performance Results of Different Models with Multiple Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.89,0.91,0.85,0.87, Random Forest,0.92,0.90,0.91,0.91, Decision Tree,0.82,0.80,0.87,0.83, Support Vector Machine,0.91,0.92,0.89,0.90, Naive Bayes,0.86,0.90,0.82,0.84","Table 1 shows the performance results of five different models, namely Logistic Regression, Random Forest, Decision Tree, Support Vector Machine and Naive Bayes, using multiple evaluation metrics such as Accuracy, Precision, Recall and F1 Score. Among the models, Random Forest showed the highest overall performance with an accuracy of 0.92 and an F1 score of 0.91. Support Vector Machine showed the highest precision value of 0.92, while Logistic Regression had the highest recall value of 0.85. Interestingly, Decision Tree had the lowest accuracy of 0.82, but the highest recall of 0.87. Overall, the results suggest that Random Forest and Support Vector Machine have the best overall performance along with high precision and recall scores."
2805,"caption: Performance metrics of different modelstable: Model,Accuracy,Precision,Recall,F1-Score, Model 1,90%,0.89,0.92,0.91, Model 2,87%,0.84,0.91,0.87, Model 3,89%,0.91,0.88,0.89, Model 4,91%,0.93,0.89,0.91, Model 5,92%,0.91,0.93,0.92, Model 6,88%,0.85,0.90,0.87, Model 7,93%,0.94,0.92,0.93","Table presents the performance of seven different models based on different evaluation metrics including Accuracy, Precision, Recall, and F1-Score. Notably, Model 7 achieved the highest accuracy score of 93% and the best metrics result, with a Precision of 0.94, Recall of 0.92, and F1-score of 0.93. Conversely, Model 2 and Model 6 showed the lowest accuracy scores of 87% and 88%, respectively. Overall, the table indicates that different models perform differently based on various performance metrics and Model 7 appears to be the best performing model according to the metrics evaluated."
2806,"caption: Performance comparison of different models using standard evaluation metrics like Accuracy, F1 Score, Recall, and Precision.table: Model,Accuracy,F1 Score,Recall,Precision, Model A,0.80,0.75,0.70,0.81, Model B,0.78,0.68,0.75,0.61, Model C,0.84,0.80,0.72,0.92, Model D,0.82,0.77,0.80,0.74, Model E,0.91,0.88,0.90,0.89","The table compares the performance of five different models on a classification task using standard evaluation metrics such as Accuracy, F1 Score, Recall, and Precision. Model E showed the highest accuracy of 0.91, while Model A achieved the highest precision of 0.81. Model C had the highest F1 Score of 0.80 and Model E also showed the highest recall of 0.90. It is interesting to note that although Model D had a relatively high accuracy of 0.82, its F1 Score was lower than Models C and E, indicating that it was not equally effective in identifying both classes."
2807,"caption: Performance comparison of different models based on various evaluation metricstable: Model,Accuracy,F1-Score,Precision,Recall,AUC, LogReg,0.83,0.81,0.86,0.77,0.905, SVM,0.82,0.8,0.85,0.76,0.901, KNN,0.70,0.68,0.74,0.63,0.769, RF,0.86,0.85,0.89,0.81,0.936, XGB,0.88,0.87,0.91,0.84,0.943","The table presents a comparison of different machine learning models' performance based on multiple evaluation metrics. The models were evaluated using accuracy, F1-score, precision, recall, and the area under the ROC curve (AUC). The LogReg model showed the highest accuracy of 0.83, while the XGB model showed the highest accuracy of 0.88. Similarly, the Random Forest (RF) and XGB models showed the highest F1-score of 0.85 and 0.87, respectively. Interestingly, RF and XGB models showed similar performance scores in all evaluation metrics, except precision, with XGB outperforming RF. Conversely, KNN has the weakest performance scores among all models, indicating it is the least optimal model for this classification problem."
2808,"caption: Table 4: Performance results of different models based on multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.856,0.882,0.833,0.857, Random Forest,0.876,0.897,0.854,0.875, Multilayer Perceptron,0.861,0.869,0.888,0.878, Logistic Regression,0.850,0.862,0.870,0.863","Table 4 presents a comparison of the performance results for four different classification models, including SVM, Random Forest, Multilayer Perceptron, and Logistic Regression. The table displays the evaluation metrics, including Accuracy, Precision, Recall, and F1-score for each model. Results indicate that the Random Forest model achieved the best Accuracy score of 0.876, while the Multilayer Perceptron achieved the highest F1-score of 0.878. Interestingly, the SVM model scored the highest Precision score of 0.882, and the Multilayer Perceptron scored the highest Recall score of 0.888. These findings suggest that different models perform differently based on the evaluation metrics used."
2809,"caption: Table 4: Model Performance Comparison Using Multiple Evaluation Metricstable: Model,PR-AUC,F1-score,Accuracy, Model 1,0.853,0.743,0.899, Model 2,0.908,0.758,0.894, Model 3,0.911,0.786,0.909, Model 4,0.824,0.652,0.875, Model 5,0.832,0.671,0.886","Table 4 compares multiple models' performance using PR-AUC, F1-score, and accuracy metrics. The table shows that Model 3 performs the best with the highest PR-AUC score of 0.911, F1-score of 0.786, and an accuracy of 0.909. Model 2 also shows excellent performance with a PR-AUC score of 0.908 and F1-score of 0.758, although its accuracy score of 0.894 is slightly lower than Model 1 with 0.899 accuracy result. Model 4 and Model 5 did not perform as well as the other models with PR-AUC scores of 0.824 and 0.832, respectively, although their F1-scores and accuracy were relatively high at 0.652 and 0.671, and 0.875 and 0.886."
2810,"caption: Table 4: Performance metrics of different machine learning models.table: Model,F1-score,Accuracy,Precision,Recall, SVM,0.875,0.891,0.901,0.850, Naive Bayes,0.824,0.836,0.806,0.845, Random Forest,0.916,0.925,0.936,0.896, K-NN,0.856,0.865,0.880,0.832","Table 4 presents the evaluation metrics of four different machine learning algorithms for a classification task. The presented metrics include F1-score, Accuracy, Precision, and Recall. The models evaluated include Support Vector Machine (SVM), Naive Bayes, Random Forest, and K-NN. From the table, Random Forest reported the highest F1-score, Accuracy and Precision values of 0.916, 0.925, and 0.936, respectively. SVM and Naive Bayes models, on the other hand, reported lower but strong metrics close to those of Random Forest. It is worth noting that K-NN achieved the lowest metrics but still of high accuracy with an F1-score of 0.856 and accuracy of 0.865."
2811,"caption: Performances of different models with various evaluation metricstable: Models,Accuracy,F1 Score,Precision,Recall, Random Forest,0.91 ± 0.02,0.91 ± 0.02,0.92 ± 0.03,0.90 ± 0.02, Gradient Boosting Classifier,0.89 ± 0.03,0.87 ± 0.04,0.91 ± 0.02,0.83 ± 0.05, Support Vector Machine,0.87 ± 0.03,0.85 ± 0.04,0.88 ± 0.03,0.82 ± 0.05, Neural Network,0.88 ± 0.02,0.87 ± 0.03,0.89 ± 0.03,0.85 ± 0.04","The table above compares the performances of four different models - Random Forest, Gradient Boosting Classifier, Support Vector Machine, and Neural Network, based on three different evaluation metrics - Accuracy, F1 Score, Precision, and Recall. Each model's performance results are presented through mean scores and standard deviations, calculated from ten-fold cross-validation process. Notably, the Random Forest model shows the highest Accuracy, F1 Score, and Precision scores, while the Neural Network model has the highest Recall score. The results indicate that the Random Forest model performs best on the given dataset, while the Neural Network model has a balance between Precision and Recall."
2812,"caption: Comparison of different classification algorithms' performance metrics.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.86,0.90,0.80,0.85, KNN,0.82,0.85,0.75,0.80, Naive Bayes,0.78,0.83,0.65,0.73, Logistic Regression,0.84,0.89,0.78,0.83, Neural Network,0.88,0.93,0.85,0.89","The table presents the evaluation metrics of different classification algorithms, including SVM, KNN, Naive Bayes, Logistic Regression, and Neural Network. These models' performance was evaluated based on their accuracy, precision, recall, and F1-score. Interestingly, the neural network model outperforms all other models in accuracy, precision, and F1-score. The SVM model achieved the highest recall score of 0.80, but it is not the best performing model concerning other metrics. Overall, the table reveals that the neural network model had the highest overall performance amongst all of the models, while the Naive Bayes model had the lowest overall performance."
2813,"caption: Comparison of five machine learning models based on their performance using different evaluation metrics.table: Model,F1-score,Precision,Recall,Accuracy, Logistic Regression,0.86,0.82,0.90,0.85, Support Vector Machines,0.88,0.86,0.91,0.87, Naive Bayes,0.76,0.70,0.84,0.75, Random Forest,0.90,0.87,0.94,0.89, Gradient Boosting,0.92,0.89,0.95,0.91",
2814,"caption: Performance evaluation of different models based on multiple metrics.table: Model,Accuracy,F1 Score,Precision,Recall, Model 1,0.87,0.83,0.85,0.81, Model 2,0.82,0.79,0.74,0.85, Model 3,0.90,0.86,0.89,0.83, Model 4,0.88,0.84,0.86,0.82","The table presents the performance evaluation of four different models using multiple evaluation metrics, including accuracy, F1 score, precision, and recall. Model 1 achieved the highest accuracy of 0.87, followed by Model 4 with an accuracy of 0.88. In terms of F1 score, Model 3 showed the highest score of 0.86. However, Model 4 had the highest precision of 0.86, and Model 1 had the highest recall of 0.81. Overall, the results suggest that each model has its own strengths and weaknesses based on the evaluation metrics used."
2815,"caption: Table 4: Evaluation metrics of different models.table: Model,Accuracy,Precision,Recall,F1, Model A,0.80,0.75,0.85,0.79, Model B,0.82,0.79,0.84,0.81, Model C,0.75,0.73,0.77,0.72, Model D,0.85,0.84,0.86,0.83, Model E,0.87,0.85,0.90,0.86","Table 4 compares the performance of different models using various evaluation metrics, including accuracy, precision, recall, and F1. The table presents five models, namely Model A, Model B, Model C, Model D, and Model E. Notably, Model E shows the highest accuracy of 0.87, while Model C exhibits the lowest of 0.75. However, Model D achieves the highest precision of 0.84, whereas Model A has the lowest precision of 0.75. Meanwhile, Model E has the highest recall and F1 scores of 0.90 and 0.86, respectively. Overall, the table provides an in-depth comparison of different models' performances using different evaluation metrics."
2816,"caption: Performance comparison of different classification models on the customer churn dataset.table: Model Name,F1 Score (Macro),Precision Score (Macro),Recall Score (Macro),Accuracy Score, SVM,0.723,0.695,0.747,0.802, Logistic Reg.,0.717,0.699,0.731,0.798, Decision Tree,0.671,0.654,0.707,0.745, Random Forest,0.749,0.729,0.787,0.828, Naive Bayes,0.625,0.575,0.719,0.705","The table presents a comparison of five different classification models based on multiple evaluation metrics. The evaluation metrics used in this study include F1 Score (Macro), Precision Score (Macro), Recall Score (Macro), and Accuracy Score. The models include SVM, Logistic Regression, Decision Tree, Random Forest, and Naive Bayes. The Random Forest model shows the highest performance on the metrics and accuracy score, with an F1 score of 0.749, a precision score of 0.729, a recall score of 0.787, and an accuracy score of 0.828. Interestingly, the Naive Bayes model shows the lowest performance, while the Logistic Regression model provides competitive results remarkably close to the SVM model."
2817,"caption: Model performances based on different evaluation metrics.table: Models,Accuracy,F1-Score,Precision,Recall, Model 1,0.89,0.87,0.90,0.85, Model 2,0.91,0.92,0.93,0.90, Model 3,0.83,0.80,0.86,0.75, Model 4,0.95,0.96,0.95,0.97, Model 5,0.92,0.91,0.93,0.90",
2818,"caption: Model Performance based on different evaluation metrics.table: Model Name,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.76,0.81,0.65,0.72, K-Nearest Neighbors,0.69,0.71,0.62,0.66, Decision Trees,0.72,0.74,0.60,0.66, Random Forest,0.82,0.87,0.77,0.82, Support Vector Machine,0.71,0.74,0.63,0.68","The table exhibits the performance of five different models, i.e., Logistic Regression, K-Nearest Neighbors, Decision Trees, Random Forest, and Support Vector Machine. The models were evaluated based on four different evaluation metrics: Accuracy, Precision, Recall, and F1-Score. The Random Forest model achieved the highest Accuracy of 0.82 and Precision of 0.87. The Logistic Regression model achieved the highest Recall of 0.65 and F1-Score of 0.72. Interestingly, the table shows that there is no single best-performing model across all the evaluation metrics. This indicates that choosing an appropriate evaluation metric is essential when selecting the model that best fits the task requirement."
2819,"caption: Model performances comparison based on different evaluation metrics.table: Models,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.87,0.84,0.89,0.86, Decision Tree,0.78,0.71,0.85,0.77, Random Forest,0.91,0.89,0.93,0.91, SVM-linear,0.88,0.85,0.91,0.88, SVM-RBF,0.90,0.87,0.92,0.90, KNN,0.82,0.78,0.86,0.81","Table above shows the comparison of different models' performances based on various evaluation metrics, including Accuracy, Precision, Recall, and F1-Score. The models included in the table are Logistic Regression, Decision Tree, Random Forest, SVM-Linear, SVM-RBF, and KNN. Notably, the Random Forest model displayed the highest accuracy of 0.91. The Decision Tree model reported the lowest accuracy of 0.78, whereas the SVM-RBF reported the highest Precision and Recall values of 0.87 and 0.92, respectively. Based on the F1-score, the Random Forest attained the highest score of 0.91."
2820,"caption: Table 4: Performance evaluation with multiple models based on different evaluation metricstable: Model,Accuracy,F1-score,Precision,Recall, Model A,0.82,0.80,0.83,0.77, Model B,0.79,0.74,0.81,0.68, Model C,0.85,0.83,0.84,0.82, Model D,0.80,0.78,0.77,0.80, Model E,0.87,0.85,0.86,0.84","Table 4 exhibits the performance evaluation of five different models based on four different evaluation metrics: Accuracy, F1-score, Precision, and Recall. The models' performance results reveal that Model E has the highest Accuracy score of 0.87, while Model C has the highest F1-score of 0.83, followed closely by Model E of 0.85. Interestingly, Model A shows the highest Precision score of 0.83, while Model C and Model E have the highest Recall score of 0.82 and 0.84, respectively. These results explicitly showcase the differences in model performance, highlighting their strengths and weaknesses based on various evaluation metrics."
2821,"caption: Performance comparison of different models using multiple metrics.table: Model,Accuracy,F1-Score,Precision,Recall, Model 1,0.85,0.81,0.79,0.83, Model 2,0.86,0.79,0.84,0.75, Model 3,0.89,0.86,0.88,0.84, Model 4,0.90,0.87,0.87,0.87","The above table shows the performance comparison of different models based on their accuracy, F1-Score, Precision, and Recall. The table displays four models, where Model 4 shows the highest accuracy of 0.90. Interestingly, Model 4 also has the highest F1-Score and Recall of 0.87 each. On the other hand, Model 3 demonstrated the highest Precision score of 0.88. Overall, the results show that all models have high performance, where Models 3 and 4 showcase better results compared to Models 1 and 2."
2822,"caption: Table 4: Model performance on different evaluation metrics.table: Model,Precision,F1-score,AUC-ROC, SVM,0.89,0.79,0.92, KNN,0.78,0.83,0.88, RF,0.86,0.87,0.91, LR,0.83,0.84,0.90","Table 4 presents the performance of four different machine learning models, SVM, KNN, RF and LR on three different evaluation metrics - precision, F1-score, and AUC-ROC. The best performance was observed for the SVM model in terms of AUC-ROC, which achieved the highest score of 0.92. RF had the highest precision of 0.86, while KNN had the highest F1-score of 0.83. It's interesting to note that even though KNN achieved the highest F1-score, its precision is lower than SVM, RF, and LR. Conversely, RF had a high F1-score and precision, but the AUC-ROC was only 0.91 compared to SVM's 0.92."
2823,"caption: Table 4 presents the performance of five different models on multiple evaluation metrics.table: Model,Accuracy,F1,Precision,Recall,AUC, Model 1,0.94,0.91,0.92,0.89,0.92, Model 2,0.92,0.93,0.91,0.95,0.93, Model 3,0.91,0.87,0.89,0.86,0.90, Model 4,0.95,0.93,0.94,0.96,0.95, Model 5,0.93,0.94,0.92,0.96,0.94","Table 4 showcases five different models' performance based on five different evaluation metrics, including accuracy, F1 score, precision, recall, and AUC. Notably, each model's performance results significantly vary based on the metrics under consideration. Model 4 had the highest accuracy and AUC scores of 0.95 and 0.95, respectively, while Model 2 had the highest F1 score and recall score of 0.93 and 0.95, respectively. Model 2 also had the lowest precision score, while Model 3 had the lowest recall score. The table highlights the importance of selecting appropriate metrics while evaluating model performance."
2824,"caption: The performance of multiple models based on different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score, SVM,0.87,0.89,0.80,0.84, KNN,0.82,0.80,0.82,0.80, Naive Bayes,0.79,0.76,0.83,0.76, Logistic Regression,0.88,0.88,0.86,0.87, Decision Tree,0.76,0.81,0.73,0.76","The table presents the performance of multiple models based on different evaluation metrics, including Accuracy, Precision, Recall, and F1-score. The SVM model achieved the highest Accuracy score of 0.87, whereas the Naive Bayes model demonstrated the lowest accuracy score of 0.79. The Logistic Regression model displayed the best Precision score of 0.88, and the SVM model had the highest Recall of 0.80. On the other hand, the Decision Tree model exhibited the lowest F1-score of 0.76. Overall, the table reveals that each model performs differently based on different evaluation metrics, and therefore, it is essential to select the appropriate models and evaluation metrics based on the research objectives."
2825,"caption: Performance comparison of various models based on different evaluation metrics.table: Models,Precision,Recall,F1-score,Accuracy, Logistic Regression,0.82,0.76,0.78,0.81, Naive Bayes,0.70,0.78,0.74,0.70, Support Vector Machine,0.71,0.75,0.73,0.68, Random Forest,0.81,0.86,0.83,0.80, Neural Network,0.84,0.84,0.84,0.82","The presented table demonstrates the performance of five models: Logistic Regression, Naive Bayes, Support Vector Machine, Random Forest, and Neural Network, based on different evaluation metrics such as precision, recall, F1-score, and accuracy. Notably, all models were trained and tested using the same dataset. From the table, the Random Forest model exhibited the highest F1-score of 0.83. The Neural Network model demonstrated the best precision (0.84) and recall (0.84) results. Interestingly, the Naive Bayes model, which typically performs worse than other models, achieved a relatively better precision result of 0.70. Overall, the table illustrates the superior performance of Random Forest and Neural Network models based on the evaluated metrics."
2826,"caption: Table 4: Model performance comparison based on accuracy, F1 score, and recall.table: Model,Accuracy,F1 Score,Recall, Model 1,0.85,0.82,0.77, Model 2,0.81,0.80,0.72, Model 3,0.87,0.86,0.78, Model 4,0.89,0.88,0.86, Model 5,0.83,0.79,0.72",
2827,"caption: Comparison of different models based on different evaluation metrics.table: Model,Accuracy,F1 Score,Precision,Recall, SVM,0.91,0.89,0.88,0.93, DecisionTree,0.85,0.81,0.84,0.82, KNN,0.82,0.80,0.76,0.84, Logistic,0.90,0.88,0.89,0.87, Naive Bayes,0.94,0.93,0.92,0.95","The tabulated results show the performance comparison of five different models based on various evaluation metrics including accuracy, F1 score, precision, and recall. The models considered in the table include SVM, DecisionTree, KNN, Logistic, and Naive Bayes. SVM achieved the highest accuracy of 0.91 of all models, whereas Naive Bayes achieved the highest F1 score of 0.93 and recall of 0.95. SVM and Logistic regressions showed the best precision scores of 0.88 and 0.89, respectively. Overall, the results suggest that the Naive Bayes model performs well across evaluation metrics, whereas SVM and Logistic regression models perform well in some metrics. DecisionTree and KNN models appear to be the least performing models capturing less amount of variation in the dataset."
2828,"caption: Table 4: Model performance using different evaluation metrics.table: Model,Accuracy,F1 Score,Recall,Precision, SVM,0.76,0.64,0.67,0.62, KNN,0.73,0.58,0.63,0.54, Random Forest,0.82,0.70,0.68,0.73, Naive Bayes,0.69,0.53,0.55,0.52, XGBoost,0.84,0.75,0.72,0.79","Table 4 shows a comparison of five different machine learning models' performance results evaluated using four different evaluation metrics - Accuracy, F1 Score, Recall, and Precision. The evaluated models are SVM, KNN, Random Forest, Naive Bayes, and XGBoost. From the table, we can observe that XGBoost performs the best regarding accuracy (0.84) and F1 Score (0.75) while SVM, on the other hand, has the highest Recall (0.67) among all the models. The Random forest has the highest Precision (0.73) compared to other models. In summary, based on the given evaluation metrics, the XGBoost model outperforms all the other tested models."
2829,"caption: Evaluation of Different Models using Multiple Metrics.table: Model,Accuracy,F1-score,Precision,Recall,AUC, Model 1,0.79,0.82,0.85,0.79,0.88, Model 2,0.87,0.90,0.90,0.89,0.92, Model 3,0.91,0.91,0.92,0.90,0.94, Model 4,0.83,0.85,0.88,0.82,0.90, Model 5,0.86,0.88,0.89,0.87,0.91","Table shows the evaluation of five different models based on five different evaluation metrics - Accuracy, F1-score, Precision, Recall, and AUC. Model 3 shows the highest accuracy of 0.91, followed by Model 2 with 0.87. Similarly, Model 3 reports the highest F1-score of 0.91, while Model 2 and Model 5 obtained F1-scores above 0.88. Furthermore, Model 3 reports the highest Precision of 0.92, followed by Model 5 with 0.89. Model 2 and Model 5 exhibit the highest Recall with 0.89 and 0.87, respectively. Finally, Model 3 reports the highest AUC of 0.94, while all models achieve AUC scores above 0.88."
2830,"caption: Performance comparison of different models on the classification tasktable: Model,Precision,Recall,F1-Score,Accuracy, Random forest,0.93,0.88,0.91,0.92, SVM,0.92,0.89,0.91,0.91, Multi-layer Perceptron,0.91,0.86,0.89,0.90, Naive Bayes,0.88,0.85,0.87,0.88","Table presents the comparison of four different machine learning models' performance on the classification task. The evaluation was carried out using four metrics, namely precision, recall, F1-score, and accuracy. The table shows that the Random Forest model has the highest precision score of 0.93 and the Naive Bayes model has the lowest precision score of 0.88. For recall, the SVM model performed the best with a score of 0.89, while Naive Bayes had the lowest score of 0.85. Random Forest showed the highest F1 score of 0.91, while the Neural Network-based Multi-layer Perceptron had the lowest F1 score of 0.89. Finally, the Random Forest model had the highest accuracy score of 0.92, while the Naive Bayes model had the lowest accuracy score of 0.88."
2831,"caption: Table 4: Performance results of different models based on evaluation metrics.table: Model,RMSE,MAE,R-squared, Model A,3.62,2.85,0.72, Model B,2.99,2.43,0.82, Model C,4.13,3.34,0.63, Model D,3.25,2.67,0.78, Model E,3.80,2.90,0.68","Table 4 presents the performance results of five different models based on three evaluation metrics, namely Root Mean Square Error (RMSE), Mean Absolute Error (MAE), and R-squared. Model B attained the lowest RMSE of 2.99, while model C achieved the highest RMSE of 4.13. Furthermore, model B incurred the lowest MAE with a score of 2.43, while model C recorded the highest MAE with a score of 3.34. The highest R-squared score of 0.82 was achieved by model B, indicating that 82% of the variance could be explained. In summary, model B was the best-performing model among all the models, having the lowest RMSE, MAE, and the highest R-squared score."
2832,"caption: Table 4: Performance Summary of Machine Learning Modelstable: Model,Precision,Recall,F1-Score,AUPRC,AUROC, Random Forest,0.92,0.79,0.85,0.89,0.90, MLP,0.89,0.81,0.85,0.89,0.87, SVM,0.83,0.70,0.74,0.77,0.81, Logistic Reg.,0.83,0.75,0.79,0.82,0.80, Decision Tree,0.75,0.72,0.73,0.70,0.75, Naive Bayes,0.69,0.80,0.64,0.66,0.72","Table 4 presents the model performance summary of six different machine learning models, including Random Forest, MLP, SVM, Logistic Regression, Decision Tree, and Naive Bayes. The table shows the precision, recall, F1-Score, AUPRC, and AUROC scores for each model. Interestingly, the Random Forest model achieved the highest precision score of 0.92, while the MLP model scored the highest recall and F1-Score values of 0.81 and 0.85, respectively. Additionally, the Logistic Regression model had the highest AUPRC score of 0.82, while the Random Forest had the highest AUROC score of 0.90."
2833,"caption: Comparison table of different models' performances using multiple evaluation metrics.table: Models,Accuracy,Precision,Recall,F1 score,AUC-ROC, Model 1,0.89,0.91,0.94,0.92,0.82, Model 2,0.93,0.95,0.91,0.93,0.87, Model 3,0.91,0.89,0.93,0.91,0.84, Model 4,0.95,0.96,0.97,0.96,0.92, Model 5,0.88,0.90,0.91,0.90,0.81","The table presents a comparison of the performance results of five different models using five different evaluation metrics. The models' performance is based on accuracy, precision, recall, F1 score, and AUC-ROC. Notably, Model 4 performs the best in all metrics, with the highest accuracy of 0.95, precision of 0.96, recall of 0.97, F1 score of 0.96, and AUC-ROC of 0.92. Meanwhile, Model 5 underperformed other models in all metrics with an accuracy of 0.88, which is the lowest in the group. Generally, Models 2, 3, and 4 perform well in all metrics, while Models 1 and 5 underperform in comparison."
2834,"caption: Performance metrics of multiple models.table: Model Name,Accuracy,F1-Score,Recall,AUPRC,AUC, Model A,0.91,0.89,0.85,0.91,0.87, Model B,0.89,0.84,0.78,0.87,0.90, Model C,0.88,0.87,0.84,0.89,0.86, Model D,0.92,0.91,0.90,0.93,0.88","The table shows the performance metrics of four different models, including Accuracy, F1-Score, Recall, AUPRC, and AUC. Model A achieved the highest accuracy and AUC of 0.91 and 0.87, respectively, while Model D had the highest F1-Score, Recall, and AUPRC, with scores of 0.91, 0.90, and 0.93, respectively. Interestingly, Model B had a relatively low Recall compared to the other models. The results suggest that Model D might be more suitable for the task at hand, with high scores across all metrics."
2835,"caption: Table 4: Model Performance for Different Classification Models with Multiple Evaluation Metricstable: Model,Accuracy,F1-Score,Precision,Recall, SVM,0.78,0.70,0.85,0.60, K-NN,0.75,0.69,0.76,0.63, Naive Bayes,0.69,0.66,0.74,0.61, Random Forest,0.82,0.77,0.87,0.69, Gradient Boosted,0.81,0.76,0.86,0.68","Table 4 shows a performance comparison of various classification models based on the accuracy, F1-Score, Precision, and Recall evaluation metrics. The table includes SVM, K-NN, Naive Bayes, Random Forest, and Gradient Boosted models' performance scores. Notably, the Random Forest model outperforms all other models with the highest Accuracy of 0.82, F1-Score of 0.77, Precision of 0.87, and Recall of 0.69. The Gradient Boosted model achieved the second-best performance in all metrics, with an accuracy score of 0.81 and an F1-score of 0.76. Interestingly, the Naive Bayes model has the lowest accuracy score of 0.69 but has the highest Precision score of 0.74, which reveals the model's strength in predicting positive cases."
2836,"caption: Performance of Classification Models on Test Data.table: Model,Accuracy,F1 score,Precision,Recall, Logistic Regression,0.85,0.81,0.85,0.77, Decision Tree,0.82,0.77,0.83,0.73, Random Forest,0.88,0.84,0.87,0.82, XGBoost,0.87,0.83,0.88,0.78, Support Vector Machine,0.80,0.76,0.79,0.71","The table presents the model evaluation metrics, including accuracy, F1 score, precision, and recall, for five different classification models: Logistic Regression, Decision Tree, Random Forest, XGBoost, and Support Vector Machine. The table highlights that Random Forest achieved the highest accuracy (0.88), F1 score (0.84), and Precision (0.87) but had a relatively lower recall (0.82). Logistic Regression showed the best precision of all models (0.85), while Decision Tree had the lowest performance scores across the board. Interestingly, Support Vector Machine scored the second-lowest accuracy score among the models, with 0.80 but showed a respectable recall of 0.71."
2837,"caption: Table 4: Comparison of multiple models based on different evaluation metrics.table: Model,f1-score,Accuracy,Precision,Recall, Model A,0.85,0.90,0.89,**0.81**, Model B,0.92,0.87,**0.93**,0.91, Model C,**0.94**,**0.95**,0.89,0.98, Model D,0.91,0.92,0.91,0.92, Model E,0.90,0.89,0.88,0.93","Table 4 presents a comparison of multiple models used in a machine learning task. The table exhibits each model's performance regarding f1-score, accuracy, precision, and recall. The models are labeled as Model A, Model B, Model C, Model D, and, Model E. Notably, each model has different strengths and weaknesses and should be selected based on the specific task's requirements. Interestingly, Model C attained the highest both f1-score and accuracy metrics at 0.94 and 0.95, respectively. However, Model B achieved the highest precision of 0.93, while Model A performed best regarding recall with a score of 0.81."
2838,"caption: Table 4: Evaluation metrics of different models on the test datasettable: Model,F1-Score,Accuracy,Precision,Recall, SVM,0.854,0.889,0.880,0.829, KNN,0.798,0.832,0.847,0.753, Random Forest,0.876,0.912,0.904,0.849, Decision Tree,0.787,0.814,0.812,0.767, Logistic Regression,0.824,0.868,0.859,0.790","Table 4 shows the performance results of five different machine learning models on the test dataset. The evaluation metrics include F1-Score, Accuracy, Precision, and Recall. Random Forest model shows the highest F1-Score of 0.876, while the SVM model exhibits the highest Accuracy with a score of 0.889. The highest Precision score is shown by the Logistic Regression model with a score of 0.859, while the highest Recall score is shown by the Random Forest model at 0.849. Overall, the table suggests that Random Forest and SVM models are the top-performing models for this dataset, considering different evaluation metrics."
2839,"caption: Model performance comparison based on multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-score,ROC-AUC, Logistic Regression,0.876,0.867,0.872,0.868,0.913, Support Vector Classifier,0.890,0.888,0.891,0.889,0.919, Random Forest,0.904,0.909,0.907,0.908,0.935, K-Nearest Neighbors,0.850,0.834,0.849,0.838,0.888","The table presents a comparison of four models, namely Logistic Regression, Support Vector Classifier, Random Forest, and K-Nearest Neighbors, based on multiple evaluation metrics. The models were tested on the same dataset, and accuracy, precision, recall, F1-score, and ROC-AUC were used as evaluation metrics. The Random Forest model achieved the highest accuracy of 0.904, and it also had the highest ROC-AUC of 0.935. Furthermore, the Random Forest model also showed the highest precision, recall, and F1-score. Interestingly, the Support Vector Classifier model had the second-highest performance results among the models. In contrast, K-Nearest Neighbors showed the lowest performance results across all evaluation metrics."
2840,"caption: Table 4. Comparison of accuracy, precision, recall, and F1 score of different models.table: Models,Accuracy,Precision,Recall,F1 Score, Model 1,0.91,0.87,0.89,0.88, Model 2,0.92,0.89,0.90,0.89, Model 3,0.89,0.86,0.87,0.86, Model 4,0.93,0.91,0.90,0.90, Model 5,0.94,0.93,0.92,0.92","Table 4 compares the performance of five different models with various evaluation metrics, including accuracy, precision, recall, and F1 Score. Model 5 exhibits the best accuracy score of 0.94, while Model 4 has the best precision and recall scores of 0.91 and 0.90, respectively. Interestingly, Model 5 shows the best F1 score of 0.92, outperforming the rest of the models by some margin. The results highlight the importance of evaluating the models across multiple evaluation metrics to get a comprehensive understanding of their overall performance."
2841,"caption: Performance of different classification models on cancer prediction dataset.table: Model,Precision,Recall,F1 Score,ROC-AUC,PR-AUC, Logistic Regression,0.84,0.86,0.85,0.88,0.90, Decision Tree,0.80,0.89,0.84,0.86,0.83, Random Forest,0.89,0.91,0.90,0.94,0.94, Gradient Boosting,0.90,0.92,0.91,0.95,0.96, Support Vector Machine,0.86,0.89,0.87,0.92,0.93","The table above compares the performances of five different classification models on a cancer prediction dataset. The models are Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Support Vector Machine. Five evaluation metrics are considered, namely Precision, Recall, F1 Score, ROC-AUC, and PR-AUC. The Gradient Boosting model outperforms all other models in terms of PR-AUC and ROC-AUC metrics, having scores of 0.96 and 0.95, respectively. The Random Forest model also exhibits great performance, achieving scores of 0.94 in both PR-AUC and ROC-AUC metrics. The Decision Tree, Logistic Regression, and Support Vector Machine models also show satisfactory performances, but none of them received the best scores. Overall, these results can help to identify an appropriate model with sufficient performance for cancer prediction applications."
2842,"caption: Table 4: Evaluation metrics for different modelstable: Model,Accuracy,F1 Score,Recall,Precision,ROC-AUC, Model 1,0.78,0.81,0.83,0.79,0.82, Model 2,0.85,0.87,0.88,0.88,0.84, Model 3,0.71,0.74,0.73,0.77,0.72, Model 4,0.90,0.94,0.95,0.94,0.88","Table 4 compares the performance of different models using multiple evaluation metrics. The models' accuracy, F1 Score, recall, precision, and ROC-AUC are shown. Model 1 had an accuracy of 0.78, F1 score of 0.81, recall of 0.83, precision of 0.79, and ROC-AUC of 0.82. Model 2 had the highest accuracy with 0.85 and F1 score of 0.87, recall of 0.88, precision of 0.88, but the ROC-AUC was not the best with 0.84. Model 3 had the lowest accuracy with 0.71, F1 score of 0.74, recall of 0.73, precision of 0.77, and ROC-AUC of 0.72. Model 4 had the best performance in all the evaluation metrics, including accuracy (0.90), F1 score (0.94), recall (0.95), precision (0.94), and had a ROC-AUC of 0.88, which is lower than Model 2."
2843,"caption: Comparison of multiple models' performances using different evaluation metrics.table: Model,F1-Score,Precision,Recall,Accuracy, SVM-RBF,0.90,0.92,0.89,0.92, RF,0.87,0.86,0.89,0.89, GB,0.88,0.90,0.86,0.90, BERT,0.93,0.94,0.92,0.95, CNN,0.91,0.93,0.89,0.93",
2844,"caption: Table 4: Model performance evaluated using different metricstable: Model,Accuracy,F1-Score,Precision,Recall, Model A,0.95,0.93,0.93,0.93, Model B,0.93,0.91,0.92,0.89, Model C,0.94,0.93,0.93,0.92, Model D,0.92,0.89,0.90,0.88, Model E,0.96,0.95,0.96,0.94","Table 4 shows the comparison of model performances using different evaluation metrics. The table consists of five different models tested and evaluated based on accuracy, F1-Score, precision, and recall metrics. Notably, Model E provides the highest accuracy of 0.96, whereas Model D has the lowest accuracy of 0.92. Model E also provides the best F1-Score of 0.95, while Model D has the lowest F1-score of 0.89. Interestingly, Model A provides the highest precision and recall scores of 0.93, while Model B achieves the lowest precision and recall scores of 0.92 and 0.89, respectively. The table provides a detailed insight into models, allowing researchers to decide which model performs better based on specific criteria."
2845,"caption: Table 4: Model performance comparison based on different evaluation metrics.table: Model,F1-score,Accuracy,Recall,Precision, SVM,0.82,0.81,0.80,0.84, KNN,0.76,0.74,0.68,0.84, Logistic Regression,0.87,0.85,0.84,0.89, Random Forest,0.93,0.93,0.92,0.94, XGBoost,0.91,0.91,0.90,0.92","Table 4 presents the model performance comparison based on different evaluation metrics, including F1-score, Accuracy, Recall, and Precision. The table exhibits the results obtained from five different models, SVM, KNN, Logistic Regression, Random Forest, and XGBoost. Notably, Random Forest achieved the highest F1-score of 0.93, closely followed by XGBoost with a score of 0.91. Additionally, both models obtained the highest precision of 0.94 and 0.92, respectively. On the other hand, KNN model had the lowest scores across all the evaluation metrics, indicating inferior performance for the given dataset."
2846,"caption: Table 4: Comparison of Different Models Based on Different Evaluation Metrics.table: Model,F1 Score,Accuracy,Recall,Precision, SVM,0.92,0.89,0.88,0.92, Random Forest,0.91,0.88,0.84,0.94, Adaptive Boosting,0.89,0.86,0.79,0.99, KNN,0.87,0.83,0.80,0.93","Table 4 presents a comparison of different models' performances based on F1 score, accuracy, recall, and precision. The table exhibits SVM, Random Forest, Adaptive Boosting, and KNN models' performance results. Notably, all models were trained and tested using the same dataset. The SVM model outperformed all other models in terms of F1 score, achieving a score of 0.92. Meanwhile, Random Forest was slightly behind, with an F1 score of 0.91. However, when it comes to precision, Random Forest was the best-performing model (0.94). Adaptive Boosting achieved the highest accuracy (0.86) while SVM had powerful recall (0.88). KNN has the lowest results regarding F1 Score, Accuracy, Recall, and Precision."
2847,"caption: Model performances based on different evaluation metrics.table: Model,Accuracy,Recall,Precision,F1-score,AUC, KNN,0.85,0.82,0.88,0.85,0.92, SVM,0.87,0.84,0.91,0.87,0.94, Naive Bayes,0.80,0.78,0.82,0.80,0.86, Random Forest,0.91,0.89,0.93,0.91,0.97, Gradient Boosting,0.90,0.88,0.92,0.90,0.95","Table 4 presents the model performances of K-Nearest Neighbors (KNN), Support Vector Machine (SVM), Naive Bayes, Random Forest, and Gradient Boosting regarding multiple evaluation metrics, including Accuracy, Recall, Precision, F1-score, and AUC. The models were trained and tested on the same dataset. Random Forest achieved the highest accuracy of 0.91, and Gradient Boosting almost equalled it with a score of 0.90. SVM and Random Forest achieved high scores in Recall, Precision, and F1-score. Interestingly, Naive Bayes yielded the lowest score in all evaluation metrics, including AUC with a score of 0.86. The AUC score suggests that SVM, Random Forest, and Gradient Boosting generated highly specific and sensitive classification models."
2848,"caption: A Comparison of Different Model Performances using Multiple Evaluation Metrics.table: Models,Accuracy Score,Precision Score,Recall Score,F1-Score,ROC AUC, Model 1,0.82,0.75,0.84,0.78,0.89, Model 2,0.78,0.68,0.65,0.66,0.75, Model 3,0.85,0.82,0.77,0.79,0.89, Model 4,0.88,0.84,0.82,0.82,0.91","Table displays the comparison of four different models' performance scores using multiple evaluation metrics: Accuracy, Precision, Recall, F1-Score, and ROC AUC. Notably, Model 4 shows the highest accuracy score of 0.88, while Model 3 has the highest precision score at 0.82. Furthermore, Model 1 and Model 3 show excellent recall and F1-Score, with scores of 0.84 and 0.79, respectively. The ROC AUC scores show that Model 4 has the best performance with a score of 0.91, indicating its excellent ability in distinguishing between positive and negative cases."
2849,"caption: Performance comparison of different models using different evaluation metrics.table: Model Name,Accuracy,F1 Score,Precision,Recall, Model 1,0.89,0.90,0.92,0.88, Model 2,0.87,0.86,0.82,0.91, Model 3,0.86,0.87,0.89,0.84, Model 4,0.91,0.92,0.94,0.90, Model 5,0.88,0.89,0.93,0.85","The table illustrates a performance comparison of five different models using multiple evaluation metrics, namely accuracy, F1 score, precision, and recall. Model 4 had the highest accuracy and F1 score of 0.91 and 0.92, respectively, indicating its potential to correctly predict the target variable. Model 5 had the highest precision score of 0.93, and Model 2 achieved the highest recall score of 0.91. This table's results provide useful insights into the strengths and limitations of the different models, allowing for informed decisions when choosing the most appropriate model for a given task."
2850,"caption: Table 4: Model comparison in terms of accuracy, precision, recall, and F1-score.table: Model,Accuracy,Precision,Recall,F1-score, Logistic Regression,0.85 (+/-0.01),0.86 (+/- 0.02),0.84 (+/- 0.03),0.84 (+/- 0.01), Decision Tree,0.90 (+/- 0.01),0.91 (+/- 0.02),0.88 (+/-0.03),0.89 (+/-0.02), Random Forest,0.95 (+/-0.01),0.94 (+/-0.02),0.97 (+/- 0.02),0.95 (+/-0.01), Support Vector Machines,0.88 (+/- 0.02),0.90 (+/- 0.03),0.85 (+/- 0.04),0.87 (+/-0.01), XGBoost,0.94 (+/-0.01),0.93 (+/-0.02),0.95 (+/- 0.03),0.94 (+/-0.01)","Table 4 presents a comparison of different models' performances based on accuracy, precision, recall, and F1-score. The Logistic Regression model shows an accuracy of 0.85 (+/- 0.01). Meanwhile, the Decision Tree model outperforms the Logistic Regression with an accuracy of 0.90 (+/-0.01). The Random Forest model demonstrates the highest accuracy of 0.95 (+/-0.01). Among the models, the Support Vector Machines model has the lowest recall score of 0.85 (+/- 0.04), while the XGBoost model has the highest recall score of 0.95 (+/- 0.03) with relatively high precision, accuracy, and F1-score. Therefore, XGBoost is the best performing model for this dataset based on overall evaluation metrics."
2851,"caption: Model performances on various evaluation metrics.table: Model,Metric 1,Metric 2,Metric 3, Model A,0.75,0.81,0.68, Model B,0.83,0.72,0.91, Model C,0.92,0.62,0.84, Model D,0.66,0.92,0.74, Model E,0.88,0.76,0.79","Table captioned 'Model performances on various evaluation metrics' presents the evaluation performances of five different models. The table shows the models' performance on three evaluation metrics: Metric 1, Metric 2, and Metric 3. Model B is the top-performing model with the best performance in Metric 1, scoring 0.83. Model C outperforms the other models on Metric 2 with a scoring rate of 0.92. When it comes to Metric 3, Model B again performs remarkably, with a score of 0.91. Notably, Model D obtained the lowest scores on all three evaluation metrics, indicating inadequate performance. Overall, the table illustrates that different models may perform better on different evaluation metrics."
2852,"caption: Performance comparison of different models using multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, Logistic Regression,0.90,0.85,0.78,0.81, Naive Bayes,0.78,0.81,0.61,0.69, Decision Tree,0.82,0.62,0.81,0.65, Random Forest,0.91,0.89,0.85,0.86, XGBoost,0.93,0.91,0.87,0.89","Table presents a performance comparison of different models using four evaluation metrics: Accuracy, Precision, Recall, and F1-Score. The table reveals that the XGBoost model performed the best, achieving an accuracy score of 0.93, followed closely by the Random Forest model at 0.91. Notably, the Logistic Regression model and the Naive Bayes model showed lower accuracy scores of 0.90 and 0.78, respectively. The Random Forest model achieved the highest precision and recall score of 0.89 and 0.85, respectively. Interestingly, the Naive Bayes achieved the highest precision score, while the Decision Tree had the highest recall score. Ultimately, the XGBoost model proves to be the most efficient model across all evaluation metrics observed."
2853,"caption: Model performance based on different evaluation metrics across multiple models.table: Model,Accuracy,Precision,Recall,F1-Score, Model A,0.92,0.93,0.95,0.94, Model B,0.85,0.88,0.92,0.89, Model C,0.91,0.87,0.98,0.92, Model D,0.89,0.90,0.87,0.88, Model E,0.88,0.85,0.90,0.87","Table 1 showcases the model performances based on accuracy, precision, recall, and F1-score metrics, and demonstrates the evaluation of multiple different models. Upon inspection of the table, Model A has the highest model accuracy of 0.92, whereas Model C has the highest precision of 0.87, recall of 0.98, and F1-score of 0.92. The table also entails that Model E obtained the lowest accuracy of 0.88 and precision of 0.85 while having the lowest recall of 0.90 and F1-score of 0.87. The results reveal the contrasting model performances based on different evaluation metrics and highlight the need for careful selection of model evaluation metrics."
2854,"caption: Evaluation table of multiple models based on different metrics.table: Model,Accuracy,F1 score,Precision,Recall, SVM,0.89,0.86,0.87,0.88, KNN,0.82,0.78,0.77,0.82, Decision Tree,0.75,0.70,0.68,0.75, Random Forest,0.94,0.92,0.93,0.93, XGBoost,0.91,0.88,0.88,0.89","The table shows the performance of five classification models, including SVM, KNN, Decision Tree, Random Forest, and XGBoost. The evaluation metrics include Accuracy, F1 score, Precision, and Recall. The Random Forest model showcases the best performance on all metrics with an accuracy of 0.94, F1 score of 0.92, precision of 0.93, and recall of 0.93. The SVM model delivers the best accuracy, precision, and recall, with values of 0.89, 0.87, and 0.88, respectively. The KNN and Decision Tree models fall behind in comparison, with accuracies of 0.82 and 0.75, respectively. Overall, the results indicate that Random Forest and XGBoost perform better than the other models."
2855,"caption: Model performances based on accuracy, F1-score, precision, and recall.table: Model name,Accuracy,F1-score,Precision,Recall, Model A,0.92,0.89,0.91,0.87, Model B,0.90,0.85,0.86,0.84, Model C,0.88,0.87,0.83,0.91, Model D,0.95,0.93,0.94,0.92","The table presents the evaluation results of four models (Model A, Model B, Model C, and Model D) using four different metrics (accuracy, F1-score, precision, and recall). Model D achieved the highest accuracy of 0.95, which was 3% higher than Model B, the second-best model. In terms of F1-score, Model A outperformed the other models with a score of 0.89. However, Model D achieved a higher F1-score of 0.93 while also having the highest precision and recall scores of 0.94 and 0.92, respectively. Model C had the lowest accuracy of 0.88, although it still displayed a competitive F1-score of 0.87 due to its high recall of 0.91."
2856,"caption: Table 4: Multiple Model Performances Based on Different Evaluation Metricstable: Model,Accuracy,Precision,F1 Score, SVM,0.85,0.88,0.87, LR,0.81,0.80,0.80, KNN,0.79,0.81,0.79, RF,0.89,0.91,0.89, DT,0.81,0.79,0.80","Table 4 presents multiple machine learning models' performances based on different evaluation metrics. The table reports the accuracy, precision, and F1 score of the SVM, LR, KNN, RF, and DT models. The RF model exhibits the highest accuracy of 0.89, while also achieving the highest precision of 0.91, and an F1 score of 0.89. The SVM model is the second-best model with an accuracy of 0.85 and precision of 0.88, although its F1 score was slightly lower than the RF model. The LR and DT models exhibit similar performances, achieving accuracies of 0.81 and F1 scores of 0.80. However, the LR model achieved a slightly higher precision than the DT model, with values of 0.80 and 0.79, respectively. The KNN model ranks last in all three metrics with an accuracy of 0.79, precision of 0.81, and F1 score of 0.79."
2857,"caption: Comparison of different Machine Learning models based on various evaluation measures.table: Model,Acc,Prec,Rec,F1, SVM,0.885,0.92,0.84,0.88, Logistic,0.888,0.93,0.83,0.88, kNN,0.874,0.91,0.80,0.85, Naive Bayes,0.862,0.88,0.81,0.84, Decision Tree,0.863,0.88,0.82,0.85, Random Forest,0.899,0.94,0.84,0.88, XGBoost,0.893,0.929,0.859,0.894","Table presents the performance of seven different machine learning models based on four different measures: accuracy (Acc), precision (Prec), recall (Rec), and F1 score (F1). The models' performance was tested on the same dataset. The Random Forest model shows the highest Accuracy score of 0.899, while the Logistic Regression model has the highest Precision score of 0.93. In contrast, the Naive Bayes model shows a lower Precision score than other models with a value of 0.88. The Random Forest model has the highest F1 score of 0.88. We observe that the Random Forest, Logistic, and XGBoost models generally perform better than the rest of the models based on their overall performance scores."
2858,"caption: Comparison of different models using multiple evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Logistic Regression,0.78,0.76,0.69,0.72, SVM (rbf kernel),0.81,0.79,0.74,0.76, Random Forest,0.83,0.81,0.79,0.80, XGBoost,0.84,0.83,0.80,0.81","The table presents a comparison of multiple models used to solve a binary classification problem. The models' performance was evaluated using different metrics such as accuracy, precision, recall, and F1 score. The table shows that the XGBoost model achieved the best performance with an accuracy score of 0.84 and the highest precision, recall, and F1 score of 0.83, 0.80, and 0.81, respectively. The Random Forest model follows closely, achieving an accuracy score of 0.83 and a precision, recall, and F1 score of 0.81, 0.79, and 0.80, respectively. Interestingly, the Logistic Regression model achieved a precision score of 0.76, the lowest among the compared models. Overall, the results suggest that ensemble learning models, such as XGBoost and Random Forest, are suitable for solving binary classification problems, given their excellent performance in different evaluation metrics."
2859,"caption: Performance comparison of different machine learning models based on multiple evaluation metrics.table: Model,Accuracy,F1-Score,Precision,Recall, Logistic Regression,0.87,0.89,0.91,0.86, Support Vector Machine,0.84,0.82,0.87,0.79, Decision Tree,0.78,0.70,0.65,0.76, Random Forest,0.90,0.92,0.93,0.91, XGBoost,0.91,0.93,0.94,0.92","Table shows a comparison of various machine learning models based on multiple evaluation metrics, including Accuracy, F1-Score, Precision, and Recall. The models compared in the table are Logistic Regression, Support Vector Machine, Decision Tree, Random Forest, and XGBoost. Notably, Random Forest and XGBoost outperform other models in terms of Accuracy, F1-Score, Precision, and Recall. Specifically, the XGBoost model achieved the highest Accuracy, F1-Score, Precision, and Recall with 0.91, 0.93, 0.94, and 0.92, respectively. The table's results provide insights into selecting the best-performing models for the problem at hand."
2860,"caption: Evaluation metrics for five different models.table: Model Name,Precision,Recall,F1-Score,Accuracy, Model A,0.92,0.88,0.90,0.91, Model B,0.84,0.92,0.88,0.85, Model C,0.88,0.82,0.85,0.87, Model D,0.78,0.84,0.80,0.77, Model E,0.96,0.97,0.96,0.95",
2861,"caption: Performance of Different Models Based on Various Evaluation Metricstable: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.90,0.87,0.85,0.86, Logistic Regression,0.89,0.87,0.81,0.83, Random Forest,0.87,0.76,0.85,0.80, XGBoost,0.91,0.91,0.87,0.89","The table presents the performance evaluation of different models including SVM, Logistic Regression, Random Forest and XGBoost. The models are evaluated based on various evaluation metrics, including accuracy, precision, recall, and F1-score. The XGBoost model achieved the highest accuracy score of 0.91, followed by SVM with an accuracy of 0.90. XGBoost also exhibited the highest precision score of 0.91 and recall score of 0.87. On the other hand, Logistic Regression and Random Forest demonstrated lower performance results than SVM and XGBoost. Nonetheless, Random Forest and Logistic Regression achieved better recall scores of 0.85 and 0.81, respectively, compared to SVM and XGBoost. Finally, XGBoost had the highest F1-Score of 0.89, followed by SVM, Logistic Regression, and Random Forest with F1-Scores of 0.86, 0.83, and 0.80, respectively."
2862,"caption: Model performance comparison using different evaluation metrics.table: Model,Accuracy,Precision,Recall,F1 Score, Random Forest,0.92,0.92,0.89,0.904, Decision Tree,0.87,0.86,0.81,0.831, Support Vector,0.91,0.91,0.87,0.886, Logistic Regression,0.90,0.90,0.86,0.868, Naive Bayes,0.83,0.83,0.78,0.789, Neural Network,0.94,0.94,0.91,0.922","Table presents the evaluation of different models—Random Forest, Decision Tree, Support Vector, Logistic Regression, Naive Bayes, and Neural Network—using multiple evaluation metrics, including Accuracy, Precision, Recall, and F1 Score. The Neural Network model shows the best overall performance, with an accuracy score of 0.94 and F1 score of 0.922, while the Naive Bayes model shows the worst overall performance, with an accuracy score of 0.83 and F1 score of 0.789. Interestingly, the performance scores varied among the models, with some models performing better in some metrics and worse in others. For instance, the Neural Network model has the best Precision and Recall scores of 0.94 and 0.91, while the Random Forest model has the best F1 score of 0.904."
2863,"caption: Table 4: Performance comparison of different classification models using multiple metrics.table: Model,F1-score,PR-AUC,ROC-AUC, Logistic Regression,0.842,0.920,0.784, Random Forest,0.831,0.885,0.809, Gradient Boosting,0.847,0.898,0.826, Support Vector Machine,0.825,0.892,0.754, Multilayer Perceptron,0.821,0.873,0.766","Table 4 shows the performance comparison of different classification models using multiple metrics, including F1-score, PR-AUC, and ROC-AUC. The models included in the table are Logistic Regression, Random Forest, Gradient Boosting, Support Vector Machine, and Multilayer Perceptron. Among them, Gradient Boosting achieved the highest F1-score of 0.847, while Logistic Regression achieved the highest PR-AUC of 0.920, and Random Forest achieved the highest ROC-AUC of 0.809. These different metrics provide a comprehensive evaluation of model performance, highlighting the strengths and weaknesses of each model."
2864,"caption: Table 4: Model Evaluation Metrics for Classification Tasktable: Model,Accuracy,F1-Score,Recall,Precision, SVM,0.85,0.82,0.79,0.87, KNN,0.78,0.75,0.68,0.83, RF,0.89,0.87,0.86,0.89, GBDT,0.92,0.90,0.89,0.91","Table 4 compares the performance of four different models in terms of multiple evaluation metrics for a classification task. The models evaluated in the table are Support Vector Machines (SVM), K-Nearest Neighbors (KNN), Random Forest (RF), and Gradient Boosting Decision Trees (GBDT). The evaluation metrics included in the table are Accuracy, F1-Score, Recall, and Precision. The GBDT model outperforms other models in all metrics with the highest Accuracy, F1-score, Recall, and Precision. The SVM model shows the second-best performance in F1-score and Precision, while RF model has the second-best performance in Accuracy and Recall metrics. The KNN model performs the worst among the evaluated models."
2865,"caption: Table 4: Model performance metrics for different machine learning models on a binary classification tasktable: Model name,Precision,Recall,F1 score,Accuracy, Logistic Regression,0.93,0.92,0.91,0.76, Naive Bayes,0.86,0.91,0.88,0.72, Random Forest,0.92,0.93,0.92,0.81, XGBoost,0.91,0.95,0.93,0.79, SVM,0.95,0.91,0.93,0.79","Table 4 shows the model performance metrics for different machine learning models on a binary classification task. The table includes the Precision, Recall, F1 score, and Accuracy for the Logistic Regression, Naive Bayes, Random Forest, XGBoost, and SVM models. Notably, each model's accuracy score ranges between 0.72 and 0.81, indicating that all models provide relatively good predictions. The SVM model outperformed the other models with the highest Precision score of 0.95, while the Naive Bayes model favored Recall score with a score of 0.91. Overall, the table provides an overview of the different model metrics, a comparison of their respective metrics, and a guide on which metric would suit specific use cases."
2866,"caption: Evaluation metrics for different modelstable: Model,Accuracy,F1-score,Precision,Recall, LR,0.75,0.72,0.68,0.77, SVM,0.71,0.69,0.65,0.73, RF,0.81,0.76,0.74,0.79, XGB,0.82,0.78,0.77,0.80, KNN,0.69,0.64,0.68,0.60","The table displays the performance results of different models using multiple evaluation metrics. The accuracy, F1-score, precision, and recall metrics were used to evaluate the LR, SVM, RF, XGB, and KNN models. The RF and XGB models' performances were found to be better than the LR and SVM models with an accuracy of 0.81 and 0.82, respectively, compared to 0.75 and 0.71 for LR and SVM. Similarly, the F1-score of RF and XGB was improved with 0.76 and 0.78, respectively, compared to 0.72 and 0.69 for LR and SVM. Precision and recall followed a similar trend, where RF and XGB had higher scores than the other models. Notably, KNN showed the weakest performance among all models in this evaluation."
2867,"caption: Table 4: Performance comparison of different models using various evaluation metrics.table: Model,Accuracy,Precision,Recall,F1-Score, SVM,0.86,0.89,0.85,0.87, Decision Tree,0.79,0.76,0.83,0.77, Random Forest,0.91,0.92,0.90,0.91, Naive Bayes,0.73,0.65,0.88,0.75, Logistic,0.84,0.82,0.85,0.83","Table 4 provides a performance comparison of five different models, namely SVM, Decision Tree, Random Forest, Naive Bayes, and Logistic. The evaluation criteria utilized includes accuracy, precision, recall, and F1-score. Random Forest demonstrates the best overall performance with an accuracy of 0.91, precision of 0.92, recall of 0.90, and F1-score of 0.91, while Naive Bayes has the lowest overall performance. The results suggest that Random Forest could be a suitable choice for this particular application."
2868,"caption: Comparison of Different Models based on Varying Evaluation Metricstable: Model,Accuracy,F1 Score,Precision,Recall, Logistic Regression,0.89,0.89,0.89,0.89, Decision Tree,0.82,0.81,0.83,0.80, Naive Bayes,0.91,0.90,0.91,0.89, Random Forest,0.95,0.95,0.96,0.93, XGBoost,0.94,0.94,0.95,0.93","The table shows a comparison of different machine learning models based on varying evaluation metrics. The table includes the accuracy, F1 score, precision, and recall metrics for each model. Notably, the Random Forest model exhibits the highest accuracy, F1 score, and precision values, while the Naive Bayes model achieved the highest recall score. In terms of accuracy, Random Forest achieved 95%, followed closely by the XGBoost model with 94% accuracy. Among the models, Decision Tree exhibited the lowest accuracy of 82%, although its F1 score, precision, and recall metrics are comparable with other models. Overall, the results suggest that the Random Forest model is the best-performing model based on the evaluation metrics considered."
2869,"caption: Comparison of different classification models based on accuracy, precision, recall, and F1-Score.table: Model,Accuracy,Precision,Recall,F1-Score, SVM (rbf kernel),0.785,0.782,0.798,0.780, Random Forest,0.805,0.814,0.786,0.798, Neural Network (sigmoid),0.795,0.812,0.763,0.787, Logistic Regression,0.773,0.780,0.732,0.754","Table summarises the accuracy, precision, recall, and F1-Score of four different classification models - SVM (rbf kernel), Random Forest, Neural Network (sigmoid), and Logistic Regression. The table exhibits that Random Forest has the highest accuracy of 0.805, while Neural Network (sigmoid) has the highest precision of 0.812. Furthermore, the SVM (rbf kernel) has the highest recall of 0.798 and F1-score of 0.780. Logistic regression has the lowest performance concerning each metric. The table highlights the need to examine multiple evaluation metrics as there is no universally best model."
2870,"caption: Model Performance Comparison using Multiple Evaluation Metricstable: Model Name,Precision,Recall,F1 Score,Accuracy, Model 1,0.85,0.75,0.80,0.92, Model 2,0.78,0.82,0.80,0.89, Model 3,0.82,0.77,0.79,0.91, Model 4,0.91,0.69,0.78,0.95, Model 5,0.79,0.85,0.82,0.90","Table displays the performance of five different models comparing their precision, recall, f1 score, and accuracy. Each model had distinct evaluation results, indicating strengths and weaknesses in their prediction capabilities. Notably, Model 4 had the highest precision score of 0.91, while Model 5 had the highest recall score of 0.85. In contrast, Model 4 had the highest accuracy of 0.95, while Model 2 had the lowest accuracy score of 0.89. Overall, these results illustrate the crucial need for evaluating models using various metrics as each metric conveys a different aspect of model performance."
2871,"caption: Table 4: Metrics comparison of different models.table: Model,F1 Score,Precision,Recall,Accuracy, Model A,0.85,0.82,0.89,0.87, Model B,0.83,0.85,0.80,0.88, Model C,0.87,0.86,0.89,0.85, Model D,0.81,0.77,0.86,0.83, Model E,0.89,0.92,0.87,0.91","Table 4 presents a comparison of five different models' performance on multiple evaluation metrics. The models have been evaluated on F1 Score, Precision, Recall, and Accuracy. Notably, Model E has the highest F1 Score of 0.89. On the other hand, Model A and Model C performed well on Precision and Recall, respectively, both achieving a score of 0.86. Interestingly, Model E had the highest accuracy score, with a value of 0.91. Overall, this table suggests Model E as the best-performing model, considering its superior performance across different evaluation metrics."
2872,"caption: Table 4: Performance of different classifiers on binary classification.table: Model,Accuracy,F1-Score,Precision,Recall,AUC, Logistic Reg.,0.75,0.72,0.73,0.73,0.846, SVM (Linear),0.71,0.67,0.68,0.67,0.819, Random Forest,0.78,0.77,0.78,0.77,0.892, XGBoost,0.79,0.78,0.79,0.78,0.893, Neural Network,0.81,0.80,0.81,0.80,0.903","Table 4 presents the performance evaluation of different classifiers on binary classification based on several evaluation metrics, including Accuracy, F1-Score, Precision, Recall, and AUC. The classifiers selected for the comparison are Logistic Regression, SVM (Linear), Random Forest, XGBoost, and Neural Network. The table indicates that Neural Network model attained the highest values of the evaluation metrics with the highest AUC score of 0.903. Random Forest and XGBoost also performed well and were better than both Logistic Regression and SVM models. Overall, the study suggests that a Neural Network could be a potential classifier for binary classification tasks."
2873,"caption: Performance metrics of different models in a classification task.table: Model,Accuracy,F1 score,Precision,Recall, Model 1,0.85,0.89,0.90,0.88, Model 2,0.84,0.87,0.88,0.86, Model 3,0.81,0.85,0.87,0.83, Model 4,0.86,0.90,0.89,0.91, Model 5,0.83,0.86,0.87,0.85","Table presents the comparison of different models' performance using four evaluation metrics: accuracy, F1 score, precision and recall. Among the five models, Model 4 has achieved the highest accuracy score (0.86) while Model 1 has the highest F1 score (0.89). Model 3, on the other hand, has low accuracy, F1, and recall scores compared to other models. Interestingly, most of the models have similar precision scores, with a range of 0.87 to 0.90. Overall, each model's performance was unique and can be analyzed based on their evaluation metrics to make informed decisions about their effectiveness for the classification task."
2874,"caption: Model performance on different evaluation metricstable: Model,Accuracy,F1-score,Precision,Recall, Model-A,0.9,0.86,0.83,0.88, Model-B,0.89,0.87,0.84,0.87, Model-C,0.92,0.91,0.92,0.90, Model-D,0.86,0.84,0.82,0.86","The presented table shows model performance measured by different evaluation metrics: Accuracy, F1-score, Precision, and Recall. Model-A achieved the highest Accuracy of 0.9, while Model-C achieved the highest F1-score of 0.91 and Precision of 0.92. However, Model-D had the lowest results in all metrics, with 0.86 Accuracy, 0.84 F1-score, 0.82 Precision, and 0.86 Recall. Interestingly, even though Model-B had lower performance than Model-A, it achieved higher Precision and Recall scores. The table presents insights into comparative analysis between multiple models, highlighting the significant variations in performance based on the evaluation metric."
2875,"caption: Performance comparison table of different models using multiple evaluation metrics.table: Model,Precision Score,Recall Score,F1-Score,Accuracy Score, Model A,0.80,0.70,0.75,0.85, Model B,0.70,0.80,0.70,0.80, Model C,0.90,0.65,0.76,0.88, Model D,0.75,0.87,0.79,0.82, Model E,0.89,0.79,0.83,0.90","Table 1 presents the performance comparison of different models based on different evaluation metrics, including Precision score, Recall score, F1 score, and Accuracy score. The table consists of five models: Model A, Model B, Model C, Model D, and Model E. Interestingly, all models performed well in at least one of the evaluation metrics. Model C demonstrated the highest precision score of 0.90, Model D had the highest recall score of 0.87, while Model E achieved the highest accuracy score of 0.90. In summary, Model E appears to be the best-performing model in this comparison, having high scores across all metrics."
